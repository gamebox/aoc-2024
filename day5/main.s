	.section	__TEXT,__text,regular,pure_instructions
	.build_version macos, 11, 7, 1
	.p2align	2                               ; -- Begin function panic.panic_help
l_panic.panic_help:                     ; @panic.panic_help
Lfunc_begin0:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	mov	x2, x1
	mov	x1, x0
	add	x0, sp, #8
	bl	l_str.RocStr.init
	add	x0, sp, #8
	mov	w1, wzr
	bl	_roc_panic
Lfunc_end0:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function str.RocStr.init
l_str.RocStr.init:                      ; @str.RocStr.init
Lfunc_begin1:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	mov	x20, x2
	mov	x21, x1
	mov	x19, x0
	cmp	x2, #23
	b.ls	LBB1_2
; %bb.1:                                ; %str.RocStr.allocate.exit
	cmp	x20, #64
	mov	w8, #64
	csel	x22, x20, x8, hi
	mov	w1, #8
	add	x0, x22, #8
	bl	_roc_alloc
	mov	x8, #-9223372036854775808
	cmp	x22, #0
	add	x9, sp, #8
	str	x8, [x0], #8
	csel	x8, x9, x0, lt
	mov	x9, x20
	b	LBB1_3
LBB1_2:                                 ; %str.RocStr.allocate.exit.thread
	lsl	x8, x20, #56
	mov	x0, xzr
	mov	x9, xzr
	orr	x22, x8, #0x8000000000000000
	add	x8, sp, #8
LBB1_3:                                 ; %str.RocStr.asU8ptrMut.exit
	stp	x0, x9, [sp, #8]
	mov	x0, x8
	mov	x1, x21
	mov	x2, x20
	str	x22, [sp, #24]
	bl	_memcpy
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #80
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	ret
Lfunc_end1:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.fluxsort
l_sort.fluxsort:                        ; @sort.fluxsort
Lfunc_begin2:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 4192
	sub	sp, sp, #880
	.cfi_def_cfa_offset 5072
	.cfi_remember_state
	mov	x28, x6
	mov	x26, x5
	mov	w19, w4
	mov	x24, x3
	mov	x27, x1
	ldr	x8, [sp, #5072]
	cmp	x1, #132
	str	x2, [sp, #328]                  ; 8-byte Folded Spill
	stp	x0, x5, [sp, #240]              ; 16-byte Folded Spill
	str	x8, [sp, #264]                  ; 8-byte Folded Spill
	str	x3, [sp, #360]                  ; 8-byte Folded Spill
	b.hs	LBB2_4
; %bb.1:
	cmp	x28, #96
	b.hi	LBB2_9
; %bb.2:
	mov	x1, x27
	tbz	w19, #0, LBB2_16
; %bb.3:
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	mov	w5, w7
	b	LBB2_46
LBB2_4:
	cmp	x28, #96
	mov	x8, x28
	str	x28, [sp, #352]                 ; 8-byte Folded Spill
	str	x27, [sp, #168]                 ; 8-byte Folded Spill
	str	w7, [sp, #164]                  ; 4-byte Folded Spill
	b.hi	LBB2_13
; %bb.5:
	mul	x0, x28, x27
	mov	w1, w7
	str	x0, [sp, #120]                  ; 8-byte Folded Spill
	bl	_roc_alloc
	str	x0, [sp, #152]                  ; 8-byte Folded Spill
	tbz	w19, #0, LBB2_17
; %bb.6:
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	cbz	x0, LBB2_45
; %bb.7:
	lsr	x8, x27, #1
	lsr	x21, x27, #2
	sub	x19, x27, x8
	mov	x13, x28
	lsr	x10, x19, #1
	mul	x11, x21, x28
	add	x12, x10, x8
	add	x20, x9, x11
	str	x10, [sp, #128]                 ; 8-byte Folded Spill
	mul	x10, x8, x28
	stp	x12, x11, [sp, #48]             ; 16-byte Folded Spill
	mul	x12, x12, x28
	add	x23, x9, x10
	stp	x10, x8, [sp, #72]              ; 16-byte Folded Spill
	sub	x8, x8, x21
	cmp	x21, x8
	str	x12, [sp, #88]                  ; 8-byte Folded Spill
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	b.hs	LBB2_51
; %bb.8:
	mov	x0, x24
	mov	w1, #1
	mov	x22, x20
	add	x20, x20, x28
	blr	x26
	mov	x0, x24
	mov	x1, x22
	mov	x2, x20
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	cmp	w8, #1
	cset	w8, eq
	str	x8, [sp, #224]                  ; 8-byte Folded Spill
	b	LBB2_52
LBB2_9:
	lsl	x0, x27, #3
	mov	w1, #8
	mov	w24, w7
	bl	_roc_alloc
	cbz	x0, LBB2_1256
; %bb.10:                               ; %.preheader13.i
	mov	x22, x0
	cbz	x27, LBB2_37
; %bb.11:                               ; %.preheader13.i
	cmp	x27, #1
	b.ne	LBB2_32
; %bb.12:
	mov	x8, xzr
	b	LBB2_35
LBB2_13:
	lsl	x0, x27, #3
	mov	w1, #8
	str	x0, [sp, #192]                  ; 8-byte Folded Spill
	bl	_roc_alloc
	str	x0, [sp, #208]                  ; 8-byte Folded Spill
	cbz	x0, LBB2_1256
; %bb.14:                               ; %.lr.ph.preheader
	cmp	x27, #2
	b.hs	LBB2_20
; %bb.15:
	mov	x8, xzr
	b	LBB2_23
LBB2_16:
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	mov	w5, w7
	b	LBB2_48
LBB2_17:
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	cbz	x0, LBB2_47
; %bb.18:
	lsr	x8, x27, #1
	lsr	x26, x27, #2
	sub	x10, x27, x8
	mov	x13, x28
	mul	x11, x26, x28
	str	x10, [sp, #128]                 ; 8-byte Folded Spill
	lsr	x10, x10, #1
	add	x12, x10, x8
	add	x1, x9, x11
	str	x10, [sp, #144]                 ; 8-byte Folded Spill
	mul	x10, x8, x28
	mul	x19, x12, x28
	stp	x12, x11, [sp, #64]             ; 16-byte Folded Spill
	stp	x10, x8, [sp, #80]              ; 16-byte Folded Spill
	sub	x8, x8, x26
	add	x10, x9, x10
	cmp	x26, x8
	stp	x10, x8, [sp, #96]              ; 16-byte Folded Spill
	b.hs	LBB2_54
; %bb.19:
	add	x20, x1, x28
	mov	x0, x24
	mov	x2, x20
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x1, x20
	cset	w23, eq
	b	LBB2_55
LBB2_20:                                ; %vector.ph
	ldr	x9, [sp, #208]                  ; 8-byte Folded Reload
	and	x8, x27, #0xfffffffffffffffe
	lsl	x10, x28, #1
	neg	x11, x8
	ldr	x12, [sp, #240]                 ; 8-byte Folded Reload
	add	x9, x9, #8
LBB2_21:                                ; %vector.body
                                        ; =>This Inner Loop Header: Depth=1
	add	x13, x12, x28
	adds	x11, x11, #2
	stp	x12, x13, [x9, #-8]
	add	x9, x9, #16
	add	x12, x12, x10
	b.ne	LBB2_21
; %bb.22:                               ; %middle.block
	cmp	x8, x27
	b.eq	LBB2_25
LBB2_23:                                ; %.lr.ph.preheader2703
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	madd	x9, x8, x28, x9
	add	x10, x10, x8, lsl #3
	sub	x8, x8, x27
LBB2_24:                                ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	str	x9, [x10], #8
	add	x9, x9, x28
	adds	x8, x8, #1
	b.lo	LBB2_24
LBB2_25:                                ; %._crit_edge
	ldr	x0, [sp, #192]                  ; 8-byte Folded Reload
	mov	w1, #8
	bl	_roc_alloc
	str	x0, [sp, #200]                  ; 8-byte Folded Spill
	tbz	w19, #0, LBB2_29
; %bb.26:
	cbz	x0, LBB2_49
; %bb.27:
	lsr	x9, x27, #1
	lsr	x11, x27, #2
	sub	x8, x27, x9
	lsl	x13, x9, #3
	lsr	x12, x8, #1
	sub	x10, x9, x11
	lsl	x14, x11, #3
	cmp	x11, x10
	str	x8, [sp, #152]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	stp	x13, x9, [sp, #112]             ; 16-byte Folded Spill
	add	x9, x12, x9
	stp	x12, x11, [sp, #176]            ; 16-byte Folded Spill
	lsl	x12, x9, #3
	add	x25, x8, x14
	add	x8, x8, x13
	stp	x9, x14, [sp, #96]              ; 16-byte Folded Spill
	stp	x8, x10, [sp, #128]             ; 16-byte Folded Spill
	b.hs	LBB2_115
; %bb.28:
	mov	x0, x24
	mov	w1, #1
	mov	x20, x12
	blr	x26
	mov	x19, x25
	ldr	x1, [x25]
	mov	x0, x24
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x2, [x19, #8]!
	blr	x8
	and	w8, w0, #0xff
	mov	x12, x20
	cmp	w8, #1
	mov	x25, x19
	cset	w10, eq
	b	LBB2_116
LBB2_29:
	cbz	x0, LBB2_50
; %bb.30:
	lsr	x9, x27, #1
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	sub	x20, x27, x9
	lsl	x11, x9, #3
	lsr	x10, x20, #1
	lsr	x22, x27, #2
	sub	x21, x9, x22
	lsl	x12, x22, #3
	stp	x11, x9, [sp, #128]             ; 16-byte Folded Spill
	add	x9, x10, x9
	add	x13, x8, x12
	str	x10, [sp, #216]                 ; 8-byte Folded Spill
	add	x23, x8, x11
	lsl	x10, x9, #3
	cmp	x22, x21
	stp	x9, x12, [sp, #104]             ; 16-byte Folded Spill
	b.hs	LBB2_118
; %bb.31:
	mov	x19, x13
	ldr	x1, [x13]
	mov	x0, x24
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	mov	x28, x10
	ldr	x2, [x19, #8]!
	blr	x8
	and	w8, w0, #0xff
	mov	x10, x28
	cmp	w8, #1
	str	x19, [sp, #344]                 ; 8-byte Folded Spill
	cset	w8, eq
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
	b	LBB2_119
LBB2_32:                                ; %vector.ph2410
	and	x8, x27, #0xfffffffffffffffe
	add	x9, x22, #8
	lsl	x10, x28, #1
	neg	x11, x8
	ldr	x12, [sp, #240]                 ; 8-byte Folded Reload
LBB2_33:                                ; %vector.body2415
                                        ; =>This Inner Loop Header: Depth=1
	add	x13, x12, x28
	adds	x11, x11, #2
	stp	x12, x13, [x9, #-8]
	add	x9, x9, #16
	add	x12, x12, x10
	b.ne	LBB2_33
; %bb.34:                               ; %middle.block2407
	cmp	x8, x27
	b.eq	LBB2_37
LBB2_35:                                ; %.lr.ph.i.preheader2692
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	add	x10, x22, x8, lsl #3
	madd	x9, x8, x28, x9
	sub	x8, x8, x27
LBB2_36:                                ; %.lr.ph.i
                                        ; =>This Inner Loop Header: Depth=1
	str	x9, [x10], #8
	add	x9, x9, x28
	adds	x8, x8, #1
	b.lo	LBB2_36
LBB2_37:                                ; %._crit_edge.i
	mov	x0, x22
	mov	x1, x27
	tbz	w19, #0, LBB2_39
; %bb.38:
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #248]                  ; 8-byte Folded Reload
	bl	l_sort.quadsort_direct__anon_14343
	b	LBB2_40
LBB2_39:
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quadsort_direct__anon_14344
LBB2_40:
	mul	x19, x28, x27
	mov	w1, w24
	mov	x0, x19
	bl	_roc_alloc
	cbz	x0, LBB2_1256
; %bb.41:                               ; %.preheader.i
	mov	x20, x0
	cbz	x27, LBB2_44
; %bb.42:
	mov	x23, x20
	mov	x21, x22
LBB2_43:                                ; %.lr.ph16.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x21], #8
	mov	x0, x23
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	subs	x27, x27, #1
	add	x23, x23, x28
	b.ne	LBB2_43
LBB2_44:                                ; %._crit_edge17.i
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x1, x20
	mov	x2, x19
	bl	_memcpy
	mov	x0, x20
	mov	w1, w24
	bl	_roc_dealloc
	mov	x0, x22
	b	LBB2_1246
LBB2_45:
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x0, x9
	ldr	w5, [sp, #164]                  ; 4-byte Folded Reload
	mov	x1, x27
	mov	x3, x24
	mov	x4, x28
LBB2_46:
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x26
	add	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 976
	add	sp, sp, #880
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.quadsort_direct__anon_14341
LBB2_47:
	.cfi_restore_state
	.cfi_remember_state
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x0, x9
	ldr	w5, [sp, #164]                  ; 4-byte Folded Reload
	mov	x1, x27
	mov	x3, x24
	mov	x4, x28
LBB2_48:
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	add	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 976
	add	sp, sp, #880
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.quadsort_direct__anon_14342
LBB2_49:
	.cfi_restore_state
	.cfi_remember_state
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	mov	x1, x27
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x26
	bl	l_sort.quadsort_direct__anon_14343
	b	LBB2_1242
LBB2_50:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	mov	x1, x27
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	bl	l_sort.quadsort_direct__anon_14344
	b	LBB2_1242
LBB2_51:
	str	xzr, [sp, #224]                 ; 8-byte Folded Spill
LBB2_52:
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	sub	x10, x19, x8
	cmp	x21, x8
	str	x10, [sp, #136]                 ; 8-byte Folded Spill
	ldr	x10, [sp, #88]                  ; 8-byte Folded Reload
	add	x9, x9, x10
	str	x9, [sp, #312]                  ; 8-byte Folded Spill
	b.hs	LBB2_58
; %bb.53:
	mov	x0, x24
	mov	w1, #1
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	add	x22, x23, x28
	blr	x8
	mov	x0, x24
	mov	x1, x23
	mov	x2, x22
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	str	x22, [sp, #304]                 ; 8-byte Folded Spill
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, eq
	str	x8, [sp, #232]                  ; 8-byte Folded Spill
	b	LBB2_59
LBB2_54:
	mov	x23, xzr
LBB2_55:
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	add	x17, x9, x19
	ldr	x10, [sp, #144]                 ; 8-byte Folded Reload
	mov	x22, x1
	sub	x8, x8, x10
	cmp	x26, x10
	str	x8, [sp, #136]                  ; 8-byte Folded Spill
	b.hs	LBB2_61
; %bb.56:
	ldr	x1, [sp, #96]                   ; 8-byte Folded Reload
	mov	x0, x24
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	mov	x20, x17
	add	x21, x1, x28
	mov	x2, x21
	blr	x8
	and	w8, w0, #0xff
	mov	x17, x20
	cmp	w8, #1
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	cset	w9, eq
	str	x9, [sp, #232]                  ; 8-byte Folded Spill
	cmp	x26, x8
	b.lo	LBB2_62
LBB2_57:
	mov	x20, xzr
	b	LBB2_63
LBB2_58:
	str	xzr, [sp, #232]                 ; 8-byte Folded Spill
	str	x23, [sp, #304]                 ; 8-byte Folded Spill
LBB2_59:
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	cmp	x21, x8
	b.hs	LBB2_73
; %bb.60:
	ldr	x22, [sp, #312]                 ; 8-byte Folded Reload
	mov	x0, x24
	mov	w1, #1
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	str	x20, [sp, #344]                 ; 8-byte Folded Spill
	add	x20, x22, x28
	blr	x8
	mov	x0, x24
	mov	x1, x22
	mov	x2, x20
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	str	x20, [sp, #312]                 ; 8-byte Folded Spill
	ldr	x20, [sp, #344]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w0, eq
	b	LBB2_74
LBB2_61:
	ldr	x21, [sp, #96]                  ; 8-byte Folded Reload
	str	xzr, [sp, #232]                 ; 8-byte Folded Spill
	cmp	x26, x8
	b.hs	LBB2_57
LBB2_62:
	add	x20, x17, x28
	mov	x0, x24
	mov	x1, x17
	mov	x2, x20
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	mov	x17, x20
	cmp	w8, #1
	cset	w20, eq
LBB2_63:
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	mov	x11, x22
	cmp	x27, #133
	str	x19, [sp, #56]                  ; 8-byte Folded Spill
	str	x26, [sp, #112]                 ; 8-byte Folded Spill
	b.lo	LBB2_85
; %bb.64:                               ; %.preheader461.lr.ph.i.i
	add	x8, x28, x28, lsl #1
	mov	x0, xzr
	lsl	x8, x8, #5
	mov	x22, x9
	mov	x2, x27
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	str	wzr, [sp, #184]                 ; 4-byte Folded Spill
	str	wzr, [sp, #192]                 ; 4-byte Folded Spill
	str	wzr, [sp, #200]                 ; 4-byte Folded Spill
	str	wzr, [sp, #208]                 ; 4-byte Folded Spill
	str	x8, [sp, #176]                  ; 8-byte Folded Spill
	b	LBB2_68
LBB2_65:                                ;   in Loop: Header=BB2_68 Depth=1
	ldr	x28, [sp, #352]                 ; 8-byte Folded Reload
LBB2_66:                                ; %.critedge.i.i22
                                        ;   in Loop: Header=BB2_68 Depth=1
	str	x1, [sp, #232]                  ; 8-byte Folded Spill
	mov	x17, x11
	mov	x21, x10
	mov	x11, x9
	mov	x22, x8
LBB2_67:                                ; %.critedge.i.i22
                                        ;   in Loop: Header=BB2_68 Depth=1
	sub	x2, x2, #128
	cmp	x2, #132
	b.ls	LBB2_86
LBB2_68:                                ; %.preheader461.i.i
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB2_69 Depth 2
	add	x8, x22, x28
	stp	x23, x0, [sp, #216]             ; 16-byte Folded Spill
	mov	x19, xzr
	mov	w24, wzr
	mov	w26, wzr
	mov	w27, wzr
	stp	x8, x22, [sp, #296]             ; 16-byte Folded Spill
	add	x8, x11, x28
	mov	w15, wzr
	mov	x23, #-32
	str	x11, [sp, #320]                 ; 8-byte Folded Spill
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
	add	x8, x21, x28
	stp	x2, x20, [sp, #248]             ; 16-byte Folded Spill
	str	x17, [sp, #312]                 ; 8-byte Folded Spill
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
	add	x8, x17, x28
	ldr	x28, [sp, #328]                 ; 8-byte Folded Reload
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
LBB2_69:                                ;   Parent Loop BB2_68 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x1, x22, x19
	mov	x0, x25
	add	x22, x21, x19
	add	x20, x8, x19
	add	x8, x17, x19
	stp	x8, x15, [sp, #336]             ; 16-byte Folded Spill
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x2, x8, x19
	blr	x28
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	mov	x1, x20
	add	x2, x8, x19
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	cinc	w24, w24, eq
	blr	x28
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	mov	x1, x22
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	add	x2, x8, x19
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	cinc	w26, w26, eq
	blr	x28
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #336]                  ; 8-byte Folded Reload
	add	x2, x8, x19
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	cinc	w27, w27, eq
	blr	x28
	ldp	x15, x8, [sp, #344]             ; 16-byte Folded Reload
	ldr	x17, [sp, #312]                 ; 8-byte Folded Reload
	add	x19, x19, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	cinc	w15, w15, eq
	adds	x23, x23, #1
	b.lo	LBB2_69
; %bb.70:                               ;   in Loop: Header=BB2_68 Depth=1
	ldr	w8, [sp, #184]                  ; 4-byte Folded Reload
	mov	w9, #223
	tst	w24, w9
	ldr	x1, [sp, #232]                  ; 8-byte Folded Reload
	ldp	x23, x0, [sp, #216]             ; 16-byte Folded Reload
	cinc	w8, w8, eq
	tst	w26, w9
	ldp	x2, x20, [sp, #248]             ; 16-byte Folded Reload
	add	x1, x1, w27, uxtb
	add	x10, x21, x19
	str	w8, [sp, #184]                  ; 4-byte Folded Spill
	ldr	w8, [sp, #192]                  ; 4-byte Folded Reload
	ldr	x16, [sp, #320]                 ; 8-byte Folded Reload
	add	x0, x0, w24, uxtb
	add	x23, x23, w26, uxtb
	add	x11, x17, x19
	cinc	w8, w8, eq
	tst	w27, w9
	add	x20, x20, w15, uxtb
	str	w8, [sp, #192]                  ; 4-byte Folded Spill
	ldr	w8, [sp, #200]                  ; 4-byte Folded Reload
	cinc	w8, w8, eq
	tst	w15, w9
	add	x9, x16, x19
	str	w8, [sp, #200]                  ; 4-byte Folded Spill
	ldr	w8, [sp, #208]                  ; 4-byte Folded Reload
	cinc	w8, w8, eq
	cmp	x2, #516
	str	w8, [sp, #208]                  ; 4-byte Folded Spill
	add	x8, x22, x19
	b.ls	LBB2_65
; %bb.71:                               ;   in Loop: Header=BB2_68 Depth=1
	and	w12, w24, #0xffffffdf
	and	w15, w15, #0xffffffdf
	tst	w12, #0xff
	and	w13, w26, #0xffffffdf
	cset	w12, eq
	tst	w15, #0xff
	and	w14, w27, #0xffffffdf
	csetm	w15, eq
	tst	w13, #0xff
	ldr	x28, [sp, #352]                 ; 8-byte Folded Reload
	cinc	w12, w12, eq
	tst	w14, #0xff
	cinc	w12, w12, eq
	cmp	w12, w15
	b.ne	LBB2_66
; %bb.72:                               ;   in Loop: Header=BB2_68 Depth=1
	ldr	x9, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x0, #48
	add	x23, x23, #48
	add	x1, x1, #48
	add	x20, x20, #48
	sub	x2, x2, #384
	add	x8, x22, x9
	add	x22, x8, x19
	add	x8, x16, x9
	add	x11, x8, x19
	add	x8, x21, x9
	add	x21, x8, x19
	add	x8, x17, x9
	add	x17, x8, x19
	str	x1, [sp, #232]                  ; 8-byte Folded Spill
	b	LBB2_67
LBB2_73:
	mov	x0, xzr
LBB2_74:
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	cmp	x27, #133
	str	x23, [sp, #64]                  ; 8-byte Folded Spill
	stp	x19, x21, [sp, #96]             ; 16-byte Folded Spill
	b.lo	LBB2_99
; %bb.75:                               ; %.lr.ph.i.i
	ldp	x23, x25, [sp, #304]            ; 16-byte Folded Reload
	add	x8, x28, x28, lsl #1
	mov	x21, xzr
	lsl	x8, x8, #5
	mov	x3, x27
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	str	wzr, [sp, #184]                 ; 4-byte Folded Spill
	str	wzr, [sp, #192]                 ; 4-byte Folded Spill
	str	wzr, [sp, #200]                 ; 4-byte Folded Spill
	str	wzr, [sp, #208]                 ; 4-byte Folded Spill
	str	x8, [sp, #144]                  ; 8-byte Folded Spill
	str	x9, [sp, #320]                  ; 8-byte Folded Spill
	b	LBB2_79
LBB2_76:                                ;   in Loop: Header=BB2_79 Depth=1
	mov	x20, x9
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	stp	x2, x1, [sp, #224]              ; 16-byte Folded Spill
LBB2_77:                                ; %.critedge.i.i
                                        ;   in Loop: Header=BB2_79 Depth=1
	str	x8, [sp, #320]                  ; 8-byte Folded Spill
LBB2_78:                                ; %.critedge.i.i
                                        ;   in Loop: Header=BB2_79 Depth=1
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	sub	x3, x3, #128
	cmp	x3, #132
	b.ls	LBB2_100
LBB2_79:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB2_80 Depth 2
	str	x0, [sp, #256]                  ; 8-byte Folded Spill
	mov	x0, x24
	mov	w1, #128
	str	x25, [sp, #312]                 ; 8-byte Folded Spill
	str	x3, [sp, #176]                  ; 8-byte Folded Spill
	str	x21, [sp, #216]                 ; 8-byte Folded Spill
	blr	x22
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x19, xzr
	mov	w26, wzr
	mov	w22, wzr
	mov	w27, wzr
	mov	w24, wzr
	add	x8, x8, x28
	stp	x8, x23, [sp, #296]             ; 16-byte Folded Spill
	add	x8, x20, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
	add	x8, x23, x28
	mov	x23, #-32
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
	add	x8, x25, x28
	ldr	x25, [sp, #328]                 ; 8-byte Folded Reload
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
LBB2_80:                                ;   Parent Loop BB2_79 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x21, x20, x19
	ldr	x28, [sp, #360]                 ; 8-byte Folded Reload
	add	x1, x8, x19
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	mov	x0, x28
	add	x8, x8, x19
	str	x8, [sp, #336]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	add	x8, x8, x19
	str	x8, [sp, #344]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x2, x8, x19
	blr	x25
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	mov	x1, x21
	add	x2, x8, x19
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	cinc	w26, w26, eq
	blr	x25
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #336]                  ; 8-byte Folded Reload
	ldr	x21, [sp, #352]                 ; 8-byte Folded Reload
	add	x2, x8, x19
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	cinc	w22, w22, eq
	blr	x25
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #344]                  ; 8-byte Folded Reload
	add	x2, x8, x19
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	cinc	w27, w27, eq
	blr	x25
	and	w8, w0, #0xff
	add	x19, x19, x21
	cmp	w8, #1
	cinc	w24, w24, eq
	adds	x23, x23, #1
	b.lo	LBB2_80
; %bb.81:                               ;   in Loop: Header=BB2_79 Depth=1
	ldr	w8, [sp, #184]                  ; 4-byte Folded Reload
	mov	w9, #223
	tst	w26, w9
	mov	x28, x21
	ldp	x21, x2, [sp, #216]             ; 16-byte Folded Reload
	cinc	w8, w8, eq
	tst	w22, w9
	ldr	x1, [sp, #232]                  ; 8-byte Folded Reload
	ldr	x0, [sp, #256]                  ; 8-byte Folded Reload
	str	w8, [sp, #184]                  ; 4-byte Folded Spill
	ldr	w8, [sp, #192]                  ; 4-byte Folded Reload
	ldr	x16, [sp, #304]                 ; 8-byte Folded Reload
	add	x21, x21, w26, uxtb
	ldr	x3, [sp, #176]                  ; 8-byte Folded Reload
	add	x2, x2, w22, uxtb
	cinc	w8, w8, eq
	tst	w27, w9
	add	x1, x1, w27, uxtb
	add	x0, x0, w24, uxtb
	add	x23, x16, x19
	str	w8, [sp, #192]                  ; 4-byte Folded Spill
	ldr	w8, [sp, #200]                  ; 4-byte Folded Reload
	cinc	w8, w8, eq
	tst	w24, w9
	add	x9, x20, x19
	str	w8, [sp, #200]                  ; 4-byte Folded Spill
	ldr	w8, [sp, #208]                  ; 4-byte Folded Reload
	cinc	w8, w8, eq
	cmp	x3, #516
	str	w8, [sp, #208]                  ; 4-byte Folded Spill
	ldp	x17, x8, [sp, #312]             ; 16-byte Folded Reload
	add	x25, x17, x19
	add	x8, x8, x19
	b.ls	LBB2_76
; %bb.82:                               ;   in Loop: Header=BB2_79 Depth=1
	and	w12, w26, #0xffffffdf
	and	w15, w24, #0xffffffdf
	tst	w12, #0xff
	and	w13, w22, #0xffffffdf
	cset	w12, eq
	tst	w15, #0xff
	and	w14, w27, #0xffffffdf
	csetm	w15, eq
	tst	w13, #0xff
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	cinc	w12, w12, eq
	tst	w14, #0xff
	cinc	w12, w12, eq
	cmp	w12, w15
	b.ne	LBB2_84
; %bb.83:                               ;   in Loop: Header=BB2_79 Depth=1
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x2, x2, #48
	ldr	x9, [sp, #144]                  ; 8-byte Folded Reload
	add	x1, x1, #48
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	add	x21, x21, #48
	add	x0, x0, #48
	sub	x3, x3, #384
	add	x8, x8, x9
	stp	x2, x1, [sp, #224]              ; 16-byte Folded Spill
	add	x8, x8, x19
	str	x8, [sp, #320]                  ; 8-byte Folded Spill
	add	x8, x20, x9
	add	x20, x8, x19
	add	x8, x16, x9
	add	x23, x8, x19
	add	x8, x17, x9
	add	x25, x8, x19
	b	LBB2_78
LBB2_84:                                ;   in Loop: Header=BB2_79 Depth=1
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	stp	x2, x1, [sp, #224]              ; 16-byte Folded Spill
	mov	x20, x9
	b	LBB2_77
LBB2_85:
	str	wzr, [sp, #184]                 ; 4-byte Folded Spill
	mov	x0, xzr
	str	wzr, [sp, #192]                 ; 4-byte Folded Spill
	mov	w2, #132
	str	wzr, [sp, #200]                 ; 4-byte Folded Spill
	mov	x22, x9
	str	wzr, [sp, #208]                 ; 4-byte Folded Spill
	b	LBB2_87
LBB2_86:                                ; %.preheader.i.i
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	cmp	x2, #8
	ldr	x26, [sp, #112]                 ; 8-byte Folded Reload
	b.lo	LBB2_90
LBB2_87:                                ; %.lr.ph.i.i24.preheader
	mov	x26, x0
	ldr	x24, [sp, #232]                 ; 8-byte Folded Reload
	ldr	x25, [sp, #352]                 ; 8-byte Folded Reload
	ldr	x28, [sp, #328]                 ; 8-byte Folded Reload
LBB2_88:                                ; %.lr.ph.i.i24
                                        ; =>This Inner Loop Header: Depth=1
	stp	x2, x20, [sp, #248]             ; 16-byte Folded Spill
	ldr	x20, [sp, #360]                 ; 8-byte Folded Reload
	mov	x1, x22
	str	x17, [sp, #344]                 ; 8-byte Folded Spill
	add	x19, x1, x25
	mov	x22, x11
	mov	x0, x20
	mov	x2, x19
	blr	x28
	add	x27, x22, x25
	and	w8, w0, #0xff
	mov	x0, x20
	mov	x1, x22
	mov	x2, x27
	cmp	w8, #1
	cinc	x26, x26, eq
	mov	x22, x19
	blr	x28
	add	x9, x21, x25
	and	w8, w0, #0xff
	mov	x0, x20
	mov	x1, x21
	mov	x2, x9
	cmp	w8, #1
	cinc	x23, x23, eq
	mov	x21, x9
	blr	x28
	ldr	x1, [sp, #344]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	mov	x0, x20
	ldr	x20, [sp, #256]                 ; 8-byte Folded Reload
	cmp	w8, #1
	add	x19, x1, x25
	cinc	x24, x24, eq
	mov	x2, x19
	blr	x28
	ldr	x2, [sp, #248]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x11, x27
	mov	x17, x19
	cinc	x20, x20, eq
	sub	x2, x2, #4
	cmp	x2, #7
	b.hi	LBB2_88
; %bb.89:
	str	x24, [sp, #232]                 ; 8-byte Folded Spill
	mov	x0, x26
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	ldr	x26, [sp, #112]                 ; 8-byte Folded Reload
LBB2_90:                                ; %._crit_edge.i.i27
	ldr	x19, [sp, #232]                 ; 8-byte Folded Reload
	stp	x17, x11, [sp, #312]            ; 16-byte Folded Spill
	str	x0, [sp, #224]                  ; 8-byte Folded Spill
	add	x8, x19, x0
	add	x8, x23, x8
	cmn	x8, x20
	b.ne	LBB2_94
; %bb.91:
	add	x2, x22, x28
	mov	x0, x24
	mov	x1, x22
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	ldr	x11, [sp, #320]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	ldr	x0, [sp, #224]                  ; 8-byte Folded Reload
	cmp	w8, #1
	b.eq	LBB2_94
; %bb.92:
	add	x2, x11, x28
	mov	x0, x24
	mov	x1, x11
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	ldr	x11, [sp, #320]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	ldr	x0, [sp, #224]                  ; 8-byte Folded Reload
	cmp	w8, #1
	b.eq	LBB2_94
; %bb.93:
	add	x2, x21, x28
	mov	x0, x24
	mov	x1, x21
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	ldr	x11, [sp, #320]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	ldr	x0, [sp, #224]                  ; 8-byte Folded Reload
	cmp	w8, #1
	b.ne	LBB2_916
LBB2_94:                                ; %.critedge2.i.i31
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	str	x21, [sp, #344]                 ; 8-byte Folded Spill
	sub	x12, x26, x0
	str	x22, [sp, #304]                 ; 8-byte Folded Spill
	cmp	x12, #1
	sub	x10, x8, x23
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	sub	x21, x8, x19
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	sub	x25, x8, x20
	b.eq	LBB2_171
; %bb.95:                               ; %.critedge2.i.i31
	cmp	x10, #1
	b.eq	LBB2_171
; %bb.96:                               ; %.critedge2.i.i31
	cmp	x21, #1
	b.eq	LBB2_171
; %bb.97:                               ; %.critedge2.i.i31
	cmp	x25, #1
	b.eq	LBB2_171
; %bb.98:
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	b	LBB2_600
LBB2_99:
	ldp	x23, x25, [sp, #304]            ; 16-byte Folded Reload
	str	wzr, [sp, #184]                 ; 4-byte Folded Spill
	mov	x21, xzr
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	str	wzr, [sp, #192]                 ; 4-byte Folded Spill
	str	wzr, [sp, #200]                 ; 4-byte Folded Spill
	mov	w3, #132
	str	wzr, [sp, #208]                 ; 4-byte Folded Spill
	str	x9, [sp, #320]                  ; 8-byte Folded Spill
	b	LBB2_101
LBB2_100:                               ; %._crit_edge.i.i
	cmp	x3, #7
	b.ls	LBB2_104
LBB2_101:                               ; %.lr.ph507.preheader.i.i
	and	x8, x3, #0xfc
	mov	x28, x3
	sub	x1, x8, #4
	mov	x8, x22
	mov	x22, x0
	mov	x0, x24
	mov	x26, x23
	blr	x8
	mov	x9, x20
	ldr	x19, [sp, #360]                 ; 8-byte Folded Reload
	ldp	x23, x20, [sp, #320]            ; 16-byte Folded Reload
	ldp	x24, x27, [sp, #224]            ; 16-byte Folded Reload
LBB2_102:                               ; %.lr.ph507.i.i
                                        ; =>This Inner Loop Header: Depth=1
	str	x22, [sp, #256]                 ; 8-byte Folded Spill
	ldr	x22, [sp, #352]                 ; 8-byte Folded Reload
	mov	x1, x23
	mov	x0, x19
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	str	x25, [sp, #336]                 ; 8-byte Folded Spill
	add	x23, x23, x22
	mov	x25, x26
	mov	x2, x23
	mov	x26, x9
	blr	x8
	add	x2, x26, x22
	and	w8, w0, #0xff
	mov	x0, x19
	mov	x1, x26
	cmp	w8, #1
	str	x2, [sp, #344]                  ; 8-byte Folded Spill
	cinc	x21, x21, eq
	blr	x20
	add	x26, x25, x22
	and	w8, w0, #0xff
	mov	x0, x19
	mov	x1, x25
	mov	x2, x26
	cmp	w8, #1
	cinc	x24, x24, eq
	blr	x20
	ldr	x1, [sp, #336]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	cinc	x27, x27, eq
	add	x25, x1, x22
	ldr	x22, [sp, #256]                 ; 8-byte Folded Reload
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	ldr	x9, [sp, #344]                  ; 8-byte Folded Reload
	cmp	w8, #1
	sub	x28, x28, #4
	cinc	x22, x22, eq
	cmp	x28, #7
	b.hi	LBB2_102
; %bb.103:
	stp	x24, x27, [sp, #224]            ; 16-byte Folded Spill
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	str	x23, [sp, #320]                 ; 8-byte Folded Spill
	mov	x20, x9
	mov	x0, x22
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	mov	x23, x26
LBB2_104:                               ; %._crit_edge508.i.i
	ldp	x9, x8, [sp, #224]              ; 16-byte Folded Reload
	str	x20, [sp, #344]                 ; 8-byte Folded Spill
	str	x0, [sp, #256]                  ; 8-byte Folded Spill
	add	x8, x8, x21
	add	x8, x9, x8
	cmn	x8, x0
	b.ne	LBB2_108
; %bb.105:
	ldr	x19, [sp, #320]                 ; 8-byte Folded Reload
	mov	x0, x24
	mov	w1, #1
	mov	x26, x23
	add	x20, x19, x28
	blr	x22
	mov	x0, x24
	mov	x1, x19
	mov	x2, x20
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x20, [sp, #344]                 ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	ldr	x0, [sp, #256]                  ; 8-byte Folded Reload
	cmp	w8, #1
	b.eq	LBB2_108
; %bb.106:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x0, x24
	mov	w1, #1
	add	x20, x8, x28
	blr	x22
	mov	x0, x24
	ldr	x1, [sp, #344]                  ; 8-byte Folded Reload
	mov	x2, x20
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x20, [sp, #344]                 ; 8-byte Folded Reload
	blr	x8
	mov	x23, x26
	and	w8, w0, #0xff
	ldr	x0, [sp, #256]                  ; 8-byte Folded Reload
	cmp	w8, #1
	b.eq	LBB2_108
; %bb.107:
	mov	x0, x24
	mov	w1, #1
	add	x20, x23, x28
	blr	x22
	mov	x0, x24
	mov	x1, x26
	mov	x2, x20
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x20, [sp, #344]                 ; 8-byte Folded Reload
	blr	x8
	mov	x23, x26
	and	w8, w0, #0xff
	ldr	x0, [sp, #256]                  ; 8-byte Folded Reload
	cmp	w8, #1
	b.ne	LBB2_916
LBB2_108:                               ; %.critedge2.i.i
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	str	x23, [sp, #304]                 ; 8-byte Folded Spill
	ldr	x9, [sp, #224]                  ; 8-byte Folded Reload
	str	x21, [sp, #216]                 ; 8-byte Folded Spill
	sub	x11, x8, x21
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	cmp	x11, #1
	sub	x19, x8, x9
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #232]                  ; 8-byte Folded Reload
	sub	x9, x8, x9
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	sub	x8, x8, x0
	b.eq	LBB2_112
; %bb.109:                              ; %.critedge2.i.i
	cmp	x19, #1
	b.eq	LBB2_112
; %bb.110:                              ; %.critedge2.i.i
	cmp	x9, #1
	b.eq	LBB2_112
; %bb.111:                              ; %.critedge2.i.i
	cmp	x8, #1
	b.ne	LBB2_543
LBB2_112:
	mov	x0, x24
	mov	w1, #3
	cmp	x11, #1
	str	x11, [sp, #32]                  ; 8-byte Folded Spill
	cset	w23, eq
	str	x8, [sp, #176]                  ; 8-byte Folded Spill
	mov	x21, x9
	blr	x22
	cmp	x19, #1
	str	x19, [sp, #40]                  ; 8-byte Folded Spill
	csel	w19, wzr, w23, ne
	mov	x0, x24
	ldp	x1, x23, [sp, #320]             ; 16-byte Folded Reload
	mov	x22, x20
	cset	w20, eq
	mov	x26, x28
	add	x2, x1, x28
	str	x2, [sp, #288]                  ; 8-byte Folded Spill
	blr	x23
	and	w8, w0, #0xff
	add	x2, x22, x28
	cmp	w8, #1
	mov	x0, x24
	csel	w8, wzr, w19, ne
	mov	x1, x22
	cmp	x21, #1
	str	x21, [sp, #144]                 ; 8-byte Folded Spill
	cset	w19, eq
	csel	w20, wzr, w20, ne
	str	w8, [sp, #312]                  ; 4-byte Folded Spill
	str	x2, [sp, #296]                  ; 8-byte Folded Spill
	blr	x23
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	mov	x0, x24
	cset	w22, eq
	add	x2, x1, x28
	cmp	x8, #1
	csel	w21, wzr, w19, ne
	str	x2, [sp, #336]                  ; 8-byte Folded Spill
	blr	x23
	and	w9, w0, #0xff
	ldr	w10, [sp, #312]                 ; 4-byte Folded Reload
	cmp	w9, #1
	mov	w8, #2
	cset	w9, eq
	tst	w20, w22
	csel	w8, w8, wzr, ne
	tst	w21, w9
	mov	w9, #4
	orr	w8, w8, w10
	csel	w9, w9, wzr, ne
	orr	w8, w8, w9
Lloh0:
	adrp	x9, LJTI2_6@PAGE
Lloh1:
	add	x9, x9, LJTI2_6@PAGEOFF
	adr	x10, LBB2_113
	ldrh	w11, [x9, x8, lsl #1]
	add	x10, x10, x11, lsl #2
	ldr	x21, [sp, #304]                 ; 8-byte Folded Reload
	ldp	x22, x0, [sp, #248]             ; 16-byte Folded Reload
	str	x25, [sp, #312]                 ; 8-byte Folded Spill
	br	x10
LBB2_113:
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	ldr	x11, [sp, #344]                 ; 8-byte Folded Reload
	mov	x12, x28
	sub	x8, x11, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x19, x10, x8
	sub	x26, x11, x8
	tbnz	w20, #0, LBB2_390
; %bb.114:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x19
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x19
	mov	x1, x26
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x19, x19, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_391
LBB2_115:
	mov	x10, xzr
LBB2_116:
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	str	x12, [sp, #88]                  ; 8-byte Folded Spill
	ldr	x9, [sp, #176]                  ; 8-byte Folded Reload
	str	x10, [sp, #296]                 ; 8-byte Folded Spill
	sub	x19, x8, x9
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	add	x21, x8, x12
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	cmp	x8, x9
	b.hs	LBB2_122
; %bb.117:
	mov	x0, x24
	mov	w1, #1
	blr	x26
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	mov	x0, x24
	mov	x20, x8
	ldr	x1, [x8]
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x2, [x20, #8]!
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w9, eq
	b	LBB2_123
LBB2_118:
	str	x13, [sp, #344]                 ; 8-byte Folded Spill
	str	xzr, [sp, #288]                 ; 8-byte Folded Spill
LBB2_119:
	ldp	x8, x9, [sp, #208]              ; 16-byte Folded Reload
	str	x10, [sp, #96]                  ; 8-byte Folded Spill
	add	x25, x8, x10
	sub	x28, x20, x9
	cmp	x22, x9
	b.hs	LBB2_129
; %bb.120:
	mov	x26, x23
	ldr	x1, [x23]
	mov	x0, x24
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x2, [x26, #8]!
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, eq
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
	cmp	x22, x28
	b.lo	LBB2_130
LBB2_121:
	mov	x1, xzr
	b	LBB2_131
LBB2_122:
	mov	x9, xzr
	ldr	x20, [sp, #128]                 ; 8-byte Folded Reload
LBB2_123:
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	str	x19, [sp, #144]                 ; 8-byte Folded Spill
	str	x9, [sp, #288]                  ; 8-byte Folded Spill
	cmp	x8, x19
	b.hs	LBB2_139
; %bb.124:
	mov	x0, x24
	mov	w1, #1
	blr	x26
	mov	x19, x21
	ldr	x1, [x21]
	mov	x0, x24
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x2, [x19, #8]!
	blr	x8
	and	w8, w0, #0xff
	mov	x21, x19
	cmp	w8, #1
	cset	w1, eq
	cmp	x27, #133
	b.hs	LBB2_140
LBB2_125:
	mov	x23, xzr
	mov	w12, wzr
	mov	w13, wzr
	mov	x17, x27
	ldr	x4, [sp, #208]                  ; 8-byte Folded Reload
	str	wzr, [sp, #272]                 ; 4-byte Folded Spill
	str	wzr, [sp, #256]                 ; 4-byte Folded Spill
LBB2_126:                               ; %._crit_edge.i.i91
	cmp	x17, #7
	str	w12, [sp, #232]                 ; 4-byte Folded Spill
	str	w13, [sp, #280]                 ; 4-byte Folded Spill
	b.ls	LBB2_147
; %bb.127:                              ; %.lr.ph134.preheader.i.i
	and	x8, x17, #0xfc
	mov	x19, x1
	sub	x1, x8, #4
	mov	x0, x24
	mov	x28, x25
	mov	x25, x20
	mov	x22, x17
	mov	x27, x4
	blr	x26
	mov	x9, x27
	mov	x27, x28
	str	x28, [sp, #344]                 ; 8-byte Folded Spill
	mov	x1, x19
	ldp	x28, x24, [sp, #288]            ; 16-byte Folded Reload
	mov	x26, x9
	mov	x19, x21
LBB2_128:                               ; %.lr.ph134.i.i
                                        ; =>This Inner Loop Header: Depth=1
	str	x25, [sp, #320]                 ; 8-byte Folded Spill
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	str	x21, [sp, #336]                 ; 8-byte Folded Spill
	ldr	x21, [sp, #328]                 ; 8-byte Folded Reload
	str	x1, [sp, #304]                  ; 8-byte Folded Spill
	ldr	x1, [x9]
	ldr	x2, [x26, #8]!
	mov	x0, x25
	blr	x21
	ldr	x1, [x27]
	and	w8, w0, #0xff
	ldr	x27, [sp, #344]                 ; 8-byte Folded Reload
	mov	x0, x25
	cmp	w8, #1
	cinc	x23, x23, eq
	ldr	x2, [x27, #8]!
	blr	x21
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	ldr	x2, [x20, #8]!
	ldr	x1, [x8]
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	cinc	x24, x24, eq
	blr	x21
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	ldr	x2, [x19, #8]!
	ldr	x1, [x8]
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	cinc	x28, x28, eq
	blr	x21
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	sub	x22, x22, #4
	mov	x9, x26
	mov	x25, x20
	cinc	x1, x1, eq
	mov	x21, x19
	cmp	x22, #7
	str	x27, [sp, #344]                 ; 8-byte Folded Spill
	b.hi	LBB2_128
	b	LBB2_148
LBB2_129:
	mov	x26, x23
	str	xzr, [sp, #280]                 ; 8-byte Folded Spill
	cmp	x22, x28
	b.hs	LBB2_121
LBB2_130:
	mov	x19, x25
	ldr	x1, [x25]
	mov	x0, x24
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x2, [x19, #8]!
	blr	x8
	and	w8, w0, #0xff
	mov	x25, x19
	cmp	w8, #1
	cset	w1, eq
LBB2_131:
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	mov	x0, x26
	cmp	x27, #133
	stp	x28, x21, [sp, #176]            ; 16-byte Folded Spill
	str	x23, [sp, #120]                 ; 8-byte Folded Spill
	stp	x20, x22, [sp, #144]            ; 16-byte Folded Spill
	b.lo	LBB2_157
; %bb.132:                              ; %.preheader89.i.i.preheader
	mov	w13, wzr
	mov	w14, wzr
	mov	x15, xzr
	mov	x6, x8
	ldr	x5, [sp, #344]                  ; 8-byte Folded Reload
	mov	x4, x0
	mov	x3, x25
	mov	x2, x27
	ldr	x21, [sp, #360]                 ; 8-byte Folded Reload
	str	wzr, [sp, #232]                 ; 4-byte Folded Spill
	str	wzr, [sp, #248]                 ; 4-byte Folded Spill
	b	LBB2_134
LBB2_133:                               ; %.critedge.i.i204
                                        ;   in Loop: Header=BB2_134 Depth=1
	sub	x2, x2, #128
	mov	x6, x8
	mov	x5, x22
	mov	x4, x0
	mov	x3, x25
	cmp	x2, #132
	stp	x16, x17, [sp, #280]            ; 16-byte Folded Spill
	b.ls	LBB2_158
LBB2_134:                               ; %.preheader89.i.i
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB2_135 Depth 2
	mov	x28, xzr
	mov	w24, wzr
	mov	w19, wzr
	mov	w26, wzr
	mov	w23, wzr
	ldr	x25, [sp, #328]                 ; 8-byte Folded Reload
	stp	x2, x1, [sp, #296]              ; 16-byte Folded Spill
	str	x15, [sp, #224]                 ; 8-byte Folded Spill
	str	w13, [sp, #256]                 ; 4-byte Folded Spill
	str	w14, [sp, #272]                 ; 4-byte Folded Spill
	stp	x4, x3, [sp, #336]              ; 16-byte Folded Spill
	stp	x6, x5, [sp, #312]              ; 16-byte Folded Spill
LBB2_135:                               ;   Parent Loop BB2_134 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x8, x6, x28
	mov	x0, x21
	add	x20, x5, x28
	add	x27, x4, x28
	add	x22, x3, x28
	ldp	x1, x2, [x8]
	blr	x25
	ldp	x1, x2, [x20]
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	cinc	w24, w24, eq
	blr	x25
	ldp	x1, x2, [x27]
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	cinc	w19, w19, eq
	blr	x25
	ldp	x1, x2, [x22]
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	cinc	w26, w26, eq
	blr	x25
	ldp	x6, x5, [sp, #312]              ; 16-byte Folded Reload
	and	w8, w0, #0xff
	add	x28, x28, #8
	ldp	x4, x3, [sp, #336]              ; 16-byte Folded Reload
	cmp	w8, #1
	cinc	w23, w23, eq
	cmp	x28, #256
	b.ne	LBB2_135
; %bb.136:                              ;   in Loop: Header=BB2_134 Depth=1
	ldr	w10, [sp, #232]                 ; 4-byte Folded Reload
	mov	w8, #223
	ldp	x16, x17, [sp, #280]            ; 16-byte Folded Reload
	tst	w24, w8
	add	x22, x5, x28
	ldr	w9, [sp, #248]                  ; 4-byte Folded Reload
	cinc	w10, w10, eq
	ldp	x2, x1, [sp, #296]              ; 16-byte Folded Reload
	tst	w19, w8
	add	x16, x16, w26, uxtb
	ldr	w13, [sp, #256]                 ; 4-byte Folded Reload
	cinc	w9, w9, eq
	ldr	x15, [sp, #224]                 ; 8-byte Folded Reload
	tst	w26, w8
	ldr	w14, [sp, #272]                 ; 4-byte Folded Reload
	add	x17, x17, w19, uxtb
	cinc	w13, w13, eq
	tst	w23, w8
	add	x15, x15, w24, uxtb
	add	x1, x1, w23, uxtb
	cinc	w14, w14, eq
	add	x8, x6, x28
	add	x25, x3, x28
	add	x0, x4, x28
	cmp	x2, #516
	str	w9, [sp, #248]                  ; 4-byte Folded Spill
	str	w10, [sp, #232]                 ; 4-byte Folded Spill
	b.ls	LBB2_133
; %bb.137:                              ;   in Loop: Header=BB2_134 Depth=1
	and	w9, w24, #0xffffffdf
	and	w12, w23, #0xffffffdf
	tst	w9, #0xff
	and	w10, w19, #0xffffffdf
	cset	w9, eq
	tst	w12, #0xff
	and	w11, w26, #0xffffffdf
	csetm	w12, eq
	tst	w10, #0xff
	cinc	w9, w9, eq
	tst	w11, #0xff
	cinc	w9, w9, eq
	cmp	w9, w12
	b.ne	LBB2_133
; %bb.138:                              ;   in Loop: Header=BB2_134 Depth=1
	add	x9, x5, x28
	add	x8, x6, x28
	add	x22, x9, #768
	add	x9, x4, x28
	add	x0, x9, #768
	add	x9, x3, x28
	add	x15, x15, #48
	add	x17, x17, #48
	add	x8, x8, #768
	add	x16, x16, #48
	add	x1, x1, #48
	add	x25, x9, #768
	sub	x2, x2, #384
	b	LBB2_133
LBB2_139:
	mov	x1, xzr
	cmp	x27, #133
	b.lo	LBB2_125
LBB2_140:                               ; %.lr.ph.i.i77.preheader
	mov	w13, wzr
	mov	w12, wzr
	mov	x23, xzr
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	mov	x9, x25
	mov	x8, x20
	mov	x22, x21
	mov	x17, x27
	str	wzr, [sp, #256]                 ; 4-byte Folded Spill
	str	wzr, [sp, #272]                 ; 4-byte Folded Spill
	b	LBB2_142
LBB2_141:                               ;   in Loop: Header=BB2_142 Depth=1
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	sub	x17, x17, #128
	ldr	x26, [sp, #248]                 ; 8-byte Folded Reload
	mov	x10, x4
	mov	x9, x25
	mov	x8, x20
	mov	x22, x21
	cmp	x17, #132
	stp	x16, x15, [sp, #288]            ; 16-byte Folded Spill
	b.ls	LBB2_126
LBB2_142:                               ; %.lr.ph.i.i77
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB2_143 Depth 2
	str	x1, [sp, #304]                  ; 8-byte Folded Spill
	mov	x0, x24
	mov	w1, #128
	stp	x10, x9, [sp, #312]             ; 16-byte Folded Spill
	str	x8, [sp, #336]                  ; 8-byte Folded Spill
	stp	x17, x23, [sp, #216]            ; 16-byte Folded Spill
	str	w13, [sp, #280]                 ; 4-byte Folded Spill
	str	w12, [sp, #232]                 ; 4-byte Folded Spill
	blr	x26
	mov	x19, xzr
	mov	w24, wzr
	mov	w26, wzr
	mov	w27, wzr
	mov	w5, wzr
LBB2_143:                               ;   Parent Loop BB2_142 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	x8, x9, [sp, #312]              ; 16-byte Folded Reload
	str	x5, [sp, #344]                  ; 8-byte Folded Spill
	mov	x21, x22
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	add	x22, x22, x19
	add	x8, x8, x19
	add	x20, x9, x19
	mov	x0, x25
	ldp	x23, x9, [sp, #328]             ; 16-byte Folded Reload
	ldp	x1, x2, [x8]
	add	x28, x9, x19
	blr	x23
	ldp	x1, x2, [x20]
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	cinc	w24, w24, eq
	blr	x23
	ldp	x1, x2, [x28]
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	cinc	w26, w26, eq
	blr	x23
	ldp	x1, x2, [x22]
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	mov	x22, x21
	cinc	w27, w27, eq
	blr	x23
	ldr	x5, [sp, #344]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	add	x19, x19, #8
	cinc	w5, w5, eq
	cmp	x19, #256
	b.ne	LBB2_143
; %bb.144:                              ;   in Loop: Header=BB2_142 Depth=1
	ldr	w9, [sp, #256]                  ; 4-byte Folded Reload
	mov	w10, #223
	ldp	x16, x15, [sp, #288]            ; 16-byte Folded Reload
	tst	w24, w10
	add	x21, x22, x19
	ldr	w8, [sp, #272]                  ; 4-byte Folded Reload
	cinc	w9, w9, eq
	ldp	x1, x3, [sp, #304]              ; 16-byte Folded Reload
	tst	w26, w10
	add	x16, x16, w27, uxtb
	ldr	w13, [sp, #280]                 ; 4-byte Folded Reload
	cinc	w8, w8, eq
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
	tst	w27, w10
	ldr	w12, [sp, #232]                 ; 4-byte Folded Reload
	add	x15, x15, w26, uxtb
	ldr	x2, [sp, #320]                  ; 8-byte Folded Reload
	cinc	w13, w13, eq
	ldr	x0, [sp, #336]                  ; 8-byte Folded Reload
	tst	w5, w10
	ldr	x17, [sp, #216]                 ; 8-byte Folded Reload
	add	x23, x23, w24, uxtb
	add	x1, x1, w5, uxtb
	cinc	w12, w12, eq
	add	x4, x3, x19
	add	x25, x2, x19
	add	x20, x0, x19
	cmp	x17, #516
	str	w8, [sp, #272]                  ; 4-byte Folded Spill
	str	w9, [sp, #256]                  ; 4-byte Folded Spill
	b.ls	LBB2_141
; %bb.145:                              ;   in Loop: Header=BB2_142 Depth=1
	mov	x11, x26
	and	w8, w24, #0xffffffdf
	and	w9, w11, #0xffffffdf
	and	w11, w5, #0xffffffdf
	tst	w8, #0xff
	and	w10, w27, #0xffffffdf
	cset	w8, eq
	tst	w11, #0xff
	csetm	w11, eq
	tst	w9, #0xff
	cinc	w8, w8, eq
	tst	w10, #0xff
	cinc	w8, w8, eq
	cmp	w8, w11
	b.ne	LBB2_141
; %bb.146:                              ;   in Loop: Header=BB2_142 Depth=1
	add	x8, x3, x19
	add	x23, x23, #48
	add	x4, x8, #768
	add	x8, x2, x19
	add	x25, x8, #768
	add	x8, x0, x19
	add	x20, x8, #768
	add	x8, x22, x19
	add	x15, x15, #48
	add	x16, x16, #48
	add	x1, x1, #48
	add	x21, x8, #768
	sub	x17, x17, #384
	b	LBB2_141
LBB2_147:
	ldp	x28, x24, [sp, #288]            ; 16-byte Folded Reload
	mov	x19, x21
	str	x25, [sp, #344]                 ; 8-byte Folded Spill
	mov	x26, x4
LBB2_148:                               ; %._crit_edge135.i.i
	add	x8, x28, x23
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	mov	x30, x23
	mov	x4, x24
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	mov	x17, x28
	ldr	x28, [sp, #352]                 ; 8-byte Folded Reload
	mov	x21, x26
	add	x8, x24, x8
	str	x19, [sp, #312]                 ; 8-byte Folded Spill
	cmn	x8, x1
	b.ne	LBB2_152
; %bb.149:
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	mov	x19, x1
	mov	w1, #1
	mov	x26, x17
	mov	x23, x30
	mov	x24, x4
	mov	x0, x25
	blr	x22
	ldp	x1, x2, [x21]
	mov	x0, x25
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	blr	x8
	mov	x4, x24
	mov	x30, x23
	mov	x1, x19
	mov	x17, x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB2_152
; %bb.150:
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	mov	w1, #1
	mov	x0, x25
	blr	x22
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x0, x25
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	ldp	x1, x2, [x8]
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	mov	x4, x24
	mov	x30, x23
	mov	x1, x19
	mov	x17, x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB2_152
; %bb.151:
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	mov	w1, #1
	mov	x0, x25
	blr	x22
	ldp	x1, x2, [x20]
	mov	x0, x25
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	blr	x8
	mov	x4, x24
	mov	x30, x23
	mov	x1, x19
	mov	x17, x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB2_1241
LBB2_152:                               ; %.critedge2.i.i115
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	str	x20, [sp, #336]                 ; 8-byte Folded Spill
	str	x21, [sp, #320]                 ; 8-byte Folded Spill
	sub	x10, x8, x30
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	cmp	x10, #1
	sub	x20, x8, x4
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	sub	x9, x8, x17
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	sub	x23, x8, x1
	b.eq	LBB2_174
; %bb.153:                              ; %.critedge2.i.i115
	cmp	x20, #1
	b.eq	LBB2_174
; %bb.154:                              ; %.critedge2.i.i115
	cmp	x9, #1
	b.eq	LBB2_174
; %bb.155:                              ; %.critedge2.i.i115
	cmp	x23, #1
	b.eq	LBB2_174
; %bb.156:
	ldr	w5, [sp, #232]                  ; 4-byte Folded Reload
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	b	LBB2_1152
LBB2_157:
	mov	x15, xzr
	mov	w14, wzr
	mov	w13, wzr
	mov	x2, x27
	ldr	x22, [sp, #344]                 ; 8-byte Folded Reload
	str	wzr, [sp, #248]                 ; 4-byte Folded Spill
	str	wzr, [sp, #232]                 ; 4-byte Folded Spill
LBB2_158:                               ; %.preheader.i.i192
	cmp	x2, #8
	str	w13, [sp, #256]                 ; 4-byte Folded Spill
	str	w14, [sp, #272]                 ; 4-byte Folded Spill
	b.lo	LBB2_161
; %bb.159:
	mov	x24, x25
	mov	x19, x25
	ldp	x25, x28, [sp, #280]            ; 16-byte Folded Reload
	mov	x21, x8
	mov	x26, x15
	ldr	x20, [sp, #360]                 ; 8-byte Folded Reload
	stp	x22, x0, [sp, #336]             ; 16-byte Folded Spill
	ldr	x23, [sp, #328]                 ; 8-byte Folded Reload
LBB2_160:                               ; %.lr.ph.i.i208
                                        ; =>This Inner Loop Header: Depth=1
	stp	x2, x1, [sp, #296]              ; 16-byte Folded Spill
	ldr	x1, [x8]
	ldr	x2, [x21, #8]!
	mov	x27, x0
	mov	x0, x20
	blr	x23
	ldr	x1, [x22]
	and	w8, w0, #0xff
	ldr	x22, [sp, #336]                 ; 8-byte Folded Reload
	mov	x0, x20
	cmp	w8, #1
	cinc	x26, x26, eq
	ldr	x2, [x22, #8]!
	blr	x23
	ldr	x1, [x27]
	and	w8, w0, #0xff
	ldr	x27, [sp, #344]                 ; 8-byte Folded Reload
	mov	x0, x20
	cmp	w8, #1
	cinc	x28, x28, eq
	ldr	x2, [x27, #8]!
	blr	x23
	ldr	x1, [x19]
	and	w8, w0, #0xff
	ldr	x2, [x24, #8]!
	mov	x0, x20
	cmp	w8, #1
	cinc	x25, x25, eq
	blr	x23
	ldp	x2, x1, [sp, #296]              ; 16-byte Folded Reload
	and	w9, w0, #0xff
	mov	x8, x21
	cmp	w9, #1
	mov	x0, x27
	mov	x19, x24
	stp	x22, x27, [sp, #336]            ; 16-byte Folded Spill
	sub	x2, x2, #4
	cinc	x1, x1, eq
	cmp	x2, #7
	b.hi	LBB2_160
	b	LBB2_162
LBB2_161:
	mov	x24, x25
	stp	x22, x0, [sp, #336]             ; 16-byte Folded Spill
	ldp	x25, x28, [sp, #280]            ; 16-byte Folded Reload
	mov	x21, x8
	mov	x26, x15
LBB2_162:                               ; %._crit_edge.i.i217
	add	x8, x25, x26
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	add	x8, x28, x8
	cmn	x8, x1
	b.ne	LBB2_166
; %bb.163:
	mov	x19, x1
	ldr	x0, [sp, #360]                  ; 8-byte Folded Reload
	ldp	x1, x2, [x21]
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	mov	x1, x19
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB2_166
; %bb.164:
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	ldr	x0, [sp, #360]                  ; 8-byte Folded Reload
	ldp	x1, x2, [x8]
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	mov	x1, x19
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB2_166
; %bb.165:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	ldr	x0, [sp, #360]                  ; 8-byte Folded Reload
	ldp	x1, x2, [x8]
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	mov	x1, x19
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB2_1049
LBB2_166:                               ; %.critedge2.i.i221
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	str	x21, [sp, #320]                 ; 8-byte Folded Spill
	sub	x11, x8, x26
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	cmp	x11, #1
	sub	x12, x8, x28
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	sub	x10, x8, x25
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	sub	x19, x8, x1
	b.eq	LBB2_179
; %bb.167:                              ; %.critedge2.i.i221
	cmp	x12, #1
	b.eq	LBB2_179
; %bb.168:                              ; %.critedge2.i.i221
	cmp	x10, #1
	b.eq	LBB2_179
; %bb.169:                              ; %.critedge2.i.i221
	cmp	x19, #1
	b.eq	LBB2_179
; %bb.170:
	mov	x23, x28
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
	ldr	w7, [sp, #272]                  ; 4-byte Folded Reload
	b	LBB2_961
LBB2_171:
	add	x2, x22, x28
	mov	x0, x24
	mov	x1, x22
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	cmp	x12, #1
	str	x19, [sp, #232]                 ; 8-byte Folded Spill
	cset	w8, eq
	cmp	x10, #1
	str	x20, [sp, #256]                 ; 8-byte Folded Spill
	cset	w19, eq
	stp	x12, x10, [sp, #40]             ; 16-byte Folded Spill
	csel	w20, wzr, w8, ne
	mov	x27, x28
	str	x2, [sp, #288]                  ; 8-byte Folded Spill
	mov	x22, x11
	blr	x26
	add	x2, x22, x28
	and	w8, w0, #0xff
	mov	x0, x24
	mov	x1, x22
	cmp	w8, #1
	str	x21, [sp, #176]                 ; 8-byte Folded Spill
	csel	w20, wzr, w20, ne
	cmp	x21, #1
	cset	w21, eq
	csel	w19, wzr, w19, ne
	str	x2, [sp, #296]                  ; 8-byte Folded Spill
	blr	x26
	ldr	x1, [sp, #344]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	mov	x0, x24
	cmp	w8, #1
	cset	w22, eq
	cmp	x25, #1
	add	x2, x1, x28
	str	x25, [sp, #248]                 ; 8-byte Folded Spill
	csel	w21, wzr, w21, ne
	str	x2, [sp, #336]                  ; 8-byte Folded Spill
	blr	x26
	and	w9, w0, #0xff
	mov	w8, #2
	cmp	w9, #1
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	cset	w9, eq
	tst	w19, w22
	csel	w8, w8, wzr, ne
	tst	w21, w9
	mov	w9, #4
	orr	w8, w8, w20
	csel	w9, w9, wzr, ne
	orr	w8, w8, w9
Lloh2:
	adrp	x9, LJTI2_4@PAGE
Lloh3:
	add	x9, x9, LJTI2_4@PAGEOFF
	adr	x10, LBB2_172
	ldrh	w11, [x9, x8, lsl #1]
	add	x10, x10, x11, lsl #2
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	ldp	x22, x11, [sp, #304]            ; 16-byte Folded Reload
	ldp	x0, x14, [sp, #224]             ; 16-byte Folded Reload
	ldr	x20, [sp, #256]                 ; 8-byte Folded Reload
	ldr	x13, [sp, #320]                 ; 8-byte Folded Reload
	br	x10
LBB2_172:
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	sub	x8, x13, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x19, x10, x8
	sub	x26, x13, x8
	tbnz	w20, #0, LBB2_396
; %bb.173:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x19
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x19
	mov	x1, x26
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x19, x19, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_397
LBB2_174:
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	str	x1, [sp, #304]                  ; 8-byte Folded Spill
	mov	w1, #3
	mov	x8, x22
	cmp	x10, #1
	stp	x17, x4, [sp, #288]             ; 16-byte Folded Spill
	mov	x0, x24
	str	x30, [sp, #224]                 ; 8-byte Folded Spill
	str	x10, [sp, #56]                  ; 8-byte Folded Spill
	cset	w19, eq
	mov	x22, x9
	blr	x8
	mov	x8, x21
	ldr	x1, [x21]
	mov	x0, x24
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	cmp	x20, #1
	str	x20, [sp, #72]                  ; 8-byte Folded Spill
	ldr	x2, [x8, #8]!
	cset	w20, eq
	csel	w19, wzr, w19, ne
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	blr	x26
	ldr	x9, [sp, #344]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	mov	x0, x24
	cmp	w8, #1
	csel	w19, wzr, w19, ne
	cmp	x22, #1
	ldr	x1, [x9]
	str	x22, [sp, #80]                  ; 8-byte Folded Spill
	ldr	x2, [x9, #8]!
	cset	w21, eq
	csel	w20, wzr, w20, ne
	str	x9, [sp, #48]                   ; 8-byte Folded Spill
	blr	x26
	ldr	x9, [sp, #336]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	mov	x0, x24
	cmp	w8, #1
	cset	w22, eq
	cmp	x23, #1
	mov	x10, x9
	ldr	x1, [x9]
	str	x23, [sp, #216]                 ; 8-byte Folded Spill
	csel	w21, wzr, w21, ne
	mov	x23, x24
	ldr	x2, [x10, #8]!
	str	x10, [sp, #64]                  ; 8-byte Folded Spill
	blr	x26
	and	w9, w0, #0xff
	mov	w8, #2
	cmp	w9, #1
	cset	w9, eq
	tst	w20, w22
	csel	w8, w8, wzr, ne
	tst	w21, w9
	mov	w9, #4
	orr	w8, w8, w19
	csel	w9, w9, wzr, ne
	orr	w8, w8, w9
Lloh4:
	adrp	x9, LJTI2_2@PAGE
Lloh5:
	add	x9, x9, LJTI2_2@PAGEOFF
	adr	x10, LBB2_175
	ldrh	w11, [x9, x8, lsl #1]
	add	x10, x10, x11, lsl #2
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	ldp	x26, x5, [sp, #328]             ; 16-byte Folded Reload
	ldp	x7, x6, [sp, #312]              ; 16-byte Folded Reload
	ldp	x4, x1, [sp, #296]              ; 16-byte Folded Reload
	ldr	x30, [sp, #224]                 ; 8-byte Folded Reload
	ldr	x17, [sp, #288]                 ; 8-byte Folded Reload
	br	x10
LBB2_175:
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	ldr	x12, [sp, #344]                 ; 8-byte Folded Reload
	sub	x11, x12, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x12, x9
	tbnz	w11, #4, LBB2_177
; %bb.176:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_177:
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	ldr	x11, [x14]
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x14]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.hs	LBB2_652
LBB2_178:
	mov	x30, xzr
	mov	x4, xzr
	mov	x24, x23
	b	LBB2_1106
LBB2_179:
	str	x28, [sp, #288]                 ; 8-byte Folded Spill
	mov	x28, x11
	cmp	x11, #1
	mov	x11, x21
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	stp	x1, x24, [sp, #304]             ; 16-byte Folded Spill
	ldr	x1, [x21]
	cset	w8, eq
	ldr	x2, [x11, #8]!
	mov	x0, x23
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	cmp	x12, #1
	str	x12, [sp, #80]                  ; 8-byte Folded Spill
	cset	w22, eq
	csel	w20, wzr, w8, ne
	str	x11, [sp, #224]                 ; 8-byte Folded Spill
	mov	x21, x10
	blr	x24
	ldr	x9, [sp, #336]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x0, x23
	csel	w27, wzr, w20, ne
	cmp	x21, #1
	mov	x20, x9
	ldr	x1, [x9]
	csel	w8, wzr, w22, ne
	str	x21, [sp, #88]                  ; 8-byte Folded Spill
	cset	w21, eq
	ldr	x2, [x20, #8]!
	str	w8, [sp, #296]                  ; 4-byte Folded Spill
	blr	x24
	ldr	x10, [sp, #344]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	cset	w22, eq
	cmp	x19, #1
	mov	x9, x10
	ldr	x1, [x10]
	str	x19, [sp, #280]                 ; 8-byte Folded Spill
	csel	w21, wzr, w21, ne
	ldr	x2, [x9, #8]!
	str	x9, [sp, #72]                   ; 8-byte Folded Spill
	blr	x24
	ldr	w10, [sp, #296]                 ; 4-byte Folded Reload
	and	w9, w0, #0xff
	cmp	w9, #1
	mov	w8, #2
	cset	w9, eq
	tst	w10, w22
	csel	w8, w8, wzr, ne
	tst	w21, w9
	mov	w9, #4
	orr	w8, w8, w27
	csel	w9, w9, wzr, ne
	orr	w8, w8, w9
Lloh6:
	adrp	x9, LJTI2_0@PAGE
Lloh7:
	add	x9, x9, LJTI2_0@PAGEOFF
	adr	x10, LBB2_180
	ldrh	w11, [x9, x8, lsl #1]
	add	x10, x10, x11, lsl #2
	ldr	w7, [sp, #272]                  ; 4-byte Folded Reload
	ldp	x6, x5, [sp, #312]              ; 16-byte Folded Reload
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	br	x10
LBB2_180:
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	ldr	x12, [sp, #336]                 ; 8-byte Folded Reload
	sub	x11, x12, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x12, x9
	tbnz	w11, #4, LBB2_182
; %bb.181:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_182:
	ldr	x14, [sp, #336]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
	ldr	x11, [x14]
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x14]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_737
; %bb.183:                              ; %.lr.ph188.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_733
; %bb.184:                              ; %vector.scevcheck1200
	ldr	x13, [sp, #336]                 ; 8-byte Folded Reload
	sub	x12, x11, #1
	sub	x14, x13, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_733
; %bb.185:                              ; %vector.scevcheck1200
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_733
; %bb.186:                              ; %vector.scevcheck1200
	lsr	x12, x12, #61
	cbnz	x12, LBB2_733
; %bb.187:                              ; %vector.memcheck1209
	ldr	x14, [sp, #208]                 ; 8-byte Folded Reload
	lsl	x12, x11, #3
	ldr	x4, [sp, #336]                  ; 8-byte Folded Reload
	add	x13, x12, #8
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x17, x14, #8
	add	x0, x14, x13
	sub	x16, x4, x12
	cmp	x17, x4
	ccmp	x16, x0, #2, lo
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x4
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x4, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_948
; %bb.188:                              ; %vector.memcheck1209
	tbnz	w12, #0, LBB2_948
; %bb.189:                              ; %vector.memcheck1209
	tbnz	w13, #0, LBB2_948
; %bb.190:                              ; %vector.memcheck1209
	tbnz	w14, #0, LBB2_948
; %bb.191:                              ; %vector.memcheck1209
	tbnz	w15, #0, LBB2_948
; %bb.192:                              ; %vector.memcheck1209
	tbnz	w16, #0, LBB2_948
; %bb.193:                              ; %vector.ph1242
	ldr	x17, [sp, #208]                 ; 8-byte Folded Reload
	and	x16, x11, #0x7ffffffffffffffe
	ldr	x0, [sp, #336]                  ; 8-byte Folded Reload
	lsl	x15, x16, #3
	ubfx	x8, x8, #1, #1
	sub	x13, x10, x15
	add	x12, x17, x15
	add	x14, x9, x15
	sub	x15, x0, x15
	add	x17, x17, #8
	add	x9, x9, #8
	sub	x0, x0, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_194:                               ; %vector.body1256
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_194
; %bb.195:                              ; %middle.block1239
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	cmp	x11, x16
	b.ne	LBB2_735
	b	LBB2_737
LBB2_196:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	add	x10, x8, #1
	sub	x8, x21, x10
	udiv	x20, x8, x9
	str	x10, [sp, #280]                 ; 8-byte Folded Spill
	mul	x8, x20, x28
	add	x25, x10, x8
	sub	x19, x21, x8
	tbnz	w20, #0, LBB2_401
; %bb.197:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	ldr	x23, [sp, #264]                 ; 8-byte Folded Reload
	blr	x23
	mov	x0, x25
	mov	x1, x19
	blr	x23
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x19
	sub	x25, x25, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
	blr	x23
	add	x19, x19, x28
	sub	x20, x20, #1
	b	LBB2_402
LBB2_198:
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	sub	x8, x21, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x26, x10, x8
	sub	x25, x21, x8
	tbnz	w20, #0, LBB2_406
; %bb.199:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x26
	add	x0, x0, #784
	ldr	x22, [sp, #264]                 ; 8-byte Folded Reload
	blr	x22
	mov	x0, x26
	mov	x1, x25
	blr	x22
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x25
	sub	x26, x26, x28
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
	blr	x22
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	add	x25, x25, x28
	sub	x20, x20, #1
	b	LBB2_407
LBB2_200:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	add	x10, x8, #1
	sub	x8, x25, x10
	udiv	x20, x8, x9
	str	x10, [sp, #280]                 ; 8-byte Folded Spill
	mul	x8, x20, x28
	add	x27, x10, x8
	sub	x19, x25, x8
	tbnz	w20, #0, LBB2_411
; %bb.201:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x27
	mov	x1, x19
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x19
	sub	x27, x27, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
	blr	x21
	add	x19, x19, x28
	sub	x20, x20, #1
	b	LBB2_412
LBB2_202:
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	lsl	x11, x28, #1
	ldr	x10, [sp, #344]                 ; 8-byte Folded Reload
	mov	x12, x28
	str	x11, [sp, #296]                 ; 8-byte Folded Spill
	sub	x8, x10, x9
	udiv	x20, x8, x11
	mul	x8, x20, x28
	add	x25, x9, x8
	sub	x19, x10, x8
	tbnz	w20, #0, LBB2_416
; %bb.203:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x25
	mov	x1, x19
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x19
	sub	x25, x25, x28
	str	x8, [sp, #336]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	add	x19, x19, x28
	sub	x20, x20, #1
	b	LBB2_417
LBB2_204:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	add	x10, x8, #1
	sub	x8, x25, x10
	udiv	x20, x8, x9
	str	x10, [sp, #280]                 ; 8-byte Folded Spill
	mul	x8, x20, x28
	add	x27, x10, x8
	sub	x19, x25, x8
	tbnz	w20, #0, LBB2_422
; %bb.205:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x27
	mov	x1, x19
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x19
	sub	x27, x27, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
	blr	x21
	add	x19, x19, x28
	sub	x20, x20, #1
	b	LBB2_423
LBB2_206:
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	sub	x8, x25, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x23, x10, x8
	sub	x22, x25, x8
	tbnz	w20, #0, LBB2_464
; %bb.207:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x23
	add	x0, x0, #784
	ldr	x19, [sp, #264]                 ; 8-byte Folded Reload
	blr	x19
	mov	x0, x23
	mov	x1, x22
	blr	x19
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x22
	sub	x23, x23, x28
	str	x8, [sp, #360]                  ; 8-byte Folded Spill
	blr	x19
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	add	x22, x22, x28
	sub	x20, x20, #1
	b	LBB2_465
LBB2_208:
	add	x10, x22, #1
	lsl	x9, x28, #1
	sub	x8, x21, x10
	mov	x11, x28
	udiv	x20, x8, x9
	str	x10, [sp, #280]                 ; 8-byte Folded Spill
	mul	x8, x20, x28
	add	x27, x10, x8
	sub	x19, x21, x8
	tbnz	w20, #0, LBB2_468
; %bb.209:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	add	x0, x0, #784
	ldr	x23, [sp, #264]                 ; 8-byte Folded Reload
	blr	x23
	mov	x0, x27
	mov	x1, x19
	blr	x23
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x19
	sub	x27, x27, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
	blr	x23
	add	x19, x19, x28
	sub	x20, x20, #1
	b	LBB2_469
LBB2_210:
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	sub	x8, x21, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x19, x10, x8
	sub	x26, x21, x8
	tbnz	w20, #0, LBB2_473
; %bb.211:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x19
	add	x0, x0, #784
	ldr	x22, [sp, #264]                 ; 8-byte Folded Reload
	blr	x22
	mov	x0, x19
	mov	x1, x26
	blr	x22
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x19, x19, x28
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
	blr	x22
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_474
LBB2_212:
	add	x10, x13, #1
	lsl	x9, x28, #1
	sub	x8, x11, x10
	mov	x12, x28
	str	x23, [sp, #216]                 ; 8-byte Folded Spill
	udiv	x20, x8, x9
	str	x10, [sp, #280]                 ; 8-byte Folded Spill
	mul	x8, x20, x28
	add	x27, x10, x8
	sub	x19, x11, x8
	tbnz	w20, #0, LBB2_478
; %bb.213:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x27
	mov	x1, x19
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x19
	sub	x27, x27, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x11, [sp, #312]                 ; 8-byte Folded Reload
	add	x19, x19, x28
	sub	x20, x20, #1
	b	LBB2_479
LBB2_214:
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	lsl	x10, x28, #1
	mov	x11, x28
	sub	x8, x13, x9
	str	x10, [sp, #296]                 ; 8-byte Folded Spill
	udiv	x20, x8, x10
	mul	x8, x20, x28
	add	x27, x9, x8
	sub	x19, x13, x8
	tbnz	w20, #0, LBB2_483
; %bb.215:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x27
	mov	x1, x19
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x19
	sub	x27, x27, x28
	str	x8, [sp, #336]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	add	x19, x19, x28
	sub	x20, x20, #1
	b	LBB2_484
LBB2_216:
	add	x10, x22, #1
	lsl	x9, x28, #1
	sub	x8, x11, x10
	mov	x12, x28
	udiv	x20, x8, x9
	str	x10, [sp, #280]                 ; 8-byte Folded Spill
	mul	x8, x20, x28
	add	x27, x10, x8
	sub	x19, x11, x8
	tbnz	w20, #0, LBB2_489
; %bb.217:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x27
	mov	x1, x19
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x19
	sub	x27, x27, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x11, [sp, #312]                 ; 8-byte Folded Reload
	add	x19, x19, x28
	sub	x20, x20, #1
	b	LBB2_490
LBB2_218:
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x12, x28
	sub	x8, x11, x10
	udiv	x21, x8, x9
	mul	x8, x21, x28
	add	x23, x10, x8
	sub	x20, x11, x8
	tbnz	w21, #0, LBB2_533
; %bb.219:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x23
	add	x0, x0, #784
	ldr	x19, [sp, #264]                 ; 8-byte Folded Reload
	blr	x19
	mov	x0, x23
	mov	x1, x20
	blr	x19
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x20
	sub	x23, x23, x28
	str	x8, [sp, #360]                  ; 8-byte Folded Spill
	blr	x19
	ldr	x11, [sp, #312]                 ; 8-byte Folded Reload
	add	x20, x20, x28
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	sub	x21, x21, #1
	b	LBB2_534
LBB2_220:
	add	x8, x6, #1
	sub	x12, x5, x8
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x8, x10
	sub	x10, x5, x10
	tbnz	w12, #4, LBB2_222
; %bb.221:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB2_222:                               ; %._crit_edge.i292.i.i
	ldr	x12, [x5]
	cmp	x9, #2
	ldr	x13, [x8]
	str	x12, [x8]
	str	x13, [x5]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB2_953
; %bb.223:                              ; %.lr.ph185.preheader.i.i
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB2_950
; %bb.224:                              ; %vector.scevcheck1981
	sub	x13, x12, #1
	sub	x15, x5, #8
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB2_950
; %bb.225:                              ; %vector.scevcheck1981
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB2_950
; %bb.226:                              ; %vector.scevcheck1981
	lsr	x13, x13, #61
	cbnz	x13, LBB2_950
; %bb.227:                              ; %vector.memcheck1990
	add	x0, x6, #9
	lsl	x14, x12, #3
	add	x1, x0, x14
	sub	x17, x5, x14
	cmp	x0, x5
	sub	x2, x11, x14
	ccmp	x17, x1, #2, lo
	add	x3, x10, #8
	add	x4, x3, x14
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x5
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x5, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB2_949
; %bb.228:                              ; %vector.memcheck1990
	tbnz	w13, #0, LBB2_949
; %bb.229:                              ; %vector.memcheck1990
	tbnz	w14, #0, LBB2_949
; %bb.230:                              ; %vector.memcheck1990
	tbnz	w15, #0, LBB2_949
; %bb.231:                              ; %vector.memcheck1990
	tbnz	w16, #0, LBB2_949
; %bb.232:                              ; %vector.memcheck1990
	tbnz	w17, #0, LBB2_949
; %bb.233:                              ; %vector.ph2023
	and	x16, x12, #0x7ffffffffffffffe
	ubfx	x9, x9, #1, #1
	lsl	x15, x16, #3
	add	x17, x6, #9
	add	x8, x8, x15
	sub	x13, x11, x15
	add	x14, x10, x15
	sub	x15, x5, x15
	add	x10, x10, #8
	sub	x0, x5, #16
	sub	x11, x11, #16
	neg	x1, x16
LBB2_234:                               ; %vector.body2037
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x10]
	ldr	q1, [x11]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x11], #-16
	str	q1, [x10], #16
	b.ne	LBB2_234
; %bb.235:                              ; %middle.block2020
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	cmp	x12, x16
	b.ne	LBB2_951
	b	LBB2_953
LBB2_236:
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	sub	x11, x5, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x5, x9
	tbnz	w11, #4, LBB2_238
; %bb.237:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_238:
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	mov	x24, x23
	ldr	x11, [x5]
	cmp	x8, #2
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x5]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_727
; %bb.239:                              ; %.lr.ph179.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_723
; %bb.240:                              ; %vector.scevcheck1910
	sub	x12, x11, #1
	sub	x14, x5, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_723
; %bb.241:                              ; %vector.scevcheck1910
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_723
; %bb.242:                              ; %vector.scevcheck1910
	lsr	x12, x12, #61
	cbnz	x12, LBB2_723
; %bb.243:                              ; %vector.memcheck1919
	ldr	x14, [sp, #208]                 ; 8-byte Folded Reload
	lsl	x12, x11, #3
	add	x13, x12, #8
	sub	x16, x5, x12
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x17, x14, #8
	add	x0, x14, x13
	cmp	x17, x5
	add	x3, x9, x13
	ccmp	x16, x0, #2, lo
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x5
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x5, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1053
; %bb.244:                              ; %vector.memcheck1919
	tbnz	w12, #0, LBB2_1053
; %bb.245:                              ; %vector.memcheck1919
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	tbnz	w13, #0, LBB2_723
; %bb.246:                              ; %vector.memcheck1919
	tbnz	w14, #0, LBB2_723
; %bb.247:                              ; %vector.memcheck1919
	tbnz	w15, #0, LBB2_723
; %bb.248:                              ; %vector.memcheck1919
	tbnz	w16, #0, LBB2_723
; %bb.249:                              ; %vector.ph1952
	ldr	x17, [sp, #208]                 ; 8-byte Folded Reload
	and	x16, x11, #0x7ffffffffffffffe
	lsl	x15, x16, #3
	ubfx	x8, x8, #1, #1
	sub	x13, x10, x15
	add	x14, x9, x15
	add	x12, x17, x15
	sub	x15, x5, x15
	add	x17, x17, #8
	add	x9, x9, #8
	sub	x0, x5, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_250:                               ; %vector.body1966
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_250
; %bb.251:                              ; %middle.block1949
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	cmp	x11, x16
	b.ne	LBB2_725
	b	LBB2_727
LBB2_252:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x8, x8, #1
	sub	x12, x7, x8
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x8, x10
	sub	x10, x7, x10
	tbnz	w12, #4, LBB2_254
; %bb.253:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB2_254:                               ; %._crit_edge.i312.i.i
	ldr	x12, [x7]
	cmp	x9, #2
	ldr	x13, [x8]
	str	x12, [x8]
	str	x13, [x7]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB2_1058
; %bb.255:                              ; %.lr.ph173.preheader.i.i
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB2_1055
; %bb.256:                              ; %vector.scevcheck1839
	sub	x13, x12, #1
	sub	x15, x7, #8
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB2_1055
; %bb.257:                              ; %vector.scevcheck1839
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB2_1055
; %bb.258:                              ; %vector.scevcheck1839
	lsr	x13, x13, #61
	cbnz	x13, LBB2_1055
; %bb.259:                              ; %vector.memcheck1848
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	lsl	x14, x12, #3
	sub	x17, x7, x14
	sub	x2, x11, x14
	add	x3, x10, #8
	add	x0, x13, #9
	add	x4, x3, x14
	add	x1, x0, x14
	cmp	x0, x7
	ccmp	x17, x1, #2, lo
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x7
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x7, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB2_1054
; %bb.260:                              ; %vector.memcheck1848
	tbnz	w13, #0, LBB2_1054
; %bb.261:                              ; %vector.memcheck1848
	ldr	x4, [sp, #296]                  ; 8-byte Folded Reload
	tbnz	w14, #0, LBB2_1055
; %bb.262:                              ; %vector.memcheck1848
	tbnz	w15, #0, LBB2_1055
; %bb.263:                              ; %vector.memcheck1848
	tbnz	w16, #0, LBB2_1055
; %bb.264:                              ; %vector.memcheck1848
	tbnz	w17, #0, LBB2_1055
; %bb.265:                              ; %vector.ph1881
	ldr	x17, [sp, #344]                 ; 8-byte Folded Reload
	and	x16, x12, #0x7ffffffffffffffe
	lsl	x15, x16, #3
	ubfx	x9, x9, #1, #1
	add	x8, x8, x15
	sub	x13, x11, x15
	add	x14, x10, x15
	sub	x15, x7, x15
	add	x17, x17, #9
	add	x10, x10, #8
	sub	x0, x7, #16
	sub	x11, x11, #16
	neg	x1, x16
LBB2_266:                               ; %vector.body1895
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x10]
	ldr	q1, [x11]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x11], #-16
	str	q1, [x10], #16
	b.ne	LBB2_266
; %bb.267:                              ; %middle.block1878
	cmp	x12, x16
	b.ne	LBB2_1056
	b	LBB2_1058
LBB2_268:
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	ldr	x12, [sp, #344]                 ; 8-byte Folded Reload
	sub	x11, x12, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x12, x9
	tbnz	w11, #4, LBB2_270
; %bb.269:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_270:
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	mov	x24, x23
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	w5, [sp, #232]                  ; 4-byte Folded Reload
	ldr	x11, [x14]
	ldr	x12, [x13]
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	str	x11, [x13]
	str	x12, [x14]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_668
; %bb.271:                              ; %.lr.ph161.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_665
; %bb.272:                              ; %vector.scevcheck1697
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	sub	x12, x11, #1
	sub	x14, x13, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_665
; %bb.273:                              ; %vector.scevcheck1697
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_665
; %bb.274:                              ; %vector.scevcheck1697
	lsr	x12, x12, #61
	cbnz	x12, LBB2_665
; %bb.275:                              ; %vector.memcheck1706
	ldr	x14, [sp, #208]                 ; 8-byte Folded Reload
	lsl	x12, x11, #3
	ldr	x4, [sp, #344]                  ; 8-byte Folded Reload
	add	x13, x12, #8
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x17, x14, #8
	add	x0, x14, x13
	sub	x16, x4, x12
	cmp	x17, x4
	ccmp	x16, x0, #2, lo
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x4
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x4, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_665
; %bb.276:                              ; %vector.memcheck1706
	tbnz	w12, #0, LBB2_665
; %bb.277:                              ; %vector.memcheck1706
	tbnz	w13, #0, LBB2_665
; %bb.278:                              ; %vector.memcheck1706
	tbnz	w14, #0, LBB2_665
; %bb.279:                              ; %vector.memcheck1706
	tbnz	w15, #0, LBB2_665
; %bb.280:                              ; %vector.memcheck1706
	tbnz	w16, #0, LBB2_665
; %bb.281:                              ; %vector.ph1739
	ldr	x17, [sp, #208]                 ; 8-byte Folded Reload
	and	x16, x11, #0x7ffffffffffffffe
	ldr	x0, [sp, #344]                  ; 8-byte Folded Reload
	lsl	x15, x16, #3
	ubfx	x8, x8, #1, #1
	sub	x13, x10, x15
	add	x12, x17, x15
	add	x14, x9, x15
	sub	x15, x0, x15
	add	x17, x17, #8
	add	x9, x9, #8
	sub	x0, x0, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_282:                               ; %vector.body1753
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_282
; %bb.283:                              ; %middle.block1736
	cmp	x11, x16
	b.ne	LBB2_666
	b	LBB2_668
LBB2_284:
	add	x8, x6, #1
	sub	x12, x7, x8
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x8, x10
	sub	x10, x7, x10
	tbnz	w12, #4, LBB2_286
; %bb.285:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB2_286:                               ; %._crit_edge.i342.i.i
	ldr	x12, [x7]
	cmp	x9, #2
	ldr	x13, [x8]
	str	x12, [x8]
	str	x13, [x7]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB2_687
; %bb.287:                              ; %.lr.ph155.preheader.i.i
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB2_684
; %bb.288:                              ; %vector.scevcheck1626
	sub	x13, x12, #1
	sub	x15, x7, #8
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB2_684
; %bb.289:                              ; %vector.scevcheck1626
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB2_684
; %bb.290:                              ; %vector.scevcheck1626
	lsr	x13, x13, #61
	cbnz	x13, LBB2_684
; %bb.291:                              ; %vector.memcheck1635
	add	x0, x6, #9
	lsl	x14, x12, #3
	add	x1, x0, x14
	sub	x17, x7, x14
	cmp	x0, x7
	sub	x2, x11, x14
	ccmp	x17, x1, #2, lo
	add	x3, x10, #8
	add	x4, x3, x14
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x7
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x7, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB2_684
; %bb.292:                              ; %vector.memcheck1635
	tbnz	w13, #0, LBB2_684
; %bb.293:                              ; %vector.memcheck1635
	tbnz	w14, #0, LBB2_684
; %bb.294:                              ; %vector.memcheck1635
	tbnz	w15, #0, LBB2_684
; %bb.295:                              ; %vector.memcheck1635
	tbnz	w16, #0, LBB2_684
; %bb.296:                              ; %vector.memcheck1635
	tbnz	w17, #0, LBB2_684
; %bb.297:                              ; %vector.ph1668
	and	x16, x12, #0x7ffffffffffffffe
	ubfx	x9, x9, #1, #1
	lsl	x15, x16, #3
	add	x17, x6, #9
	add	x8, x8, x15
	sub	x13, x11, x15
	add	x14, x10, x15
	sub	x15, x7, x15
	add	x10, x10, #8
	sub	x0, x7, #16
	sub	x11, x11, #16
	neg	x1, x16
LBB2_298:                               ; %vector.body1682
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x10]
	ldr	q1, [x11]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x11], #-16
	str	q1, [x10], #16
	b.ne	LBB2_298
; %bb.299:                              ; %middle.block1665
	cmp	x12, x16
	b.ne	LBB2_685
	b	LBB2_687
LBB2_300:
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	sub	x11, x7, x13
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x13, x9
	sub	x9, x7, x9
	tbnz	w11, #4, LBB2_302
; %bb.301:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_302:                               ; %._crit_edge.i352.i.i
	ldr	x11, [x7]
	cmp	x8, #2
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x7]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_1241
; %bb.303:                              ; %.lr.ph149.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.hs	LBB2_917
; %bb.304:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #312]                 ; 8-byte Folded Reload
	mov	x13, x10
	mov	x14, x9
	b	LBB2_942
LBB2_305:
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	add	x8, x5, #1
	sub	x12, x13, x8
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x8, x10
	sub	x10, x13, x10
	tbnz	w12, #4, LBB2_307
; %bb.306:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB2_307:                               ; %._crit_edge.i290.i.i
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	cmp	x9, #2
	ldr	x13, [x8]
	ldr	x12, [x14]
	str	x12, [x8]
	str	x13, [x14]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB2_742
; %bb.308:                              ; %.lr.ph182.preheader.i.i
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB2_738
; %bb.309:                              ; %vector.scevcheck1129
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	sub	x13, x12, #1
	sub	x15, x14, #8
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB2_738
; %bb.310:                              ; %vector.scevcheck1129
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB2_738
; %bb.311:                              ; %vector.scevcheck1129
	lsr	x13, x13, #61
	cbnz	x13, LBB2_738
; %bb.312:                              ; %vector.memcheck1138
	mov	x21, x20
	ldr	x20, [sp, #344]                 ; 8-byte Folded Reload
	add	x0, x5, #9
	lsl	x14, x12, #3
	add	x1, x0, x14
	sub	x2, x11, x14
	sub	x17, x20, x14
	cmp	x0, x20
	ccmp	x17, x1, #2, lo
	add	x3, x10, #8
	add	x4, x3, x14
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x20
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x20, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB2_1254
; %bb.313:                              ; %vector.memcheck1138
	tbnz	w13, #0, LBB2_1254
; %bb.314:                              ; %vector.memcheck1138
	mov	x20, x21
	tbnz	w14, #0, LBB2_955
; %bb.315:                              ; %vector.memcheck1138
	tbnz	w15, #0, LBB2_955
; %bb.316:                              ; %vector.memcheck1138
	tbnz	w16, #0, LBB2_955
; %bb.317:                              ; %vector.memcheck1138
	tbnz	w17, #0, LBB2_955
; %bb.318:                              ; %vector.ph1171
	ldr	x0, [sp, #344]                  ; 8-byte Folded Reload
	and	x16, x12, #0x7ffffffffffffffe
	lsl	x15, x16, #3
	ubfx	x9, x9, #1, #1
	add	x8, x8, x15
	sub	x13, x11, x15
	add	x14, x10, x15
	sub	x15, x0, x15
	add	x17, x5, #9
	add	x10, x10, #8
	sub	x0, x0, #16
	sub	x11, x11, #16
	neg	x1, x16
LBB2_319:                               ; %vector.body1185
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x10]
	ldr	q1, [x11]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x11], #-16
	str	q1, [x10], #16
	b.ne	LBB2_319
; %bb.320:                              ; %middle.block1168
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	cmp	x12, x16
	b.ne	LBB2_740
	b	LBB2_742
LBB2_321:
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	ldr	x12, [sp, #344]                 ; 8-byte Folded Reload
	sub	x11, x12, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x12, x9
	tbnz	w11, #4, LBB2_323
; %bb.322:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_323:
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
	ldr	x11, [x14]
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x14]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_732
; %bb.324:                              ; %.lr.ph176.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_728
; %bb.325:                              ; %vector.scevcheck1058
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	sub	x12, x11, #1
	sub	x14, x13, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_728
; %bb.326:                              ; %vector.scevcheck1058
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_728
; %bb.327:                              ; %vector.scevcheck1058
	lsr	x12, x12, #61
	cbnz	x12, LBB2_728
; %bb.328:                              ; %vector.memcheck1067
	ldr	x14, [sp, #208]                 ; 8-byte Folded Reload
	lsl	x12, x11, #3
	ldr	x4, [sp, #344]                  ; 8-byte Folded Reload
	add	x13, x12, #8
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x17, x14, #8
	add	x0, x14, x13
	sub	x16, x4, x12
	cmp	x17, x4
	ccmp	x16, x0, #2, lo
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x4
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x4, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1255
; %bb.329:                              ; %vector.memcheck1067
	tbnz	w12, #0, LBB2_1255
; %bb.330:                              ; %vector.memcheck1067
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	tbnz	w13, #0, LBB2_728
; %bb.331:                              ; %vector.memcheck1067
	tbnz	w14, #0, LBB2_728
; %bb.332:                              ; %vector.memcheck1067
	tbnz	w15, #0, LBB2_728
; %bb.333:                              ; %vector.memcheck1067
	tbnz	w16, #0, LBB2_728
; %bb.334:                              ; %vector.ph1100
	ldr	x17, [sp, #208]                 ; 8-byte Folded Reload
	and	x16, x11, #0x7ffffffffffffffe
	ldr	x0, [sp, #344]                  ; 8-byte Folded Reload
	lsl	x15, x16, #3
	ubfx	x8, x8, #1, #1
	sub	x13, x10, x15
	add	x12, x17, x15
	add	x14, x9, x15
	sub	x15, x0, x15
	add	x17, x17, #8
	add	x9, x9, #8
	sub	x0, x0, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_335:                               ; %vector.body1114
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_335
; %bb.336:                              ; %middle.block1097
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	cmp	x11, x16
	b.ne	LBB2_730
	b	LBB2_732
LBB2_337:
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x8, x8, #1
	sub	x12, x6, x8
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x8, x10
	sub	x10, x6, x10
	tbnz	w12, #4, LBB2_339
; %bb.338:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB2_339:                               ; %._crit_edge.i310.i.i
	ldr	x12, [x6]
	cmp	x9, #2
	ldr	x13, [x8]
	str	x12, [x8]
	str	x13, [x6]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB2_691
; %bb.340:                              ; %.lr.ph170.preheader.i.i
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB2_688
; %bb.341:                              ; %vector.scevcheck987
	sub	x13, x12, #1
	sub	x15, x6, #8
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB2_688
; %bb.342:                              ; %vector.scevcheck987
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB2_688
; %bb.343:                              ; %vector.scevcheck987
	lsr	x13, x13, #61
	cbnz	x13, LBB2_688
; %bb.344:                              ; %vector.memcheck996
	ldr	x13, [sp, #336]                 ; 8-byte Folded Reload
	lsl	x14, x12, #3
	sub	x17, x6, x14
	sub	x2, x11, x14
	add	x3, x10, #8
	add	x0, x13, #9
	add	x4, x3, x14
	add	x1, x0, x14
	cmp	x0, x6
	ccmp	x17, x1, #2, lo
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x6
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x6, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB2_688
; %bb.345:                              ; %vector.memcheck996
	tbnz	w13, #0, LBB2_688
; %bb.346:                              ; %vector.memcheck996
	tbnz	w14, #0, LBB2_688
; %bb.347:                              ; %vector.memcheck996
	tbnz	w15, #0, LBB2_688
; %bb.348:                              ; %vector.memcheck996
	tbnz	w16, #0, LBB2_688
; %bb.349:                              ; %vector.memcheck996
	tbnz	w17, #0, LBB2_688
; %bb.350:                              ; %vector.ph1029
	ldr	x17, [sp, #336]                 ; 8-byte Folded Reload
	and	x16, x12, #0x7ffffffffffffffe
	lsl	x15, x16, #3
	ubfx	x9, x9, #1, #1
	add	x8, x8, x15
	sub	x13, x11, x15
	add	x14, x10, x15
	sub	x15, x6, x15
	add	x17, x17, #9
	add	x10, x10, #8
	sub	x0, x6, #16
	sub	x11, x11, #16
	neg	x1, x16
LBB2_351:                               ; %vector.body1043
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x10]
	ldr	q1, [x11]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x11], #-16
	str	q1, [x10], #16
	b.ne	LBB2_351
; %bb.352:                              ; %middle.block1026
	cmp	x12, x16
	b.ne	LBB2_689
	b	LBB2_691
LBB2_353:
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	ldr	x12, [sp, #336]                 ; 8-byte Folded Reload
	sub	x11, x12, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x12, x9
	tbnz	w11, #4, LBB2_355
; %bb.354:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_355:
	ldr	x14, [sp, #336]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
	ldr	x11, [x14]
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x14]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_695
; %bb.356:                              ; %.lr.ph158.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_692
; %bb.357:                              ; %vector.scevcheck845
	ldr	x13, [sp, #336]                 ; 8-byte Folded Reload
	sub	x12, x11, #1
	sub	x14, x13, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_692
; %bb.358:                              ; %vector.scevcheck845
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_692
; %bb.359:                              ; %vector.scevcheck845
	lsr	x12, x12, #61
	cbnz	x12, LBB2_692
; %bb.360:                              ; %vector.memcheck854
	ldr	x14, [sp, #208]                 ; 8-byte Folded Reload
	lsl	x12, x11, #3
	ldr	x4, [sp, #336]                  ; 8-byte Folded Reload
	add	x13, x12, #8
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x17, x14, #8
	add	x0, x14, x13
	sub	x16, x4, x12
	cmp	x17, x4
	ccmp	x16, x0, #2, lo
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x4
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x4, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_692
; %bb.361:                              ; %vector.memcheck854
	tbnz	w12, #0, LBB2_692
; %bb.362:                              ; %vector.memcheck854
	tbnz	w13, #0, LBB2_692
; %bb.363:                              ; %vector.memcheck854
	tbnz	w14, #0, LBB2_692
; %bb.364:                              ; %vector.memcheck854
	tbnz	w15, #0, LBB2_692
; %bb.365:                              ; %vector.memcheck854
	tbnz	w16, #0, LBB2_692
; %bb.366:                              ; %vector.ph887
	ldr	x17, [sp, #208]                 ; 8-byte Folded Reload
	and	x16, x11, #0x7ffffffffffffffe
	ldr	x0, [sp, #336]                  ; 8-byte Folded Reload
	lsl	x15, x16, #3
	ubfx	x8, x8, #1, #1
	sub	x13, x10, x15
	add	x12, x17, x15
	add	x14, x9, x15
	sub	x15, x0, x15
	add	x17, x17, #8
	add	x9, x9, #8
	sub	x0, x0, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_367:                               ; %vector.body901
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_367
; %bb.368:                              ; %middle.block884
	cmp	x11, x16
	b.ne	LBB2_693
	b	LBB2_695
LBB2_369:
	add	x8, x5, #1
	sub	x12, x6, x8
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x8, x10
	sub	x10, x6, x10
	tbnz	w12, #4, LBB2_371
; %bb.370:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB2_371:                               ; %._crit_edge.i340.i.i
	ldr	x12, [x6]
	cmp	x9, #2
	ldr	x13, [x8]
	str	x12, [x8]
	str	x13, [x6]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB2_714
; %bb.372:                              ; %.lr.ph152.preheader.i.i
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB2_711
; %bb.373:                              ; %vector.scevcheck774
	sub	x13, x12, #1
	sub	x15, x6, #8
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB2_711
; %bb.374:                              ; %vector.scevcheck774
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB2_711
; %bb.375:                              ; %vector.scevcheck774
	lsr	x13, x13, #61
	cbnz	x13, LBB2_711
; %bb.376:                              ; %vector.memcheck783
	add	x0, x5, #9
	lsl	x14, x12, #3
	add	x1, x0, x14
	sub	x17, x6, x14
	cmp	x0, x6
	sub	x2, x11, x14
	ccmp	x17, x1, #2, lo
	add	x3, x10, #8
	add	x4, x3, x14
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x6
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x6, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB2_711
; %bb.377:                              ; %vector.memcheck783
	tbnz	w13, #0, LBB2_711
; %bb.378:                              ; %vector.memcheck783
	tbnz	w14, #0, LBB2_711
; %bb.379:                              ; %vector.memcheck783
	tbnz	w15, #0, LBB2_711
; %bb.380:                              ; %vector.memcheck783
	tbnz	w16, #0, LBB2_711
; %bb.381:                              ; %vector.memcheck783
	tbnz	w17, #0, LBB2_711
; %bb.382:                              ; %vector.ph816
	and	x16, x12, #0x7ffffffffffffffe
	ubfx	x9, x9, #1, #1
	lsl	x15, x16, #3
	add	x17, x5, #9
	add	x8, x8, x15
	sub	x13, x11, x15
	add	x14, x10, x15
	sub	x15, x6, x15
	add	x10, x10, #8
	sub	x0, x6, #16
	sub	x11, x11, #16
	neg	x1, x16
LBB2_383:                               ; %vector.body830
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x10]
	ldr	q1, [x11]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x11], #-16
	str	q1, [x10], #16
	b.ne	LBB2_383
; %bb.384:                              ; %middle.block813
	cmp	x12, x16
	b.ne	LBB2_712
	b	LBB2_714
LBB2_385:
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	sub	x11, x6, x13
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x13, x9
	sub	x9, x6, x9
	tbnz	w11, #4, LBB2_387
; %bb.386:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_387:                               ; %._crit_edge.i350.i.i
	ldr	x11, [x6]
	cmp	x8, #2
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x6]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_1049
; %bb.388:                              ; %.lr.ph146.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.hs	LBB2_929
; %bb.389:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	b	LBB2_945
LBB2_390:                               ; %._crit_edge.i.i.i
	neg	x8, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
LBB2_391:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_392:                               ; =>This Inner Loop Header: Depth=1
	add	x21, x10, x22
	add	x0, sp, #1, lsl #12             ; =4096
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x25, x26
	add	x27, x26, x22
	add	x0, x0, #688
	mov	x1, x21
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x20, x8, x23
	add	x28, x19, x23
	blr	x26
	mov	x0, x21
	mov	x1, x20
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x27
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x27
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_394
; %bb.393:                              ;   in Loop: Header=BB2_392 Depth=1
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	mov	x26, x25
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_392
LBB2_394:                               ; %sort.quad_reversal.exit.i.i
	str	xzr, [sp, #216]                 ; 8-byte Folded Spill
LBB2_395:                               ; %sort.quad_reversal.exit399.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	str	xzr, [sp, #224]                 ; 8-byte Folded Spill
	ldp	x22, x0, [sp, #248]             ; 16-byte Folded Reload
	ldp	x21, x25, [sp, #304]            ; 16-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	b	LBB2_441
LBB2_396:                               ; %._crit_edge.i.i.i39
	neg	x8, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
LBB2_397:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_398:                               ; =>This Inner Loop Header: Depth=1
	add	x20, x10, x22
	add	x0, sp, #1, lsl #12             ; =4096
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x25, x26
	add	x27, x26, x22
	add	x0, x0, #688
	mov	x1, x20
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x8, x23
	add	x28, x19, x23
	blr	x26
	mov	x0, x20
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x27
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x27
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_400
; %bb.399:                              ;   in Loop: Header=BB2_398 Depth=1
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	mov	x26, x25
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_398
LBB2_400:                               ; %sort.quad_reversal.exit.i.i49
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x0, xzr
	mov	x23, xzr
	ldp	x22, x11, [sp, #304]            ; 16-byte Folded Reload
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x20, [sp, #256]                 ; 8-byte Folded Reload
	b	LBB2_513
LBB2_401:                               ; %._crit_edge.i293.i.i
	neg	x8, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
LBB2_402:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
LBB2_403:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	add	x0, x0, #688
	add	x20, x21, x24
	mov	x22, x19
	add	x21, x19, x23
	add	x28, x8, x23
	mov	x19, x25
	mov	x1, x28
	add	x25, x25, x24
	blr	x27
	mov	x0, x28
	mov	x1, x20
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	blr	x27
	mov	x0, x25
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_405
; %bb.404:                              ;   in Loop: Header=BB2_403 Depth=1
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x21, [sp, #304]                 ; 8-byte Folded Reload
	mov	x25, x19
	mov	x19, x22
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_403
LBB2_405:                               ; %sort.quad_reversal.exit303.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	stp	xzr, xzr, [sp, #224]            ; 16-byte Folded Spill
	ldp	x22, x0, [sp, #248]             ; 16-byte Folded Reload
	ldp	x21, x25, [sp, #304]            ; 16-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	b	LBB2_428
LBB2_406:                               ; %._crit_edge.i305.i.i
	neg	x8, x28
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
LBB2_407:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_408:                               ; =>This Inner Loop Header: Depth=1
	add	x28, x10, x22
	add	x0, sp, #1, lsl #12             ; =4096
	add	x20, x21, x23
	mov	x27, x25
	add	x21, x25, x22
	mov	x19, x26
	add	x25, x26, x23
	add	x0, x0, #688
	mov	x1, x28
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	blr	x26
	mov	x0, x28
	mov	x1, x20
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	blr	x26
	mov	x0, x25
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_410
; %bb.409:                              ;   in Loop: Header=BB2_408 Depth=1
	ldp	x8, x21, [sp, #296]             ; 16-byte Folded Reload
	sub	x24, x24, #1
	mov	x25, x27
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	mov	x26, x19
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_408
LBB2_410:                               ; %sort.quad_reversal.exit315.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x10, xzr
	stp	xzr, xzr, [sp, #224]            ; 16-byte Folded Spill
	ldp	x22, x0, [sp, #248]             ; 16-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x25, [sp, #312]                 ; 8-byte Folded Reload
	b	LBB2_451
LBB2_411:                               ; %._crit_edge.i317.i.i
	neg	x8, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
LBB2_412:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
LBB2_413:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	add	x20, x25, x24
	mov	x22, x19
	add	x21, x19, x23
	mov	x19, x27
	add	x28, x8, x23
	add	x25, x27, x24
	add	x0, x0, #688
	mov	x1, x28
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	blr	x27
	mov	x0, x28
	mov	x1, x20
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	blr	x27
	mov	x0, x25
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_415
; %bb.414:                              ;   in Loop: Header=BB2_413 Depth=1
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x25, [sp, #312]                 ; 8-byte Folded Reload
	mov	x27, x19
	mov	x19, x22
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_413
LBB2_415:                               ; %sort.quad_reversal.exit327.i.i
	mov	x0, xzr
	str	xzr, [sp, #232]                 ; 8-byte Folded Spill
	b	LBB2_427
LBB2_416:                               ; %._crit_edge.i329.i.i
	neg	x8, x28
	str	x8, [sp, #336]                  ; 8-byte Folded Spill
LBB2_417:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
LBB2_418:                               ; =>This Inner Loop Header: Depth=1
	add	x28, x9, x23
	add	x0, sp, #1, lsl #12             ; =4096
	add	x0, x0, #688
	mov	x1, x28
	add	x20, x8, x24
	mov	x22, x19
	add	x21, x19, x23
	mov	x19, x25
	add	x25, x25, x24
	blr	x27
	mov	x0, x28
	mov	x1, x20
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	blr	x27
	mov	x0, x25
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_420
; %bb.419:                              ;   in Loop: Header=BB2_418 Depth=1
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	mov	x25, x19
	mov	x19, x22
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	b	LBB2_418
LBB2_420:                               ; %sort.quad_reversal.exit339.i.i
	ldp	x8, x21, [sp, #344]             ; 16-byte Folded Reload
	ldr	x25, [sp, #312]                 ; 8-byte Folded Reload
	ldr	x9, [sp, #296]                  ; 8-byte Folded Reload
	add	x10, x8, #1
	sub	x8, x25, x10
	udiv	x20, x8, x9
	str	x10, [sp, #336]                 ; 8-byte Folded Spill
	mul	x8, x20, x21
	add	x27, x10, x8
	sub	x22, x25, x8
	tbnz	w20, #0, LBB2_537
; %bb.421:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	add	x0, x0, #784
	ldr	x23, [sp, #264]                 ; 8-byte Folded Reload
	blr	x23
	mov	x0, x27
	mov	x1, x22
	blr	x23
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x21
	add	x1, x1, #784
	mov	x0, x22
	sub	x27, x27, x21
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
	blr	x23
	add	x22, x22, x21
	sub	x20, x20, #1
	b	LBB2_538
LBB2_422:                               ; %._crit_edge.i353.i.i
	neg	x8, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
LBB2_423:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
LBB2_424:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	add	x20, x25, x24
	mov	x22, x19
	add	x21, x19, x23
	mov	x19, x27
	add	x28, x8, x23
	add	x25, x27, x24
	add	x0, x0, #688
	mov	x1, x28
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	blr	x27
	mov	x0, x28
	mov	x1, x20
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	blr	x27
	mov	x0, x25
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_426
; %bb.425:                              ;   in Loop: Header=BB2_424 Depth=1
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x25, [sp, #312]                 ; 8-byte Folded Reload
	mov	x27, x19
	mov	x19, x22
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_424
LBB2_426:                               ; %sort.quad_reversal.exit363.i.i
	mov	x0, xzr
	stp	xzr, xzr, [sp, #224]            ; 16-byte Folded Spill
LBB2_427:
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	ldp	x21, x25, [sp, #304]            ; 16-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
LBB2_428:
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	str	x0, [sp, #256]                  ; 8-byte Folded Spill
	cbz	x8, LBB2_437
; %bb.429:
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_437
; %bb.430:
	ldr	x11, [sp, #320]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x12, x28
	sub	x8, x11, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x26, x10, x8
	sub	x25, x11, x8
	tbnz	w20, #0, LBB2_432
; %bb.431:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x26
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x26
	mov	x1, x25
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x25
	sub	x26, x26, x28
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	add	x25, x25, x28
	sub	x20, x20, #1
	b	LBB2_433
LBB2_432:                               ; %._crit_edge.i377.i.i
	neg	x8, x28
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
LBB2_433:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_434:                               ; =>This Inner Loop Header: Depth=1
	add	x28, x10, x22
	add	x0, sp, #1, lsl #12             ; =4096
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x27, x25
	add	x21, x25, x22
	mov	x19, x26
	add	x25, x26, x23
	add	x0, x0, #688
	mov	x1, x28
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x20, x8, x23
	blr	x26
	mov	x0, x28
	mov	x1, x20
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	blr	x26
	mov	x0, x25
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_436
; %bb.435:                              ;   in Loop: Header=BB2_434 Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	mov	x25, x27
	mov	x26, x19
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_434
LBB2_436:                               ; %sort.quad_reversal.exit387.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	str	xzr, [sp, #216]                 ; 8-byte Folded Spill
	ldp	x22, x0, [sp, #248]             ; 16-byte Folded Reload
	ldp	x21, x25, [sp, #304]            ; 16-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
LBB2_437:
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	ldr	x10, [sp, #344]                 ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_441
; %bb.438:
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_441
; %bb.439:
	ldr	x11, [sp, #288]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x12, x28
	sub	x8, x10, x11
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x26, x11, x8
	sub	x25, x10, x8
	tbnz	w20, #0, LBB2_460
; %bb.440:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x26
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x26
	mov	x1, x25
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x25
	sub	x26, x26, x28
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
	blr	x21
	add	x25, x25, x28
	sub	x20, x20, #1
	b	LBB2_461
LBB2_441:                               ; %.thread444.i.i
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_450
; %bb.442:                              ; %.thread444.i.i
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_450
; %bb.443:
	ldr	x10, [sp, #296]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	str	x0, [sp, #256]                  ; 8-byte Folded Spill
	sub	x8, x21, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x19, x10, x8
	sub	x26, x21, x8
	tbnz	w20, #0, LBB2_445
; %bb.444:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x19
	add	x0, x0, #784
	ldr	x22, [sp, #264]                 ; 8-byte Folded Reload
	blr	x22
	mov	x0, x19
	mov	x1, x26
	blr	x22
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x19, x19, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
	blr	x22
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_446
LBB2_445:                               ; %._crit_edge.i401.i.i
	neg	x8, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
LBB2_446:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_447:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x25, x26
	add	x27, x26, x22
	add	x0, x0, #688
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x20, x8, x22
	add	x21, x21, x23
	mov	x1, x20
	add	x28, x19, x23
	blr	x26
	mov	x0, x20
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x27
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x27
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_449
; %bb.448:                              ;   in Loop: Header=BB2_447 Depth=1
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	ldr	x21, [sp, #304]                 ; 8-byte Folded Reload
	mov	x26, x25
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_447
LBB2_449:                               ; %sort.quad_reversal.exit411.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	str	xzr, [sp, #232]                 ; 8-byte Folded Spill
	ldp	x22, x0, [sp, #248]             ; 16-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x25, [sp, #312]                 ; 8-byte Folded Reload
LBB2_450:                               ; %.thread444.thread.i.i
	ldr	x10, [sp, #216]                 ; 8-byte Folded Reload
LBB2_451:                               ; %.thread444.thread.i.i
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	str	x10, [sp, #216]                 ; 8-byte Folded Spill
	cmp	x8, #1
	b.ne	LBB2_543
; %bb.452:                              ; %.thread444.thread.i.i
	cbz	x0, LBB2_543
; %bb.453:
	ldr	x11, [sp, #336]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x12, x28
	sub	x8, x25, x11
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x19, x11, x8
	sub	x26, x25, x8
	tbnz	w20, #0, LBB2_455
; %bb.454:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x19
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x19
	mov	x1, x26
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x19, x19, x28
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
	blr	x21
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_456
LBB2_455:                               ; %._crit_edge.i413.i.i
	neg	x8, x28
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
LBB2_456:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_457:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	add	x21, x25, x23
	mov	x27, x26
	add	x25, x26, x22
	add	x0, x0, #688
	add	x20, x8, x22
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x1, x20
	add	x28, x19, x23
	blr	x26
	mov	x0, x20
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x25
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_459
; %bb.458:                              ;   in Loop: Header=BB2_457 Depth=1
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	ldr	x25, [sp, #312]                 ; 8-byte Folded Reload
	mov	x26, x27
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_457
LBB2_459:                               ; %sort.quad_reversal.exit423.i.i
	mov	x0, xzr
	b	LBB2_542
LBB2_460:                               ; %._crit_edge.i389.i.i
	neg	x8, x28
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
LBB2_461:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_462:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x27, x25
	add	x21, x25, x22
	mov	x19, x26
	add	x25, x26, x23
	add	x20, x8, x23
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	add	x0, x0, #688
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x28, x8, x22
	mov	x1, x28
	blr	x26
	mov	x0, x28
	mov	x1, x20
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	blr	x26
	mov	x0, x25
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_395
; %bb.463:                              ;   in Loop: Header=BB2_462 Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	mov	x25, x27
	mov	x26, x19
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_462
LBB2_464:                               ; %._crit_edge.i365.i.i
	neg	x8, x28
	str	x8, [sp, #360]                  ; 8-byte Folded Spill
LBB2_465:
	mov	x26, xzr
	mov	x27, xzr
	lsr	x28, x20, #1
	ldr	x19, [sp, #264]                 ; 8-byte Folded Reload
LBB2_466:                               ; =>This Inner Loop Header: Depth=1
	add	x24, x10, x26
	add	x0, sp, #1, lsl #12             ; =4096
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	add	x0, x0, #688
	mov	x1, x24
	mov	x21, x22
	add	x25, x22, x26
	mov	x22, x23
	add	x20, x8, x27
	add	x23, x23, x27
	blr	x19
	mov	x0, x24
	mov	x1, x20
	blr	x19
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x19
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x23
	add	x0, x0, #784
	blr	x19
	mov	x0, x23
	mov	x1, x25
	blr	x19
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x1, x1, #784
	blr	x19
	cbz	x28, LBB2_916
; %bb.467:                              ;   in Loop: Header=BB2_466 Depth=1
	ldr	x8, [sp, #360]                  ; 8-byte Folded Reload
	sub	x28, x28, #1
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	mov	x23, x22
	mov	x22, x21
	add	x27, x27, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x26, x26, x8
	b	LBB2_466
LBB2_468:                               ; %._crit_edge.i291.i.i
	neg	x8, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
LBB2_469:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
LBB2_470:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x22, x19
	add	x25, x19, x23
	mov	x19, x27
	add	x28, x27, x24
	add	x20, x8, x23
	add	x0, x0, #688
	mov	x1, x20
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x21, x24
	blr	x27
	mov	x0, x20
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x27
	mov	x0, x28
	mov	x1, x25
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_472
; %bb.471:                              ;   in Loop: Header=BB2_470 Depth=1
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	mov	x27, x19
	mov	x19, x22
	add	x24, x24, x8
	ldp	x21, x8, [sp, #344]             ; 16-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_470
LBB2_472:                               ; %sort.quad_reversal.exit301.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x14, xzr
	mov	x23, xzr
	ldp	x11, x13, [sp, #312]            ; 16-byte Folded Reload
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	ldr	x20, [sp, #256]                 ; 8-byte Folded Reload
	b	LBB2_494
LBB2_473:                               ; %._crit_edge.i303.i.i
	neg	x8, x28
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
LBB2_474:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_475:                               ; =>This Inner Loop Header: Depth=1
	add	x20, x10, x22
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x25, x26
	add	x27, x26, x22
	add	x0, x0, #688
	mov	x1, x20
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x21, x23
	add	x28, x19, x23
	blr	x26
	mov	x0, x20
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x27
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x27
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_477
; %bb.476:                              ;   in Loop: Header=BB2_475 Depth=1
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	mov	x26, x25
	add	x23, x23, x8
	ldp	x21, x8, [sp, #344]             ; 16-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_475
LBB2_477:                               ; %sort.quad_reversal.exit313.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x23, xzr
	mov	x0, xzr
	ldp	x22, x11, [sp, #304]            ; 16-byte Folded Reload
	mov	x14, xzr
	b	LBB2_523
LBB2_478:                               ; %._crit_edge.i315.i.i
	neg	x8, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
LBB2_479:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
LBB2_480:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x22, x19
	add	x25, x19, x23
	mov	x19, x27
	add	x28, x27, x24
	add	x20, x8, x23
	add	x0, x0, #688
	mov	x1, x20
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x11, x24
	blr	x27
	mov	x0, x20
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x27
	mov	x0, x28
	mov	x1, x25
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_482
; %bb.481:                              ;   in Loop: Header=BB2_480 Depth=1
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x11, [sp, #312]                 ; 8-byte Folded Reload
	mov	x27, x19
	mov	x19, x22
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_480
LBB2_482:                               ; %sort.quad_reversal.exit325.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x20, xzr
	mov	x14, xzr
	ldp	x11, x13, [sp, #312]            ; 16-byte Folded Reload
	ldp	x23, x0, [sp, #216]             ; 16-byte Folded Reload
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	b	LBB2_495
LBB2_483:                               ; %._crit_edge.i327.i.i
	neg	x8, x28
	str	x8, [sp, #336]                  ; 8-byte Folded Spill
LBB2_484:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
LBB2_485:                               ; =>This Inner Loop Header: Depth=1
	add	x20, x9, x23
	add	x0, sp, #1, lsl #12             ; =4096
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x22, x19
	add	x25, x19, x23
	mov	x19, x27
	add	x28, x27, x24
	add	x0, x0, #688
	mov	x1, x20
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x8, x24
	blr	x27
	mov	x0, x20
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x27
	mov	x0, x28
	mov	x1, x25
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_487
; %bb.486:                              ;   in Loop: Header=BB2_485 Depth=1
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	mov	x27, x19
	mov	x19, x22
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_485
LBB2_487:                               ; %sort.quad_reversal.exit337.i.i
	ldp	x9, x8, [sp, #312]              ; 16-byte Folded Reload
	ldr	x10, [sp, #296]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #352]                 ; 8-byte Folded Reload
	add	x11, x8, #1
	sub	x8, x9, x11
	udiv	x20, x8, x10
	str	x11, [sp, #336]                 ; 8-byte Folded Spill
	mul	x8, x20, x21
	add	x27, x11, x8
	sub	x22, x9, x8
	tbnz	w20, #0, LBB2_595
; %bb.488:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	add	x0, x0, #784
	ldr	x23, [sp, #264]                 ; 8-byte Folded Reload
	blr	x23
	mov	x0, x27
	mov	x1, x22
	blr	x23
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x21
	add	x1, x1, #784
	mov	x0, x22
	sub	x27, x27, x21
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
	blr	x23
	ldr	x9, [sp, #312]                  ; 8-byte Folded Reload
	add	x22, x22, x21
	sub	x20, x20, #1
	b	LBB2_596
LBB2_489:                               ; %._crit_edge.i351.i.i
	neg	x8, x28
	str	x8, [sp, #272]                  ; 8-byte Folded Spill
LBB2_490:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
LBB2_491:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x22, x19
	add	x25, x19, x23
	mov	x19, x27
	add	x28, x27, x24
	add	x20, x8, x23
	add	x0, x0, #688
	mov	x1, x20
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x11, x24
	blr	x27
	mov	x0, x20
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x27
	mov	x0, x28
	mov	x1, x25
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_493
; %bb.492:                              ;   in Loop: Header=BB2_491 Depth=1
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x11, [sp, #312]                 ; 8-byte Folded Reload
	mov	x27, x19
	mov	x19, x22
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_491
LBB2_493:                               ; %sort.quad_reversal.exit361.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x20, xzr
	mov	x14, xzr
	ldp	x11, x13, [sp, #312]            ; 16-byte Folded Reload
	mov	x23, xzr
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
LBB2_494:
	ldr	x0, [sp, #224]                  ; 8-byte Folded Reload
LBB2_495:
	str	x20, [sp, #256]                 ; 8-byte Folded Spill
	str	x14, [sp, #232]                 ; 8-byte Folded Spill
	cbz	x0, LBB2_504
; %bb.496:
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_504
; %bb.497:
	sub	x8, x22, x10
	lsl	x9, x28, #1
	mov	x11, x28
	str	x23, [sp, #216]                 ; 8-byte Folded Spill
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x24, x10, x8
	sub	x26, x22, x8
	tbnz	w20, #0, LBB2_499
; %bb.498:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x24
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x24
	mov	x1, x26
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x27, x24, x28
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_500
LBB2_499:                               ; %._crit_edge.i375.i.i
	neg	x8, x28
	mov	x27, x24
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
LBB2_500:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_501:                               ; =>This Inner Loop Header: Depth=1
	add	x20, x10, x22
	add	x0, sp, #1, lsl #12             ; =4096
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	mov	x25, x26
	add	x19, x26, x22
	add	x0, x0, #688
	mov	x1, x20
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x8, x23
	add	x28, x27, x23
	blr	x26
	mov	x0, x20
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x19
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x19
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_503
; %bb.502:                              ;   in Loop: Header=BB2_501 Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	mov	x26, x25
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_501
LBB2_503:                               ; %sort.quad_reversal.exit385.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x0, xzr
	ldp	x11, x13, [sp, #312]            ; 16-byte Folded Reload
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	ldr	x20, [sp, #256]                 ; 8-byte Folded Reload
	ldr	x14, [sp, #232]                 ; 8-byte Folded Reload
	ldr	x23, [sp, #216]                 ; 8-byte Folded Reload
LBB2_504:
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_514
; %bb.505:
	cbz	x23, LBB2_514
; %bb.506:
	ldr	x10, [sp, #288]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x11, x28
	str	x0, [sp, #224]                  ; 8-byte Folded Spill
	sub	x8, x13, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x22, x10, x8
	sub	x26, x13, x8
	tbnz	w20, #0, LBB2_508
; %bb.507:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x22
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x22
	mov	x1, x26
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x27, x22, x28
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
	blr	x21
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_509
LBB2_508:                               ; %._crit_edge.i387.i.i
	neg	x8, x28
	mov	x27, x22
	str	x8, [sp, #280]                  ; 8-byte Folded Spill
LBB2_509:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_510:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x25, x26
	add	x19, x26, x22
	add	x0, x0, #688
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x8, x23
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	add	x28, x27, x23
	add	x20, x8, x22
	mov	x1, x20
	blr	x26
	mov	x0, x20
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x19
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x19
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_512
; %bb.511:                              ;   in Loop: Header=BB2_510 Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	mov	x26, x25
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_510
LBB2_512:                               ; %sort.quad_reversal.exit397.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x23, xzr
	ldp	x22, x11, [sp, #304]            ; 16-byte Folded Reload
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x20, [sp, #256]                 ; 8-byte Folded Reload
	ldr	x0, [sp, #224]                  ; 8-byte Folded Reload
LBB2_513:                               ; %.thread442.i.i
	ldr	x14, [sp, #232]                 ; 8-byte Folded Reload
LBB2_514:                               ; %.thread442.i.i
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_524
; %bb.515:                              ; %.thread442.i.i
	cbz	x14, LBB2_524
; %bb.516:
	ldr	x10, [sp, #296]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	str	x20, [sp, #256]                 ; 8-byte Folded Spill
	mov	x11, x28
	stp	x23, x0, [sp, #216]             ; 16-byte Folded Spill
	sub	x8, x21, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x19, x10, x8
	sub	x26, x21, x8
	tbnz	w20, #0, LBB2_518
; %bb.517:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x19
	add	x0, x0, #784
	ldr	x22, [sp, #264]                 ; 8-byte Folded Reload
	blr	x22
	mov	x0, x19
	mov	x1, x26
	blr	x22
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x19, x19, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
	blr	x22
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_519
LBB2_518:                               ; %._crit_edge.i399.i.i
	neg	x8, x28
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
LBB2_519:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_520:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x25, x26
	add	x27, x26, x22
	add	x0, x0, #688
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x20, x8, x22
	add	x21, x21, x23
	mov	x1, x20
	add	x28, x19, x23
	blr	x26
	mov	x0, x20
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x27
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x27
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_522
; %bb.521:                              ;   in Loop: Header=BB2_520 Depth=1
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	mov	x26, x25
	add	x23, x23, x8
	ldp	x21, x8, [sp, #344]             ; 16-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_520
LBB2_522:                               ; %sort.quad_reversal.exit409.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x14, xzr
	ldp	x22, x11, [sp, #304]            ; 16-byte Folded Reload
	ldp	x23, x0, [sp, #216]             ; 16-byte Folded Reload
LBB2_523:                               ; %.thread442.thread.i.i
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x20, [sp, #256]                 ; 8-byte Folded Reload
LBB2_524:                               ; %.thread442.thread.i.i
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	str	x14, [sp, #232]                 ; 8-byte Folded Spill
	cmp	x8, #1
	b.ne	LBB2_600
; %bb.525:                              ; %.thread442.thread.i.i
	cbz	x20, LBB2_600
; %bb.526:
	ldr	x10, [sp, #336]                 ; 8-byte Folded Reload
	lsl	x9, x28, #1
	mov	x12, x28
	stp	x23, x0, [sp, #216]             ; 16-byte Folded Spill
	sub	x8, x11, x10
	udiv	x20, x8, x9
	mul	x8, x20, x28
	add	x22, x10, x8
	sub	x26, x11, x8
	tbnz	w20, #0, LBB2_528
; %bb.527:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x22
	add	x0, x0, #784
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x22
	mov	x1, x26
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	neg	x8, x28
	add	x1, x1, #784
	mov	x0, x26
	sub	x27, x22, x28
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
	blr	x21
	ldr	x11, [sp, #312]                 ; 8-byte Folded Reload
	add	x26, x26, x28
	sub	x20, x20, #1
	b	LBB2_529
LBB2_528:                               ; %._crit_edge.i411.i.i
	neg	x8, x28
	mov	x27, x22
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
LBB2_529:
	mov	x22, xzr
	mov	x23, xzr
	lsr	x24, x20, #1
LBB2_530:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x25, x26
	add	x19, x26, x22
	add	x0, x0, #688
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	add	x20, x8, x22
	add	x21, x11, x23
	mov	x1, x20
	add	x28, x27, x23
	blr	x26
	mov	x0, x20
	mov	x1, x21
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x26
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x26
	mov	x0, x28
	mov	x1, x19
	blr	x26
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x19
	add	x1, x1, #784
	blr	x26
	cbz	x24, LBB2_532
; %bb.531:                              ;   in Loop: Header=BB2_530 Depth=1
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	sub	x24, x24, #1
	ldr	x11, [sp, #312]                 ; 8-byte Folded Reload
	mov	x26, x25
	add	x23, x23, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	b	LBB2_530
LBB2_532:                               ; %sort.quad_reversal.exit421.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x20, xzr
	ldp	x23, x0, [sp, #216]             ; 16-byte Folded Reload
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	b	LBB2_600
LBB2_533:                               ; %._crit_edge.i363.i.i
	neg	x8, x28
	str	x8, [sp, #360]                  ; 8-byte Folded Spill
LBB2_534:
	mov	x26, xzr
	mov	x27, xzr
	lsr	x28, x21, #1
	ldr	x19, [sp, #264]                 ; 8-byte Folded Reload
LBB2_535:                               ; =>This Inner Loop Header: Depth=1
	add	x24, x10, x26
	add	x0, sp, #1, lsl #12             ; =4096
	add	x0, x0, #688
	mov	x1, x24
	add	x21, x11, x27
	mov	x25, x20
	add	x22, x20, x26
	mov	x20, x23
	add	x23, x23, x27
	blr	x19
	mov	x0, x24
	mov	x1, x21
	blr	x19
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x19
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x23
	add	x0, x0, #784
	blr	x19
	mov	x0, x23
	mov	x1, x22
	blr	x19
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x22
	add	x1, x1, #784
	blr	x19
	cbz	x28, LBB2_916
; %bb.536:                              ;   in Loop: Header=BB2_535 Depth=1
	ldr	x8, [sp, #360]                  ; 8-byte Folded Reload
	sub	x28, x28, #1
	ldr	x10, [sp, #240]                 ; 8-byte Folded Reload
	mov	x23, x20
	ldr	x11, [sp, #312]                 ; 8-byte Folded Reload
	mov	x20, x25
	add	x27, x27, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x26, x26, x8
	b	LBB2_535
LBB2_537:                               ; %._crit_edge.i341.i.i
	neg	x8, x21
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
LBB2_538:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
LBB2_539:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	add	x20, x25, x24
	mov	x19, x22
	add	x21, x22, x23
	mov	x22, x27
	add	x28, x8, x23
	add	x25, x27, x24
	add	x0, x0, #688
	mov	x1, x28
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	blr	x27
	mov	x0, x28
	mov	x1, x20
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x20
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	add	x0, x0, #784
	blr	x27
	mov	x0, x25
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_541
; %bb.540:                              ;   in Loop: Header=BB2_539 Depth=1
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x25, [sp, #312]                 ; 8-byte Folded Reload
	mov	x27, x22
	mov	x22, x19
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_539
LBB2_541:                               ; %.thread444.thread.thread.i.i
	mov	x0, xzr
	stp	xzr, xzr, [sp, #224]            ; 16-byte Folded Spill
	str	xzr, [sp, #216]                 ; 8-byte Folded Spill
LBB2_542:
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
LBB2_543:
	ldr	w8, [sp, #184]                  ; 4-byte Folded Reload
	lsr	x9, x27, #9
	ldr	w10, [sp, #192]                 ; 4-byte Folded Reload
	cmp	x9, w8, uxtw
	cset	w8, lo
	cmp	x9, w10, uxtw
	ldr	w10, [sp, #200]                 ; 4-byte Folded Reload
	cset	w19, lo
	cmp	x9, w10, uxtw
	ldr	w10, [sp, #208]                 ; 4-byte Folded Reload
	cset	w25, lo
	cmp	x9, w10, uxtw
	mov	w9, #3
	cset	w21, lo
	movk	w9, #16, lsl #16
	cmp	x27, x9
	b.ls	LBB2_545
; %bb.544:
	mov	w21, #1
	mov	w25, #1
	mov	w19, #1
	mov	w8, #1
LBB2_545:
	lsl	w9, w25, #2
Lloh8:
	adrp	x10, LJTI2_7@PAGE
Lloh9:
	add	x10, x10, LJTI2_7@PAGEOFF
	orr	w9, w9, w19, lsl #1
	orr	w9, w9, w21, lsl #3
	ldr	x23, [sp, #152]                 ; 8-byte Folded Reload
	orr	w9, w9, w8
	ldr	x27, [sp, #328]                 ; 8-byte Folded Reload
	adr	x11, LBB2_546
	ldrh	w12, [x10, x9, lsl #1]
	add	x11, x11, x12, lsl #2
	br	x11
LBB2_546:
	str	x0, [sp, #256]                  ; 8-byte Folded Spill
	cbz	w8, LBB2_550
; %bb.547:
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_553
; %bb.548:
	ldr	x8, [sp, #168]                  ; 8-byte Folded Reload
	cmp	x8, #383
	b.hi	LBB2_551
; %bb.549:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_553
LBB2_550:
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	mov	x1, x23
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x5, x27
	ldr	x4, [sp, #104]                  ; 8-byte Folded Reload
	mov	x6, x24
	add	x3, x23, x8
	mov	x7, x28
	mov	x2, x0
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	b	LBB2_553
LBB2_551:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_553
; %bb.552:
	ldp	x20, x8, [sp, #240]             ; 16-byte Folded Reload
	mov	x2, x23
	mov	x4, x27
	ldr	x22, [sp, #168]                 ; 8-byte Folded Reload
	mov	x5, x24
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x6, x28
	mov	x0, x20
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	mov	x3, x22
	mov	x26, x28
	str	x8, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x22
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_553:                               ; %sort.quadsort_swap__anon_14855.exit433.i.i
	cbz	w19, LBB2_557
; %bb.554:
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_560
; %bb.555:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	cmp	x1, #95
	b.hi	LBB2_558
; %bb.556:
	mov	x0, x20
	mov	x2, x23
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_560
LBB2_557:
	ldr	x4, [sp, #112]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x1, x23
	mov	x5, x27
	mov	x6, x24
	madd	x3, x4, x28, x23
	add	x0, x8, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x2, x0
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	b	LBB2_560
LBB2_558:
	mov	x0, x20
	mov	x2, x27
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_560
; %bb.559:
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x2, x23
	mov	x4, x27
	mov	x5, x24
	mov	x3, x19
	mov	x6, x28
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	mov	x26, x28
	str	x22, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x19
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_560:                               ; %sort.quadsort_swap__anon_14855.exit434.i.i
	cbz	w25, LBB2_564
; %bb.561:
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_567
; %bb.562:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_565
; %bb.563:
	mov	x0, x20
	ldr	x1, [sp, #128]                  ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_567
LBB2_564:
	ldr	x4, [sp, #128]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x1, x23
	mov	x5, x27
	mov	x6, x24
	madd	x3, x4, x28, x23
	add	x0, x8, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x2, x0
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	b	LBB2_567
LBB2_565:
	mov	x0, x20
	ldr	x1, [sp, #128]                  ; 8-byte Folded Reload
	mov	x2, x27
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_567
; %bb.566:
	ldr	x25, [sp, #128]                 ; 8-byte Folded Reload
	mov	x0, x20
	mov	x2, x23
	mov	x3, x19
	mov	x4, x27
	mov	x5, x24
	mov	x1, x25
	mov	x6, x28
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	mov	x26, x28
	str	x22, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x25
	mov	x2, x23
	mov	x3, x19
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_567:                               ; %sort.quadsort_swap__anon_14855.exit435.i.i
	cbz	w21, LBB2_571
; %bb.568:
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	mov	x25, x22
	cbz	x8, LBB2_844
LBB2_569:
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	cmp	x1, #95
	b.hi	LBB2_572
; %bb.570:
	mov	x0, x20
	mov	x2, x23
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x25
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_844
LBB2_571:
	ldr	x4, [sp, #136]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	b	LBB2_841
LBB2_572:
	mov	x0, x20
	mov	x2, x27
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x25
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_844
LBB2_573:
	ldr	x21, [sp, #136]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x22, [sp, #264]                 ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x19
	mov	x4, x27
	mov	x1, x21
	mov	x5, x24
	mov	x6, x28
	mov	x7, x22
	mov	x26, x28
	str	x25, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x21
	mov	x2, x23
	mov	x3, x19
LBB2_574:                               ; %sort.quadsort_swap__anon_14855.exit428.i.i
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	stp	x22, x25, [sp]
	bl	l_sort.rotate_merge__anon_14836
	b	LBB2_844
LBB2_575:
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	mov	x1, x23
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x5, x27
	ldr	x4, [sp, #168]                  ; 8-byte Folded Reload
	mov	x6, x24
	add	x3, x23, x8
	mov	x7, x28
	mov	x2, x0
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	b	LBB2_916
LBB2_576:
	ldr	x20, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_837
; %bb.577:
	cmp	x20, #383
	b.hi	LBB2_835
; %bb.578:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_837
LBB2_579:
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	mov	x1, x23
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x5, x27
	ldr	x4, [sp, #104]                  ; 8-byte Folded Reload
	mov	x6, x24
	add	x3, x23, x8
	mov	x7, x28
	mov	x2, x0
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_840
; %bb.580:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	cmp	x1, #95
	b.hi	LBB2_838
; %bb.581:
	mov	x0, x20
	mov	x2, x23
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_840
LBB2_582:
	mov	x25, x24
	ldr	x21, [sp, #168]                 ; 8-byte Folded Reload
	ldp	x8, x24, [sp, #216]             ; 16-byte Folded Reload
	cbz	x8, LBB2_856
; %bb.583:
	cmp	x21, #383
	b.hi	LBB2_854
; %bb.584:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x25
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_856
LBB2_585:
	ldp	x8, x4, [sp, #72]               ; 16-byte Folded Reload
	mov	x1, x23
	mov	x5, x27
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x6, x24
	mov	x7, x28
	add	x3, x23, x8
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x2, x0
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #304]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_861
; %bb.586:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_859
; %bb.587:
	mov	x0, x20
	ldr	x1, [sp, #128]                  ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_861
LBB2_588:
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	x20, x0
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x1, x23
	ldr	x4, [sp, #48]                   ; 8-byte Folded Reload
	mov	x5, x27
	add	x3, x23, x8
	mov	x6, x24
	mov	x2, x0
	mov	x7, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	mov	x25, x22
	cbnz	x20, LBB2_569
	b	LBB2_844
LBB2_589:
	mov	x19, x0
	ldr	x21, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_864
; %bb.590:
	cmp	x21, #383
	b.hi	LBB2_862
; %bb.591:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_864
LBB2_592:
	ldp	x8, x4, [sp, #72]               ; 16-byte Folded Reload
	mov	x9, x22
	mov	x22, x0
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x1, x23
	mov	x5, x27
	mov	x6, x24
	add	x3, x23, x8
	mov	x7, x28
	mov	x2, x0
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x21, x9
	stp	x8, x9, [sp]
	bl	l_sort.flux_partition__anon_14854
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_869
; %bb.593:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_867
; %bb.594:
	mov	x0, x20
	ldr	x1, [sp, #128]                  ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x21
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_869
LBB2_595:                               ; %._crit_edge.i339.i.i
	neg	x8, x21
	str	x8, [sp, #296]                  ; 8-byte Folded Spill
LBB2_596:
	mov	x23, xzr
	mov	x24, xzr
	lsr	x26, x20, #1
LBB2_597:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x19, x22
	add	x25, x22, x23
	mov	x22, x27
	add	x28, x27, x24
	add	x20, x8, x23
	add	x0, x0, #688
	mov	x1, x20
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	add	x21, x9, x24
	blr	x27
	mov	x0, x20
	mov	x1, x21
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x21
	add	x1, x1, #688
	blr	x27
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	add	x0, x0, #784
	blr	x27
	mov	x0, x28
	mov	x1, x25
	blr	x27
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x1, x1, #784
	blr	x27
	cbz	x26, LBB2_599
; %bb.598:                              ;   in Loop: Header=BB2_597 Depth=1
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	sub	x26, x26, #1
	ldr	x9, [sp, #312]                  ; 8-byte Folded Reload
	mov	x27, x22
	mov	x22, x19
	add	x24, x24, x8
	ldr	x8, [sp, #352]                  ; 8-byte Folded Reload
	add	x23, x23, x8
	b	LBB2_597
LBB2_599:                               ; %.thread442.thread.thread.i.i
	ldp	x28, x24, [sp, #352]            ; 16-byte Folded Reload
	mov	x20, xzr
	str	xzr, [sp, #232]                 ; 8-byte Folded Spill
	ldr	x12, [sp, #168]                 ; 8-byte Folded Reload
	mov	x23, xzr
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	mov	x0, xzr
LBB2_600:
	ldr	w8, [sp, #184]                  ; 4-byte Folded Reload
	lsr	x9, x12, #9
	ldr	w10, [sp, #192]                 ; 4-byte Folded Reload
	str	x23, [sp, #216]                 ; 8-byte Folded Spill
	ldr	w11, [sp, #208]                 ; 4-byte Folded Reload
	cmp	x9, w8, uxtw
	cset	w8, lo
	cmp	x9, w10, uxtw
	ldr	w10, [sp, #200]                 ; 4-byte Folded Reload
	cset	w19, lo
	cmp	x9, w10, uxtw
	mov	x10, x12
	cset	w25, lo
	cmp	x9, w11, uxtw
	cset	w21, lo
	mov	w9, #3
	movk	w9, #16, lsl #16
	cmp	x12, x9
	b.ls	LBB2_602
; %bb.601:
	mov	w21, #1
	mov	w25, #1
	mov	w19, #1
	mov	w8, #1
LBB2_602:
	lsl	w9, w25, #2
Lloh10:
	adrp	x10, LJTI2_5@PAGE
Lloh11:
	add	x10, x10, LJTI2_5@PAGEOFF
	orr	w9, w9, w19, lsl #1
	orr	w9, w9, w21, lsl #3
	ldr	x23, [sp, #152]                 ; 8-byte Folded Reload
	orr	w9, w9, w8
	adr	x11, LBB2_603
	ldrh	w12, [x10, x9, lsl #1]
	add	x11, x11, x12, lsl #2
	br	x11
LBB2_603:
	str	x20, [sp, #256]                 ; 8-byte Folded Spill
	cbz	w8, LBB2_607
; %bb.604:
	cbz	x0, LBB2_610
; %bb.605:
	ldr	x8, [sp, #168]                  ; 8-byte Folded Reload
	cmp	x8, #383
	b.hi	LBB2_608
; %bb.606:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x4, x24
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_610
LBB2_607:
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x1, x23
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x6, x24
	ldr	x4, [sp, #112]                  ; 8-byte Folded Reload
	mov	x7, x28
	add	x3, x23, x8
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	mov	x2, x0
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	b	LBB2_610
LBB2_608:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x3, x24
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x4, x28
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_610
; %bb.609:
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x20, [sp, #240]                 ; 8-byte Folded Reload
	mov	x5, x24
	ldr	x22, [sp, #168]                 ; 8-byte Folded Reload
	mov	x6, x28
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	mov	x7, x27
	mov	x0, x20
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x3, x22
	mov	x4, x26
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x3, x22
	ldr	x2, [sp, #152]                  ; 8-byte Folded Reload
	mov	x5, x26
	mov	x6, x24
	ldr	x7, [sp, #352]                  ; 8-byte Folded Reload
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	str	x27, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_610:                               ; %sort.quadsort_swap__anon_14858.exit431.i.i
	cbz	w19, LBB2_614
; %bb.611:
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_617
; %bb.612:
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	add	x20, x22, x28
	cmp	x1, #95
	b.hi	LBB2_615
; %bb.613:
	mov	x0, x20
	mov	x2, x23
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_617
LBB2_614:
	ldr	x4, [sp, #104]                  ; 8-byte Folded Reload
	add	x0, x22, x28
	mov	x1, x23
	mov	x7, x28
	mov	x2, x0
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	madd	x3, x4, x28, x23
	mov	x6, x24
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	b	LBB2_617
LBB2_615:
	mov	x0, x20
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_617
; %bb.616:
	ldr	x22, [sp, #104]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	mov	x5, x24
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	mov	x1, x22
	mov	x3, x19
	mov	x6, x28
	mov	x4, x26
	mov	x7, x27
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	mov	x1, x22
	ldr	x2, [sp, #152]                  ; 8-byte Folded Reload
	mov	x3, x19
	mov	x5, x26
	mov	x6, x24
	ldr	x7, [sp, #352]                  ; 8-byte Folded Reload
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	str	x27, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_617:                               ; %sort.quadsort_swap__anon_14858.exit432.i.i
	cbz	w25, LBB2_621
; %bb.618:
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_624
; %bb.619:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_622
; %bb.620:
	mov	x0, x20
	ldr	x1, [sp, #144]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_624
LBB2_621:
	ldp	x8, x5, [sp, #320]              ; 16-byte Folded Reload
	mov	x7, x28
	mov	x1, x23
	ldr	x4, [sp, #144]                  ; 8-byte Folded Reload
	mov	x6, x24
	add	x0, x8, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	madd	x3, x4, x28, x23
	mov	x2, x0
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	b	LBB2_624
LBB2_622:
	mov	x0, x20
	ldr	x1, [sp, #144]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_624
; %bb.623:
	ldr	x22, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x25, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x3, x19
	mov	x1, x22
	mov	x5, x24
	mov	x4, x25
	mov	x6, x28
	mov	x7, x26
	mov	x27, x28
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	mov	x1, x22
	mov	x2, x23
	mov	x3, x19
	mov	x5, x25
	mov	x6, x24
	mov	x7, x28
	ldr	x22, [sp, #304]                 ; 8-byte Folded Reload
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_624:                               ; %sort.quadsort_swap__anon_14858.exit433.i.i
	cbz	w21, LBB2_628
; %bb.625:
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_906
LBB2_626:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	cmp	x1, #95
	b.hi	LBB2_629
LBB2_627:
	mov	x0, x20
	mov	x2, x23
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_906
LBB2_628:
	ldr	x4, [sp, #136]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	b	LBB2_904
LBB2_629:
	mov	x0, x20
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_906
; %bb.630:
	ldr	x21, [sp, #136]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x25, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x3, x19
	mov	x1, x21
	mov	x5, x24
	mov	x4, x25
	mov	x6, x28
	mov	x7, x26
	mov	x27, x28
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	mov	x1, x21
	mov	x2, x23
	mov	x3, x19
LBB2_631:                               ; %sort.quadsort_swap__anon_14858.exit426.i.i
	mov	x5, x25
	mov	x6, x24
	mov	x7, x28
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
	b	LBB2_906
LBB2_632:
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	mov	x1, x23
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x6, x24
	ldr	x4, [sp, #168]                  ; 8-byte Folded Reload
	mov	x7, x28
	add	x3, x23, x8
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	mov	x2, x0
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	b	LBB2_916
LBB2_633:
	ldr	x20, [sp, #168]                 ; 8-byte Folded Reload
	cbz	x0, LBB2_874
; %bb.634:
	cmp	x20, #383
	b.hi	LBB2_872
; %bb.635:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x4, x24
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_874
LBB2_636:
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x1, x23
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x6, x24
	ldr	x4, [sp, #112]                  ; 8-byte Folded Reload
	mov	x7, x28
	add	x3, x23, x8
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	mov	x2, x0
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x25, x23
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_877
; %bb.637:
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	add	x20, x22, x28
	cmp	x1, #95
	b.hi	LBB2_875
; %bb.638:
	mov	x0, x20
	mov	x2, x23
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x25, x23
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_877
LBB2_639:
	ldr	x21, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	cbz	x0, LBB2_880
; %bb.640:
	cmp	x21, #383
	b.hi	LBB2_878
; %bb.641:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_880
LBB2_642:
	ldp	x8, x4, [sp, #80]               ; 16-byte Folded Reload
	mov	x1, x23
	mov	x6, x24
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	add	x3, x23, x8
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x2, x0
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_885
; %bb.643:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_883
; %bb.644:
	mov	x0, x20
	ldr	x1, [sp, #144]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_885
LBB2_645:
	ldp	x8, x4, [sp, #56]               ; 16-byte Folded Reload
	mov	x1, x23
	mov	x6, x24
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	add	x3, x23, x8
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x2, x0
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	cbnz	x20, LBB2_626
	b	LBB2_906
LBB2_646:
	ldr	x21, [sp, #168]                 ; 8-byte Folded Reload
	cbz	x0, LBB2_888
; %bb.647:
	cmp	x21, #383
	b.hi	LBB2_886
; %bb.648:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x4, x24
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_888
LBB2_649:
	ldp	x8, x4, [sp, #80]               ; 16-byte Folded Reload
	mov	x1, x23
	mov	x6, x24
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	mov	x25, x20
	add	x3, x23, x8
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x2, x0
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	ldr	x19, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_894
; %bb.650:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_892
; %bb.651:
	mov	x0, x20
	ldr	x1, [sp, #144]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	cbnz	x25, LBB2_626
	b	LBB2_906
LBB2_652:                               ; %.lr.ph191.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_831
; %bb.653:                              ; %vector.scevcheck2052
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	sub	x12, x11, #1
	sub	x14, x13, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_831
; %bb.654:                              ; %vector.scevcheck2052
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_831
; %bb.655:                              ; %vector.scevcheck2052
	lsr	x12, x12, #61
	cbnz	x12, LBB2_831
; %bb.656:                              ; %vector.memcheck2061
	ldr	x14, [sp, #208]                 ; 8-byte Folded Reload
	lsl	x12, x11, #3
	ldr	x4, [sp, #344]                  ; 8-byte Folded Reload
	add	x13, x12, #8
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x17, x14, #8
	add	x0, x14, x13
	sub	x16, x4, x12
	cmp	x17, x4
	ccmp	x16, x0, #2, lo
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x4
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x4, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_954
; %bb.657:                              ; %vector.memcheck2061
	tbnz	w12, #0, LBB2_954
; %bb.658:                              ; %vector.memcheck2061
	tbnz	w13, #0, LBB2_954
; %bb.659:                              ; %vector.memcheck2061
	tbnz	w14, #0, LBB2_954
; %bb.660:                              ; %vector.memcheck2061
	tbnz	w15, #0, LBB2_954
; %bb.661:                              ; %vector.memcheck2061
	tbnz	w16, #0, LBB2_954
; %bb.662:                              ; %vector.ph2094
	ldr	x17, [sp, #208]                 ; 8-byte Folded Reload
	and	x16, x11, #0x7ffffffffffffffe
	ldr	x0, [sp, #344]                  ; 8-byte Folded Reload
	lsl	x15, x16, #3
	ubfx	x8, x8, #1, #1
	sub	x13, x10, x15
	add	x12, x17, x15
	add	x14, x9, x15
	sub	x15, x0, x15
	add	x17, x17, #8
	add	x9, x9, #8
	sub	x0, x0, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_663:                               ; %vector.body2108
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_663
; %bb.664:                              ; %middle.block2091
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	cmp	x11, x16
	ldr	x17, [sp, #288]                 ; 8-byte Folded Reload
	b.eq	LBB2_178
	b	LBB2_832
LBB2_665:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #344]                 ; 8-byte Folded Reload
	mov	x13, x10
	mov	x14, x9
LBB2_666:                               ; %.lr.ph161.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_667:                               ; %.lr.ph161.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_667
LBB2_668:                               ; %sort.quad_reversal.exit331.i.i
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x8, x8, #1
	sub	x12, x7, x8
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x8, x10
	sub	x10, x7, x10
	tbnz	w12, #4, LBB2_670
; %bb.669:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB2_670:                               ; %._crit_edge.i332.i.i
	ldr	x12, [x7]
	cmp	x9, #2
	ldr	x13, [x8]
	str	x12, [x8]
	str	x13, [x7]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB2_718
; %bb.671:                              ; %.lr.ph167.preheader.i.i
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB2_715
; %bb.672:                              ; %vector.scevcheck1768
	sub	x13, x12, #1
	sub	x15, x7, #8
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB2_715
; %bb.673:                              ; %vector.scevcheck1768
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB2_715
; %bb.674:                              ; %vector.scevcheck1768
	lsr	x13, x13, #61
	cbnz	x13, LBB2_715
; %bb.675:                              ; %vector.memcheck1777
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	lsl	x14, x12, #3
	sub	x17, x7, x14
	sub	x2, x11, x14
	add	x3, x10, #8
	add	x0, x13, #9
	add	x4, x3, x14
	add	x1, x0, x14
	cmp	x0, x7
	ccmp	x17, x1, #2, lo
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x7
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x7, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB2_715
; %bb.676:                              ; %vector.memcheck1777
	tbnz	w13, #0, LBB2_715
; %bb.677:                              ; %vector.memcheck1777
	tbnz	w14, #0, LBB2_715
; %bb.678:                              ; %vector.memcheck1777
	tbnz	w15, #0, LBB2_715
; %bb.679:                              ; %vector.memcheck1777
	tbnz	w16, #0, LBB2_715
; %bb.680:                              ; %vector.memcheck1777
	tbnz	w17, #0, LBB2_715
; %bb.681:                              ; %vector.ph1810
	ldr	x17, [sp, #344]                 ; 8-byte Folded Reload
	and	x16, x12, #0x7ffffffffffffffe
	lsl	x15, x16, #3
	ubfx	x9, x9, #1, #1
	add	x8, x8, x15
	sub	x13, x11, x15
	add	x14, x10, x15
	sub	x15, x7, x15
	add	x17, x17, #9
	add	x10, x10, #8
	sub	x0, x7, #16
	sub	x11, x11, #16
	neg	x1, x16
LBB2_682:                               ; %vector.body1824
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x10]
	ldr	q1, [x11]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x11], #-16
	str	q1, [x10], #16
	b.ne	LBB2_682
; %bb.683:                              ; %middle.block1807
	cmp	x12, x16
	b.ne	LBB2_716
	b	LBB2_718
LBB2_684:
	mov	x9, x12
	mov	x13, x11
	mov	x14, x10
	mov	x15, x7
LBB2_685:                               ; %.lr.ph155.i.i.preheader
	add	x8, x8, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_686:                               ; %.lr.ph155.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x8]
	str	x13, [x8], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_686
LBB2_687:
	mov	x1, xzr
	b	LBB2_953
LBB2_688:
	mov	x9, x12
	mov	x13, x11
	mov	x14, x10
	mov	x15, x6
LBB2_689:                               ; %.lr.ph170.i.i.preheader
	add	x8, x8, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_690:                               ; %.lr.ph170.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x8]
	str	x13, [x8], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_690
LBB2_691:
	mov	x1, xzr
	mov	x25, xzr
	b	LBB2_743
LBB2_692:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #336]                 ; 8-byte Folded Reload
	mov	x13, x10
	mov	x14, x9
LBB2_693:                               ; %.lr.ph158.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_694:                               ; %.lr.ph158.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_694
LBB2_695:                               ; %sort.quad_reversal.exit329.i.i
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x8, x8, #1
	sub	x12, x6, x8
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x8, x10
	sub	x10, x6, x10
	tbnz	w12, #4, LBB2_697
; %bb.696:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB2_697:                               ; %._crit_edge.i330.i.i
	ldr	x12, [x6]
	cmp	x9, #2
	ldr	x13, [x8]
	str	x12, [x8]
	str	x13, [x6]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB2_722
; %bb.698:                              ; %.lr.ph164.preheader.i.i
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB2_719
; %bb.699:                              ; %vector.scevcheck916
	sub	x13, x12, #1
	sub	x15, x6, #8
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB2_719
; %bb.700:                              ; %vector.scevcheck916
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB2_719
; %bb.701:                              ; %vector.scevcheck916
	lsr	x13, x13, #61
	cbnz	x13, LBB2_719
; %bb.702:                              ; %vector.memcheck925
	ldr	x13, [sp, #336]                 ; 8-byte Folded Reload
	lsl	x14, x12, #3
	sub	x17, x6, x14
	sub	x2, x11, x14
	add	x3, x10, #8
	add	x0, x13, #9
	add	x4, x3, x14
	add	x1, x0, x14
	cmp	x0, x6
	ccmp	x17, x1, #2, lo
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x6
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x6, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB2_719
; %bb.703:                              ; %vector.memcheck925
	tbnz	w13, #0, LBB2_719
; %bb.704:                              ; %vector.memcheck925
	tbnz	w14, #0, LBB2_719
; %bb.705:                              ; %vector.memcheck925
	tbnz	w15, #0, LBB2_719
; %bb.706:                              ; %vector.memcheck925
	tbnz	w16, #0, LBB2_719
; %bb.707:                              ; %vector.memcheck925
	tbnz	w17, #0, LBB2_719
; %bb.708:                              ; %vector.ph958
	ldr	x17, [sp, #336]                 ; 8-byte Folded Reload
	and	x16, x12, #0x7ffffffffffffffe
	lsl	x15, x16, #3
	ubfx	x9, x9, #1, #1
	add	x8, x8, x15
	sub	x13, x11, x15
	add	x14, x10, x15
	sub	x15, x6, x15
	add	x17, x17, #9
	add	x10, x10, #8
	sub	x0, x6, #16
	sub	x11, x11, #16
	neg	x1, x16
LBB2_709:                               ; %vector.body972
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x10]
	ldr	q1, [x11]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x11], #-16
	str	q1, [x10], #16
	b.ne	LBB2_709
; %bb.710:                              ; %middle.block955
	cmp	x12, x16
	b.ne	LBB2_720
	b	LBB2_722
LBB2_711:
	mov	x9, x12
	mov	x13, x11
	mov	x14, x10
	mov	x15, x6
LBB2_712:                               ; %.lr.ph152.i.i.preheader
	add	x8, x8, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_713:                               ; %.lr.ph152.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x8]
	str	x13, [x8], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_713
LBB2_714:
	mov	x1, xzr
	b	LBB2_742
LBB2_715:
	mov	x9, x12
	mov	x13, x11
	mov	x14, x10
	mov	x15, x7
LBB2_716:                               ; %.lr.ph167.i.i.preheader
	add	x8, x8, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_717:                               ; %.lr.ph167.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x8]
	str	x13, [x8], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_717
LBB2_718:
	mov	x1, xzr
	mov	x17, xzr
	mov	x4, xzr
	mov	x30, xzr
	b	LBB2_1152
LBB2_719:
	mov	x9, x12
	mov	x13, x11
	mov	x14, x10
	mov	x15, x6
LBB2_720:                               ; %.lr.ph164.i.i.preheader
	add	x8, x8, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_721:                               ; %.lr.ph164.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x8]
	str	x13, [x8], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_721
LBB2_722:
	mov	x1, xzr
	mov	x25, xzr
	mov	x23, xzr
	mov	x26, xzr
	b	LBB2_961
LBB2_723:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
LBB2_724:                               ; %.lr.ph179.i.i.preheader
	mov	x13, x10
	mov	x14, x9
	mov	x15, x5
LBB2_725:                               ; %.lr.ph179.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_726:                               ; %.lr.ph179.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_726
LBB2_727:
	mov	x4, xzr
	mov	x30, xzr
	b	LBB2_1127
LBB2_728:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #344]                 ; 8-byte Folded Reload
	mov	x13, x10
LBB2_729:                               ; %.lr.ph176.i.i.preheader
	mov	x14, x9
LBB2_730:                               ; %.lr.ph176.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_731:                               ; %.lr.ph176.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_731
LBB2_732:
	mov	x23, xzr
	mov	x26, xzr
	b	LBB2_812
LBB2_733:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #336]                 ; 8-byte Folded Reload
	mov	x13, x10
LBB2_734:                               ; %.lr.ph188.i.i.preheader
	mov	x14, x9
LBB2_735:                               ; %.lr.ph188.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_736:                               ; %.lr.ph188.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_736
LBB2_737:
	mov	x26, xzr
	b	LBB2_788
LBB2_738:
	ldr	x15, [sp, #344]                 ; 8-byte Folded Reload
	mov	x9, x12
LBB2_739:                               ; %.lr.ph182.i.i.preheader
	mov	x13, x11
	mov	x14, x10
LBB2_740:                               ; %.lr.ph182.i.i.preheader
	add	x8, x8, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_741:                               ; %.lr.ph182.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x8]
	str	x13, [x8], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_741
LBB2_742:
	mov	x25, xzr
	str	xzr, [sp, #288]                 ; 8-byte Folded Spill
LBB2_743:                               ; %sort.quad_reversal.exit299.i.i
	cbz	x26, LBB2_765
; %bb.744:                              ; %sort.quad_reversal.exit299.i.i
	cmp	x28, #1
	b.ne	LBB2_765
; %bb.745:
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	sub	x11, x5, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x5, x9
	tbnz	w11, #4, LBB2_747
; %bb.746:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_747:                               ; %._crit_edge.i360.i.i
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x11, [x5]
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x5]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_764
; %bb.748:                              ; %.lr.ph194.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_761
; %bb.749:                              ; %vector.scevcheck1271
	sub	x12, x11, #1
	sub	x14, x5, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_761
; %bb.750:                              ; %vector.scevcheck1271
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_761
; %bb.751:                              ; %vector.scevcheck1271
	lsr	x12, x12, #61
	cbnz	x12, LBB2_761
; %bb.752:                              ; %vector.memcheck1280
	ldr	x14, [sp, #208]                 ; 8-byte Folded Reload
	lsl	x12, x11, #3
	add	x13, x12, #8
	sub	x16, x5, x12
	mov	x4, x1
	sub	x1, x10, x12
	add	x17, x14, #8
	add	x0, x14, x13
	cmp	x17, x5
	add	x2, x9, #8
	ccmp	x16, x0, #2, lo
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x5
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x5, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1051
; %bb.753:                              ; %vector.memcheck1280
	tbnz	w12, #0, LBB2_1051
; %bb.754:                              ; %vector.memcheck1280
	mov	x1, x4
	tbnz	w13, #0, LBB2_761
; %bb.755:                              ; %vector.memcheck1280
	tbnz	w14, #0, LBB2_761
; %bb.756:                              ; %vector.memcheck1280
	tbnz	w15, #0, LBB2_761
; %bb.757:                              ; %vector.memcheck1280
	tbnz	w16, #0, LBB2_761
; %bb.758:                              ; %vector.ph1313
	ldr	x17, [sp, #208]                 ; 8-byte Folded Reload
	and	x16, x11, #0x7ffffffffffffffe
	lsl	x15, x16, #3
	ubfx	x8, x8, #1, #1
	sub	x13, x10, x15
	add	x14, x9, x15
	add	x12, x17, x15
	sub	x15, x5, x15
	add	x17, x17, #8
	add	x9, x9, #8
	sub	x0, x5, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_759:                               ; %vector.body1327
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_759
; %bb.760:                              ; %middle.block1310
	mov	x1, x4
	cmp	x11, x16
	b.ne	LBB2_762
	b	LBB2_764
LBB2_761:
	mov	x8, x11
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x13, x10
	mov	x14, x9
	mov	x15, x5
LBB2_762:                               ; %.lr.ph194.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_763:                               ; %.lr.ph194.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_763
LBB2_764:
	mov	x26, xzr
LBB2_765:                               ; %sort.quad_reversal.exit369.i.i
	ldr	x8, [sp, #80]                   ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_771
; %bb.766:                              ; %sort.quad_reversal.exit369.i.i
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_771
; %bb.767:
	ldr	x12, [sp, #336]                 ; 8-byte Folded Reload
	ldr	x10, [sp, #224]                 ; 8-byte Folded Reload
	sub	x11, x12, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x12, x9
	tbnz	w11, #4, LBB2_769
; %bb.768:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_769:                               ; %._crit_edge.i370.i.i
	ldr	x13, [sp, #336]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x14, [sp, #224]                 ; 8-byte Folded Reload
	ldr	x11, [x13]
	ldr	x12, [x14]
	str	x11, [x14]
	str	x12, [x13]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.hs	LBB2_772
; %bb.770:
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
	b	LBB2_788
LBB2_771:
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
	b	LBB2_789
LBB2_772:                               ; %.lr.ph200.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_785
; %bb.773:                              ; %vector.scevcheck1342
	ldr	x13, [sp, #336]                 ; 8-byte Folded Reload
	sub	x12, x11, #1
	sub	x14, x13, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_785
; %bb.774:                              ; %vector.scevcheck1342
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_785
; %bb.775:                              ; %vector.scevcheck1342
	lsr	x12, x12, #61
	cbnz	x12, LBB2_785
; %bb.776:                              ; %vector.memcheck1351
	mov	x21, x20
	ldr	x20, [sp, #336]                 ; 8-byte Folded Reload
	add	x17, x5, #16
	lsl	x13, x11, #3
	add	x0, x17, x13
	mov	x4, x1
	sub	x16, x20, x13
	cmp	x17, x20
	ccmp	x16, x0, #2, lo
	sub	x1, x10, x13
	add	x2, x9, #8
	add	x3, x2, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x20
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x20, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1052
; %bb.777:                              ; %vector.memcheck1351
	tbnz	w12, #0, LBB2_1052
; %bb.778:                              ; %vector.memcheck1351
	mov	x1, x4
	mov	x20, x21
	tbnz	w13, #0, LBB2_785
; %bb.779:                              ; %vector.memcheck1351
	tbnz	w14, #0, LBB2_785
; %bb.780:                              ; %vector.memcheck1351
	tbnz	w15, #0, LBB2_785
; %bb.781:                              ; %vector.memcheck1351
	tbnz	w16, #0, LBB2_785
; %bb.782:                              ; %vector.ph1384
	ldr	x12, [sp, #224]                 ; 8-byte Folded Reload
	and	x15, x11, #0x7ffffffffffffffe
	lsl	x14, x15, #3
	ldr	x17, [sp, #336]                 ; 8-byte Folded Reload
	ubfx	x8, x8, #1, #1
	add	x13, x9, x14
	add	x12, x12, x14
	add	x16, x5, #16
	add	x9, x9, #8
	neg	x0, x15
	str	x12, [sp, #224]                 ; 8-byte Folded Spill
	sub	x12, x10, x14
	sub	x14, x17, x14
	sub	x17, x17, #16
	sub	x10, x10, #16
LBB2_783:                               ; %vector.body1398
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x17]
	adds	x0, x0, #2
	ldr	q1, [x16]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x16], #16
	str	q1, [x17], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_783
; %bb.784:                              ; %middle.block1381
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
	cmp	x11, x15
	b.ne	LBB2_786
	b	LBB2_788
LBB2_785:
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
	ldr	x14, [sp, #336]                 ; 8-byte Folded Reload
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
LBB2_786:                               ; %.lr.ph200.i.i.preheader
	ldr	x9, [sp, #224]                  ; 8-byte Folded Reload
	sub	x10, x12, #8
	add	x11, x13, #8
	sub	x12, x14, #8
	add	x9, x9, #8
LBB2_787:                               ; %.lr.ph200.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_787
LBB2_788:                               ; %sort.quad_reversal.exit379.i.i
	str	xzr, [sp, #288]                 ; 8-byte Folded Spill
LBB2_789:                               ; %sort.quad_reversal.exit379.i.i
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_807
; %bb.790:                              ; %sort.quad_reversal.exit379.i.i
	cbz	x25, LBB2_807
; %bb.791:
	ldr	x12, [sp, #344]                 ; 8-byte Folded Reload
	sub	x11, x12, x20
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x20, x9
	sub	x9, x12, x9
	tbnz	w11, #4, LBB2_793
; %bb.792:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_793:                               ; %._crit_edge.i380.i.i
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x12, [x20]
	ldr	x11, [x13]
	str	x11, [x20]
	str	x12, [x13]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_811
; %bb.794:                              ; %.lr.ph206.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_808
; %bb.795:                              ; %vector.scevcheck1413
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	sub	x12, x11, #1
	sub	x14, x13, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_808
; %bb.796:                              ; %vector.scevcheck1413
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_808
; %bb.797:                              ; %vector.scevcheck1413
	lsr	x12, x12, #61
	cbnz	x12, LBB2_808
; %bb.798:                              ; %vector.memcheck1422
	mov	x21, x20
	lsl	x13, x11, #3
	ldp	x12, x20, [sp, #336]            ; 16-byte Folded Reload
	mov	x4, x1
	sub	x1, x10, x13
	add	x2, x9, #8
	add	x3, x2, x13
	add	x17, x12, #16
	add	x0, x17, x13
	sub	x16, x20, x13
	cmp	x17, x20
	ccmp	x16, x0, #2, lo
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x20
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x20, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1050
; %bb.799:                              ; %vector.memcheck1422
	tbnz	w12, #0, LBB2_1050
; %bb.800:                              ; %vector.memcheck1422
	mov	x1, x4
	mov	x20, x21
	tbnz	w13, #0, LBB2_808
; %bb.801:                              ; %vector.memcheck1422
	tbnz	w14, #0, LBB2_808
; %bb.802:                              ; %vector.memcheck1422
	tbnz	w15, #0, LBB2_808
; %bb.803:                              ; %vector.memcheck1422
	tbnz	w16, #0, LBB2_808
; %bb.804:                              ; %vector.ph1455
	ldp	x16, x17, [sp, #336]            ; 16-byte Folded Reload
	and	x15, x11, #0x7ffffffffffffffe
	ubfx	x8, x8, #1, #1
	lsl	x14, x15, #3
	neg	x0, x15
	add	x20, x20, x14
	sub	x12, x10, x14
	add	x13, x9, x14
	add	x16, x16, #16
	sub	x14, x17, x14
	add	x9, x9, #8
	sub	x17, x17, #16
	sub	x10, x10, #16
LBB2_805:                               ; %vector.body1469
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x17]
	adds	x0, x0, #2
	ldr	q1, [x16]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x16], #16
	str	q1, [x17], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_805
; %bb.806:                              ; %middle.block1452
	cmp	x11, x15
	b.ne	LBB2_809
	b	LBB2_811
LBB2_807:
	ldr	x23, [sp, #288]                 ; 8-byte Folded Reload
	b	LBB2_813
LBB2_808:
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
LBB2_809:                               ; %.lr.ph206.i.i.preheader
	add	x9, x20, #8
	sub	x10, x12, #8
	add	x11, x13, #8
	sub	x12, x14, #8
LBB2_810:                               ; %.lr.ph206.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_810
LBB2_811:
	ldr	x23, [sp, #288]                 ; 8-byte Folded Reload
LBB2_812:                               ; %sort.quad_reversal.exit389.i.i
	mov	x25, xzr
LBB2_813:                               ; %sort.quad_reversal.exit389.i.i
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_961
; %bb.814:                              ; %sort.quad_reversal.exit389.i.i
	cbz	x1, LBB2_961
; %bb.815:
	ldr	x1, [sp, #72]                   ; 8-byte Folded Reload
	sub	x11, x6, x1
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x1, x9
	sub	x9, x6, x9
	tbnz	w11, #4, LBB2_817
; %bb.816:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_817:                               ; %._crit_edge.i390.i.i
	ldr	x11, [x6]
	cmp	x8, #2
	ldr	x12, [x1]
	str	x11, [x1]
	str	x12, [x6]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_960
; %bb.818:                              ; %.lr.ph212.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_957
; %bb.819:                              ; %vector.scevcheck1484
	sub	x12, x11, #1
	sub	x14, x6, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_957
; %bb.820:                              ; %vector.scevcheck1484
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_957
; %bb.821:                              ; %vector.scevcheck1484
	lsr	x12, x12, #61
	cbnz	x12, LBB2_957
; %bb.822:                              ; %vector.memcheck1493
	ldr	x12, [sp, #344]                 ; 8-byte Folded Reload
	lsl	x13, x11, #3
	sub	x16, x6, x13
	sub	x1, x10, x13
	add	x2, x9, #8
	add	x17, x12, #16
	add	x3, x2, x13
	add	x0, x17, x13
	cmp	x17, x6
	ccmp	x16, x0, #2, lo
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x6
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x6, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_956
; %bb.823:                              ; %vector.memcheck1493
	tbnz	w12, #0, LBB2_956
; %bb.824:                              ; %vector.memcheck1493
	ldr	x1, [sp, #72]                   ; 8-byte Folded Reload
	tbnz	w13, #0, LBB2_957
; %bb.825:                              ; %vector.memcheck1493
	tbnz	w14, #0, LBB2_957
; %bb.826:                              ; %vector.memcheck1493
	tbnz	w15, #0, LBB2_957
; %bb.827:                              ; %vector.memcheck1493
	tbnz	w16, #0, LBB2_957
; %bb.828:                              ; %vector.ph1526
	ldr	x16, [sp, #344]                 ; 8-byte Folded Reload
	and	x15, x11, #0x7ffffffffffffffe
	lsl	x14, x15, #3
	ubfx	x8, x8, #1, #1
	add	x1, x1, x14
	sub	x12, x10, x14
	add	x13, x9, x14
	sub	x14, x6, x14
	add	x16, x16, #16
	add	x9, x9, #8
	sub	x17, x6, #16
	sub	x10, x10, #16
	neg	x0, x15
LBB2_829:                               ; %vector.body1540
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x17]
	adds	x0, x0, #2
	ldr	q1, [x16]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x16], #16
	str	q1, [x17], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_829
; %bb.830:                              ; %middle.block1523
	cmp	x11, x15
	b.eq	LBB2_960
	b	LBB2_958
LBB2_831:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #344]                 ; 8-byte Folded Reload
	mov	x13, x10
	mov	x14, x9
LBB2_832:                               ; %.lr.ph191.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
	mov	x24, x23
LBB2_833:                               ; %.lr.ph191.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_833
; %bb.834:
	mov	x30, xzr
	b	LBB2_1105
LBB2_835:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_837
; %bb.836:
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x21, [sp, #104]                 ; 8-byte Folded Reload
	mov	x3, x20
	ldr	x25, [sp, #264]                 ; 8-byte Folded Reload
	mov	x4, x27
	mov	x0, x19
	mov	x5, x24
	mov	x1, x21
	mov	x6, x28
	mov	x7, x25
	mov	x26, x28
	str	x22, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x23
	mov	x3, x20
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	stp	x25, x22, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_837:                               ; %sort.quadsort_swap__anon_14855.exit.i.i
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x9, [sp, #112]                  ; 8-byte Folded Reload
	add	x4, x9, x8
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	b	LBB2_841
LBB2_838:
	mov	x0, x20
	mov	x2, x27
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_840
; %bb.839:
	ldr	x21, [sp, #112]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x25, [sp, #264]                 ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x19
	mov	x4, x27
	mov	x1, x21
	mov	x5, x24
	mov	x6, x28
	mov	x7, x25
	mov	x26, x28
	str	x22, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x21
	mov	x2, x23
	mov	x3, x19
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	stp	x25, x22, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_840:                               ; %sort.quadsort_swap__anon_14855.exit424.i.i
	ldr	x4, [sp, #96]                   ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
LBB2_841:                               ; %sort.quadsort_swap__anon_14855.exit428.i.i
	madd	x3, x4, x28, x23
	add	x0, x8, x28
LBB2_842:                               ; %sort.quadsort_swap__anon_14855.exit428.i.i
	mov	x1, x23
	mov	x2, x0
	mov	x5, x27
	mov	x6, x24
LBB2_843:                               ; %sort.quadsort_swap__anon_14855.exit428.i.i
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	mov	x25, x22
LBB2_844:                               ; %sort.quadsort_swap__anon_14855.exit428.i.i
	ldr	x19, [sp, #320]                 ; 8-byte Folded Reload
	mov	x0, x24
	mov	w1, #1
	mov	x22, x28
	add	x20, x19, x28
	blr	x25
	mov	x0, x24
	mov	x1, x19
	mov	x2, x20
	blr	x27
	ldr	x21, [sp, #304]                 ; 8-byte Folded Reload
	and	w19, w0, #0xff
	mov	x0, x24
	mov	w1, #1
	add	x20, x21, x28
	blr	x25
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	blr	x27
	and	w8, w0, #0xff
	cmp	w19, #1
	b.ne	LBB2_847
; %bb.845:
	ldr	x9, [sp, #72]                   ; 8-byte Folded Reload
	cmp	w8, #1
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x0, x23, x9
	b.ne	LBB2_849
; %bb.846:
	ldr	x20, [sp, #264]                 ; 8-byte Folded Reload
	add	x1, x8, x28
	ldp	x2, x3, [sp, #128]              ; 16-byte Folded Reload
	mov	x4, x27
	mov	x5, x24
	mov	x6, x28
	mov	x7, x20
	mov	x21, x28
	str	x25, [sp]
	bl	l_sort.cross_merge__anon_14856
	ldp	x2, x3, [sp, #104]              ; 16-byte Folded Reload
	mov	x0, x23
	mov	x4, x27
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x5, x24
	mov	x6, x28
	mov	x7, x20
	mov	x1, x19
	b	LBB2_850
LBB2_847:
	ldr	x19, [sp, #344]                 ; 8-byte Folded Reload
	cmp	w8, #1
	b.ne	LBB2_852
; %bb.848:
	ldp	x1, x20, [sp, #64]              ; 16-byte Folded Reload
	mov	x4, x27
	mov	x5, x24
	ldp	x2, x3, [sp, #128]              ; 16-byte Folded Reload
	mov	x6, x28
	str	x25, [sp]
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	add	x0, x23, x20
	bl	l_sort.cross_merge__anon_14856
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x0, x23
	mov	x2, x20
	mov	x1, x19
	bl	_memcpy
	b	LBB2_851
LBB2_849:
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	mov	x20, x28
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	mul	x2, x8, x28
	bl	_memcpy
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x0, x23
	ldp	x2, x3, [sp, #104]              ; 16-byte Folded Reload
	mov	x4, x27
	mov	x5, x24
	mov	x1, x19
	mov	x6, x28
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
LBB2_850:
	str	x25, [sp]
	bl	l_sort.cross_merge__anon_14856
LBB2_851:
	mov	x0, x19
	mov	x1, x23
	ldr	x2, [sp, #80]                   ; 8-byte Folded Reload
	mov	x4, x27
	ldr	x3, [sp, #96]                   ; 8-byte Folded Reload
	mov	x5, x24
	mov	x6, x28
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	str	x25, [sp]
	bl	l_sort.cross_merge__anon_14856
	b	LBB2_916
LBB2_852:
	mov	x0, x24
	mov	w1, #1
	add	x20, x19, x28
	blr	x25
	mov	x0, x24
	mov	x1, x19
	mov	x2, x20
	blr	x27
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB2_916
; %bb.853:
	ldr	x23, [sp, #152]                 ; 8-byte Folded Reload
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	ldr	x2, [sp, #120]                  ; 8-byte Folded Reload
	mov	x0, x23
	mov	x1, x19
	bl	_memcpy
	ldr	x27, [sp, #328]                 ; 8-byte Folded Reload
	b	LBB2_851
LBB2_854:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x25
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_856
; %bb.855:
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x20, [sp, #104]                 ; 8-byte Folded Reload
	mov	x3, x21
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x4, x27
	mov	x0, x19
	mov	x5, x25
	mov	x1, x20
	ldr	x6, [sp, #352]                  ; 8-byte Folded Reload
	mov	x7, x26
	mov	x28, x25
	str	x22, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x19
	mov	x1, x20
	mov	x2, x23
	mov	x3, x21
	mov	x5, x27
	mov	x6, x25
	ldr	x7, [sp, #352]                  ; 8-byte Folded Reload
	stp	x26, x22, [sp]
	mov	x28, x7
	bl	l_sort.rotate_merge__anon_14836
LBB2_856:                               ; %sort.quadsort_swap__anon_14855.exit425.i.i
	cbz	x24, LBB2_897
; %bb.857:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	cmp	x1, #95
	b.hi	LBB2_895
; %bb.858:
	mov	x0, x20
	mov	x2, x23
	mov	x3, x27
	mov	x4, x25
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_897
LBB2_859:
	mov	x0, x20
	ldr	x1, [sp, #128]                  ; 8-byte Folded Reload
	mov	x2, x27
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_861
; %bb.860:
	ldr	x21, [sp, #128]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x25, [sp, #264]                 ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x19
	mov	x4, x27
	mov	x1, x21
	mov	x5, x24
	mov	x6, x28
	mov	x7, x25
	mov	x26, x28
	str	x22, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x21
	mov	x2, x23
	mov	x3, x19
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	ldr	x21, [sp, #304]                 ; 8-byte Folded Reload
	stp	x25, x22, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_861:                               ; %sort.quadsort_swap__anon_14855.exit427.i.i
	ldr	x4, [sp, #136]                  ; 8-byte Folded Reload
	mov	x7, x28
	add	x0, x21, x28
	madd	x3, x4, x28, x23
	b	LBB2_842
LBB2_862:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_864
; %bb.863:
	ldr	x25, [sp, #240]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x20, [sp, #104]                 ; 8-byte Folded Reload
	mov	x3, x21
	mov	x4, x27
	mov	x5, x24
	mov	x0, x25
	mov	x6, x28
	mov	x1, x20
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	mov	x26, x28
	str	x22, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x25
	mov	x1, x20
	mov	x2, x23
	mov	x3, x21
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	ldr	x9, [sp, #248]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_864:                               ; %sort.quadsort_swap__anon_14855.exit429.i.i
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x9, [sp, #128]                  ; 8-byte Folded Reload
	mov	x1, x23
	mov	x5, x27
	mov	x6, x24
	mov	x25, x22
	add	x4, x9, x8
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	madd	x3, x4, x28, x23
	add	x0, x8, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	mov	x2, x0
	stp	x8, x22, [sp]
	bl	l_sort.flux_partition__anon_14854
	cbz	x19, LBB2_844
; %bb.865:
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	cmp	x1, #95
	b.hi	LBB2_898
; %bb.866:
	mov	x0, x20
	mov	x2, x23
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x22
	mov	x25, x22
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_844
LBB2_867:
	mov	x0, x20
	ldr	x1, [sp, #128]                  ; 8-byte Folded Reload
	mov	x2, x27
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x21
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_869
; %bb.868:
	ldr	x25, [sp, #128]                 ; 8-byte Folded Reload
	mov	x0, x20
	mov	x2, x23
	mov	x3, x19
	mov	x4, x27
	mov	x5, x24
	mov	x1, x25
	mov	x6, x28
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	mov	x26, x28
	str	x21, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x25
	mov	x2, x23
	mov	x3, x19
	mov	x5, x27
	mov	x6, x24
	mov	x7, x28
	ldr	x9, [sp, #248]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_869:                               ; %sort.quadsort_swap__anon_14855.exit431.i.i
	mov	x25, x21
	cbz	x22, LBB2_844
; %bb.870:
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	cmp	x1, #95
	b.hi	LBB2_900
; %bb.871:
	mov	x0, x20
	mov	x2, x23
	mov	x3, x27
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	mov	x7, x21
	mov	x25, x21
	bl	l_sort.tail_swap__anon_14832
	b	LBB2_844
LBB2_872:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x3, x24
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x4, x28
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_874
; %bb.873:
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x21, [sp, #112]                 ; 8-byte Folded Reload
	mov	x3, x20
	ldr	x25, [sp, #328]                 ; 8-byte Folded Reload
	mov	x5, x24
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x1, x21
	mov	x6, x28
	mov	x4, x25
	mov	x27, x28
	mov	x7, x26
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x23
	mov	x3, x20
	mov	x5, x25
	mov	x6, x24
	mov	x7, x28
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_874:                               ; %sort.quadsort_swap__anon_14858.exit.i.i
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x9, [sp, #104]                  ; 8-byte Folded Reload
	add	x0, x22, x28
	add	x4, x9, x8
	madd	x3, x4, x28, x23
	b	LBB2_905
LBB2_875:
	mov	x0, x20
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	mov	x25, x23
	tbz	w0, #0, LBB2_877
; %bb.876:
	ldr	x21, [sp, #104]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x23, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x25
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x3, x19
	mov	x1, x21
	mov	x5, x24
	mov	x4, x23
	mov	x6, x28
	mov	x7, x26
	mov	x27, x28
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	mov	x1, x21
	mov	x2, x25
	mov	x3, x19
	mov	x5, x23
	mov	x6, x24
	mov	x7, x28
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_877:                               ; %sort.quadsort_swap__anon_14858.exit422.i.i
	ldp	x8, x5, [sp, #320]              ; 16-byte Folded Reload
	mov	x7, x28
	mov	x1, x25
	ldr	x4, [sp, #128]                  ; 8-byte Folded Reload
	mov	x6, x24
	add	x0, x8, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	madd	x3, x4, x28, x25
	mov	x2, x0
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	mov	x23, x25
	b	LBB2_906
LBB2_878:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x3, x24
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_880
; %bb.879:
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x25, [sp, #328]                 ; 8-byte Folded Reload
	mov	x3, x21
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x5, x24
	mov	x0, x19
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x4, x25
	mov	x6, x28
	mov	x7, x26
	mov	x20, x23
	mov	x27, x28
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x19
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x21
	mov	x5, x25
	mov	x6, x24
	mov	x7, x28
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_880:                               ; %sort.quadsort_swap__anon_14858.exit423.i.i
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_903
; %bb.881:
	ldr	x1, [sp, #104]                  ; 8-byte Folded Reload
	add	x20, x22, x28
	cmp	x1, #95
	b.hi	LBB2_901
; %bb.882:
	mov	x0, x20
	mov	x2, x23
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x4, x24
	mov	x5, x28
	ldr	x6, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	b	LBB2_903
LBB2_883:
	mov	x0, x20
	ldr	x1, [sp, #144]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_885
; %bb.884:
	ldr	x21, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x25, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x3, x19
	mov	x1, x21
	mov	x5, x24
	mov	x4, x25
	mov	x6, x28
	mov	x7, x26
	mov	x27, x28
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	mov	x1, x21
	mov	x2, x23
	mov	x3, x19
	mov	x5, x25
	mov	x6, x24
	mov	x7, x28
	ldr	x21, [sp, #344]                 ; 8-byte Folded Reload
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_885:                               ; %sort.quadsort_swap__anon_14858.exit425.i.i
	ldr	x4, [sp, #136]                  ; 8-byte Folded Reload
	mov	x7, x28
	add	x0, x21, x28
	madd	x3, x4, x28, x23
	b	LBB2_905
LBB2_886:
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x3, x24
	ldr	x1, [sp, #112]                  ; 8-byte Folded Reload
	mov	x4, x28
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_888
; %bb.887:
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	str	x20, [sp, #256]                 ; 8-byte Folded Spill
	ldr	x20, [sp, #112]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	mov	x3, x21
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x1, x20
	mov	x5, x24
	mov	x4, x26
	mov	x6, x28
	mov	x7, x27
	mov	x25, x28
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x19
	mov	x1, x20
	mov	x2, x23
	mov	x3, x21
	mov	x5, x26
	mov	x6, x24
	mov	x7, x28
	ldr	x20, [sp, #256]                 ; 8-byte Folded Reload
	str	x27, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_888:                               ; %sort.quadsort_swap__anon_14858.exit427.i.i
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	add	x0, x22, x28
	ldr	x9, [sp, #144]                  ; 8-byte Folded Reload
	mov	x7, x28
	mov	x1, x23
	mov	x2, x0
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	mov	x6, x24
	add	x4, x9, x8
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	madd	x3, x4, x28, x23
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
	cbz	x20, LBB2_906
; %bb.889:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	add	x20, x8, x28
	cmp	x1, #95
	b.ls	LBB2_627
; %bb.890:
	mov	x0, x20
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_906
; %bb.891:
	ldr	x19, [sp, #136]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x25, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x26, [sp, #264]                 ; 8-byte Folded Reload
	mov	x3, x21
	mov	x1, x19
	mov	x5, x24
	mov	x4, x25
	mov	x6, x28
	mov	x7, x26
	mov	x27, x28
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	mov	x1, x19
	mov	x2, x23
	mov	x3, x21
	b	LBB2_631
LBB2_892:
	mov	x0, x20
	ldr	x1, [sp, #144]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_894
; %bb.893:
	ldr	x21, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	mov	x3, x19
	mov	x1, x21
	mov	x5, x24
	mov	x4, x26
	mov	x6, x28
	mov	x7, x27
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	mov	x1, x21
	mov	x2, x23
	mov	x3, x19
	mov	x5, x26
	mov	x6, x24
	ldr	x7, [sp, #352]                  ; 8-byte Folded Reload
	str	x27, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_894:                               ; %sort.quadsort_swap__anon_14858.exit429.i.i
	cbnz	x25, LBB2_626
	b	LBB2_906
LBB2_895:
	mov	x0, x20
	mov	x2, x27
	mov	x3, x25
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_897
; %bb.896:
	ldr	x19, [sp, #112]                 ; 8-byte Folded Reload
	mov	x0, x20
	mov	x2, x23
	mov	x3, x21
	mov	x4, x27
	mov	x5, x25
	mov	x1, x19
	mov	x6, x28
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	mov	x24, x25
	mov	x26, x28
	str	x22, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x19
	mov	x2, x23
	mov	x3, x21
	mov	x5, x27
	mov	x6, x25
	mov	x7, x28
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	stp	x8, x22, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB2_897:                               ; %sort.quadsort_swap__anon_14855.exit426.i.i
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x4, [sp, #96]                   ; 8-byte Folded Reload
	mov	x1, x23
	mov	x5, x27
	mov	x24, x25
	add	x0, x8, x28
	mov	x6, x25
	madd	x3, x4, x28, x23
	mov	x2, x0
	b	LBB2_843
LBB2_898:
	mov	x0, x20
	mov	x2, x27
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x6, x22
	mov	x25, x22
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB2_844
; %bb.899:
	ldr	x19, [sp, #136]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x22, [sp, #264]                 ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x21
	mov	x4, x27
	mov	x1, x19
	mov	x5, x24
	mov	x6, x28
	mov	x7, x22
	mov	x26, x28
	str	x25, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x19
	mov	x2, x23
	mov	x3, x21
	b	LBB2_574
LBB2_900:
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	mov	x0, x20
	mov	x2, x27
	mov	x3, x24
	mov	x4, x28
	mov	x25, x21
	mov	x6, x21
	bl	l_sort.quad_swap__anon_14834
	tbnz	w0, #0, LBB2_573
	b	LBB2_844
LBB2_901:
	mov	x0, x20
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x28
	ldr	x5, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB2_903
; %bb.902:
	ldr	x19, [sp, #104]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x27, [sp, #264]                 ; 8-byte Folded Reload
	mov	x3, x21
	mov	x1, x19
	mov	x5, x24
	mov	x4, x26
	mov	x6, x28
	mov	x7, x27
	mov	x25, x23
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x20
	mov	x1, x19
	mov	x2, x23
	mov	x3, x21
	mov	x5, x26
	mov	x6, x24
	ldr	x7, [sp, #352]                  ; 8-byte Folded Reload
	str	x27, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB2_903:                               ; %sort.quadsort_swap__anon_14858.exit424.i.i
	ldr	x4, [sp, #128]                  ; 8-byte Folded Reload
	mov	x7, x28
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
LBB2_904:                               ; %sort.quadsort_swap__anon_14858.exit426.i.i
	madd	x3, x4, x28, x23
	add	x0, x8, x28
LBB2_905:                               ; %sort.quadsort_swap__anon_14858.exit426.i.i
	mov	x1, x23
	mov	x2, x0
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	mov	x6, x24
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.flux_partition__anon_14857
LBB2_906:                               ; %sort.quadsort_swap__anon_14858.exit426.i.i
	add	x2, x22, x28
	mov	x0, x24
	mov	x1, x22
	ldr	x20, [sp, #328]                 ; 8-byte Folded Reload
	mov	x19, x28
	blr	x20
	ldr	x1, [sp, #344]                  ; 8-byte Folded Reload
	and	w19, w0, #0xff
	mov	x0, x24
	add	x2, x1, x28
	blr	x20
	and	w8, w0, #0xff
	cmp	w19, #1
	b.ne	LBB2_909
; %bb.907:
	ldr	x9, [sp, #80]                   ; 8-byte Folded Reload
	cmp	w8, #1
	add	x0, x23, x9
	b.ne	LBB2_911
; %bb.908:
	ldp	x8, x20, [sp, #320]             ; 16-byte Folded Reload
	mov	x5, x24
	mov	x6, x28
	ldr	x21, [sp, #264]                 ; 8-byte Folded Reload
	mov	x22, x28
	ldp	x3, x2, [sp, #136]              ; 16-byte Folded Reload
	add	x1, x8, x28
	mov	x4, x20
	mov	x7, x21
	bl	l_sort.cross_merge__anon_14859
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x0, x23
	ldp	x3, x2, [sp, #104]              ; 16-byte Folded Reload
	mov	x4, x20
	mov	x5, x24
	mov	x1, x19
	mov	x6, x28
	mov	x7, x21
	bl	l_sort.cross_merge__anon_14859
	b	LBB2_915
LBB2_909:
	cmp	w8, #1
	b.ne	LBB2_912
; %bb.910:
	ldr	x20, [sp, #80]                  ; 8-byte Folded Reload
	mov	x5, x24
	ldp	x3, x2, [sp, #136]              ; 16-byte Folded Reload
	mov	x6, x28
	add	x0, x23, x20
	ldr	x1, [sp, #96]                   ; 8-byte Folded Reload
	ldr	x4, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.cross_merge__anon_14859
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x0, x23
	mov	x2, x20
	b	LBB2_914
LBB2_911:
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	mov	x20, x28
	ldr	x1, [sp, #96]                   ; 8-byte Folded Reload
	mul	x2, x8, x28
	bl	_memcpy
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	mov	x0, x23
	ldp	x3, x2, [sp, #104]              ; 16-byte Folded Reload
	mov	x5, x24
	mov	x6, x28
	mov	x1, x19
	ldr	x4, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.cross_merge__anon_14859
	b	LBB2_915
LBB2_912:
	ldp	x1, x8, [sp, #320]              ; 16-byte Folded Reload
	mov	x0, x24
	add	x2, x1, x28
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB2_916
; %bb.913:
	ldr	x23, [sp, #152]                 ; 8-byte Folded Reload
	ldr	x19, [sp, #240]                 ; 8-byte Folded Reload
	ldr	x2, [sp, #120]                  ; 8-byte Folded Reload
	mov	x0, x23
LBB2_914:
	mov	x1, x19
	bl	_memcpy
LBB2_915:
	mov	x0, x19
	mov	x1, x23
	ldr	x2, [sp, #88]                   ; 8-byte Folded Reload
	mov	x5, x24
	ldr	x3, [sp, #128]                  ; 8-byte Folded Reload
	mov	x6, x28
	ldr	x4, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x7, [sp, #264]                  ; 8-byte Folded Reload
	bl	l_sort.cross_merge__anon_14859
LBB2_916:                               ; %sort.quadsort.exit
	ldr	x0, [sp, #152]                  ; 8-byte Folded Reload
	ldr	w1, [sp, #164]                  ; 4-byte Folded Reload
	bl	_roc_dealloc
	add	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 976
	add	sp, sp, #880
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB2_917:                               ; %vector.scevcheck1555
	.cfi_restore_state
	.cfi_remember_state
	ldr	x5, [sp, #312]                  ; 8-byte Folded Reload
	sub	x12, x11, #1
	lsl	x13, x12, #3
	ldr	x4, [sp, #208]                  ; 8-byte Folded Reload
	sub	x14, x5, #8
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_941
; %bb.918:                              ; %vector.scevcheck1555
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_941
; %bb.919:                              ; %vector.scevcheck1555
	lsr	x12, x12, #61
	cbnz	x12, LBB2_941
; %bb.920:                              ; %vector.memcheck1564
	lsl	x12, x11, #3
	add	x17, x4, #8
	add	x13, x12, #8
	sub	x16, x5, x12
	add	x0, x4, x13
	cmp	x17, x5
	ccmp	x16, x0, #2, lo
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x5
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x5, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_941
; %bb.921:                              ; %vector.memcheck1564
	tbnz	w12, #0, LBB2_941
; %bb.922:                              ; %vector.memcheck1564
	tbnz	w13, #0, LBB2_941
; %bb.923:                              ; %vector.memcheck1564
	tbnz	w14, #0, LBB2_941
; %bb.924:                              ; %vector.memcheck1564
	tbnz	w15, #0, LBB2_941
; %bb.925:                              ; %vector.memcheck1564
	tbnz	w16, #0, LBB2_941
; %bb.926:                              ; %vector.ph1597
	and	x16, x11, #0x7ffffffffffffffe
	ubfx	x8, x8, #1, #1
	lsl	x15, x16, #3
	add	x17, x4, #8
	add	x12, x4, x15
	sub	x13, x10, x15
	add	x14, x9, x15
	sub	x15, x5, x15
	add	x9, x9, #8
	sub	x0, x5, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_927:                               ; %vector.body1611
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_927
; %bb.928:                              ; %middle.block1594
	cmp	x11, x16
	b.eq	LBB2_1241
	b	LBB2_942
LBB2_929:                               ; %vector.scevcheck
	sub	x12, x11, #1
	sub	x14, x6, #8
	lsl	x13, x12, #3
	ldr	x4, [sp, #208]                  ; 8-byte Folded Reload
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_944
; %bb.930:                              ; %vector.scevcheck
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_944
; %bb.931:                              ; %vector.scevcheck
	lsr	x12, x12, #61
	cbnz	x12, LBB2_944
; %bb.932:                              ; %vector.memcheck
	lsl	x12, x11, #3
	add	x17, x4, #8
	add	x13, x12, #8
	sub	x16, x6, x12
	add	x0, x4, x13
	cmp	x17, x6
	ccmp	x16, x0, #2, lo
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x6
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x6, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_944
; %bb.933:                              ; %vector.memcheck
	tbnz	w12, #0, LBB2_944
; %bb.934:                              ; %vector.memcheck
	tbnz	w13, #0, LBB2_944
; %bb.935:                              ; %vector.memcheck
	tbnz	w14, #0, LBB2_944
; %bb.936:                              ; %vector.memcheck
	tbnz	w15, #0, LBB2_944
; %bb.937:                              ; %vector.memcheck
	tbnz	w16, #0, LBB2_944
; %bb.938:                              ; %vector.ph749
	and	x16, x11, #0x7ffffffffffffffe
	ubfx	x8, x8, #1, #1
	lsl	x15, x16, #3
	add	x17, x4, #8
	add	x12, x4, x15
	sub	x13, x10, x15
	add	x14, x9, x15
	sub	x15, x6, x15
	add	x9, x9, #8
	sub	x0, x6, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_939:                               ; %vector.body762
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_939
; %bb.940:                              ; %middle.block746
	cmp	x11, x16
	b.eq	LBB2_1049
	b	LBB2_946
LBB2_941:
	mov	x8, x11
	mov	x12, x4
	mov	x13, x10
	mov	x14, x9
	mov	x15, x5
LBB2_942:                               ; %.lr.ph149.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_943:                               ; %.lr.ph149.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_943
	b	LBB2_1241
LBB2_944:
	mov	x8, x11
	mov	x12, x4
LBB2_945:                               ; %.lr.ph146.i.i.preheader
	mov	x13, x10
	mov	x14, x9
	mov	x15, x6
LBB2_946:                               ; %.lr.ph146.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_947:                               ; %.lr.ph146.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_947
	b	LBB2_1049
LBB2_948:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #336]                 ; 8-byte Folded Reload
	mov	x13, x10
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	b	LBB2_734
LBB2_949:
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
LBB2_950:
	mov	x9, x12
	mov	x13, x11
	mov	x14, x10
	mov	x15, x5
LBB2_951:                               ; %.lr.ph185.i.i.preheader
	add	x8, x8, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_952:                               ; %.lr.ph185.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x8]
	str	x13, [x8], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_952
LBB2_953:
	mov	x17, xzr
	mov	x4, xzr
	b	LBB2_1059
LBB2_954:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #344]                 ; 8-byte Folded Reload
	mov	x13, x10
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	mov	x14, x9
	ldr	x17, [sp, #288]                 ; 8-byte Folded Reload
	b	LBB2_832
LBB2_955:
	ldr	x15, [sp, #344]                 ; 8-byte Folded Reload
	mov	x9, x12
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	b	LBB2_739
LBB2_956:
	ldr	x1, [sp, #72]                   ; 8-byte Folded Reload
LBB2_957:
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
	mov	x14, x6
LBB2_958:                               ; %.lr.ph212.i.i.preheader
	add	x9, x1, #8
	sub	x10, x12, #8
	add	x11, x13, #8
	sub	x12, x14, #8
LBB2_959:                               ; %.lr.ph212.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_959
LBB2_960:
	mov	x1, xzr
LBB2_961:                               ; %sort.quad_reversal.exit399.i.i229
	ldr	w8, [sp, #232]                  ; 4-byte Folded Reload
	lsr	x9, x27, #9
	ldr	w10, [sp, #248]                 ; 4-byte Folded Reload
	cmp	x9, w8, uxtw
	cset	w8, lo
	cmp	x9, w10, uxtw
	cset	w19, lo
	cmp	x9, w5, uxtw
	cset	w21, lo
	cmp	x9, w7, uxtw
	cset	w20, lo
	mov	w9, #3
	movk	w9, #16, lsl #16
	cmp	x27, x9
	b.ls	LBB2_963
; %bb.962:
	mov	w20, #1
	mov	w21, #1
	mov	w19, #1
	mov	w8, #1
LBB2_963:
	lsl	w9, w21, #2
Lloh12:
	adrp	x10, LJTI2_1@PAGE
Lloh13:
	add	x10, x10, LJTI2_1@PAGEOFF
	orr	w9, w9, w19, lsl #1
	orr	w9, w9, w20, lsl #3
	orr	w9, w9, w8
	adr	x11, LBB2_964
	ldrh	w12, [x10, x9, lsl #1]
	add	x11, x11, x12, lsl #2
	br	x11
LBB2_964:
	str	x1, [sp, #304]                  ; 8-byte Folded Spill
	cbz	w8, LBB2_968
; %bb.965:
	cbz	x26, LBB2_971
; %bb.966:
	cmp	x27, #383
	b.hi	LBB2_969
; %bb.967:
	ldp	x2, x0, [sp, #200]              ; 16-byte Folded Reload
	ldr	x1, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_971
LBB2_968:
	ldp	x1, x0, [sp, #200]              ; 16-byte Folded Reload
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	add	x3, x1, x8
	mov	x2, x0
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.flux_partition__anon_14863
	b	LBB2_971
LBB2_969:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB2_971
; %bb.970:
	ldp	x26, x22, [sp, #200]            ; 16-byte Folded Reload
	ldr	x28, [sp, #152]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x26
	ldr	x3, [sp, #168]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x1, x28
	mov	x4, x24
	ldr	x5, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_merge__anon_14850
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	mov	x4, x0
	mov	x0, x22
	mov	x1, x28
	mov	x2, x26
	mov	x5, x24
	mov	x3, x27
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14851
LBB2_971:                               ; %sort.quadsort_swap__anon_14864.exit409.i.i
	cbz	w19, LBB2_975
; %bb.972:
	cbz	x23, LBB2_978
; %bb.973:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	cmp	x1, #95
	b.hi	LBB2_976
; %bb.974:
	mov	x0, x19
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_978
LBB2_975:
	ldp	x8, x5, [sp, #320]              ; 16-byte Folded Reload
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #184]                  ; 8-byte Folded Reload
	add	x0, x8, #8
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	mov	x2, x0
	add	x3, x1, x4, lsl #3
	bl	l_sort.flux_partition__anon_14863
	b	LBB2_978
LBB2_976:
	mov	x0, x19
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB2_978
; %bb.977:
	ldr	x26, [sp, #184]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #200]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	mov	x1, x26
	ldr	x3, [sp, #168]                  ; 8-byte Folded Reload
	mov	x5, x23
	mov	x2, x22
	mov	x4, x24
	bl	l_sort.quad_merge__anon_14850
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	mov	x4, x0
	mov	x0, x19
	mov	x1, x26
	mov	x2, x22
	mov	x5, x24
	mov	x3, x27
	mov	x6, x23
	bl	l_sort.rotate_merge__anon_14851
LBB2_978:                               ; %sort.quadsort_swap__anon_14864.exit410.i.i
	cbz	w21, LBB2_982
; %bb.979:
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	cbz	x25, LBB2_985
; %bb.980:
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_983
; %bb.981:
	mov	x0, x19
	ldr	x1, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_985
LBB2_982:
	ldp	x5, x8, [sp, #328]              ; 16-byte Folded Reload
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	add	x0, x8, #8
	add	x3, x1, x4, lsl #3
	mov	x2, x0
	bl	l_sort.flux_partition__anon_14863
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	b	LBB2_985
LBB2_983:
	mov	x0, x19
	ldr	x1, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB2_985
; %bb.984:
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x22, [sp, #216]                 ; 8-byte Folded Reload
	mov	x3, x27
	ldr	x21, [sp, #200]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	mov	x5, x23
	mov	x1, x22
	mov	x2, x21
	mov	x4, x24
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x19
	mov	x1, x22
	mov	x2, x21
	mov	x3, x27
	mov	x5, x24
	mov	x6, x23
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14851
LBB2_985:                               ; %sort.quadsort_swap__anon_14864.exit411.i.i
	cbz	w20, LBB2_989
; %bb.986:
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_1039
LBB2_987:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #176]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	cmp	x1, #95
	b.hi	LBB2_990
; %bb.988:
	mov	x0, x19
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_1039
LBB2_989:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x8, #8
	b	LBB2_1015
LBB2_990:
	mov	x0, x19
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB2_1039
; %bb.991:
	ldr	x21, [sp, #176]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	mov	x3, x27
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	mov	x1, x21
	mov	x2, x20
	mov	x4, x24
	mov	x5, x23
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x24
	mov	x6, x23
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14851
	b	LBB2_1039
LBB2_992:
	ldp	x8, x1, [sp, #192]              ; 16-byte Folded Reload
	mov	x4, x27
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	add	x3, x1, x8
	mov	x2, x0
	bl	l_sort.flux_partition__anon_14863
	b	LBB2_1049
LBB2_993:
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	cbz	x26, LBB2_1014
; %bb.994:
	cmp	x27, #383
	b.hi	LBB2_1012
; %bb.995:
	ldp	x2, x0, [sp, #200]              ; 16-byte Folded Reload
	ldr	x1, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_1014
LBB2_996:
	ldp	x20, x0, [sp, #200]             ; 16-byte Folded Reload
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #152]                  ; 8-byte Folded Reload
	mov	x1, x20
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	add	x3, x20, x8
	mov	x2, x0
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.flux_partition__anon_14863
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	cbz	x23, LBB2_1018
; %bb.997:
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	add	x19, x21, #8
	cmp	x1, #95
	b.hi	LBB2_1016
; %bb.998:
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	mov	x2, x20
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_1018
LBB2_999:
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	mov	x19, x23
	cbz	x26, LBB2_1021
; %bb.1000:
	cmp	x27, #383
	b.hi	LBB2_1019
; %bb.1001:
	ldp	x2, x0, [sp, #200]              ; 16-byte Folded Reload
	ldr	x1, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_1021
LBB2_1002:
	ldp	x20, x0, [sp, #200]             ; 16-byte Folded Reload
	ldp	x8, x4, [sp, #128]              ; 16-byte Folded Reload
	mov	x1, x20
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	mov	x2, x0
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	add	x3, x20, x8
	bl	l_sort.flux_partition__anon_14863
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	cbz	x25, LBB2_1026
; %bb.1003:
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_1024
; %bb.1004:
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x1, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	mov	x2, x20
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_1026
LBB2_1005:
	mov	x19, x1
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	ldp	x1, x0, [sp, #200]              ; 16-byte Folded Reload
	ldp	x8, x4, [sp, #96]               ; 16-byte Folded Reload
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	mov	x2, x0
	add	x3, x1, x8
	bl	l_sort.flux_partition__anon_14863
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	cbnz	x19, LBB2_987
	b	LBB2_1039
LBB2_1006:
	mov	x19, x1
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	cbz	x26, LBB2_1030
; %bb.1007:
	cmp	x27, #383
	b.hi	LBB2_1028
; %bb.1008:
	ldp	x2, x0, [sp, #200]              ; 16-byte Folded Reload
	ldr	x1, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_1030
LBB2_1009:
	mov	x20, x1
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	ldp	x1, x0, [sp, #200]              ; 16-byte Folded Reload
	ldp	x8, x4, [sp, #128]              ; 16-byte Folded Reload
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	mov	x2, x0
	add	x3, x1, x8
	bl	l_sort.flux_partition__anon_14863
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	cbz	x25, LBB2_1033
; %bb.1010:
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_1031
; %bb.1011:
	mov	x0, x19
	ldr	x1, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	cbnz	x20, LBB2_987
	b	LBB2_1039
LBB2_1012:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB2_1014
; %bb.1013:
	ldp	x20, x19, [sp, #200]            ; 16-byte Folded Reload
	mov	x3, x27
	ldr	x21, [sp, #152]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	mov	x2, x20
	mov	x0, x19
	mov	x1, x21
	mov	x4, x24
	mov	x5, x23
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x24
	mov	x6, x23
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14851
LBB2_1014:                              ; %sort.quadsort_swap__anon_14864.exit.i.i
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	add	x0, x21, #8
	ldr	x9, [sp, #184]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	add	x4, x9, x8
LBB2_1015:                              ; %sort.quadsort_swap__anon_14864.exit404.i.i
	add	x3, x1, x4, lsl #3
	b	LBB2_1038
LBB2_1016:
	mov	x0, x19
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	tbz	w0, #0, LBB2_1018
; %bb.1017:
	ldr	x21, [sp, #184]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x20
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	mov	x3, x27
	mov	x1, x21
	mov	x4, x24
	mov	x5, x23
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x24
	mov	x6, x23
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14851
LBB2_1018:                              ; %sort.quadsort_swap__anon_14864.exit400.i.i
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #144]                  ; 8-byte Folded Reload
	b	LBB2_1027
LBB2_1019:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB2_1021
; %bb.1020:
	ldp	x20, x19, [sp, #200]            ; 16-byte Folded Reload
	mov	x3, x27
	ldr	x21, [sp, #152]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #360]                 ; 8-byte Folded Reload
	mov	x2, x20
	mov	x0, x19
	mov	x1, x21
	mov	x4, x24
	mov	x5, x22
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x24
	mov	x6, x22
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	mov	x19, x23
	bl	l_sort.rotate_merge__anon_14851
LBB2_1021:                              ; %sort.quadsort_swap__anon_14864.exit401.i.i
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	cbz	x19, LBB2_1037
; %bb.1022:
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	add	x19, x21, #8
	cmp	x1, #95
	b.hi	LBB2_1034
; %bb.1023:
	mov	x0, x19
	ldr	x3, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14848
	b	LBB2_1036
LBB2_1024:
	mov	x0, x19
	ldr	x1, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	tbz	w0, #0, LBB2_1026
; %bb.1025:
	ldr	x21, [sp, #216]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x20
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	mov	x3, x27
	mov	x1, x21
	mov	x4, x24
	mov	x5, x23
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x24
	mov	x6, x23
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14851
LBB2_1026:                              ; %sort.quadsort_swap__anon_14864.exit403.i.i
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #176]                  ; 8-byte Folded Reload
LBB2_1027:                              ; %sort.quadsort_swap__anon_14864.exit404.i.i
	add	x0, x8, #8
	add	x3, x20, x4, lsl #3
	mov	x1, x20
	b	LBB2_1038
LBB2_1028:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB2_1030
; %bb.1029:
	ldp	x20, x22, [sp, #200]            ; 16-byte Folded Reload
	mov	x3, x27
	ldr	x21, [sp, #152]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	mov	x2, x20
	mov	x0, x22
	mov	x1, x21
	mov	x4, x24
	mov	x5, x23
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x22
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x24
	mov	x6, x23
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14851
LBB2_1030:                              ; %sort.quadsort_swap__anon_14864.exit405.i.i
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	add	x0, x21, #8
	ldr	x9, [sp, #216]                  ; 8-byte Folded Reload
	mov	x2, x0
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	add	x4, x9, x8
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	add	x3, x1, x4, lsl #3
	bl	l_sort.flux_partition__anon_14863
	cbnz	x19, LBB2_987
	b	LBB2_1039
LBB2_1031:
	mov	x0, x19
	ldr	x1, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB2_1033
; %bb.1032:
	ldr	x21, [sp, #216]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x22, [sp, #200]                 ; 8-byte Folded Reload
	mov	x3, x27
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	mov	x1, x21
	mov	x2, x22
	mov	x4, x24
	mov	x5, x23
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x22
	mov	x3, x27
	mov	x5, x24
	mov	x6, x23
	ldr	x21, [sp, #320]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14851
LBB2_1033:                              ; %sort.quadsort_swap__anon_14864.exit407.i.i
	cbnz	x20, LBB2_987
	b	LBB2_1039
LBB2_1034:
	mov	x0, x19
	ldr	x2, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14849
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	tbz	w0, #0, LBB2_1037
; %bb.1035:
	ldr	x20, [sp, #184]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x24, [sp, #328]                 ; 8-byte Folded Reload
	mov	x3, x27
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	mov	x1, x20
	mov	x4, x24
	mov	x5, x23
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x19
	mov	x1, x20
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	mov	x3, x27
	mov	x5, x24
	mov	x6, x23
	bl	l_sort.rotate_merge__anon_14851
LBB2_1036:                              ; %sort.quadsort_swap__anon_14864.exit402.i.i
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
LBB2_1037:                              ; %sort.quadsort_swap__anon_14864.exit402.i.i
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	mov	x1, x2
	ldr	x4, [sp, #144]                  ; 8-byte Folded Reload
	add	x0, x8, #8
	add	x3, x2, x4, lsl #3
LBB2_1038:                              ; %sort.quadsort_swap__anon_14864.exit404.i.i
	mov	x2, x0
	ldr	x5, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.flux_partition__anon_14863
LBB2_1039:                              ; %sort.quadsort_swap__anon_14864.exit404.i.i
	ldr	x20, [sp, #360]                 ; 8-byte Folded Reload
	ldp	x1, x2, [x21]
	mov	x0, x20
	ldr	x21, [sp, #328]                 ; 8-byte Folded Reload
	blr	x21
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	and	w19, w0, #0xff
	mov	x0, x20
	ldp	x1, x2, [x8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w19, #1
	b.ne	LBB2_1042
; %bb.1040:
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	cmp	w8, #1
	ldr	x9, [sp, #128]                  ; 8-byte Folded Reload
	add	x0, x20, x9
	b.ne	LBB2_1044
; %bb.1041:
	ldp	x21, x8, [sp, #328]             ; 16-byte Folded Reload
	ldr	x22, [sp, #360]                 ; 8-byte Folded Reload
	ldr	x2, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #176]                  ; 8-byte Folded Reload
	mov	x4, x21
	add	x1, x8, #8
	mov	x5, x22
	bl	l_sort.cross_merge__anon_14865
	ldr	x19, [sp, #208]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x2, [sp, #152]                  ; 8-byte Folded Reload
	mov	x4, x21
	ldr	x3, [sp, #184]                  ; 8-byte Folded Reload
	mov	x5, x22
	mov	x1, x19
	bl	l_sort.cross_merge__anon_14865
	b	LBB2_1048
LBB2_1042:
	cmp	w8, #1
	b.ne	LBB2_1045
; %bb.1043:
	ldp	x1, x21, [sp, #120]             ; 16-byte Folded Reload
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	ldr	x2, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x20, x21
	ldr	x4, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.cross_merge__anon_14865
	ldr	x19, [sp, #208]                 ; 8-byte Folded Reload
	mov	x0, x20
	mov	x2, x21
	b	LBB2_1047
LBB2_1044:
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #120]                  ; 8-byte Folded Reload
	lsl	x2, x8, #3
	bl	_memcpy
	ldr	x19, [sp, #208]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x2, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #184]                  ; 8-byte Folded Reload
	mov	x1, x19
	ldr	x4, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.cross_merge__anon_14865
	b	LBB2_1048
LBB2_1045:
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	ldr	x0, [sp, #360]                  ; 8-byte Folded Reload
	ldp	x1, x2, [x8]
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB2_1049
; %bb.1046:
	ldp	x20, x19, [sp, #200]            ; 16-byte Folded Reload
	ldr	x2, [sp, #192]                  ; 8-byte Folded Reload
	mov	x0, x20
LBB2_1047:
	mov	x1, x19
	bl	_memcpy
LBB2_1048:
	ldp	x2, x3, [sp, #136]              ; 16-byte Folded Reload
	mov	x0, x19
	mov	x1, x20
	ldr	x4, [sp, #328]                  ; 8-byte Folded Reload
	ldr	x5, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.cross_merge__anon_14865
LBB2_1049:                              ; %sort.flux_analyze__anon_14348.exit.i
	ldr	x0, [sp, #200]                  ; 8-byte Folded Reload
	mov	w1, #8
	bl	_roc_dealloc
	ldr	x28, [sp, #352]                 ; 8-byte Folded Reload
	b	LBB2_1242
LBB2_1050:
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
	mov	x1, x4
	mov	x20, x21
	b	LBB2_809
LBB2_1051:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	mov	x13, x10
	mov	x14, x9
	mov	x15, x5
	mov	x1, x4
	b	LBB2_762
LBB2_1052:
	ldr	x14, [sp, #336]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	w5, [sp, #256]                  ; 4-byte Folded Reload
	mov	x12, x10
	mov	x13, x9
	mov	x1, x4
	mov	x20, x21
	b	LBB2_786
LBB2_1053:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	b	LBB2_724
LBB2_1054:
	ldr	x4, [sp, #296]                  ; 8-byte Folded Reload
LBB2_1055:
	mov	x9, x12
	mov	x13, x11
	mov	x14, x10
	mov	x15, x7
LBB2_1056:                              ; %.lr.ph173.i.i.preheader
	add	x8, x8, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_1057:                              ; %.lr.ph173.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x8]
	str	x13, [x8], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_1057
LBB2_1058:
	mov	x1, xzr
	mov	x17, xzr
LBB2_1059:                              ; %sort.quad_reversal.exit301.i.i129
	cbz	x30, LBB2_1077
; %bb.1060:                             ; %sort.quad_reversal.exit301.i.i129
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	mov	x24, x23
	cmp	x8, #1
	b.ne	LBB2_1082
; %bb.1061:
	ldr	x10, [sp, #208]                 ; 8-byte Folded Reload
	sub	x11, x6, x10
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x10, x9
	sub	x9, x6, x9
	tbnz	w11, #4, LBB2_1063
; %bb.1062:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_1063:                              ; %._crit_edge.i362.i.i
	ldr	x13, [sp, #208]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x11, [x6]
	ldr	x12, [x13]
	str	x11, [x13]
	str	x12, [x6]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_1081
; %bb.1064:                             ; %.lr.ph197.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_1078
; %bb.1065:                             ; %vector.scevcheck2123
	sub	x12, x11, #1
	sub	x14, x6, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_1078
; %bb.1066:                             ; %vector.scevcheck2123
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_1078
; %bb.1067:                             ; %vector.scevcheck2123
	lsr	x12, x12, #61
	cbnz	x12, LBB2_1078
; %bb.1068:                             ; %vector.memcheck2132
	ldr	x14, [sp, #208]                 ; 8-byte Folded Reload
	lsl	x12, x11, #3
	mov	x20, x17
	add	x13, x12, #8
	sub	x16, x6, x12
	mov	x19, x4
	add	x17, x14, #8
	add	x0, x14, x13
	cmp	x17, x6
	mov	x4, x1
	ccmp	x16, x0, #2, lo
	sub	x1, x10, x12
	add	x2, x9, #8
	add	x3, x9, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x6
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x6, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1251
; %bb.1069:                             ; %vector.memcheck2132
	tbnz	w12, #0, LBB2_1251
; %bb.1070:                             ; %vector.memcheck2132
	mov	x1, x4
	mov	x17, x20
	tbnz	w13, #0, LBB2_1247
; %bb.1071:                             ; %vector.memcheck2132
	tbnz	w14, #0, LBB2_1247
; %bb.1072:                             ; %vector.memcheck2132
	tbnz	w15, #0, LBB2_1247
; %bb.1073:                             ; %vector.memcheck2132
	tbnz	w16, #0, LBB2_1247
; %bb.1074:                             ; %vector.ph2165
	ldr	x17, [sp, #208]                 ; 8-byte Folded Reload
	and	x16, x11, #0x7ffffffffffffffe
	lsl	x15, x16, #3
	ubfx	x8, x8, #1, #1
	sub	x13, x10, x15
	add	x14, x9, x15
	add	x12, x17, x15
	sub	x15, x6, x15
	add	x17, x17, #8
	add	x9, x9, #8
	sub	x0, x6, #16
	sub	x10, x10, #16
	neg	x1, x16
LBB2_1075:                              ; %vector.body2179
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x17]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x17], #16
	str	q1, [x0], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_1075
; %bb.1076:                             ; %middle.block2162
	mov	x1, x4
	mov	x4, x19
	mov	x17, x20
	cmp	x11, x16
	b.ne	LBB2_1079
	b	LBB2_1081
LBB2_1077:
	mov	x24, x23
	b	LBB2_1082
LBB2_1078:
	mov	x8, x11
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x13, x10
	mov	x14, x9
	mov	x15, x6
LBB2_1079:                              ; %.lr.ph197.i.i.preheader
	add	x9, x12, #8
	sub	x10, x13, #8
	add	x11, x14, #8
	sub	x12, x15, #8
LBB2_1080:                              ; %.lr.ph197.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_1080
LBB2_1081:
	mov	x30, xzr
LBB2_1082:                              ; %sort.quad_reversal.exit371.i.i
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_1088
; %bb.1083:                             ; %sort.quad_reversal.exit371.i.i
	cbz	x4, LBB2_1088
; %bb.1084:
	ldr	x12, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	sub	x11, x12, x2
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x2, x9
	sub	x9, x12, x9
	tbnz	w11, #4, LBB2_1086
; %bb.1085:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_1086:                              ; %._crit_edge.i372.i.i
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	cmp	x8, #2
	ldr	x12, [x2]
	ldr	x11, [x13]
	str	x11, [x2]
	str	x12, [x13]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.hs	LBB2_1089
; %bb.1087:
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	b	LBB2_1105
LBB2_1088:
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	b	LBB2_1106
LBB2_1089:                              ; %.lr.ph203.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_1102
; %bb.1090:                             ; %vector.scevcheck2194
	ldr	x13, [sp, #344]                 ; 8-byte Folded Reload
	sub	x12, x11, #1
	sub	x14, x13, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_1102
; %bb.1091:                             ; %vector.scevcheck2194
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_1102
; %bb.1092:                             ; %vector.scevcheck2194
	lsr	x12, x12, #61
	cbnz	x12, LBB2_1102
; %bb.1093:                             ; %vector.memcheck2203
	ldr	x19, [sp, #344]                 ; 8-byte Folded Reload
	mov	x20, x17
	add	x17, x6, #16
	lsl	x13, x11, #3
	add	x0, x17, x13
	mov	x4, x1
	sub	x16, x19, x13
	cmp	x17, x19
	ccmp	x16, x0, #2, lo
	sub	x1, x10, x13
	add	x2, x9, #8
	add	x3, x2, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x19
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x19, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1252
; %bb.1094:                             ; %vector.memcheck2203
	tbnz	w12, #0, LBB2_1252
; %bb.1095:                             ; %vector.memcheck2203
	mov	x1, x4
	mov	x17, x20
	tbnz	w13, #0, LBB2_1253
; %bb.1096:                             ; %vector.memcheck2203
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	tbnz	w14, #0, LBB2_1102
; %bb.1097:                             ; %vector.memcheck2203
	tbnz	w15, #0, LBB2_1102
; %bb.1098:                             ; %vector.memcheck2203
	tbnz	w16, #0, LBB2_1102
; %bb.1099:                             ; %vector.ph2236
	ldr	x17, [sp, #344]                 ; 8-byte Folded Reload
	and	x15, x11, #0x7ffffffffffffffe
	lsl	x14, x15, #3
	ubfx	x8, x8, #1, #1
	add	x2, x2, x14
	sub	x12, x10, x14
	add	x13, x9, x14
	sub	x14, x17, x14
	add	x16, x6, #16
	add	x9, x9, #8
	sub	x17, x17, #16
	sub	x10, x10, #16
	neg	x0, x15
LBB2_1100:                              ; %vector.body2250
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x17]
	adds	x0, x0, #2
	ldr	q1, [x16]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x16], #16
	str	q1, [x17], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_1100
; %bb.1101:                             ; %middle.block2233
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	mov	x17, x20
	cmp	x11, x15
	b.ne	LBB2_1103
	b	LBB2_1105
LBB2_1102:
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
LBB2_1103:                              ; %.lr.ph203.i.i.preheader
	add	x9, x2, #8
	sub	x10, x12, #8
	add	x11, x13, #8
	sub	x12, x14, #8
LBB2_1104:                              ; %.lr.ph203.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_1104
LBB2_1105:                              ; %sort.quad_reversal.exit381.i.i
	mov	x4, xzr
LBB2_1106:                              ; %sort.quad_reversal.exit381.i.i
	ldr	x8, [sp, #80]                   ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_1128
; %bb.1107:                             ; %sort.quad_reversal.exit381.i.i
	cbz	x17, LBB2_1128
; %bb.1108:
	ldr	x17, [sp, #48]                  ; 8-byte Folded Reload
	sub	x11, x5, x17
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x17, x9
	sub	x9, x5, x9
	tbnz	w11, #4, LBB2_1110
; %bb.1109:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_1110:                              ; %._crit_edge.i382.i.i
	ldr	x11, [x5]
	cmp	x8, #2
	ldr	x12, [x17]
	str	x11, [x17]
	str	x12, [x5]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.lo	LBB2_1127
; %bb.1111:                             ; %.lr.ph209.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_1124
; %bb.1112:                             ; %vector.scevcheck2265
	sub	x12, x11, #1
	sub	x14, x5, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_1124
; %bb.1113:                             ; %vector.scevcheck2265
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_1124
; %bb.1114:                             ; %vector.scevcheck2265
	lsr	x12, x12, #61
	cbnz	x12, LBB2_1124
; %bb.1115:                             ; %vector.memcheck2274
	ldr	x12, [sp, #344]                 ; 8-byte Folded Reload
	lsl	x13, x11, #3
	sub	x16, x5, x13
	mov	x19, x4
	mov	x4, x1
	sub	x1, x10, x13
	add	x17, x12, #16
	add	x2, x9, #8
	add	x0, x17, x13
	cmp	x17, x5
	ccmp	x16, x0, #2, lo
	add	x3, x2, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x5
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x5, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1249
; %bb.1116:                             ; %vector.memcheck2274
	tbnz	w12, #0, LBB2_1249
; %bb.1117:                             ; %vector.memcheck2274
	mov	x1, x4
	ldr	x17, [sp, #48]                  ; 8-byte Folded Reload
	tbnz	w13, #0, LBB2_1250
; %bb.1118:                             ; %vector.memcheck2274
	mov	x4, x19
	tbnz	w14, #0, LBB2_1124
; %bb.1119:                             ; %vector.memcheck2274
	tbnz	w15, #0, LBB2_1124
; %bb.1120:                             ; %vector.memcheck2274
	tbnz	w16, #0, LBB2_1124
; %bb.1121:                             ; %vector.ph2307
	ldr	x16, [sp, #344]                 ; 8-byte Folded Reload
	and	x15, x11, #0x7ffffffffffffffe
	lsl	x14, x15, #3
	ubfx	x8, x8, #1, #1
	add	x2, x17, x14
	sub	x12, x10, x14
	add	x13, x9, x14
	sub	x14, x5, x14
	add	x16, x16, #16
	add	x9, x9, #8
	sub	x17, x5, #16
	sub	x10, x10, #16
	neg	x0, x15
LBB2_1122:                              ; %vector.body2321
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x17]
	adds	x0, x0, #2
	ldr	q1, [x16]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x16], #16
	str	q1, [x17], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_1122
; %bb.1123:                             ; %middle.block2304
	mov	x17, x2
	cmp	x11, x15
	b.ne	LBB2_1125
	b	LBB2_1127
LBB2_1124:
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
	mov	x14, x5
LBB2_1125:                              ; %.lr.ph209.i.i.preheader
	add	x9, x17, #8
	sub	x10, x12, #8
	add	x11, x13, #8
	sub	x12, x14, #8
LBB2_1126:                              ; %.lr.ph209.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_1126
LBB2_1127:                              ; %sort.quad_reversal.exit391.i.i
	mov	x17, xzr
LBB2_1128:                              ; %sort.quad_reversal.exit391.i.i
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	cmp	x8, #1
	b.ne	LBB2_1134
; %bb.1129:                             ; %sort.quad_reversal.exit391.i.i
	cbz	x1, LBB2_1134
; %bb.1130:
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	sub	x11, x7, x1
	lsr	x8, x11, #4
	lsl	x9, x8, #3
	add	x10, x1, x9
	sub	x9, x7, x9
	tbnz	w11, #4, LBB2_1132
; %bb.1131:
	ldr	x11, [x9]
	sub	x8, x8, #1
	ldr	x12, [x10]
	str	x11, [x10], #-8
	str	x12, [x9], #8
LBB2_1132:                              ; %._crit_edge.i392.i.i
	ldr	x11, [x7]
	cmp	x8, #2
	ldr	x12, [x1]
	str	x11, [x1]
	str	x12, [x7]
	ldr	x11, [x9]
	ldr	x12, [x10]
	str	x11, [x10]
	str	x12, [x9]
	b.hs	LBB2_1135
; %bb.1133:
	ldr	w5, [sp, #232]                  ; 4-byte Folded Reload
	mov	x1, xzr
	b	LBB2_1152
LBB2_1134:
	ldr	w5, [sp, #232]                  ; 4-byte Folded Reload
	b	LBB2_1152
LBB2_1135:                              ; %.lr.ph215.preheader.i.i
	lsr	x11, x8, #1
	cmp	x8, #48
	b.lo	LBB2_1148
; %bb.1136:                             ; %vector.scevcheck2336
	sub	x12, x11, #1
	sub	x14, x7, #8
	lsl	x13, x12, #3
	sub	x15, x14, x13
	cmp	x15, x14
	b.hi	LBB2_1148
; %bb.1137:                             ; %vector.scevcheck2336
	sub	x14, x10, #8
	sub	x13, x14, x13
	cmp	x13, x14
	b.hi	LBB2_1148
; %bb.1138:                             ; %vector.scevcheck2336
	lsr	x12, x12, #61
	cbnz	x12, LBB2_1148
; %bb.1139:                             ; %vector.memcheck2345
	mov	x19, x17
	add	x17, x5, #16
	lsl	x13, x11, #3
	cmp	x17, x7
	add	x0, x17, x13
	sub	x16, x7, x13
	ccmp	x16, x0, #2, lo
	sub	x1, x10, x13
	add	x2, x9, #8
	add	x3, x2, x13
	cset	w12, lo
	cmp	x17, x10
	ccmp	x1, x0, #2, lo
	cset	w13, lo
	cmp	x2, x7
	ccmp	x16, x3, #2, lo
	cset	w14, lo
	cmp	x2, x10
	ccmp	x1, x3, #2, lo
	cset	w15, lo
	cmp	x16, x10
	ccmp	x1, x7, #2, lo
	cset	w16, lo
	cmp	x2, x0
	ccmp	x17, x3, #2, lo
	b.lo	LBB2_1248
; %bb.1140:                             ; %vector.memcheck2345
	tbnz	w12, #0, LBB2_1248
; %bb.1141:                             ; %vector.memcheck2345
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	mov	x17, x19
	tbnz	w13, #0, LBB2_1148
; %bb.1142:                             ; %vector.memcheck2345
	tbnz	w14, #0, LBB2_1148
; %bb.1143:                             ; %vector.memcheck2345
	tbnz	w15, #0, LBB2_1148
; %bb.1144:                             ; %vector.memcheck2345
	tbnz	w16, #0, LBB2_1148
; %bb.1145:                             ; %vector.ph2378
	and	x15, x11, #0x7ffffffffffffffe
	ubfx	x8, x8, #1, #1
	lsl	x14, x15, #3
	add	x16, x5, #16
	add	x1, x1, x14
	sub	x12, x10, x14
	add	x13, x9, x14
	sub	x14, x7, x14
	add	x9, x9, #8
	sub	x17, x7, #16
	sub	x10, x10, #16
	neg	x0, x15
LBB2_1146:                              ; %vector.body2392
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x17]
	adds	x0, x0, #2
	ldr	q1, [x16]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x16], #16
	str	q1, [x17], #-16
	ldr	q0, [x9]
	ldr	q1, [x10]
	ext.16b	v0, v0, v0, #8
	ext.16b	v1, v1, v1, #8
	str	q0, [x10], #-16
	str	q1, [x9], #16
	b.ne	LBB2_1146
; %bb.1147:                             ; %middle.block2375
	ldr	w5, [sp, #232]                  ; 4-byte Folded Reload
	mov	x17, x19
	cmp	x11, x15
	b.ne	LBB2_1149
	b	LBB2_1151
LBB2_1148:
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
	mov	x14, x7
	ldr	w5, [sp, #232]                  ; 4-byte Folded Reload
LBB2_1149:                              ; %.lr.ph215.i.i.preheader
	add	x9, x1, #8
	sub	x10, x12, #8
	add	x11, x13, #8
	sub	x12, x14, #8
LBB2_1150:                              ; %.lr.ph215.i.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x8, x8, #1
	ldr	x14, [x9]
	str	x13, [x9], #8
	str	x14, [x12], #-8
	ldr	x13, [x11]
	ldr	x14, [x10]
	str	x13, [x10], #-8
	str	x14, [x11], #8
	b.ne	LBB2_1150
LBB2_1151:
	mov	x1, xzr
LBB2_1152:                              ; %sort.quad_reversal.exit401.i.i
	ldr	w8, [sp, #256]                  ; 4-byte Folded Reload
	lsr	x9, x27, #9
	ldr	w10, [sp, #272]                 ; 4-byte Folded Reload
	cmp	x9, w8, uxtw
	cset	w8, lo
	cmp	x9, w10, uxtw
	cset	w19, lo
	cmp	x9, w6, uxtw
	cset	w21, lo
	cmp	x9, w5, uxtw
	cset	w20, lo
	mov	w9, #3
	movk	w9, #16, lsl #16
	cmp	x27, x9
	b.ls	LBB2_1154
; %bb.1153:
	mov	w20, #1
	mov	w21, #1
	mov	w19, #1
	mov	w8, #1
LBB2_1154:
	lsl	w9, w21, #2
Lloh14:
	adrp	x10, LJTI2_3@PAGE
Lloh15:
	add	x10, x10, LJTI2_3@PAGEOFF
	orr	w9, w9, w19, lsl #1
	orr	w9, w9, w20, lsl #3
	orr	w9, w9, w8
	adr	x11, LBB2_1155
	ldrh	w12, [x10, x9, lsl #1]
	add	x11, x11, x12, lsl #2
	br	x11
LBB2_1155:
	mov	x23, x17
	mov	x24, x4
	str	x1, [sp, #304]                  ; 8-byte Folded Spill
	cbz	w8, LBB2_1159
; %bb.1156:
	cbz	x30, LBB2_1162
; %bb.1157:
	cmp	x27, #383
	b.hi	LBB2_1160
; %bb.1158:
	ldp	x2, x0, [sp, #200]              ; 16-byte Folded Reload
	mov	x3, x26
	mov	x5, x22
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1162
LBB2_1159:
	ldp	x1, x0, [sp, #200]              ; 16-byte Folded Reload
	mov	x5, x26
	mov	x7, x22
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #184]                  ; 8-byte Folded Reload
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	add	x3, x1, x8
	mov	x2, x0
	bl	l_sort.flux_partition__anon_14860
	b	LBB2_1162
LBB2_1160:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	mov	x2, x26
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x4, x22
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB2_1162
; %bb.1161:
	ldp	x26, x22, [sp, #200]            ; 16-byte Folded Reload
	mov	x3, x27
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x2, x26
	ldr	x4, [sp, #328]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x5, x25
	ldr	x6, [sp, #248]                  ; 8-byte Folded Reload
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x22
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	mov	x2, x26
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	mov	x6, x25
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #168]                  ; 8-byte Folded Reload
	mov	x7, x22
	mov	x5, x26
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14846
LBB2_1162:                              ; %sort.quadsort_swap__anon_14861.exit411.i.i
	cbz	w19, LBB2_1166
; %bb.1163:
	cbz	x24, LBB2_1169
; %bb.1164:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	cmp	x1, #95
	b.hi	LBB2_1167
; %bb.1165:
	mov	x0, x19
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	mov	x3, x26
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	mov	x5, x22
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1169
LBB2_1166:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x5, x26
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	mov	x7, x22
	ldr	x4, [sp, #136]                  ; 8-byte Folded Reload
	add	x0, x8, #8
	ldr	x6, [sp, #360]                  ; 8-byte Folded Reload
	mov	x2, x0
	add	x3, x1, x4, lsl #3
	bl	l_sort.flux_partition__anon_14860
	b	LBB2_1169
LBB2_1167:
	mov	x0, x19
	mov	x2, x26
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB2_1169
; %bb.1168:
	ldr	x26, [sp, #136]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x22, [sp, #200]                 ; 8-byte Folded Reload
	mov	x3, x27
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	mov	x1, x26
	ldr	x4, [sp, #328]                  ; 8-byte Folded Reload
	mov	x2, x22
	ldr	x6, [sp, #248]                  ; 8-byte Folded Reload
	mov	x5, x24
	bl	l_sort.quad_merge__anon_14845
	mov	x1, x26
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	mov	x2, x22
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	mov	x4, x0
	mov	x0, x19
	mov	x3, x27
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	bl	l_sort.rotate_merge__anon_14846
LBB2_1169:                              ; %sort.quadsort_swap__anon_14861.exit412.i.i
	cbz	w21, LBB2_1173
; %bb.1170:
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	cbz	x23, LBB2_1176
; %bb.1171:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_1174
; %bb.1172:
	mov	x0, x19
	ldr	x1, [sp, #176]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	mov	x3, x26
	mov	x4, x24
	mov	x5, x22
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1176
LBB2_1173:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x5, x26
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	mov	x7, x22
	ldr	x4, [sp, #176]                  ; 8-byte Folded Reload
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	add	x0, x8, #8
	mov	x2, x0
	add	x3, x1, x4, lsl #3
	mov	x6, x24
	bl	l_sort.flux_partition__anon_14860
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	b	LBB2_1176
LBB2_1174:
	mov	x0, x19
	ldr	x1, [sp, #176]                  ; 8-byte Folded Reload
	mov	x2, x26
	mov	x3, x24
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB2_1176
; %bb.1175:
	mov	x23, x26
	ldr	x26, [sp, #176]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #200]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x3, x27
	mov	x4, x23
	mov	x1, x26
	mov	x5, x24
	mov	x2, x21
	mov	x6, x22
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x26
	mov	x2, x21
	mov	x3, x27
	mov	x5, x23
	mov	x6, x24
	mov	x7, x22
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	mov	x26, x23
	bl	l_sort.rotate_merge__anon_14846
LBB2_1176:                              ; %sort.quadsort_swap__anon_14861.exit413.i.i
	cbz	w20, LBB2_1180
; %bb.1177:
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	cbz	x8, LBB2_1231
LBB2_1178:
	ldr	x1, [sp, #144]                  ; 8-byte Folded Reload
	add	x19, x21, #8
	cmp	x1, #95
	b.hi	LBB2_1181
; %bb.1179:
	mov	x0, x19
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	mov	x3, x26
	mov	x4, x24
	mov	x5, x22
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1231
LBB2_1180:
	add	x0, x21, #8
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #144]                  ; 8-byte Folded Reload
	b	LBB2_1206
LBB2_1181:
	mov	x0, x19
	mov	x2, x26
	mov	x3, x24
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB2_1231
; %bb.1182:
	ldr	x21, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x26
	mov	x5, x24
	mov	x1, x21
	mov	x6, x22
	mov	x2, x20
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14846
	b	LBB2_1231
LBB2_1183:
	ldp	x8, x1, [sp, #192]              ; 16-byte Folded Reload
	mov	x4, x27
	mov	x5, x26
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	mov	x6, x24
	mov	x7, x22
	add	x3, x1, x8
	mov	x2, x0
	bl	l_sort.flux_partition__anon_14860
	b	LBB2_1241
LBB2_1184:
	ldr	x19, [sp, #136]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	cbz	x30, LBB2_1205
; %bb.1185:
	cmp	x27, #383
	b.hi	LBB2_1203
; %bb.1186:
	ldp	x2, x0, [sp, #200]              ; 16-byte Folded Reload
	mov	x3, x26
	mov	x4, x24
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x5, x22
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1205
LBB2_1187:
	ldp	x20, x0, [sp, #200]             ; 16-byte Folded Reload
	mov	x19, x4
	mov	x5, x26
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	mov	x6, x24
	ldr	x4, [sp, #184]                  ; 8-byte Folded Reload
	mov	x7, x22
	mov	x1, x20
	add	x3, x20, x8
	mov	x2, x0
	bl	l_sort.flux_partition__anon_14860
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	cbz	x19, LBB2_1209
; %bb.1188:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	cmp	x1, #95
	b.hi	LBB2_1207
; %bb.1189:
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x3, x26
	mov	x4, x24
	mov	x5, x22
	mov	x2, x20
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1209
LBB2_1190:
	cbz	x30, LBB2_1213
; %bb.1191:
	mov	x24, x4
	cmp	x27, #383
	b.hi	LBB2_1210
; %bb.1192:
	ldp	x2, x0, [sp, #200]              ; 16-byte Folded Reload
	mov	x3, x26
	mov	x5, x22
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1212
LBB2_1193:
	ldp	x20, x0, [sp, #200]             ; 16-byte Folded Reload
	mov	x5, x26
	mov	x6, x24
	ldp	x8, x4, [sp, #112]              ; 16-byte Folded Reload
	mov	x7, x22
	mov	x19, x17
	mov	x1, x20
	mov	x2, x0
	add	x3, x20, x8
	bl	l_sort.flux_partition__anon_14860
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	cbz	x19, LBB2_1218
; %bb.1194:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_1216
; %bb.1195:
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x1, [sp, #176]                  ; 8-byte Folded Reload
	mov	x3, x26
	mov	x4, x24
	mov	x5, x22
	mov	x2, x20
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1218
LBB2_1196:
	mov	x19, x1
	mov	x5, x26
	ldp	x1, x0, [sp, #200]              ; 16-byte Folded Reload
	mov	x6, x24
	mov	x7, x22
	ldp	x8, x4, [sp, #88]               ; 16-byte Folded Reload
	mov	x2, x0
	add	x3, x1, x8
	bl	l_sort.flux_partition__anon_14860
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	cbnz	x19, LBB2_1178
	b	LBB2_1231
LBB2_1197:
	mov	x20, x1
	ldr	x19, [sp, #136]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	cbz	x30, LBB2_1222
; %bb.1198:
	cmp	x27, #383
	b.hi	LBB2_1220
; %bb.1199:
	ldp	x2, x0, [sp, #200]              ; 16-byte Folded Reload
	mov	x3, x26
	mov	x4, x24
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x5, x22
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1222
LBB2_1200:
	mov	x20, x1
	mov	x5, x26
	ldp	x1, x0, [sp, #200]              ; 16-byte Folded Reload
	mov	x6, x24
	mov	x7, x22
	ldp	x8, x4, [sp, #112]              ; 16-byte Folded Reload
	mov	x19, x17
	mov	x2, x0
	add	x3, x1, x8
	bl	l_sort.flux_partition__anon_14860
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	cbz	x19, LBB2_1225
; %bb.1201:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	cmp	x8, #191
	b.hi	LBB2_1223
; %bb.1202:
	mov	x0, x19
	ldr	x1, [sp, #176]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	mov	x3, x26
	mov	x4, x24
	mov	x5, x22
	bl	l_sort.tail_swap__anon_14843
	cbnz	x20, LBB2_1178
	b	LBB2_1231
LBB2_1203:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	mov	x2, x26
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB2_1205
; %bb.1204:
	ldp	x20, x19, [sp, #200]            ; 16-byte Folded Reload
	mov	x3, x27
	mov	x4, x26
	ldr	x21, [sp, #184]                 ; 8-byte Folded Reload
	mov	x5, x24
	mov	x6, x22
	mov	x2, x20
	mov	x0, x19
	mov	x1, x21
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	ldr	x19, [sp, #136]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14846
LBB2_1205:                              ; %sort.quadsort_swap__anon_14861.exit.i.i
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	add	x4, x19, x8
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x0, x8, #8
LBB2_1206:                              ; %sort.quadsort_swap__anon_14861.exit406.i.i
	add	x3, x1, x4, lsl #3
	b	LBB2_1230
LBB2_1207:
	mov	x0, x19
	mov	x2, x26
	mov	x3, x24
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	tbz	w0, #0, LBB2_1209
; %bb.1208:
	ldr	x21, [sp, #136]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x2, x20
	mov	x3, x27
	mov	x4, x26
	mov	x5, x24
	mov	x1, x21
	mov	x6, x22
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14846
LBB2_1209:                              ; %sort.quadsort_swap__anon_14861.exit402.i.i
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	ldr	x4, [sp, #152]                  ; 8-byte Folded Reload
	add	x0, x8, #8
	b	LBB2_1219
LBB2_1210:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	mov	x2, x26
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x4, x22
	ldr	x3, [sp, #360]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14844
	mov	x4, x24
	tbz	w0, #0, LBB2_1213
; %bb.1211:
	ldp	x20, x19, [sp, #200]            ; 16-byte Folded Reload
	mov	x3, x27
	mov	x4, x26
	ldr	x21, [sp, #184]                 ; 8-byte Folded Reload
	mov	x6, x22
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	mov	x2, x20
	mov	x0, x19
	mov	x1, x21
	mov	x5, x25
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	ldr	x3, [sp, #168]                  ; 8-byte Folded Reload
	mov	x5, x26
	mov	x6, x25
	mov	x7, x22
	ldr	x27, [sp, #168]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14846
LBB2_1212:                              ; %sort.quadsort_swap__anon_14861.exit403.i.i
	mov	x4, x24
LBB2_1213:                              ; %sort.quadsort_swap__anon_14861.exit403.i.i
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
	cbz	x4, LBB2_1229
; %bb.1214:
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	add	x19, x8, #8
	cmp	x1, #95
	b.hi	LBB2_1226
; %bb.1215:
	mov	x0, x19
	mov	x3, x26
	mov	x4, x24
	mov	x5, x22
	bl	l_sort.tail_swap__anon_14843
	b	LBB2_1228
LBB2_1216:
	mov	x0, x19
	ldr	x1, [sp, #176]                  ; 8-byte Folded Reload
	mov	x2, x26
	mov	x3, x24
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	tbz	w0, #0, LBB2_1218
; %bb.1217:
	ldr	x21, [sp, #176]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x2, x20
	mov	x3, x27
	mov	x4, x26
	mov	x5, x24
	mov	x1, x21
	mov	x6, x22
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x20
	mov	x3, x27
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14846
LBB2_1218:                              ; %sort.quadsort_swap__anon_14861.exit405.i.i
	add	x0, x21, #8
	ldr	x4, [sp, #144]                  ; 8-byte Folded Reload
LBB2_1219:                              ; %sort.quadsort_swap__anon_14861.exit406.i.i
	add	x3, x20, x4, lsl #3
	mov	x1, x20
	b	LBB2_1230
LBB2_1220:
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	mov	x2, x26
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB2_1222
; %bb.1221:
	ldp	x23, x19, [sp, #200]            ; 16-byte Folded Reload
	mov	x3, x27
	mov	x4, x26
	ldr	x21, [sp, #184]                 ; 8-byte Folded Reload
	mov	x5, x24
	mov	x6, x22
	mov	x2, x23
	mov	x0, x19
	mov	x1, x21
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x23
	mov	x3, x27
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	ldr	x19, [sp, #136]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14846
LBB2_1222:                              ; %sort.quadsort_swap__anon_14861.exit407.i.i
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	mov	x5, x26
	ldr	x1, [sp, #200]                  ; 8-byte Folded Reload
	mov	x6, x24
	mov	x7, x22
	add	x4, x8, x19
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x3, x1, x4, lsl #3
	add	x0, x8, #8
	mov	x2, x0
	bl	l_sort.flux_partition__anon_14860
	cbnz	x20, LBB2_1178
	b	LBB2_1231
LBB2_1223:
	mov	x0, x19
	ldr	x1, [sp, #176]                  ; 8-byte Folded Reload
	mov	x2, x26
	mov	x3, x24
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB2_1225
; %bb.1224:
	ldr	x21, [sp, #176]                 ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x23, [sp, #200]                 ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x26
	mov	x5, x24
	mov	x1, x21
	mov	x6, x22
	mov	x2, x23
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x21
	mov	x2, x23
	mov	x3, x27
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	ldr	x21, [sp, #336]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14846
LBB2_1225:                              ; %sort.quadsort_swap__anon_14861.exit409.i.i
	cbnz	x20, LBB2_1178
	b	LBB2_1231
LBB2_1226:
	mov	x0, x19
	mov	x2, x26
	mov	x3, x24
	mov	x4, x22
	bl	l_sort.quad_swap__anon_14844
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	tbz	w0, #0, LBB2_1229
; %bb.1227:
	ldr	x20, [sp, #136]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x3, x27
	mov	x4, x26
	mov	x5, x24
	mov	x6, x22
	mov	x1, x20
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x20
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
	mov	x3, x27
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	bl	l_sort.rotate_merge__anon_14846
LBB2_1228:                              ; %sort.quadsort_swap__anon_14861.exit404.i.i
	ldr	x2, [sp, #200]                  ; 8-byte Folded Reload
LBB2_1229:                              ; %sort.quadsort_swap__anon_14861.exit404.i.i
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x1, x2
	ldr	x4, [sp, #152]                  ; 8-byte Folded Reload
	add	x0, x8, #8
	add	x3, x2, x4, lsl #3
LBB2_1230:                              ; %sort.quadsort_swap__anon_14861.exit406.i.i
	mov	x2, x0
	mov	x5, x26
	mov	x6, x24
	mov	x7, x22
	bl	l_sort.flux_partition__anon_14860
LBB2_1231:                              ; %sort.quadsort_swap__anon_14861.exit406.i.i
	mov	x0, x24
	mov	w1, #1
	blr	x22
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x0, x24
	ldp	x1, x2, [x8]
	blr	x26
	and	w19, w0, #0xff
	mov	x0, x24
	mov	w1, #1
	blr	x22
	ldp	x1, x2, [x21]
	mov	x0, x24
	blr	x26
	and	w8, w0, #0xff
	cmp	w19, #1
	b.ne	LBB2_1234
; %bb.1232:
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	cmp	w8, #1
	ldr	x9, [sp, #112]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #144]                  ; 8-byte Folded Reload
	add	x0, x20, x9
	b.ne	LBB2_1236
; %bb.1233:
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x4, x26
	ldr	x2, [sp, #176]                  ; 8-byte Folded Reload
	mov	x5, x24
	mov	x6, x22
	add	x1, x8, #8
	bl	l_sort.cross_merge__anon_14862
	b	LBB2_1237
LBB2_1234:
	ldr	x3, [sp, #144]                  ; 8-byte Folded Reload
	cmp	w8, #1
	b.ne	LBB2_1238
; %bb.1235:
	ldr	x20, [sp, #200]                 ; 8-byte Folded Reload
	mov	x4, x26
	ldr	x21, [sp, #112]                 ; 8-byte Folded Reload
	mov	x5, x24
	ldr	x1, [sp, #128]                  ; 8-byte Folded Reload
	mov	x6, x22
	ldr	x2, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x20, x21
	bl	l_sort.cross_merge__anon_14862
	ldr	x19, [sp, #208]                 ; 8-byte Folded Reload
	mov	x0, x20
	mov	x2, x21
	mov	x1, x19
	bl	_memcpy
	b	LBB2_1240
LBB2_1236:
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x1, [sp, #128]                  ; 8-byte Folded Reload
	lsl	x2, x8, #3
	bl	_memcpy
LBB2_1237:
	ldr	x19, [sp, #208]                 ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x2, [sp, #184]                  ; 8-byte Folded Reload
	mov	x4, x26
	ldr	x3, [sp, #136]                  ; 8-byte Folded Reload
	mov	x5, x24
	mov	x1, x19
	mov	x6, x22
	bl	l_sort.cross_merge__anon_14862
	b	LBB2_1240
LBB2_1238:
	mov	x0, x24
	mov	w1, #1
	blr	x22
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x0, x24
	ldp	x1, x2, [x8]
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB2_1241
; %bb.1239:
	ldp	x20, x19, [sp, #200]            ; 16-byte Folded Reload
	ldr	x2, [sp, #192]                  ; 8-byte Folded Reload
	mov	x0, x20
	mov	x1, x19
	bl	_memcpy
	ldr	x26, [sp, #328]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #360]                 ; 8-byte Folded Reload
LBB2_1240:
	mov	x0, x19
	mov	x1, x20
	ldr	x2, [sp, #120]                  ; 8-byte Folded Reload
	mov	x4, x26
	ldr	x3, [sp, #152]                  ; 8-byte Folded Reload
	mov	x5, x24
	mov	x6, x22
	bl	l_sort.cross_merge__anon_14862
LBB2_1241:                              ; %sort.flux_analyze__anon_14347.exit.i
	ldr	x0, [sp, #200]                  ; 8-byte Folded Reload
	mov	w1, #8
	bl	_roc_dealloc
LBB2_1242:                              ; %sort.fluxsort_direct__anon_13350.exit
	mul	x19, x28, x27
	ldr	w1, [sp, #164]                  ; 4-byte Folded Reload
	mov	x0, x19
	bl	_roc_alloc
	cbz	x0, LBB2_1256
; %bb.1243:                             ; %.lr.ph403.preheader
	mov	x20, x0
	mov	x21, xzr
	mov	x22, x0
	ldr	x23, [sp, #208]                 ; 8-byte Folded Reload
LBB2_1244:                              ; %.lr.ph403
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x23, x21, lsl #3]
	mov	x0, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x21, x21, #1
	add	x22, x22, x28
	cmp	x27, x21
	b.ne	LBB2_1244
; %bb.1245:                             ; %._crit_edge404
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x1, x20
	mov	x2, x19
	bl	_memcpy
	mov	x0, x20
	ldr	w1, [sp, #164]                  ; 4-byte Folded Reload
	bl	_roc_dealloc
	mov	x0, x23
LBB2_1246:                              ; %._crit_edge17.i
	mov	w1, #8
	add	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 976
	add	sp, sp, #880
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_roc_dealloc
LBB2_1247:
	.cfi_restore_state
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	mov	x13, x10
	mov	x14, x9
	mov	x15, x6
	mov	x4, x19
	b	LBB2_1079
LBB2_1248:
	ldr	w5, [sp, #232]                  ; 4-byte Folded Reload
	mov	x8, x11
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	mov	x12, x10
	mov	x13, x9
	mov	x14, x7
	mov	x17, x19
	b	LBB2_1149
LBB2_1249:
	ldr	x17, [sp, #48]                  ; 8-byte Folded Reload
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
	mov	x14, x5
	mov	x1, x4
	mov	x4, x19
	b	LBB2_1125
LBB2_1250:
	mov	x8, x11
	mov	x12, x10
	mov	x13, x9
	mov	x14, x5
	mov	x4, x19
	b	LBB2_1125
LBB2_1251:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	mov	x13, x10
	mov	x14, x9
	mov	x15, x6
	mov	x1, x4
	mov	x4, x19
	mov	x17, x20
	b	LBB2_1079
LBB2_1252:
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	mov	x12, x10
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	mov	x13, x9
	mov	x1, x4
	mov	x17, x20
	b	LBB2_1103
LBB2_1253:
	ldr	x14, [sp, #344]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	w6, [sp, #280]                  ; 4-byte Folded Reload
	mov	x12, x10
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	mov	x13, x9
	b	LBB2_1103
LBB2_1254:
	ldr	x15, [sp, #344]                 ; 8-byte Folded Reload
	mov	x9, x12
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	mov	x13, x11
	mov	x14, x10
	mov	x20, x21
	b	LBB2_740
LBB2_1255:
	ldr	x12, [sp, #208]                 ; 8-byte Folded Reload
	mov	x8, x11
	ldr	x15, [sp, #344]                 ; 8-byte Folded Reload
	mov	x13, x10
	ldr	x1, [sp, #304]                  ; 8-byte Folded Reload
	b	LBB2_729
LBB2_1256:
Lloh16:
	adrp	x0, _sort.fluxsort__anon_13352@PAGE
Lloh17:
	add	x0, x0, _sort.fluxsort__anon_13352@PAGEOFF
	mov	w1, #50
	bl	l_panic.panic_help
	.loh AdrpAdd	Lloh0, Lloh1
	.loh AdrpAdd	Lloh2, Lloh3
	.loh AdrpAdd	Lloh4, Lloh5
	.loh AdrpAdd	Lloh6, Lloh7
	.loh AdrpAdd	Lloh8, Lloh9
	.loh AdrpAdd	Lloh10, Lloh11
	.loh AdrpAdd	Lloh12, Lloh13
	.loh AdrpAdd	Lloh14, Lloh15
	.loh AdrpAdd	Lloh16, Lloh17
Lfunc_end2:
	.cfi_endproc
	.section	__TEXT,__const
	.p2align	1, 0x0
LJTI2_0:
	.short	(LBB2_743-LBB2_180)>>2
	.short	(LBB2_180-LBB2_180)>>2
	.short	(LBB2_305-LBB2_180)>>2
	.short	(LBB2_321-LBB2_180)>>2
	.short	(LBB2_337-LBB2_180)>>2
	.short	(LBB2_353-LBB2_180)>>2
	.short	(LBB2_369-LBB2_180)>>2
	.short	(LBB2_385-LBB2_180)>>2
	.p2align	1, 0x0
LJTI2_1:
	.short	(LBB2_992-LBB2_964)>>2
	.short	(LBB2_993-LBB2_964)>>2
	.short	(LBB2_996-LBB2_964)>>2
	.short	(LBB2_999-LBB2_964)>>2
	.short	(LBB2_1002-LBB2_964)>>2
	.short	(LBB2_964-LBB2_964)>>2
	.short	(LBB2_964-LBB2_964)>>2
	.short	(LBB2_964-LBB2_964)>>2
	.short	(LBB2_1005-LBB2_964)>>2
	.short	(LBB2_1006-LBB2_964)>>2
	.short	(LBB2_964-LBB2_964)>>2
	.short	(LBB2_964-LBB2_964)>>2
	.short	(LBB2_1009-LBB2_964)>>2
	.short	(LBB2_964-LBB2_964)>>2
	.short	(LBB2_964-LBB2_964)>>2
	.short	(LBB2_964-LBB2_964)>>2
	.p2align	1, 0x0
LJTI2_2:
	.short	(LBB2_1059-LBB2_175)>>2
	.short	(LBB2_175-LBB2_175)>>2
	.short	(LBB2_220-LBB2_175)>>2
	.short	(LBB2_236-LBB2_175)>>2
	.short	(LBB2_252-LBB2_175)>>2
	.short	(LBB2_268-LBB2_175)>>2
	.short	(LBB2_284-LBB2_175)>>2
	.short	(LBB2_300-LBB2_175)>>2
	.p2align	1, 0x0
LJTI2_3:
	.short	(LBB2_1183-LBB2_1155)>>2
	.short	(LBB2_1184-LBB2_1155)>>2
	.short	(LBB2_1187-LBB2_1155)>>2
	.short	(LBB2_1190-LBB2_1155)>>2
	.short	(LBB2_1193-LBB2_1155)>>2
	.short	(LBB2_1155-LBB2_1155)>>2
	.short	(LBB2_1155-LBB2_1155)>>2
	.short	(LBB2_1155-LBB2_1155)>>2
	.short	(LBB2_1196-LBB2_1155)>>2
	.short	(LBB2_1197-LBB2_1155)>>2
	.short	(LBB2_1155-LBB2_1155)>>2
	.short	(LBB2_1155-LBB2_1155)>>2
	.short	(LBB2_1200-LBB2_1155)>>2
	.short	(LBB2_1155-LBB2_1155)>>2
	.short	(LBB2_1155-LBB2_1155)>>2
	.short	(LBB2_1155-LBB2_1155)>>2
	.p2align	1, 0x0
LJTI2_4:
	.short	(LBB2_495-LBB2_172)>>2
	.short	(LBB2_172-LBB2_172)>>2
	.short	(LBB2_208-LBB2_172)>>2
	.short	(LBB2_210-LBB2_172)>>2
	.short	(LBB2_212-LBB2_172)>>2
	.short	(LBB2_214-LBB2_172)>>2
	.short	(LBB2_216-LBB2_172)>>2
	.short	(LBB2_218-LBB2_172)>>2
	.p2align	1, 0x0
LJTI2_5:
	.short	(LBB2_632-LBB2_603)>>2
	.short	(LBB2_633-LBB2_603)>>2
	.short	(LBB2_636-LBB2_603)>>2
	.short	(LBB2_639-LBB2_603)>>2
	.short	(LBB2_642-LBB2_603)>>2
	.short	(LBB2_603-LBB2_603)>>2
	.short	(LBB2_603-LBB2_603)>>2
	.short	(LBB2_603-LBB2_603)>>2
	.short	(LBB2_645-LBB2_603)>>2
	.short	(LBB2_646-LBB2_603)>>2
	.short	(LBB2_603-LBB2_603)>>2
	.short	(LBB2_603-LBB2_603)>>2
	.short	(LBB2_649-LBB2_603)>>2
	.short	(LBB2_603-LBB2_603)>>2
	.short	(LBB2_603-LBB2_603)>>2
	.short	(LBB2_603-LBB2_603)>>2
	.p2align	1, 0x0
LJTI2_6:
	.short	(LBB2_428-LBB2_113)>>2
	.short	(LBB2_113-LBB2_113)>>2
	.short	(LBB2_196-LBB2_113)>>2
	.short	(LBB2_198-LBB2_113)>>2
	.short	(LBB2_200-LBB2_113)>>2
	.short	(LBB2_202-LBB2_113)>>2
	.short	(LBB2_204-LBB2_113)>>2
	.short	(LBB2_206-LBB2_113)>>2
	.p2align	1, 0x0
LJTI2_7:
	.short	(LBB2_575-LBB2_546)>>2
	.short	(LBB2_576-LBB2_546)>>2
	.short	(LBB2_579-LBB2_546)>>2
	.short	(LBB2_582-LBB2_546)>>2
	.short	(LBB2_585-LBB2_546)>>2
	.short	(LBB2_546-LBB2_546)>>2
	.short	(LBB2_546-LBB2_546)>>2
	.short	(LBB2_546-LBB2_546)>>2
	.short	(LBB2_588-LBB2_546)>>2
	.short	(LBB2_589-LBB2_546)>>2
	.short	(LBB2_546-LBB2_546)>>2
	.short	(LBB2_546-LBB2_546)>>2
	.short	(LBB2_592-LBB2_546)>>2
	.short	(LBB2_546-LBB2_546)>>2
	.short	(LBB2_546-LBB2_546)>>2
	.short	(LBB2_546-LBB2_546)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function roc_builtins.str.count_utf8_bytes
_roc_builtins.str.count_utf8_bytes:     ; @roc_builtins.str.count_utf8_bytes
Lfunc_begin3:
	.cfi_startproc
; %bb.0:                                ; %str.RocStr.len.exit
	ldp	x9, x8, [x0, #8]
	and	x9, x9, #0x7fffffffffffffff
	lsr	x10, x8, #56
	cmp	x8, #0
	eor	x10, x10, #0x80
	csel	x0, x10, x9, lt
	ret
Lfunc_end3:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function roc_builtins.str.concat
_roc_builtins.str.concat:               ; @roc_builtins.str.concat
Lfunc_begin4:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #176
	.cfi_def_cfa_offset 176
	stp	x26, x25, [sp, #96]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #160]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	ldp	x22, x21, [x1, #8]
	mov	x19, x8
	ldr	q0, [x0]
	ldr	x10, [x0, #16]
	and	x9, x22, #0x7fffffffffffffff
	lsr	x8, x21, #56
	cmp	x21, #0
	eor	x8, x8, #0x80
	str	q0, [sp]
	csel	x20, x8, x9, lt
	str	x10, [sp, #16]
	cbz	x20, LBB4_2
; %bb.1:                                ; %str.RocStr.len.exit
	ldp	x9, x8, [sp, #8]
	add	x23, sp, #24
	ldr	q0, [x0]
	ldr	x25, [x1]
	add	x1, sp, #48
	and	x9, x9, #0x7fffffffffffffff
	lsr	x10, x8, #56
	cmp	x8, #0
	eor	x10, x10, #0x80
	ldr	x8, [x0, #16]
	csel	x24, x10, x9, lt
	add	x0, sp, #24
	add	x2, x24, x20
	str	q0, [sp, #48]
	str	x8, [sp, #64]
	bl	l_str.RocStr.reallocate
	ldr	x8, [sp, #40]
	mov	x2, x20
	ldr	x9, [sp, #24]
	stp	x25, x22, [sp, #72]
	str	x21, [sp, #88]
	cmp	x8, #0
	add	x8, sp, #72
	csel	x9, x23, x9, lt
	cmp	x21, #0
	add	x0, x9, x24
	csel	x1, x8, x25, lt
	bl	_memcpy
	b	LBB4_3
LBB4_2:
	mov	x23, sp
LBB4_3:
	ldr	q0, [x23]
	ldr	x8, [x23, #16]
	ldp	x29, x30, [sp, #160]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #144]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             ; 16-byte Folded Reload
	add	sp, sp, #176
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	ret
Lfunc_end4:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function str.RocStr.reallocate
l_str.RocStr.reallocate:                ; @str.RocStr.reallocate
Lfunc_begin5:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x22, x21, [sp, #96]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_remember_state
	mov	x20, x2
	ldr	x10, [x1, #16]
	mov	x19, x0
	tbnz	x10, #63, LBB5_4
; %bb.1:                                ; %str.RocStr.isSeamlessSlice.exit
	ldr	x11, [x1, #8]
	and	x8, x11, #0x7fffffffffffffff
	cmp	x11, #0
	csel	x9, x8, x10, lt
	tbnz	x11, #63, LBB5_4
; %bb.2:                                ; %str.RocStr.getCapacity.exit.i.i
	ldr	x8, [x1]
	cbz	x10, LBB5_7
; %bb.3:                                ; %str.RocStr.isUnique.exit
	ldur	x12, [x8, #-8]
	mov	x13, #-9223372036854775808
	cmp	x12, x13
	b.eq	LBB5_8
LBB5_4:                                 ; %.critedge
	ldr	q0, [x1]
	add	x0, sp, #24
	ldr	x8, [x1, #16]
	mov	x1, sp
	mov	x2, x20
	str	q0, [sp]
	str	x8, [sp, #16]
	bl	l_str.RocStr.reallocateFresh
	ldur	q0, [sp, #24]
	ldr	x8, [sp, #40]
LBB5_5:                                 ; %common.ret
	str	q0, [x19]
	str	x8, [x19, #16]
LBB5_6:                                 ; %common.ret
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	ret
LBB5_7:
	.cfi_restore_state
	cbz	x8, LBB5_14
LBB5_8:                                 ; %.thread
	cmp	x9, x20
	b.ls	LBB5_10
; %bb.9:                                ; %str.RocStr.setLen.exit
	and	x9, x11, #0x8000000000000000
	str	x10, [x19, #16]
	orr	x9, x9, x20
	stp	x8, x9, [x19]
	b	LBB5_6
LBB5_10:
	cbz	x9, LBB5_15
; %bb.11:
	cmp	x9, #4095
	b.ls	LBB5_13
; %bb.12:
	cmp	x9, #32, lsl #12                ; =131072
	b.ls	LBB5_16
LBB5_13:
	lsl	x10, x9, #1
	b	LBB5_17
LBB5_14:
	ldr	q0, [x1]
	add	x0, sp, #72
	ldr	x8, [x1, #16]
	add	x1, sp, #48
	mov	x2, x20
	str	q0, [sp, #48]
	str	x8, [sp, #64]
	bl	l_str.RocStr.reallocateFresh
	ldur	q0, [sp, #72]
	ldr	x8, [sp, #88]
	b	LBB5_5
LBB5_15:
	mov	w10, #64
	b	LBB5_17
LBB5_16:
	add	x10, x9, x9, lsl #1
	add	x10, x10, #1
	lsr	x10, x10, #1
LBB5_17:
	cmp	x10, x20
	csel	x21, x10, x20, hi
	cmp	x9, x21
	b.hs	LBB5_19
; %bb.18:
	add	x1, x21, #8
	add	x2, x9, #8
	sub	x0, x8, #8
	mov	w3, #8
	bl	_roc_realloc
	add	x8, x0, #8
LBB5_19:                                ; %utils.unsafeReallocate.exit
	stp	x8, x20, [x19]
	str	x21, [x19, #16]
	b	LBB5_6
Lfunc_end5:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function roc_builtins.str.equal
_roc_builtins.str.equal:                ; @roc_builtins.str.equal
Lfunc_begin6:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	ldp	x8, x10, [x0]
	ldr	x11, [x1]
	ldr	x9, [x0, #16]
	cmp	x8, x11
	b.eq	LBB6_2
; %bb.1:                                ; %..critedge_crit_edge.i
	ldr	x11, [x1, #8]
	b	LBB6_4
LBB6_2:
	ldr	x11, [x1, #8]
	cmp	x10, x11
	b.ne	LBB6_4
; %bb.3:
	ldr	x12, [x1, #16]
	mov	x11, x10
	cmp	x9, x12
	b.eq	LBB6_10
LBB6_4:                                 ; %.critedge.i
	ldr	x13, [x1, #16]
	lsr	x12, x9, #56
	and	x14, x10, #0x7fffffffffffffff
	cmp	x9, #0
	eor	x12, x12, #0x80
	and	x11, x11, #0x7fffffffffffffff
	lsr	x15, x13, #56
	csel	x12, x12, x14, lt
	eor	x14, x15, #0x80
	cmp	x13, #0
	csel	x11, x14, x11, lt
	cmp	x12, x11
	b.ne	LBB6_9
; %bb.5:                                ; %str.RocStr.asU8ptr.exit.i
	ldr	q0, [x1]
	cmp	x9, #0
	ldr	x13, [x1, #16]
	add	x11, sp, #8
	csel	x11, x11, x8, lt
	add	x15, sp, #32
	str	q0, [sp, #32]
	ldr	x14, [sp, #32]
	cmp	x13, #0
	stp	x8, x10, [sp, #8]
	str	x9, [sp, #24]
	csel	x8, x15, x14, lt
	str	x13, [sp, #48]
	cbz	x12, LBB6_10
; %bb.6:                                ; %.lr.ph.i.preheader
	sub	x9, x12, #1
LBB6_7:                                 ; %.lr.ph.i
                                        ; =>This Inner Loop Header: Depth=1
	ldrb	w12, [x11], #1
	ldrb	w13, [x8], #1
	subs	x9, x9, #1
	cset	w10, hs
	cmp	w12, w13
	cset	w0, eq
	b.ne	LBB6_11
; %bb.8:                                ; %.lr.ph.i
                                        ;   in Loop: Header=BB6_7 Depth=1
	tbnz	w10, #0, LBB6_7
	b	LBB6_11
LBB6_9:
	mov	w0, wzr
	b	LBB6_11
LBB6_10:
	mov	w0, #1
LBB6_11:                                ; %str.RocStr.eq.exit
	add	sp, sp, #64
	.cfi_def_cfa_offset 0
	ret
Lfunc_end6:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function roc_builtins.str.allocation_ptr
_roc_builtins.str.allocation_ptr:       ; @roc_builtins.str.allocation_ptr
Lfunc_begin7:
	.cfi_startproc
; %bb.0:
	ldp	x8, x9, [x0, #8]
	ldr	x10, [x0]
	cmp	x8, #0
	lsl	x9, x9, #1
	csel	x0, x9, x10, lt
	ret
Lfunc_end7:
	.cfi_endproc
                                        ; -- End function
	.section	__TEXT,__literal16,16byte_literals
	.p2align	4, 0x0                          ; -- Begin function roc_builtins.str.from_int.i32
lCPI8_0:
	.quad	11                              ; 0xb
	.quad	0                               ; 0x0
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2
_roc_builtins.str.from_int.i32:         ; @roc_builtins.str.from_int.i32
Lfunc_begin8:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #160
	.cfi_def_cfa_offset 160
	stp	x22, x21, [sp, #112]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	mov	x19, x8
Lloh18:
	adrp	x8, lCPI8_0@PAGE
	cmp	w0, #0
	add	x9, sp, #5
	add	x10, sp, #16
Lloh19:
	ldr	q0, [x8, lCPI8_0@PAGEOFF]
	cneg	w8, w0, mi
	cmp	w8, #100
	str	x9, [sp, #16]
	str	x10, [sp, #40]
	stur	q0, [sp, #24]
	b.lo	LBB8_8
; %bb.1:                                ; %.lr.ph.i.i.i.i.i.i.preheader
	mov	w10, #34079
	mov	w9, #31
	movk	w10, #20971, lsl #16
	mov	w11, #100
	add	x12, sp, #79
Lloh20:
	adrp	x13, _fmt.digits2__anon_14339@PAGE
Lloh21:
	add	x13, x13, _fmt.digits2__anon_14339@PAGEOFF
LBB8_2:                                 ; %.lr.ph.i.i.i.i.i.i
                                        ; =>This Inner Loop Header: Depth=1
	mov	w14, w8
	lsr	w15, w8, #4
	umull	x8, w8, w10
	cmp	w15, #624
	lsr	x8, x8, #37
	msub	w14, w8, w11, w14
	ldrh	w14, [x13, w14, uxtw #1]
	strh	w14, [x12, x9]
	sub	x9, x9, #2
	b.hi	LBB8_2
; %bb.3:                                ; %._crit_edge.i.i.i.i.i.i.loopexit
	add	x9, x9, #2
	cmp	w8, #9
	b.ls	LBB8_9
LBB8_4:
Lloh22:
	adrp	x10, _fmt.digits2__anon_14339@PAGE
Lloh23:
	add	x10, x10, _fmt.digits2__anon_14339@PAGEOFF
	sub	x9, x9, #2
	ldrh	w8, [x10, w8, uxtw #1]
	add	x10, sp, #79
	strh	w8, [x10, x9]
	tbz	w0, #31, LBB8_6
LBB8_5:
	sub	x9, x9, #1
	add	x8, sp, #79
	mov	w10, #45
	strb	w10, [x8, x9]
LBB8_6:                                 ; %fmt.format__anon_13410.exit.i
	add	x22, sp, #79
	mov	w8, #33
	add	x0, x22, x9
	sub	x1, x8, x9
Lloh24:
	adrp	x2, l___unnamed_1@PAGE
Lloh25:
	add	x2, x2, l___unnamed_1@PAGEOFF
	add	x3, sp, #40
	bl	l_fmt.formatBuf__anon_13251
	ldr	x20, [sp, #32]
	cmp	x20, #23
	b.ls	LBB8_10
; %bb.7:                                ; %str.RocStr.allocate.exit.i
	cmp	x20, #64
	mov	w8, #64
	csel	x21, x20, x8, hi
	mov	w1, #8
	add	x0, x21, #8
	bl	_roc_alloc
	mov	x8, #-9223372036854775808
	cmp	x21, #0
	mov	x9, x20
	str	x8, [x0], #8
	csel	x8, x22, x0, lt
	b	LBB8_11
LBB8_8:
	mov	w9, #33
	cmp	w8, #9
	b.hi	LBB8_4
LBB8_9:
	sub	x9, x9, #1
	add	w8, w8, #48
	add	x10, sp, #79
	strb	w8, [x10, x9]
	tbz	w0, #31, LBB8_6
	b	LBB8_5
LBB8_10:                                ; %str.RocStr.allocate.exit.thread.i
	lsl	x8, x20, #56
	mov	x0, xzr
	mov	x9, xzr
	orr	x21, x8, #0x8000000000000000
	add	x8, sp, #79
LBB8_11:                                ; %str.RocStr.init.exit
	stur	x0, [sp, #79]
	add	x1, sp, #5
	mov	x0, x8
	mov	x2, x20
	stur	x9, [sp, #87]
	stur	x21, [sp, #95]
	bl	_memcpy
	ldur	q0, [sp, #79]
	ldur	x8, [sp, #95]
	ldp	x29, x30, [sp, #144]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #128]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #160
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	ret
	.loh AdrpLdr	Lloh18, Lloh19
	.loh AdrpAdd	Lloh20, Lloh21
	.loh AdrpAdd	Lloh22, Lloh23
	.loh AdrpAdd	Lloh24, Lloh25
Lfunc_end8:
	.cfi_endproc
                                        ; -- End function
	.section	__TEXT,__literal16,16byte_literals
	.p2align	4, 0x0                          ; -- Begin function roc_builtins.str.from_int.u64
lCPI9_0:
	.quad	20                              ; 0x14
	.quad	0                               ; 0x0
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2
_roc_builtins.str.from_int.u64:         ; @roc_builtins.str.from_int.u64
Lfunc_begin9:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #208
	.cfi_def_cfa_offset 208
	stp	x22, x21, [sp, #160]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	mov	x19, x8
Lloh26:
	adrp	x8, lCPI9_0@PAGE
	add	x9, sp, #12
	add	x10, sp, #32
	cmp	x0, #100
Lloh27:
	ldr	q0, [x8, lCPI9_0@PAGEOFF]
Lloh28:
	adrp	x8, _fmt.digits2__anon_14339@PAGE
Lloh29:
	add	x8, x8, _fmt.digits2__anon_14339@PAGEOFF
	str	x9, [sp, #32]
	str	x10, [sp, #56]
	stur	q0, [sp, #40]
	b.lo	LBB9_5
; %bb.1:                                ; %.lr.ph.i.i.i.i.i.i.preheader
	mov	x10, #62915
	mov	w9, #63
	movk	x10, #23592, lsl #16
	mov	w11, #100
	movk	x10, #49807, lsl #32
	add	x12, sp, #95
	movk	x10, #10485, lsl #48
LBB9_2:                                 ; %.lr.ph.i.i.i.i.i.i
                                        ; =>This Inner Loop Header: Depth=1
	lsr	x14, x0, #2
	mov	x13, x0
	umulh	x14, x14, x10
	lsr	x0, x14, #2
	msub	x14, x0, x11, x13
	lsr	x13, x13, #4
	cmp	x13, #624
	ldrh	w14, [x8, x14, lsl #1]
	strh	w14, [x12, x9]
	sub	x9, x9, #2
	b.hi	LBB9_2
; %bb.3:                                ; %._crit_edge.i.i.i.i.i.i.loopexit
	add	x9, x9, #2
	cmp	x0, #9
	b.ls	LBB9_6
LBB9_4:
	sub	x9, x9, #2
	ldrh	w8, [x8, x0, lsl #1]
	add	x10, sp, #95
	strh	w8, [x10, x9]
	b	LBB9_7
LBB9_5:
	mov	w9, #65
	cmp	x0, #9
	b.hi	LBB9_4
LBB9_6:
	sub	x9, x9, #1
	add	w8, w0, #48
	add	x10, sp, #95
	strb	w8, [x10, x9]
LBB9_7:                                 ; %fmt.format__anon_13518.exit.i
	add	x22, sp, #95
	mov	w8, #65
	add	x0, x22, x9
	sub	x1, x8, x9
Lloh30:
	adrp	x2, l___unnamed_1@PAGE
Lloh31:
	add	x2, x2, l___unnamed_1@PAGEOFF
	add	x3, sp, #56
	bl	l_fmt.formatBuf__anon_13251
	ldr	x20, [sp, #48]
	cmp	x20, #23
	b.ls	LBB9_9
; %bb.8:                                ; %str.RocStr.allocate.exit.i
	cmp	x20, #64
	mov	w8, #64
	csel	x21, x20, x8, hi
	mov	w1, #8
	add	x0, x21, #8
	bl	_roc_alloc
	mov	x8, #-9223372036854775808
	cmp	x21, #0
	mov	x9, x20
	str	x8, [x0], #8
	csel	x8, x22, x0, lt
	b	LBB9_10
LBB9_9:                                 ; %str.RocStr.allocate.exit.thread.i
	lsl	x8, x20, #56
	mov	x0, xzr
	mov	x9, xzr
	orr	x21, x8, #0x8000000000000000
	add	x8, sp, #95
LBB9_10:                                ; %str.RocStr.init.exit
	stur	x0, [sp, #95]
	add	x1, sp, #12
	mov	x0, x8
	mov	x2, x20
	stur	x9, [sp, #103]
	stur	x21, [sp, #111]
	bl	_memcpy
	ldur	q0, [sp, #95]
	ldur	x8, [sp, #111]
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	ret
	.loh AdrpAdd	Lloh28, Lloh29
	.loh AdrpAdrp	Lloh26, Lloh28
	.loh AdrpLdr	Lloh26, Lloh27
	.loh AdrpAdd	Lloh30, Lloh31
Lfunc_end9:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function roc_builtins.utils.allocate_with_refcount
_roc_builtins.utils.allocate_with_refcount: ; @roc_builtins.utils.allocate_with_refcount
Lfunc_begin10:
	.cfi_startproc
; %bb.0:
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	cmp	w1, #8
	mov	w9, #8
	csel	w8, w1, w9, hi
	cmp	w2, #0
	mov	w10, #16
	csel	x9, x10, x9, ne
	mov	w10, w1
	cmp	x9, x10
	mov	w1, w8
	csel	x19, x9, x10, hi
	add	x0, x19, x0
	bl	_roc_alloc
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	add	x0, x0, x19
	mov	x8, #-9223372036854775808
	stur	x8, [x0, #-8]
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	ret
Lfunc_end10:
	.cfi_endproc
                                        ; -- End function
	.globl	___roc_force_setjmp             ; -- Begin function __roc_force_setjmp
	.weak_definition	___roc_force_setjmp
	.p2align	2
___roc_force_setjmp:                    ; @__roc_force_setjmp
Lfunc_begin11:
	.cfi_startproc
; %bb.0:
	b	_setjmp
Lfunc_end11:
	.cfi_endproc
                                        ; -- End function
	.globl	___roc_force_longjmp            ; -- Begin function __roc_force_longjmp
	.weak_definition	___roc_force_longjmp
	.p2align	2
___roc_force_longjmp:                   ; @__roc_force_longjmp
Lfunc_begin12:
	.cfi_startproc
; %bb.0:
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	bl	_longjmp
Lfunc_end12:
	.cfi_endproc
                                        ; -- End function
	.globl	___divti3                       ; -- Begin function __divti3
	.weak_definition	___divti3
	.p2align	2
___divti3:                              ; @__divti3
Lfunc_begin13:
	.cfi_startproc
; %bb.0:
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	asr	x19, x1, #63
	asr	x20, x3, #63
	eor	x8, x19, x0
	eor	x9, x19, x1
	subs	x0, x8, x19
	eor	x8, x20, x2
	sbc	x1, x9, x19
	eor	x9, x20, x3
	subs	x2, x8, x20
	mov	x4, xzr
	sbc	x3, x9, x20
	bl	l_compiler_rt.udivmod.udivmod__anon_12862
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	eor	x8, x20, x19
	eor	x9, x0, x8
	eor	x10, x1, x8
	subs	x0, x9, x8
	sbc	x1, x10, x8
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	ret
Lfunc_end13:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function compiler_rt.udivmod.udivmod__anon_12862
l_compiler_rt.udivmod.udivmod__anon_12862: ; @compiler_rt.udivmod.udivmod__anon_12862
Lfunc_begin14:
	.cfi_startproc
; %bb.0:
	mov	x8, x1
	cmp	x0, x2
	sbcs	xzr, x1, x3
	b.hs	LBB14_3
; %bb.1:
	mov	x9, xzr
	mov	x1, xzr
	cbz	x4, LBB14_33
; %bb.2:
	stp	x0, x8, [x4]
	mov	x0, x9
	ret
LBB14_3:
	cbz	x3, LBB14_9
; %bb.4:
	clz	x10, x3
	clz	x11, x8
	sub	w11, w10, w11
	mov	x9, xzr
	mvn	w10, w11
	and	x12, x11, #0x7f
	tst	x12, #0x40
	lsr	x12, x2, #1
	lsl	x14, x3, x11
	lsl	x13, x2, x11
	lsr	x12, x12, x10
	csel	x10, xzr, x13, ne
	orr	x12, x14, x12
	add	w14, w11, #1
	csel	x11, x13, x12, ne
	and	x12, x14, #0x7f
LBB14_5:                                ; =>This Inner Loop Header: Depth=1
	mvn	x13, x0
	mvn	x14, x8
	cmn	x10, x13
	adc	x13, x11, x14
	asr	x14, x13, #63
	and	x15, x14, x11
	and	x14, x14, x10
	subs	x0, x0, x14
	extr	x10, x11, x10, #1
	extr	x9, x9, x13, #63
	sbc	x8, x8, x15
	lsr	x11, x11, #1
	subs	x12, x12, #1
	b.ne	LBB14_5
; %bb.6:
	cbz	x4, LBB14_8
; %bb.7:
	stp	x0, x8, [x4]
LBB14_8:
	mov	x1, xzr
	mov	x0, x9
	ret
LBB14_9:
	cmp	x8, x2
	b.hs	LBB14_21
; %bb.10:
	clz	x10, x2
	cbz	x10, LBB14_12
; %bb.11:
	neg	w9, w10
	lsl	x8, x8, x10
	lsl	x2, x2, x10
	lsr	x9, x0, x9
	lsl	x0, x0, x10
	orr	x8, x9, x8
LBB14_12:
	lsr	x12, x2, #32
	and	x14, x2, #0xffffffff
	lsr	x11, x0, #32
	and	x13, x0, #0xffffffff
	udiv	x9, x8, x12
	msub	x15, x9, x12, x8
	b	LBB14_14
LBB14_13:                               ; %.critedge.i.i
                                        ;   in Loop: Header=BB14_14 Depth=1
	add	x15, x15, x12
	sub	x9, x9, #1
	lsr	x16, x15, #32
	cbnz	x16, LBB14_16
LBB14_14:                               ; =>This Inner Loop Header: Depth=1
	lsr	x16, x9, #32
	cbnz	x16, LBB14_13
; %bb.15:                               ;   in Loop: Header=BB14_14 Depth=1
	mul	x16, x9, x14
	orr	x17, x11, x15, lsl #32
	cmp	x16, x17
	b.hi	LBB14_13
LBB14_16:
	orr	x8, x11, x8, lsl #32
	msub	x8, x9, x2, x8
	udiv	x11, x8, x12
	msub	x15, x11, x12, x8
	b	LBB14_18
LBB14_17:                               ; %.critedge2.i.i
                                        ;   in Loop: Header=BB14_18 Depth=1
	add	x15, x15, x12
	sub	x11, x11, #1
	lsr	x16, x15, #32
	cbnz	x16, LBB14_20
LBB14_18:                               ; =>This Inner Loop Header: Depth=1
	lsr	x16, x11, #32
	cbnz	x16, LBB14_17
; %bb.19:                               ;   in Loop: Header=BB14_18 Depth=1
	mul	x16, x11, x14
	orr	x17, x13, x15, lsl #32
	cmp	x16, x17
	b.hi	LBB14_17
LBB14_20:                               ; %compiler_rt.udivmod.divwide__anon_14184.exit
	orr	x8, x13, x8, lsl #32
	mov	x1, xzr
	msub	x8, x11, x2, x8
	lsr	x8, x8, x10
	add	x9, x11, x9, lsl #32
	cbnz	x4, LBB14_32
	b	LBB14_33
LBB14_21:
	udiv	x1, x8, x2
	clz	x9, x2
	msub	x11, x1, x2, x8
	ands	x8, x9, #0x3f
	b.eq	LBB14_23
; %bb.22:
	neg	w9, w9
	lsl	x10, x11, x8
	lsl	x2, x2, x8
	lsr	x9, x0, x9
	lsl	x0, x0, x8
	orr	x11, x10, x9
LBB14_23:
	lsr	x10, x2, #32
	and	x13, x2, #0xffffffff
	lsr	x14, x0, #32
	and	x12, x0, #0xffffffff
	udiv	x9, x11, x10
	msub	x15, x9, x10, x11
	b	LBB14_25
LBB14_24:                               ; %.critedge.i.i55
                                        ;   in Loop: Header=BB14_25 Depth=1
	add	x15, x15, x10
	sub	x9, x9, #1
	lsr	x16, x15, #32
	cbnz	x16, LBB14_27
LBB14_25:                               ; =>This Inner Loop Header: Depth=1
	lsr	x16, x9, #32
	cbnz	x16, LBB14_24
; %bb.26:                               ;   in Loop: Header=BB14_25 Depth=1
	mul	x16, x9, x13
	orr	x17, x14, x15, lsl #32
	cmp	x16, x17
	b.hi	LBB14_24
LBB14_27:
	orr	x11, x14, x11, lsl #32
	msub	x14, x9, x2, x11
	udiv	x11, x14, x10
	msub	x15, x11, x10, x14
	b	LBB14_29
LBB14_28:                               ; %.critedge2.i.i58
                                        ;   in Loop: Header=BB14_29 Depth=1
	add	x15, x15, x10
	sub	x11, x11, #1
	lsr	x16, x15, #32
	cbnz	x16, LBB14_31
LBB14_29:                               ; =>This Inner Loop Header: Depth=1
	lsr	x16, x11, #32
	cbnz	x16, LBB14_28
; %bb.30:                               ;   in Loop: Header=BB14_29 Depth=1
	mul	x16, x11, x13
	orr	x17, x12, x15, lsl #32
	cmp	x16, x17
	b.hi	LBB14_28
LBB14_31:                               ; %compiler_rt.udivmod.divwide__anon_14184.exit60
	orr	x10, x12, x14, lsl #32
	msub	x10, x11, x2, x10
	lsr	x8, x10, x8
	add	x9, x11, x9, lsl #32
	cbz	x4, LBB14_33
LBB14_32:
	stp	x8, xzr, [x4]
LBB14_33:                               ; %common.ret
	mov	x0, x9
	ret
Lfunc_end14:
	.cfi_endproc
                                        ; -- End function
	.globl	___udivti3                      ; -- Begin function __udivti3
	.weak_definition	___udivti3
	.p2align	2
___udivti3:                             ; @__udivti3
Lfunc_begin15:
	.cfi_startproc
; %bb.0:
	mov	x4, xzr
	b	l_compiler_rt.udivmod.udivmod__anon_12862
Lfunc_end15:
	.cfi_endproc
                                        ; -- End function
	.globl	___modti3                       ; -- Begin function __modti3
	.weak_definition	___modti3
	.p2align	2
___modti3:                              ; @__modti3
Lfunc_begin16:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	stp	x20, x19, [sp, #16]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	asr	x19, x1, #63
	mov	x4, sp
	eor	x9, x19, x0
	eor	x8, x19, x1
	subs	x0, x9, x19
	asr	x9, x3, #63
	sbc	x1, x8, x19
	eor	x8, x2, x9
	eor	x10, x3, x9
	subs	x2, x8, x9
	sbc	x3, x10, x9
	bl	l_compiler_rt.udivmod.udivmod__anon_12862
	ldp	x8, x9, [sp]
	ldp	x29, x30, [sp, #32]             ; 16-byte Folded Reload
	eor	x8, x8, x19
	eor	x9, x9, x19
	subs	x0, x8, x19
	sbc	x1, x9, x19
	ldp	x20, x19, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #48
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	ret
Lfunc_end16:
	.cfi_endproc
                                        ; -- End function
	.globl	___muloti4                      ; -- Begin function __muloti4
	.weak_definition	___muloti4
	.p2align	2
___muloti4:                             ; @__muloti4
Lfunc_begin17:
	.cfi_startproc
; %bb.0:
	asr	x9, x1, #63
	asr	x10, x3, #63
	umulh	x14, x0, x2
	mov	x8, x1
	mul	x11, x2, x9
	str	wzr, [x4]
	umulh	x12, x10, x0
	umulh	x13, x2, x9
	madd	x12, x10, x1, x12
	add	x13, x13, x11
	mul	x10, x10, x0
	madd	x9, x3, x9, x13
	add	x12, x12, x10
	adds	x10, x10, x11
	mul	x11, x1, x2
	adc	x9, x12, x9
	umulh	x13, x1, x2
	mul	x12, x0, x3
	adds	x11, x11, x14
	umulh	x14, x0, x3
	cinc	x13, x13, hs
	adds	x1, x12, x11
	mul	x12, x8, x3
	cinc	x11, x14, hs
	mul	x0, x0, x2
	adds	x11, x13, x11
	umulh	x13, x8, x3
	cset	w14, hs
	adds	x11, x12, x11
	adc	x12, x13, x14
	adds	x10, x11, x10
	asr	x11, x1, #63
	adc	x9, x12, x9
	cmp	x10, x11
	ccmp	x9, x11, #0, eq
	cset	w9, ne
	tbz	x8, #63, LBB17_2
; %bb.1:
	eor	x8, x3, #0x8000000000000000
	orr	x8, x2, x8
	cbz	x8, LBB17_3
LBB17_2:
	cbz	w9, LBB17_4
LBB17_3:                                ; %.critedge
	mov	w8, #1
	str	w8, [x4]
LBB17_4:                                ; %.critedge2
	ret
Lfunc_end17:
	.cfi_endproc
                                        ; -- End function
	.globl	_floorf                         ; -- Begin function floorf
	.weak_definition	_floorf
	.p2align	2
_floorf:                                ; @floorf
Lfunc_begin18:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #16
	.cfi_def_cfa_offset 16
	fcmp	s0, #0.0
	b.eq	LBB18_6
; %bb.1:
	fmov	w8, s0
	ubfx	w9, w8, #23, #8
	cmp	w9, #150
	b.hs	LBB18_6
; %bb.2:
	cmp	w9, #127
	b.lo	LBB18_5
; %bb.3:
	lsr	w9, w8, #23
	add	w10, w9, #1
	mov	w9, #8388607
	lsr	w9, w9, w10
	tst	w9, w8
	b.eq	LBB18_6
; %bb.4:
	mov	w11, #2071986176
	and	w10, w10, #0x1f
	and	w9, w9, w8, asr #31
	mov	w12, #-8388608
	add	w8, w9, w8
	fmov	s1, w11
	asr	w9, w12, w10
	and	w8, w8, w9
	add	x11, sp, #8
	fadd	s0, s0, s1
	str	s0, [sp, #8]
	fmov	s0, w8
	; InlineAsm Start
	; InlineAsm End
	b	LBB18_6
LBB18_5:
	mov	w9, #2071986176
	fmov	s2, #-1.00000000
	cmp	w8, #0
	fmov	s1, w9
	add	x9, sp, #12
	fadd	s0, s0, s1
	movi	d1, #0000000000000000
	str	s0, [sp, #12]
	fcsel	s0, s1, s2, ge
	; InlineAsm Start
	; InlineAsm End
LBB18_6:                                ; %common.ret
	add	sp, sp, #16
	.cfi_def_cfa_offset 0
	ret
Lfunc_end18:
	.cfi_endproc
                                        ; -- End function
	.globl	_memcpy                         ; -- Begin function memcpy
	.weak_definition	_memcpy
	.p2align	2
_memcpy:                                ; @memcpy
Lfunc_begin19:
	.cfi_startproc
; %bb.0:
	cbz	x2, LBB19_16
; %bb.1:                                ; %.preheader
	ldrb	w9, [x1]
	subs	x8, x2, #1
	strb	w9, [x0]
	b.eq	LBB19_16
; %bb.2:                                ; %iter.check
	cmp	x2, #9
	b.hs	LBB19_4
; %bb.3:
	mov	x9, x8
	mov	x12, x0
	mov	x11, x1
	b	LBB19_14
LBB19_4:                                ; %vector.main.loop.iter.check
	cmp	x2, #33
	b.hs	LBB19_6
; %bb.5:
	mov	x10, xzr
	b	LBB19_10
LBB19_6:                                ; %vector.ph
	and	x10, x8, #0xffffffffffffffe0
	add	x9, x1, #17
	add	x11, x0, #17
	neg	x12, x10
LBB19_7:                                ; %vector.body
                                        ; =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x9, #-16]
	add	x9, x9, #32
	adds	x12, x12, #32
	stp	q0, q1, [x11, #-16]
	add	x11, x11, #32
	b.ne	LBB19_7
; %bb.8:                                ; %middle.block
	cmp	x8, x10
	b.eq	LBB19_16
; %bb.9:                                ; %vec.epilog.iter.check
	tst	x8, #0x18
	b.eq	LBB19_13
LBB19_10:                               ; %vec.epilog.ph
	and	x13, x8, #0xfffffffffffffff8
	add	x15, x10, #1
	and	x9, x8, #0x7
	add	x12, x0, x13
	add	x11, x1, x13
	add	x14, x1, x15
	add	x15, x0, x15
	sub	x10, x10, x13
LBB19_11:                               ; %vec.epilog.vector.body
                                        ; =>This Inner Loop Header: Depth=1
	ldr	d0, [x14], #8
	adds	x10, x10, #8
	str	d0, [x15], #8
	b.ne	LBB19_11
; %bb.12:                               ; %vec.epilog.middle.block
	cmp	x8, x13
	b.ne	LBB19_14
	b	LBB19_16
LBB19_13:
	add	x11, x1, x10
	add	x12, x0, x10
	and	x9, x8, #0x1f
LBB19_14:                               ; %.lr.ph.preheader
	add	x8, x12, #1
	add	x10, x11, #1
LBB19_15:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	ldrb	w11, [x10], #1
	subs	x9, x9, #1
	strb	w11, [x8], #1
	b.ne	LBB19_15
LBB19_16:                               ; %.loopexit
	ret
Lfunc_end19:
	.cfi_endproc
                                        ; -- End function
	.globl	_memset                         ; -- Begin function memset
	.weak_definition	_memset
	.p2align	2
_memset:                                ; @memset
Lfunc_begin20:
	.cfi_startproc
; %bb.0:
	cbz	x2, LBB20_14
; %bb.1:                                ; %iter.check
	cmp	x2, #7
	b.hi	LBB20_3
; %bb.2:
	mov	x8, x2
	mov	x9, x0
	b	LBB20_13
LBB20_3:                                ; %vector.main.loop.iter.check
	cmp	x2, #32
	b.hs	LBB20_5
; %bb.4:
	mov	x10, xzr
	b	LBB20_9
LBB20_5:                                ; %vector.ph
	and	x10, x2, #0xffffffffffffffe0
	add	x8, x0, #16
	neg	x9, x10
	dup.16b	v0, w1
LBB20_6:                                ; %vector.body
                                        ; =>This Inner Loop Header: Depth=1
	stp	q0, q0, [x8, #-16]
	add	x8, x8, #32
	adds	x9, x9, #32
	b.ne	LBB20_6
; %bb.7:                                ; %middle.block
	cmp	x10, x2
	b.eq	LBB20_14
; %bb.8:                                ; %vec.epilog.iter.check
	tst	x2, #0x18
	b.eq	LBB20_12
LBB20_9:                                ; %vec.epilog.ph
	and	x11, x2, #0xfffffffffffffff8
	dup.8b	v0, w1
	and	x8, x2, #0x7
	add	x9, x0, x11
	add	x12, x0, x10
	sub	x10, x10, x11
LBB20_10:                               ; %vec.epilog.vector.body
                                        ; =>This Inner Loop Header: Depth=1
	adds	x10, x10, #8
	str	d0, [x12], #8
	b.ne	LBB20_10
; %bb.11:                               ; %vec.epilog.middle.block
	cmp	x11, x2
	b.ne	LBB20_13
	b	LBB20_14
LBB20_12:
	add	x9, x0, x10
	and	x8, x2, #0x1f
LBB20_13:                               ; %.preheader
                                        ; =>This Inner Loop Header: Depth=1
	subs	x8, x8, #1
	strb	w1, [x9], #1
	b.ne	LBB20_13
LBB20_14:                               ; %.loopexit
	ret
Lfunc_end20:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function unicode.utf8CountCodepoints
l_unicode.utf8CountCodepoints:          ; @unicode.utf8CountCodepoints
Lfunc_begin21:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x28, x27, [sp, #16]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x0
	cbz	x2, LBB21_18
; %bb.1:                                ; %.preheader.lr.ph
Lloh32:
	adrp	x8, l___unnamed_2@PAGE
Lloh33:
	adrp	x9, l___unnamed_3@PAGE
Lloh34:
	adrp	x10, l___unnamed_4@PAGE
Lloh35:
	adrp	x11, l___unnamed_5@PAGE
	mov	x20, x2
	mov	x21, x1
	mov	x22, xzr
	mov	x27, xzr
Lloh36:
	ldr	w23, [x8, l___unnamed_2@PAGEOFF]
	mov	w28, #20
Lloh37:
	ldr	w24, [x9, l___unnamed_3@PAGEOFF]
Lloh38:
	ldr	w25, [x10, l___unnamed_4@PAGEOFF]
Lloh39:
	ldr	w26, [x11, l___unnamed_5@PAGEOFF]
	b	LBB21_4
LBB21_2:                                ;   in Loop: Header=BB21_4 Depth=1
	add	x22, x22, #1
LBB21_3:                                ;   in Loop: Header=BB21_4 Depth=1
	cmp	x27, x20
	b.hs	LBB21_19
LBB21_4:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB21_5 Depth 2
	add	x9, x27, #8
LBB21_5:                                ; %.preheader
                                        ;   Parent Loop BB21_4 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x8, x27
	cmp	x9, x20
	b.hi	LBB21_9
; %bb.6:                                ; %.lr.ph
                                        ;   in Loop: Header=BB21_5 Depth=2
	ldr	x9, [x21, x8]
	tst	x9, #0x8080808080808080
	b.ne	LBB21_8
; %bb.7:                                ;   in Loop: Header=BB21_5 Depth=2
	add	x27, x8, #8
	add	x22, x22, #8
	add	x9, x8, #16
	b	LBB21_5
LBB21_8:                                ;   in Loop: Header=BB21_4 Depth=1
	mov	x27, x8
LBB21_9:                                ; %._crit_edge
                                        ;   in Loop: Header=BB21_4 Depth=1
	cmp	x27, x20
	b.hs	LBB21_3
; %bb.10:                               ;   in Loop: Header=BB21_4 Depth=1
	add	x1, x21, x27
	mov	w8, w26
	ldrsb	w9, [x1]
	tbz	w9, #31, LBB21_14
; %bb.11:                               ;   in Loop: Header=BB21_4 Depth=1
	and	w9, w9, #0xff
	mov	w8, w25
	and	w10, w9, #0xe0
	cmp	w10, #192
	b.eq	LBB21_14
; %bb.12:                               ;   in Loop: Header=BB21_4 Depth=1
	mov	w8, w24
	and	w10, w9, #0xf0
	cmp	w10, #224
	b.eq	LBB21_14
; %bb.13:                               ;   in Loop: Header=BB21_4 Depth=1
	and	w8, w9, #0xf8
	cmp	w8, #240
	csel	w8, w23, w28, eq
LBB21_14:                               ; %unicode.utf8ByteSequenceLength.exit
                                        ;   in Loop: Header=BB21_4 Depth=1
	tst	w8, #0xffff
	b.ne	LBB21_22
; %bb.15:                               ;   in Loop: Header=BB21_4 Depth=1
	ubfx	w2, w8, #16, #3
	add	x27, x27, x2
	cmp	x27, x20
	b.hi	LBB21_23
; %bb.16:                               ;   in Loop: Header=BB21_4 Depth=1
	and	w8, w8, #0x70000
	cmp	w8, #16, lsl #12                ; =65536
	b.eq	LBB21_2
; %bb.17:                               ;   in Loop: Header=BB21_4 Depth=1
	add	x0, sp, #8
	bl	l_unicode.utf8Decode
	ldrh	w8, [sp, #12]
	cbz	w8, LBB21_2
	b	LBB21_20
LBB21_18:
	mov	x22, xzr
LBB21_19:                               ; %._crit_edge54
	mov	w8, wzr
	str	x22, [x19]
LBB21_20:                               ; %common.ret
	strh	w8, [x19, #8]
LBB21_21:                               ; %common.ret
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB21_22:
	.cfi_restore_state
	and	w8, w8, #0xffff
	b	LBB21_20
LBB21_23:
Lloh40:
	adrp	x8, l___unnamed_6@PAGE
Lloh41:
	add	x8, x8, l___unnamed_6@PAGEOFF
Lloh42:
	ldr	q0, [x8]
	str	q0, [x19]
	b	LBB21_21
	.loh AdrpLdr	Lloh35, Lloh39
	.loh AdrpLdr	Lloh34, Lloh38
	.loh AdrpLdr	Lloh33, Lloh37
	.loh AdrpLdr	Lloh32, Lloh36
	.loh AdrpAddLdr	Lloh40, Lloh41, Lloh42
Lfunc_end21:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function unicode.utf8Decode
l_unicode.utf8Decode:                   ; @unicode.utf8Decode
Lfunc_begin22:
	.cfi_startproc
; %bb.0:
	sub	x8, x2, #1
	sub	sp, sp, #16
	.cfi_def_cfa_offset 16
	.cfi_remember_state
Lloh43:
	adrp	x9, LJTI22_0@PAGE
Lloh44:
	add	x9, x9, LJTI22_0@PAGEOFF
	adr	x10, LBB22_1
	ldrb	w11, [x9, x8]
	add	x10, x10, x11, lsl #2
	br	x10
LBB22_1:
	ldrb	w8, [x1]
	strb	wzr, [sp, #2]
	strb	wzr, [x0, #2]
	strh	wzr, [x0, #4]
	strh	w8, [sp]
	strh	w8, [x0]
	b	LBB22_18
LBB22_2:
	ldrb	w8, [x1, #1]
	and	w9, w8, #0xc0
	cmp	w9, #128
	b.ne	LBB22_16
; %bb.3:
	ldrb	w10, [x1, #2]
	and	w9, w10, #0xc0
	cmp	w9, #128
	b.ne	LBB22_16
; %bb.4:
	ldrb	w9, [x1]
	and	w9, w9, #0xf
	lsl	w11, w9, #12
	bfi	w11, w8, #6, #6
	mov	w9, w11
	bfxil	w9, w10, #0, #6
	cmp	w9, #2048
	b.lo	LBB22_15
; %bb.5:
	and	w8, w11, #0xf800
	mov	w10, #55296
	cmp	w8, w10
	b.ne	LBB22_20
; %bb.6:
	mov	x9, xzr
	mov	x8, #103079215104
	b	LBB22_17
LBB22_7:
	ldrb	w8, [x1, #1]
	and	w9, w8, #0xc0
	cmp	w9, #128
	b.ne	LBB22_16
; %bb.8:
	ldrb	w9, [x1, #2]
	and	w10, w9, #0xc0
	cmp	w10, #128
	b.ne	LBB22_16
; %bb.9:
	ldrb	w10, [x1, #3]
	and	w11, w10, #0xc0
	cmp	w11, #128
	b.ne	LBB22_16
; %bb.10:
	ldrb	w11, [x1]
	lsl	w11, w11, #12
	bfi	w11, w8, #6, #6
	and	w8, w10, #0x3f
	bfxil	w11, w9, #0, #6
	orr	w9, w8, w11, lsl #6
	and	w8, w9, #0x1fffff
	cmp	w8, #16, lsl #12                ; =65536
	b.lo	LBB22_15
; %bb.11:
	ubfx	w10, w9, #16, #5
	cmp	w10, #16
	b.ls	LBB22_22
; %bb.12:
	mov	x9, xzr
	mov	x8, #107374182400
	b	LBB22_17
LBB22_13:
	ldrb	w8, [x1, #1]
	and	w9, w8, #0xc0
	cmp	w9, #128
	b.ne	LBB22_16
; %bb.14:
	ldrb	w10, [x1]
	and	w9, w8, #0x3f
	bfi	w9, w10, #6, #5
	cmp	w9, #128
	b.hs	LBB22_19
LBB22_15:
	mov	x9, xzr
	mov	x8, #98784247808
	b	LBB22_17
LBB22_16:
	mov	x9, xzr
	mov	x8, #94489280512
LBB22_17:                               ; %unicode.utf8Decode2.exit
	orr	x8, x8, x9
	str	x8, [x0]
LBB22_18:
	add	sp, sp, #16
	.cfi_def_cfa_offset 0
	ret
LBB22_19:
	.cfi_restore_state
	strh	w9, [sp, #4]
	mov	x8, xzr
	and	w9, wzr, #0xff
	ldrh	w10, [sp, #4]
	strb	wzr, [sp, #6]
	b	LBB22_21
LBB22_20:
	strh	w9, [sp, #8]
	mov	x8, xzr
	ldrh	w10, [sp, #8]
	strb	wzr, [sp, #10]
	and	w9, wzr, #0xff
LBB22_21:                               ; %unicode.utf8Decode2.exit
	orr	x9, x10, x9, lsl #16
	b	LBB22_17
LBB22_22:
	strb	w10, [sp, #14]
	and	w10, w10, #0xff
	strh	w9, [sp, #12]
	and	w9, w9, #0xffff
	mov	x8, xzr
	orr	x9, x9, x10, lsl #16
	b	LBB22_17
	.loh AdrpAdd	Lloh43, Lloh44
Lfunc_end22:
	.cfi_endproc
	.section	__TEXT,__const
LJTI22_0:
	.byte	(LBB22_1-LBB22_1)>>2
	.byte	(LBB22_13-LBB22_1)>>2
	.byte	(LBB22_2-LBB22_1)>>2
	.byte	(LBB22_7-LBB22_1)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function fmt.formatBuf__anon_13251
l_fmt.formatBuf__anon_13251:            ; @fmt.formatBuf__anon_13251
Lfunc_begin23:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #816
	.cfi_def_cfa_offset 912
	mov	x21, x3
	mov	x19, x1
	ldrb	w8, [x2, #24]
	mov	x20, x0
	cbz	w8, LBB23_12
; %bb.1:
	mov	x22, x2
	ldr	x23, [x2, #16]
	add	x0, sp, #24
	mov	x1, x20
	mov	x2, x19
	bl	l_unicode.utf8CountCodepoints
	ldrh	w8, [sp, #32]
	ldr	x9, [sp, #24]
	cmp	w8, #0
	csel	x8, x9, x19, eq
	subs	x8, x23, x8
	csel	x24, xzr, x8, lo
	b.ls	LBB23_17
; %bb.2:
	ldrb	w8, [x22, #32]
	add	x25, sp, #560
	cbz	w8, LBB23_23
; %bb.3:
	cmp	w8, #1
	b.ne	LBB23_35
; %bb.4:
	add	x8, x22, #33
	ldr	x26, [x21]
	cmp	x24, #2
	ld1r.16b	{ v0 }, [x8]
	stp	q0, q0, [x25]
	stp	q0, q0, [x25, #32]
	stp	q0, q0, [x25, #64]
	stp	q0, q0, [x25, #96]
	stp	q0, q0, [x25, #128]
	stp	q0, q0, [x25, #160]
	stp	q0, q0, [x25, #192]
	stp	q0, q0, [x25, #224]
	b.hs	LBB23_46
; %bb.5:                                ; %.loopexit113
	cbz	x19, LBB23_11
LBB23_6:                                ; %.lr.ph.i63.preheader
	ldr	x8, [x26, #16]
	mov	x25, xzr
LBB23_7:                                ; %.lr.ph.i63
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x26, #8]
	subs	x10, x9, x8
	b.ls	LBB23_53
; %bb.8:                                ;   in Loop: Header=BB23_7 Depth=1
	sub	x11, x19, x25
	ldr	x12, [x26]
	add	x13, x8, x11
	add	x1, x20, x25
	cmp	x13, x9
	csel	x23, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x23
	bl	_memcpy
	ldr	x8, [x26, #16]
	add	x8, x8, x23
	str	x8, [x26, #16]
	cbz	x23, LBB23_53
; %bb.9:                                ;   in Loop: Header=BB23_7 Depth=1
	add	x25, x23, x25
	cmp	x25, x19
	b.ne	LBB23_7
; %bb.10:                               ; %.loopexit112.loopexit
	ldr	x26, [x21]
LBB23_11:                               ; %.loopexit112
	add	x8, x24, #1
	ldrb	w1, [x22, #33]
	lsr	x2, x8, #1
	add	x0, sp, #40
	str	x26, [sp, #40]
	bl	"l_io.writer.Writer(*io.fixed_buffer_stream.FixedBufferStream([]u8),error{NoSpaceLeft},(function 'write')).writeByteNTimes"
	b	LBB23_54
LBB23_12:
	cbz	x19, LBB23_22
; %bb.13:                               ; %.lr.ph.i.preheader
	ldr	x23, [x21]
	mov	x22, xzr
	ldr	x8, [x23, #16]
LBB23_14:                               ; %.lr.ph.i
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x23, #8]
	subs	x10, x9, x8
	b.ls	LBB23_53
; %bb.15:                               ;   in Loop: Header=BB23_14 Depth=1
	sub	x11, x19, x22
	ldr	x12, [x23]
	add	x13, x8, x11
	add	x1, x20, x22
	cmp	x13, x9
	csel	x21, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x21
	bl	_memcpy
	ldr	x8, [x23, #16]
	add	x8, x8, x21
	str	x8, [x23, #16]
	cbz	x21, LBB23_53
; %bb.16:                               ;   in Loop: Header=BB23_14 Depth=1
	add	x22, x21, x22
	cmp	x22, x19
	b.ne	LBB23_14
	b	LBB23_22
LBB23_17:
	cbz	x19, LBB23_22
; %bb.18:                               ; %.lr.ph.i21.preheader
	ldr	x23, [x21]
	mov	x22, xzr
	ldr	x8, [x23, #16]
LBB23_19:                               ; %.lr.ph.i21
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x23, #8]
	subs	x10, x9, x8
	b.ls	LBB23_53
; %bb.20:                               ;   in Loop: Header=BB23_19 Depth=1
	sub	x11, x19, x22
	ldr	x12, [x23]
	add	x13, x8, x11
	add	x1, x20, x22
	cmp	x13, x9
	csel	x21, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x21
	bl	_memcpy
	ldr	x8, [x23, #16]
	add	x8, x8, x21
	str	x8, [x23, #16]
	cbz	x21, LBB23_53
; %bb.21:                               ;   in Loop: Header=BB23_19 Depth=1
	add	x22, x21, x22
	cmp	x22, x19
	b.ne	LBB23_19
LBB23_22:
	mov	w0, wzr
	b	LBB23_54
LBB23_23:
	ldr	x26, [x21]
	cbz	x19, LBB23_29
; %bb.24:                               ; %.lr.ph.i33.preheader
	ldr	x8, [x26, #16]
	mov	x27, xzr
LBB23_25:                               ; %.lr.ph.i33
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x26, #8]
	subs	x10, x9, x8
	b.ls	LBB23_53
; %bb.26:                               ;   in Loop: Header=BB23_25 Depth=1
	sub	x11, x19, x27
	ldr	x12, [x26]
	add	x13, x8, x11
	add	x1, x20, x27
	cmp	x13, x9
	csel	x23, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x23
	bl	_memcpy
	ldr	x8, [x26, #16]
	add	x8, x8, x23
	str	x8, [x26, #16]
	cbz	x23, LBB23_53
; %bb.27:                               ;   in Loop: Header=BB23_25 Depth=1
	add	x27, x23, x27
	cmp	x27, x19
	b.ne	LBB23_25
; %bb.28:                               ; %.loopexit.loopexit
	ldr	x26, [x21]
LBB23_29:                               ; %.lr.ph.i38.preheader
	add	x8, x22, #33
	mov	w20, #256
	add	x21, sp, #560
	ld1r.16b	{ v0 }, [x8]
	ldr	x8, [x26, #16]
	stp	q0, q0, [x25]
	stp	q0, q0, [x25, #32]
	stp	q0, q0, [x25, #64]
	stp	q0, q0, [x25, #96]
	stp	q0, q0, [x25, #128]
	stp	q0, q0, [x25, #160]
	stp	q0, q0, [x25, #192]
	stp	q0, q0, [x25, #224]
LBB23_30:                               ; %.lr.ph.i38
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB23_31 Depth 2
	cmp	x24, #256
	mov	x22, xzr
	csel	x23, x24, x20, lo
LBB23_31:                               ; %.lr.ph.i.i
                                        ;   Parent Loop BB23_30 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x9, [x26, #8]
	subs	x10, x9, x8
	b.ls	LBB23_53
; %bb.32:                               ;   in Loop: Header=BB23_31 Depth=2
	sub	x11, x23, x22
	ldr	x12, [x26]
	add	x13, x11, x8
	add	x1, x21, x22
	cmp	x13, x9
	csel	x19, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x19
	bl	_memcpy
	ldr	x8, [x26, #16]
	add	x8, x8, x19
	str	x8, [x26, #16]
	cbz	x19, LBB23_53
; %bb.33:                               ;   in Loop: Header=BB23_31 Depth=2
	add	x22, x19, x22
	cmp	x22, x23
	b.ne	LBB23_31
; %bb.34:                               ;   in Loop: Header=BB23_30 Depth=1
	subs	x24, x24, x23
	b.ne	LBB23_30
	b	LBB23_22
LBB23_35:                               ; %.lr.ph.i72.preheader
	add	x8, x22, #33
	ldr	x23, [x21]
	mov	w26, #256
	add	x27, sp, #560
	ld1r.16b	{ v0 }, [x8]
	ldr	x8, [x23, #16]
	stp	q0, q0, [x25]
	stp	q0, q0, [x25, #32]
	stp	q0, q0, [x25, #64]
	stp	q0, q0, [x25, #96]
	stp	q0, q0, [x25, #128]
	stp	q0, q0, [x25, #160]
	stp	q0, q0, [x25, #192]
	stp	q0, q0, [x25, #224]
LBB23_36:                               ; %.lr.ph.i72
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB23_37 Depth 2
	cmp	x24, #256
	mov	x25, xzr
	csel	x28, x24, x26, lo
LBB23_37:                               ; %.lr.ph.i.i77
                                        ;   Parent Loop BB23_36 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x9, [x23, #8]
	subs	x10, x9, x8
	b.ls	LBB23_53
; %bb.38:                               ;   in Loop: Header=BB23_37 Depth=2
	sub	x11, x28, x25
	ldr	x12, [x23]
	add	x13, x11, x8
	add	x1, x27, x25
	cmp	x13, x9
	csel	x22, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x22
	bl	_memcpy
	ldr	x8, [x23, #16]
	add	x8, x8, x22
	str	x8, [x23, #16]
	cbz	x22, LBB23_53
; %bb.39:                               ;   in Loop: Header=BB23_37 Depth=2
	add	x25, x22, x25
	cmp	x25, x28
	b.ne	LBB23_37
; %bb.40:                               ;   in Loop: Header=BB23_36 Depth=1
	subs	x24, x24, x28
	b.ne	LBB23_36
; %bb.41:                               ; %.loopexit116
	cbz	x19, LBB23_22
; %bb.42:                               ; %.lr.ph.i90.preheader
	ldr	x23, [x21]
	mov	x22, xzr
	ldr	x8, [x23, #16]
LBB23_43:                               ; %.lr.ph.i90
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x23, #8]
	subs	x10, x9, x8
	b.ls	LBB23_53
; %bb.44:                               ;   in Loop: Header=BB23_43 Depth=1
	sub	x11, x19, x22
	ldr	x12, [x23]
	add	x13, x8, x11
	add	x1, x20, x22
	cmp	x13, x9
	csel	x21, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x21
	bl	_memcpy
	ldr	x8, [x23, #16]
	add	x8, x8, x21
	str	x8, [x23, #16]
	cbz	x21, LBB23_53
; %bb.45:                               ;   in Loop: Header=BB23_43 Depth=1
	mov	w0, wzr
	add	x22, x21, x22
	cmp	x22, x19
	b.ne	LBB23_43
	b	LBB23_54
LBB23_46:                               ; %.lr.ph.i45.preheader
	lsr	x9, x24, #1
	ldr	x8, [x26, #16]
	mov	w10, #256
	add	x28, sp, #560
LBB23_47:                               ; %.lr.ph.i45
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB23_48 Depth 2
	cmp	x9, #256
	mov	x27, xzr
	str	x9, [sp, #16]                   ; 8-byte Folded Spill
	csel	x25, x9, x10, lo
LBB23_48:                               ; %.lr.ph.i.i50
                                        ;   Parent Loop BB23_47 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x9, [x26, #8]
	subs	x10, x9, x8
	b.ls	LBB23_53
; %bb.49:                               ;   in Loop: Header=BB23_48 Depth=2
	sub	x11, x25, x27
	ldr	x12, [x26]
	add	x13, x11, x8
	add	x1, x28, x27
	cmp	x13, x9
	csel	x23, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x23
	bl	_memcpy
	ldr	x8, [x26, #16]
	add	x8, x8, x23
	str	x8, [x26, #16]
	cbz	x23, LBB23_53
; %bb.50:                               ;   in Loop: Header=BB23_48 Depth=2
	add	x27, x23, x27
	cmp	x27, x25
	b.ne	LBB23_48
; %bb.51:                               ;   in Loop: Header=BB23_47 Depth=1
	ldr	x9, [sp, #16]                   ; 8-byte Folded Reload
	mov	w10, #256
	subs	x9, x9, x25
	b.ne	LBB23_47
; %bb.52:                               ; %.loopexit113.loopexit
	ldr	x26, [x21]
	cbnz	x19, LBB23_6
	b	LBB23_11
LBB23_53:                               ; %"io.writer.Writer(*io.fixed_buffer_stream.FixedBufferStream([]u8),error{NoSpaceLeft},(function 'write')).writeByteNTimes.exit81"
	mov	w0, #5
LBB23_54:                               ; %common.ret
	add	sp, sp, #816
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end23:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function io.writer.Writer(*io.fixed_buffer_stream.FixedBufferStream([]u8),error{NoSpaceLeft},(function 'write')).writeByteNTimes
"l_io.writer.Writer(*io.fixed_buffer_stream.FixedBufferStream([]u8),error{NoSpaceLeft},(function 'write')).writeByteNTimes": ; @"io.writer.Writer(*io.fixed_buffer_stream.FixedBufferStream([]u8),error{NoSpaceLeft},(function 'write')).writeByteNTimes"
Lfunc_begin24:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #352
	.cfi_def_cfa_offset 352
	stp	x28, x27, [sp, #256]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #272]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #288]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #304]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #320]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #336]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	dup.16b	v0, w1
	stp	q0, q0, [sp]
	stp	q0, q0, [sp, #32]
	stp	q0, q0, [sp, #64]
	stp	q0, q0, [sp, #96]
	stp	q0, q0, [sp, #128]
	stp	q0, q0, [sp, #160]
	stp	q0, q0, [sp, #192]
	stp	q0, q0, [sp, #224]
	cbz	x2, LBB24_8
; %bb.1:
	mov	x19, x2
	mov	x20, x0
	mov	w22, #256
	mov	x23, sp
LBB24_2:                                ; %.lr.ph
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB24_3 Depth 2
	ldr	x26, [x20]
	cmp	x19, #256
	mov	x24, xzr
	csel	x25, x19, x22, lo
	ldr	x8, [x26, #16]
LBB24_3:                                ; %.lr.ph.i
                                        ;   Parent Loop BB24_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x9, [x26, #8]
	subs	x10, x9, x8
	b.ls	LBB24_7
; %bb.4:                                ;   in Loop: Header=BB24_3 Depth=2
	sub	x11, x25, x24
	ldr	x12, [x26]
	add	x13, x8, x11
	add	x1, x23, x24
	cmp	x13, x9
	csel	x21, x10, x11, hi
	add	x0, x12, x8
	mov	x2, x21
	bl	_memcpy
	ldr	x8, [x26, #16]
	add	x8, x8, x21
	str	x8, [x26, #16]
	cbz	x21, LBB24_7
; %bb.5:                                ;   in Loop: Header=BB24_3 Depth=2
	add	x24, x21, x24
	cmp	x24, x25
	b.ne	LBB24_3
; %bb.6:                                ;   in Loop: Header=BB24_2 Depth=1
	mov	w0, wzr
	subs	x19, x19, x25
	b.ne	LBB24_2
	b	LBB24_9
LBB24_7:
	mov	w0, #5
	b	LBB24_9
LBB24_8:
	mov	w0, wzr
LBB24_9:                                ; %common.ret
	ldp	x29, x30, [sp, #336]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #320]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            ; 16-byte Folded Reload
	add	sp, sp, #352
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end24:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function str.RocStr.reallocateFresh
l_str.RocStr.reallocateFresh:           ; @str.RocStr.reallocateFresh
Lfunc_begin25:
	.cfi_startproc
; %bb.0:                                ; %str.RocStr.len.exit
	sub	sp, sp, #208
	.cfi_def_cfa_offset 208
	stp	x26, x25, [sp, #128]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	ldp	x25, x24, [x1, #8]
	mov	x21, x2
	mov	x20, x1
	mov	x19, x0
	and	x9, x25, #0x7fffffffffffffff
	lsr	x8, x24, #56
	cmp	x24, #0
	eor	x8, x8, #0x80
	csel	x22, x8, x9, lt
	cmp	x2, #23
	b.ls	LBB25_6
; %bb.1:                                ; %str.RocStr.asU8ptr.exit
	cmp	x21, #64
	mov	w8, #64
	csel	x23, x21, x8, hi
	mov	w1, #8
	add	x0, x23, #8
	bl	_roc_alloc
	mov	x8, #-9223372036854775808
	str	x8, [x0], #8
	ldr	q0, [x20]
	stp	x0, x21, [sp, #8]
	ldr	x8, [x20, #16]
	str	x23, [sp, #24]
	str	q0, [sp, #32]
	ldr	x9, [sp, #32]
	str	x8, [sp, #48]
	cmp	x8, #0
	add	x8, sp, #32
	csel	x9, x8, x9, lt
	cmp	x23, #0
	add	x8, sp, #8
	csel	x8, x8, x0, lt
	cbz	x22, LBB25_19
; %bb.2:                                ; %iter.check
	mov	x10, xzr
	cmp	x22, #8
	b.lo	LBB25_17
; %bb.3:                                ; %iter.check
	sub	x11, x8, x9
	cmp	x11, #32
	b.lo	LBB25_17
; %bb.4:                                ; %vector.main.loop.iter.check
	cmp	x22, #32
	b.hs	LBB25_10
; %bb.5:
	mov	x10, xzr
	b	LBB25_14
LBB25_6:                                ; %str.RocStr.asU8ptr.exit14
Lloh45:
	adrp	x8, l___unnamed_7@PAGE
Lloh46:
	add	x8, x8, l___unnamed_7@PAGEOFF
	ldr	q1, [x20]
	ldr	x9, [x8, #16]
	ldr	q0, [x8]
	orr	w8, w21, #0x80
	str	q1, [sp, #96]
	str	x9, [sp, #80]
	ldr	x9, [x20, #16]
	str	q0, [sp, #64]
	strb	w8, [sp, #87]
	str	x9, [sp, #112]
	cbz	x22, LBB25_8
; %bb.7:                                ; %.lr.ph.i18.preheader
	ldr	x8, [sp, #112]
	add	x0, sp, #64
	ldr	x9, [sp, #96]
	mov	x2, x22
	cmp	x8, #0
	add	x8, sp, #96
	csel	x1, x8, x9, lt
	bl	_memcpy
LBB25_8:                                ; %mem.copyForwards__anon_9882.exit19
	add	x23, sp, #64
	sub	x1, x21, x22
	add	x0, x23, x22
	bl	_bzero
	tbnz	x24, #63, LBB25_26
; %bb.9:
	ldr	x8, [x20]
	lsl	x9, x24, #1
	cmp	x25, #0
	add	x23, sp, #64
	csel	x0, x9, x8, lt
	cbnz	x24, LBB25_21
	b	LBB25_26
LBB25_10:                               ; %vector.ph
	and	x10, x22, #0x7fffffffffffffe0
	add	x11, x8, #16
	add	x12, x9, #16
	neg	x13, x10
LBB25_11:                               ; %vector.body
                                        ; =>This Inner Loop Header: Depth=1
	ldp	q0, q1, [x12, #-16]
	add	x12, x12, #32
	adds	x13, x13, #32
	stp	q0, q1, [x11, #-16]
	add	x11, x11, #32
	b.ne	LBB25_11
; %bb.12:                               ; %middle.block
	cmp	x22, x10
	b.eq	LBB25_19
; %bb.13:                               ; %vec.epilog.iter.check
	tst	x22, #0x18
	b.eq	LBB25_17
LBB25_14:                               ; %vec.epilog.ph
	mov	x13, x10
	and	x10, x22, #0x7ffffffffffffff8
	add	x11, x8, x13
	add	x12, x9, x13
	sub	x13, x13, x10
LBB25_15:                               ; %vec.epilog.vector.body
                                        ; =>This Inner Loop Header: Depth=1
	ldr	d0, [x12], #8
	adds	x13, x13, #8
	str	d0, [x11], #8
	b.ne	LBB25_15
; %bb.16:                               ; %vec.epilog.middle.block
	cmp	x22, x10
	b.eq	LBB25_19
LBB25_17:                               ; %.lr.ph.i.preheader
	add	x9, x9, x10
	add	x11, x8, x10
	sub	x10, x10, x22
LBB25_18:                               ; %.lr.ph.i
                                        ; =>This Inner Loop Header: Depth=1
	ldrb	w12, [x9], #1
	adds	x10, x10, #1
	strb	w12, [x11], #1
	b.lo	LBB25_18
LBB25_19:                               ; %mem.copyForwards__anon_9882.exit
	add	x0, x8, x22
	sub	x1, x21, x22
	bl	_bzero
	ldr	x8, [x20, #16]
	tbnz	x8, #63, LBB25_25
; %bb.20:
	ldp	x10, x9, [x20]
	lsl	x11, x8, #1
	add	x23, sp, #8
	cmp	x9, #0
	csel	x0, x11, x10, lt
	cbz	x8, LBB25_26
LBB25_21:
	cbz	x0, LBB25_26
; %bb.22:
	ldr	x8, [x0, #-8]!
	cbz	x8, LBB25_26
; %bb.23:
	sub	x9, x8, #1
	mov	x10, #-9223372036854775808
	cmp	x8, x10
	str	x9, [x0]
	b.ne	LBB25_26
; %bb.24:                               ; %common.ret.sink.split
	mov	w1, #8
	bl	_roc_dealloc
	b	LBB25_26
LBB25_25:
	add	x23, sp, #8
LBB25_26:                               ; %common.ret
	ldr	x8, [x23, #16]
	ldr	q0, [x23]
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	str	x8, [x19, #16]
	str	q0, [x19]
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	ret
	.loh AdrpAdd	Lloh45, Lloh46
Lfunc_end25:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quadsort_direct__anon_14341
l_sort.quadsort_direct__anon_14341:     ; @sort.quadsort_direct__anon_14341
Lfunc_begin26:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #3088
	.cfi_def_cfa_offset 3184
	.cfi_remember_state
	mov	x20, x7
	mov	x19, x6
	mov	x21, x4
	mov	x22, x3
	mov	x23, x2
	mov	x25, x1
	mov	x26, x0
	cmp	x1, #32
	b.hs	LBB26_2
; %bb.1:
	add	x2, sp, #16
	mov	x0, x26
	mov	x1, x25
	mov	x3, x23
	mov	x4, x22
	mov	x5, x21
	mov	x6, x19
	mov	x7, x20
	bl	l_sort.tail_swap__anon_14832
	b	LBB26_5
LBB26_2:
	mov	w24, w5
	mov	x0, x26
	mov	x1, x25
	mov	x2, x23
	mov	x3, x22
	mov	x4, x21
	mov	x5, x19
	mov	x6, x20
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB26_5
; %bb.3:
	mul	x0, x21, x25
	mov	w1, w24
	bl	_roc_alloc
	cbz	x0, LBB26_6
; %bb.4:
	mov	x27, x0
	mov	x0, x26
	mov	x1, x25
	mov	x2, x27
	mov	x3, x25
	mov	x4, x23
	mov	x5, x22
	mov	x6, x21
	mov	x7, x19
	str	x20, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x26
	mov	x1, x25
	mov	x2, x27
	mov	x3, x25
	mov	x5, x23
	mov	x6, x22
	mov	x7, x21
	stp	x19, x20, [sp]
	bl	l_sort.rotate_merge__anon_14836
	mov	x0, x27
	mov	w1, w24
	add	sp, sp, #3088
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_roc_dealloc
LBB26_5:                                ; %common.ret
	.cfi_restore_state
	.cfi_remember_state
	add	sp, sp, #3088
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB26_6:
	.cfi_restore_state
	mov	x0, x26
	mov	x1, x25
	mov	x2, x23
	mov	x3, x22
	mov	x4, x20
	mov	x5, x21
	mov	x6, x19
	add	sp, sp, #3088
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.quadsort_stack_swap__anon_14837
Lfunc_end26:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quadsort_direct__anon_14342
l_sort.quadsort_direct__anon_14342:     ; @sort.quadsort_direct__anon_14342
Lfunc_begin27:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #3088
	.cfi_def_cfa_offset 3184
	.cfi_remember_state
	mov	x19, x6
	mov	x20, x4
	mov	x21, x3
	mov	x22, x2
	mov	x24, x1
	mov	x25, x0
	cmp	x1, #32
	b.hs	LBB27_2
; %bb.1:
	add	x2, sp, #16
	mov	x0, x25
	mov	x1, x24
	mov	x3, x22
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.tail_swap__anon_14838
	b	LBB27_5
LBB27_2:
	mov	w23, w5
	mov	x0, x25
	mov	x1, x24
	mov	x2, x22
	mov	x3, x21
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB27_5
; %bb.3:
	mul	x0, x20, x24
	mov	w1, w23
	bl	_roc_alloc
	cbz	x0, LBB27_6
; %bb.4:
	mov	x26, x0
	mov	x0, x25
	mov	x1, x24
	mov	x2, x26
	mov	x3, x24
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x25
	mov	x1, x24
	mov	x2, x26
	mov	x3, x24
	mov	x5, x22
	mov	x6, x21
	mov	x7, x20
	str	x19, [sp]
	bl	l_sort.rotate_merge__anon_14841
	mov	x0, x26
	mov	w1, w23
	add	sp, sp, #3088
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_roc_dealloc
LBB27_5:                                ; %common.ret
	.cfi_restore_state
	.cfi_remember_state
	add	sp, sp, #3088
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB27_6:
	.cfi_restore_state
	mov	x0, x25
	mov	x1, x24
	mov	x2, x22
	mov	x3, x21
	mov	x4, x20
	mov	x5, x19
	add	sp, sp, #3088
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.quadsort_stack_swap__anon_14842
Lfunc_end27:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quadsort_direct__anon_14343
l_sort.quadsort_direct__anon_14343:     ; @sort.quadsort_direct__anon_14343
Lfunc_begin28:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-80]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 80
	stp	x24, x23, [sp, #16]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	sub	sp, sp, #3072
	.cfi_def_cfa_offset 3152
	.cfi_remember_state
	mov	x19, x4
	mov	x20, x3
	mov	x21, x2
	mov	x22, x1
	mov	x23, x0
	cmp	x1, #32
	b.hs	LBB28_2
; %bb.1:
	mov	x2, sp
	mov	x0, x23
	mov	x1, x22
	mov	x3, x21
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.tail_swap__anon_14843
	b	LBB28_5
LBB28_2:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x20
	mov	x4, x19
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB28_5
; %bb.3:
	lsl	x0, x22, #3
	mov	w1, #8
	bl	_roc_alloc
	cbz	x0, LBB28_6
; %bb.4:
	mov	x24, x0
	mov	x0, x23
	mov	x1, x22
	mov	x2, x24
	mov	x3, x22
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x23
	mov	x1, x22
	mov	x2, x24
	mov	x3, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	bl	l_sort.rotate_merge__anon_14846
	mov	x0, x24
	mov	w1, #8
	add	sp, sp, #3072
	.cfi_def_cfa_offset 80
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w27
	.cfi_restore w28
	b	_roc_dealloc
LBB28_5:                                ; %common.ret
	.cfi_restore_state
	.cfi_remember_state
	add	sp, sp, #3072
	.cfi_def_cfa_offset 80
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB28_6:
	.cfi_restore_state
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x20
	mov	x4, x19
	add	sp, sp, #3072
	.cfi_def_cfa_offset 80
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.quadsort_stack_swap__anon_14847
Lfunc_end28:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quadsort_direct__anon_14344
l_sort.quadsort_direct__anon_14344:     ; @sort.quadsort_direct__anon_14344
Lfunc_begin29:
	.cfi_startproc
; %bb.0:
	stp	x24, x23, [sp, #-64]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 64
	stp	x22, x21, [sp, #16]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	sub	sp, sp, #3072
	.cfi_def_cfa_offset 3136
	.cfi_remember_state
	mov	x19, x3
	mov	x20, x2
	mov	x21, x1
	mov	x22, x0
	cmp	x1, #32
	b.hs	LBB29_2
; %bb.1:
	mov	x2, sp
	mov	x0, x22
	mov	x1, x21
	mov	x3, x20
	mov	x4, x19
	bl	l_sort.tail_swap__anon_14848
	b	LBB29_5
LBB29_2:
	mov	x0, x22
	mov	x1, x21
	mov	x2, x20
	mov	x3, x19
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB29_5
; %bb.3:
	lsl	x0, x21, #3
	mov	w1, #8
	bl	_roc_alloc
	cbz	x0, LBB29_6
; %bb.4:
	mov	x23, x0
	mov	x0, x22
	mov	x1, x21
	mov	x2, x23
	mov	x3, x21
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x22
	mov	x1, x21
	mov	x2, x23
	mov	x3, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.rotate_merge__anon_14851
	mov	x0, x23
	mov	w1, #8
	add	sp, sp, #3072
	.cfi_def_cfa_offset 64
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp], #64             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	b	_roc_dealloc
LBB29_5:                                ; %common.ret
	.cfi_restore_state
	.cfi_remember_state
	add	sp, sp, #3072
	.cfi_def_cfa_offset 64
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp], #64             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	ret
LBB29_6:
	.cfi_restore_state
	mov	x0, x22
	mov	x1, x21
	mov	x2, x20
	mov	x3, x19
	add	sp, sp, #3072
	.cfi_def_cfa_offset 64
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp], #64             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	b	l_sort.quadsort_stack_swap__anon_14852
Lfunc_end29:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.tail_swap__anon_14832
l_sort.tail_swap__anon_14832:           ; @sort.tail_swap__anon_14832
Lfunc_begin30:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #288
	.cfi_def_cfa_offset 288
	stp	x28, x27, [sp, #192]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #208]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #224]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #272]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x28, x6
	mov	x27, x5
	mov	x23, x2
	cmp	x1, #8
	stp	x0, x3, [sp, #80]               ; 16-byte Folded Spill
	b.hs	LBB30_3
; %bb.1:
Lloh47:
	adrp	x8, LJTI30_0@PAGE
Lloh48:
	add	x8, x8, LJTI30_0@PAGEOFF
	str	x27, [sp, #72]                  ; 8-byte Folded Spill
	adr	x9, LBB30_2
	ldrh	w10, [x8, x1, lsl #1]
	add	x9, x9, x10, lsl #2
	br	x9
LBB30_2:
	mov	x0, x4
	mov	w1, #1
	mov	x20, x4
	blr	x7
	ldp	x21, x23, [sp, #72]             ; 16-byte Folded Reload
	mov	x0, x20
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	add	x19, x23, x21
	mov	x1, x23
	mov	x2, x19
	blr	x8
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x23, x19, eq
	csel	x20, x21, xzr, eq
	blr	x28
	add	x1, x23, x20
	mov	x0, x23
	blr	x28
	add	x1, sp, #96
	b	LBB30_20
LBB30_3:
	lsr	x9, x1, #1
	lsr	x22, x1, #2
	sub	x8, x1, x9
	mov	x1, x22
	lsr	x21, x8, #1
	mov	x2, x23
	mov	x5, x27
	mov	x6, x28
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	sub	x8, x8, x21
	mov	x24, x0
	sub	x19, x9, x22
	mov	x20, x4
	mov	x26, x7
	stp	x8, x9, [sp, #64]               ; 16-byte Folded Spill
	bl	l_sort.tail_swap__anon_14832
	madd	x25, x22, x27, x24
	mov	x1, x19
	mov	x2, x23
	ldr	x3, [sp, #88]                   ; 8-byte Folded Reload
	mov	x0, x25
	mov	x4, x20
	mov	x5, x27
	mov	x6, x28
	mov	x7, x26
	bl	l_sort.tail_swap__anon_14832
	str	x19, [sp, #24]                  ; 8-byte Folded Spill
	madd	x19, x19, x27, x25
	mov	x1, x21
	mov	x2, x23
	mov	x0, x19
	ldr	x3, [sp, #88]                   ; 8-byte Folded Reload
	mov	x4, x20
	mov	x5, x27
	mov	x6, x28
	mov	x7, x26
	bl	l_sort.tail_swap__anon_14832
	madd	x19, x21, x27, x19
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x3, [sp, #88]                   ; 8-byte Folded Reload
	mov	x0, x19
	mov	x4, x20
	mov	x5, x27
	mov	x6, x28
	mov	x7, x26
	str	x21, [sp, #32]                  ; 8-byte Folded Spill
	str	x28, [sp, #48]                  ; 8-byte Folded Spill
	bl	l_sort.tail_swap__anon_14832
	mov	x0, x20
	mov	w1, #1
	sub	x8, x22, #1
	mov	x21, x24
	madd	x24, x8, x27, x24
	blr	x26
	mov	x0, x20
	mov	x1, x24
	mov	x2, x25
	ldr	x25, [sp, #88]                  ; 8-byte Folded Reload
	blr	x25
	and	w8, w0, #0xff
	str	x23, [sp, #56]                  ; 8-byte Folded Spill
	cmp	w8, #1
	b.ne	LBB30_5
; %bb.4:                                ; %..critedge_crit_edge
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x23, x26
	mov	x19, x20
	mul	x24, x8, x27
	b	LBB30_8
LBB30_5:
	ldr	x9, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x20
	mov	w1, #1
	mov	x28, x19
	sub	x8, x9, #1
	mul	x24, x9, x27
	madd	x19, x8, x27, x21
	add	x25, x21, x24
	blr	x26
	mov	x0, x20
	mov	x1, x19
	mov	x2, x25
	ldr	x25, [sp, #88]                  ; 8-byte Folded Reload
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB30_7
; %bb.6:
	mov	x23, x26
	mov	x19, x20
	b	LBB30_8
LBB30_7:
	mov	x0, x20
	mov	w1, #1
	mov	x21, x28
	sub	x28, x28, x27
	mov	x23, x26
	blr	x26
	mov	x0, x20
	mov	x1, x28
	mov	x2, x21
	mov	x19, x20
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB30_9
LBB30_8:                                ; %.critedge
	ldr	x28, [sp, #56]                  ; 8-byte Folded Reload
	mov	x20, x19
	ldr	x21, [sp, #80]                  ; 8-byte Folded Reload
	mov	x5, x19
	ldr	x19, [sp, #48]                  ; 8-byte Folded Reload
	mov	x2, x22
	mov	x0, x28
	ldr	x3, [sp, #24]                   ; 8-byte Folded Reload
	mov	x1, x21
	mov	x4, x25
	mov	x6, x27
	mov	x7, x19
	str	x23, [sp]
	bl	l_sort.parity_merge__anon_16476
	add	x0, x28, x24
	add	x1, x21, x24
	ldr	x2, [sp, #32]                   ; 8-byte Folded Reload
	mov	x4, x25
	ldr	x3, [sp, #64]                   ; 8-byte Folded Reload
	mov	x5, x20
	mov	x6, x27
	mov	x7, x19
	str	x23, [sp]
	bl	l_sort.parity_merge__anon_16476
	mov	x0, x21
	mov	x1, x28
	ldr	x2, [sp, #72]                   ; 8-byte Folded Reload
	mov	x4, x25
	ldr	x3, [sp, #40]                   ; 8-byte Folded Reload
	mov	x5, x20
	mov	x6, x27
	mov	x7, x19
	str	x23, [sp]
	bl	l_sort.parity_merge__anon_16476
LBB30_9:                                ; %common.ret1
	ldp	x29, x30, [sp, #272]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #256]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #224]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #208]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #192]            ; 16-byte Folded Reload
	add	sp, sp, #288
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB30_10:
	.cfi_restore_state
	mov	x0, x4
	mov	w1, #3
	mov	x24, x4
	blr	x7
	ldp	x25, x26, [sp, #72]             ; 16-byte Folded Reload
	mov	x0, x24
	ldr	x23, [sp, #88]                  ; 8-byte Folded Reload
	add	x20, x26, x25
	mov	x1, x26
	mov	x2, x20
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x26, x20, eq
	csel	x19, x25, xzr, eq
	blr	x28
	add	x1, x26, x19
	mov	x0, x26
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	add	x19, x20, x25
	mov	x0, x24
	mov	x1, x20
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x19, eq
	csel	x21, x25, xzr, eq
	blr	x28
	add	x1, x20, x21
	mov	x0, x20
	blr	x28
	add	x1, sp, #96
	mov	x0, x19
	blr	x28
	mov	x0, x24
	mov	x1, x26
	mov	x2, x20
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x26, x20, eq
	csel	x19, x25, xzr, eq
	blr	x28
	add	x1, x26, x19
	mov	x0, x26
	b	LBB30_13
LBB30_11:
	mov	x0, x4
	mov	w1, #3
	mov	x25, x4
	mov	x27, x7
	blr	x7
	ldp	x26, x24, [sp, #72]             ; 16-byte Folded Reload
	mov	x0, x25
	ldr	x23, [sp, #88]                  ; 8-byte Folded Reload
	add	x19, x24, x26
	mov	x1, x24
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x24, x19, eq
	csel	x20, x26, xzr, eq
	blr	x28
	add	x1, x24, x20
	mov	x0, x24
	blr	x28
	add	x1, sp, #96
	mov	x0, x19
	blr	x28
	lsl	x21, x26, #1
	mov	x0, x25
	add	x19, x24, x21
	add	x20, x19, x26
	mov	x1, x19
	mov	x2, x20
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	csel	x22, x26, xzr, eq
	blr	x28
	add	x1, x19, x22
	mov	x0, x19
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	sub	x20, x19, x26
	mov	x0, x25
	mov	x1, x20
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB30_9
; %bb.12:
	mov	x9, x27
	ldr	x27, [sp, #72]                  ; 8-byte Folded Reload
	mov	x0, x25
	mov	w1, #3
	mov	x26, x25
	neg	x23, x27
	blr	x9
	add	x0, sp, #96
	mov	x1, x20
	blr	x28
	mov	x0, x20
	mov	x1, x19
	blr	x28
	add	x1, sp, #96
	mov	x0, x19
	blr	x28
	add	x19, x20, x23
	mov	x0, x25
	add	x20, x19, x27
	mov	x1, x19
	mov	x2, x20
	ldr	x25, [sp, #88]                  ; 8-byte Folded Reload
	blr	x25
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	csel	x22, x27, xzr, eq
	blr	x28
	add	x1, x19, x22
	mov	x0, x19
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	add	x19, x19, x21
	mov	x0, x26
	add	x20, x19, x27
	mov	x1, x19
	mov	x2, x20
	blr	x25
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	csel	x21, x27, xzr, eq
	blr	x28
	add	x1, x19, x21
	mov	x0, x19
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	add	x19, x19, x23
	mov	x0, x26
	add	x20, x19, x27
	mov	x1, x19
	mov	x2, x20
	blr	x25
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	csel	x21, x27, xzr, eq
	blr	x28
	add	x1, x19, x21
	mov	x0, x19
LBB30_13:                               ; %sort.tiny_sort__anon_16475.exit
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	b	LBB30_9
LBB30_14:
	mov	x0, x4
	mov	w1, #4
	mov	x8, x7
	mov	x24, x4
	str	x7, [sp, #64]                   ; 8-byte Folded Spill
	blr	x8
	ldp	x26, x20, [sp, #72]             ; 16-byte Folded Reload
	mov	x0, x24
	mov	x22, x28
	ldr	x23, [sp, #88]                  ; 8-byte Folded Reload
	add	x21, x20, x26
	mov	x1, x20
	mov	x2, x21
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x19, x26, xzr, eq
	blr	x28
	add	x1, x20, x19
	mov	x0, x20
	blr	x28
	add	x1, sp, #96
	mov	x0, x21
	str	x21, [sp, #56]                  ; 8-byte Folded Spill
	blr	x28
	lsl	x19, x26, #1
	mov	x0, x24
	add	x27, x20, x19
	add	x21, x27, x26
	mov	x1, x27
	mov	x2, x21
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x27, x21, eq
	csel	x20, x26, xzr, eq
	blr	x28
	add	x1, x27, x20
	mov	x0, x27
	blr	x28
	add	x1, sp, #96
	mov	x0, x21
	str	x21, [sp, #48]                  ; 8-byte Folded Spill
	blr	x28
	sub	x25, x27, x26
	mov	x0, x24
	mov	x1, x25
	mov	x2, x27
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x25, x27, eq
	cset	w21, eq
	csel	x20, x26, xzr, eq
	blr	x28
	add	x1, x25, x20
	mov	x0, x25
	blr	x28
	add	x1, sp, #96
	mov	x0, x27
	blr	x28
	add	x20, x25, x19
	mov	x0, x24
	add	x28, x20, x26
	mov	x1, x20
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	mov	x23, x22
	csel	x1, x20, x28, eq
	csel	x19, x26, xzr, eq
	csetm	w22, eq
	blr	x23
	add	x1, x20, x19
	mov	x0, x20
	blr	x23
	add	x1, sp, #96
	mov	x0, x28
	blr	x23
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	cmp	w21, w22
	b.eq	LBB30_9
; %bb.15:
	mov	x0, x24
	mov	w1, #6
	mov	x21, x23
	mov	x22, x24
	blr	x8
	mov	x0, x24
	str	x24, [sp, #16]                  ; 8-byte Folded Spill
	ldp	x26, x24, [sp, #80]             ; 16-byte Folded Reload
	ldr	x23, [sp, #56]                  ; 8-byte Folded Reload
	mov	x1, x26
	mov	x2, x23
	blr	x24
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	csel	x1, x26, x23, eq
	csel	x19, x8, xzr, eq
	blr	x21
	add	x1, x26, x19
	mov	x0, x26
	blr	x21
	add	x1, sp, #96
	mov	x0, x23
	blr	x21
	mov	x0, x22
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	mov	x1, x27
	mov	x2, x22
	blr	x24
	and	w8, w0, #0xff
	ldr	x23, [sp, #72]                  ; 8-byte Folded Reload
	cmp	w8, #1
	add	x0, sp, #96
	csel	x1, x27, x22, eq
	csel	x19, x23, xzr, eq
	blr	x21
	add	x1, x27, x19
	mov	x0, x27
	blr	x21
	add	x1, sp, #96
	mov	x0, x22
	blr	x21
	ldr	x0, [sp, #16]                   ; 8-byte Folded Reload
	mov	x1, x25
	mov	x2, x27
	blr	x24
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x25, x27, eq
	csel	x19, x23, xzr, eq
	blr	x21
	add	x1, x25, x19
	mov	x0, x25
	blr	x21
	add	x1, sp, #96
	mov	x0, x27
	blr	x21
	ldr	x25, [sp, #16]                  ; 8-byte Folded Reload
	mov	x1, x20
	mov	x2, x28
	mov	x0, x25
	blr	x24
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	mov	x24, x23
	csel	x1, x20, x28, eq
	csel	x19, x23, xzr, eq
	blr	x21
	add	x1, x20, x19
	mov	x0, x20
	blr	x21
	add	x1, sp, #96
	mov	x0, x28
	blr	x21
	ldr	x23, [sp, #56]                  ; 8-byte Folded Reload
	mov	x0, x25
	mov	x1, x26
	ldr	x20, [sp, #88]                  ; 8-byte Folded Reload
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x26, x23, eq
	csel	x19, x24, xzr, eq
	blr	x21
	add	x1, x26, x19
	mov	x0, x26
	blr	x21
	add	x1, sp, #96
	mov	x0, x23
	blr	x21
	mov	x0, x25
	mov	x1, x27
	mov	x2, x22
	blr	x20
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x27, x22, eq
	csel	x19, x24, xzr, eq
	blr	x21
	add	x1, x27, x19
	mov	x0, x27
	blr	x21
	add	x1, sp, #96
	mov	x0, x22
	blr	x21
	b	LBB30_9
LBB30_16:
	mov	x0, x4
	mov	w1, #6
	mov	x8, x7
	stp	x23, x7, [sp, #56]              ; 16-byte Folded Spill
	mov	x26, x4
	blr	x8
	ldp	x25, x20, [sp, #72]             ; 16-byte Folded Reload
	mov	x0, x26
	ldr	x23, [sp, #88]                  ; 8-byte Folded Reload
	add	x21, x20, x25
	mov	x1, x20
	mov	x2, x21
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x19, x25, xzr, eq
	blr	x28
	add	x1, x20, x19
	mov	x0, x20
	blr	x28
	add	x1, sp, #96
	mov	x0, x21
	str	x21, [sp, #48]                  ; 8-byte Folded Spill
	blr	x28
	lsl	x24, x25, #1
	mov	x0, x26
	add	x27, x20, x24
	add	x19, x27, x25
	mov	x1, x27
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x27, x19, eq
	csel	x20, x25, xzr, eq
	blr	x28
	add	x1, x27, x20
	mov	x0, x27
	blr	x28
	add	x1, sp, #96
	mov	x0, x19
	blr	x28
	add	x19, x27, x24
	mov	x0, x26
	add	x20, x19, x25
	mov	x1, x19
	mov	x2, x20
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	csel	x21, x25, xzr, eq
	blr	x28
	add	x1, x19, x21
	mov	x0, x19
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	add	x8, x24, x25
	mov	x0, x26
	sub	x19, x19, x8
	add	x20, x19, x25
	mov	x1, x19
	mov	x2, x20
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	cset	w21, eq
	csel	x22, x25, xzr, eq
	blr	x28
	add	x1, x19, x22
	mov	x0, x19
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	add	x19, x19, x24
	mov	x0, x26
	add	x20, x19, x25
	mov	x1, x19
	mov	x2, x20
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	csel	x22, x25, xzr, eq
	cinc	w21, w21, eq
	blr	x28
	add	x1, x19, x22
	mov	x0, x19
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	add	x20, x19, x24
	mov	x0, x26
	add	x19, x20, x25
	mov	x1, x20
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x19, eq
	csel	x22, x25, xzr, eq
	csetm	w23, eq
	blr	x28
	add	x1, x20, x22
	mov	x0, x20
	mov	x22, x28
	blr	x28
	add	x1, sp, #96
	mov	x0, x19
	blr	x28
	ldp	x28, x8, [sp, #56]              ; 16-byte Folded Reload
	cmp	w21, w23
	b.eq	LBB30_9
; %bb.17:                               ; %.cont110.i.i
	mov	x25, x26
	ldr	x26, [sp, #72]                  ; 8-byte Folded Reload
	mov	x0, x25
	mov	w1, #11
	sub	x19, x20, x26
	blr	x8
	mov	x0, x25
	mov	x1, x19
	mov	x2, x20
	ldr	x21, [sp, #88]                  ; 8-byte Folded Reload
	blr	x21
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	mov	x23, x21
	csel	x1, x19, x20, eq
	csel	x21, x26, xzr, eq
	blr	x22
	add	x1, x19, x21
	mov	x0, x19
	blr	x22
	add	x1, sp, #96
	mov	x0, x20
	blr	x22
	mov	x0, x25
	mov	x21, x25
	ldr	x25, [sp, #80]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #48]                   ; 8-byte Folded Reload
	mov	x1, x25
	blr	x23
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	mov	x20, x23
	csel	x8, x26, xzr, eq
	csel	x19, xzr, x26, eq
	add	x1, x25, x8
	blr	x22
	add	x0, x28, x26
	add	x1, x25, x19
	str	x0, [sp, #32]                   ; 8-byte Folded Spill
	blr	x22
	add	x0, x28, x24
	mov	x1, x27
	str	x0, [sp, #64]                   ; 8-byte Folded Spill
	blr	x22
	ldr	x19, [sp, #40]                  ; 8-byte Folded Reload
	mov	x0, x21
	add	x23, x25, x19
	add	x2, x23, x26
	mov	x1, x23
	blr	x20
	and	w8, w0, #0xff
	add	x19, x28, x19
	cmp	w8, #1
	mov	x27, x22
	csel	x8, x26, xzr, eq
	mov	x0, x19
	add	x1, x23, x8
	csel	x22, xzr, x26, eq
	blr	x27
	lsl	x25, x26, #2
	add	x1, x23, x22
	add	x0, x28, x25
	blr	x27
	add	x23, x23, x24
	mov	x0, x21
	add	x2, x23, x26
	mov	x1, x23
	mov	x22, x21
	blr	x20
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	and	w9, w0, #0xff
	cmp	w9, #1
	csel	x9, x26, xzr, eq
	csel	x24, xzr, x26, eq
	add	x8, x8, x25
	add	x1, x23, x9
	mov	x0, x8
	blr	x27
	add	x8, x26, x26, lsl #1
	add	x1, x23, x24
	lsl	x8, x8, #1
	add	x21, x28, x8
	mov	x0, x21
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	blr	x27
	mov	x0, x22
	mov	x1, x28
	mov	x2, x19
	mov	x25, x22
	blr	x20
	ldr	x22, [sp, #80]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x19, x28, eq
	mov	x0, x22
	add	x8, x1, x26
	csel	x23, x28, x8, eq
	csel	x19, x8, x19, eq
	blr	x27
	mov	x0, x25
	mov	x1, x23
	mov	x2, x19
	blr	x20
	ldr	x24, [sp, #48]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x19, x23, eq
	mov	x0, x24
	add	x8, x1, x26
	csel	x23, x23, x8, eq
	csel	x19, x8, x19, eq
	blr	x27
	mov	x0, x25
	mov	x1, x23
	mov	x2, x19
	add	x24, x24, x26
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x24
	cmp	w8, #1
	csel	x1, x19, x23, eq
	blr	x27
	ldr	x24, [sp, #64]                  ; 8-byte Folded Reload
	mov	x0, x25
	mov	x2, x21
	mov	x23, x20
	mov	x1, x24
	blr	x20
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	add	x19, x22, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x0, x19
	csel	x1, x24, x21, eq
	cmp	w8, #1
	sub	x9, x1, x26
	csel	x20, x9, x24, eq
	csel	x21, x21, x9, eq
	blr	x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x21
	blr	x23
	and	w8, w0, #0xff
	sub	x19, x19, x26
	cmp	w8, #1
	mov	x0, x19
	csel	x1, x20, x21, eq
	cmp	w8, #1
	sub	x9, x1, x26
	csel	x20, x9, x20, eq
	csel	x21, x21, x9, eq
	blr	x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x21
	blr	x23
	and	w8, w0, #0xff
	sub	x19, x19, x26
	cmp	w8, #1
	mov	x0, x19
	csel	x1, x20, x21, eq
	cmp	w8, #1
	sub	x9, x1, x26
	csel	x20, x9, x20, eq
	csel	x21, x21, x9, eq
	blr	x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x21
	sub	x19, x19, x26
	blr	x23
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x1, x20, x21, eq
	blr	x27
	b	LBB30_9
LBB30_18:
	mov	x0, x4
	mov	w1, #5
	mov	x8, x7
	stp	x23, x7, [sp, #56]              ; 16-byte Folded Spill
	str	x4, [sp, #16]                   ; 8-byte Folded Spill
	blr	x8
	ldp	x27, x23, [sp, #72]             ; 16-byte Folded Reload
	ldr	x0, [sp, #16]                   ; 8-byte Folded Reload
	ldr	x21, [sp, #88]                  ; 8-byte Folded Reload
	add	x26, x23, x27
	mov	x1, x23
	mov	x2, x26
	blr	x21
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x23, x26, eq
	csel	x19, x27, xzr, eq
	blr	x28
	add	x1, x23, x19
	mov	x0, x23
	blr	x28
	add	x1, sp, #96
	mov	x0, x26
	blr	x28
	add	x20, x26, x27
	ldr	x0, [sp, #16]                   ; 8-byte Folded Reload
	mov	x1, x26
	mov	x2, x20
	blr	x21
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x26, x20, eq
	csel	x19, x27, xzr, eq
	blr	x28
	add	x1, x26, x19
	mov	x0, x26
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	str	x20, [sp, #40]                  ; 8-byte Folded Spill
	blr	x28
	lsl	x25, x27, #1
	mov	x24, x28
	add	x28, x25, x27
	ldr	x0, [sp, #16]                   ; 8-byte Folded Reload
	add	x19, x26, x28
	add	x20, x19, x27
	mov	x1, x19
	mov	x2, x20
	blr	x21
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	csel	x22, x27, xzr, eq
	blr	x24
	add	x1, x19, x22
	mov	x0, x19
	blr	x24
	add	x1, sp, #96
	mov	x0, x20
	blr	x24
	sub	x20, x19, x27
	ldr	x0, [sp, #16]                   ; 8-byte Folded Reload
	mov	x1, x20
	mov	x2, x19
	blr	x21
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x19, eq
	csel	x22, x27, xzr, eq
	blr	x24
	add	x1, x20, x22
	mov	x0, x20
	mov	x22, x24
	blr	x24
	add	x1, sp, #96
	mov	x0, x19
	blr	x24
	add	x19, x23, x25
	add	x2, x23, x28
	ldr	x0, [sp, #16]                   ; 8-byte Folded Reload
	mov	x1, x19
	stp	x25, x28, [sp, #24]             ; 16-byte Folded Spill
	mov	x25, x21
	blr	x21
	ldr	x9, [sp, #64]                   ; 8-byte Folded Reload
	and	w8, w0, #0xff
	ldr	x28, [sp, #16]                  ; 8-byte Folded Reload
	cmp	w8, #1
	b.ne	LBB30_21
; %bb.19:                               ; %.cont96.i.i
	neg	x8, x27
	mov	x0, x28
	mov	w1, #8
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
	blr	x9
	mov	x0, x28
	mov	x1, x23
	mov	x2, x26
	blr	x25
	and	w8, w0, #0xff
	ldr	x24, [sp, #56]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x8, x27, xzr, eq
	csel	x20, xzr, x27, eq
	add	x1, x23, x8
	mov	x0, x24
	blr	x22
	add	x0, x24, x27
	add	x1, x23, x20
	mov	x20, x23
	blr	x22
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x1, x19
	add	x0, x24, x8
	str	x0, [sp, #64]                   ; 8-byte Folded Spill
	blr	x22
	lsl	x21, x27, #2
	mov	x0, x28
	add	x19, x23, x21
	add	x2, x19, x27
	mov	x1, x19
	blr	x25
	and	w9, w0, #0xff
	add	x8, x24, x21
	cmp	w9, #1
	mov	x28, x22
	csel	x9, x27, xzr, eq
	mov	x0, x8
	add	x1, x19, x9
	csel	x22, xzr, x27, eq
	blr	x28
	add	x8, x21, x27
	add	x1, x19, x22
	add	x21, x24, x8
	mov	x0, x21
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	blr	x28
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	add	x23, x24, x8
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	mov	x0, x23
	add	x1, x19, x8
	blr	x28
	ldr	x22, [sp, #16]                  ; 8-byte Folded Reload
	mov	x1, x24
	mov	x2, x23
	mov	x0, x22
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x1, x23, x24, eq
	add	x8, x1, x27
	csel	x19, x24, x8, eq
	csel	x23, x8, x23, eq
	blr	x28
	mov	x0, x22
	mov	x1, x19
	mov	x2, x23
	mov	x24, x22
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	csel	x1, x23, x19, eq
	add	x8, x1, x27
	csel	x19, x19, x8, eq
	csel	x22, x8, x23, eq
	blr	x28
	mov	x0, x24
	mov	x1, x19
	mov	x2, x22
	mov	x23, x24
	blr	x25
	and	w8, w0, #0xff
	ldr	x0, [sp, #40]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x22, x19, eq
	blr	x28
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x0, x24
	mov	x2, x21
	add	x19, x20, x8
	ldr	x20, [sp, #64]                  ; 8-byte Folded Reload
	mov	x1, x20
	blr	x25
	and	w8, w0, #0xff
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x19
	csel	x1, x20, x21, eq
	add	x8, x1, x22
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x28
	mov	x0, x24
	mov	x1, x20
	mov	x2, x21
	add	x19, x19, x22
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x1, x20, x21, eq
	add	x8, x1, x22
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x28
	mov	x0, x24
	mov	x1, x20
	mov	x2, x21
	add	x19, x19, x22
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x20, x21, eq
LBB30_20:                               ; %sort.tiny_sort__anon_16475.exit
	mov	x0, x19
	blr	x28
	b	LBB30_9
LBB30_21:
	mov	x0, x28
	mov	w1, #2
	blr	x9
	mov	x0, x28
	mov	x1, x23
	mov	x2, x26
	blr	x25
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x23, x26, eq
	csel	x19, x27, xzr, eq
	blr	x22
	add	x1, x23, x19
	mov	x0, x23
	blr	x22
	add	x1, sp, #96
	mov	x0, x26
	blr	x22
	add	x19, x23, x27, lsl #2
	mov	x0, x28
	add	x20, x19, x27
	mov	x1, x19
	mov	x2, x20
	blr	x25
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x19, x20, eq
	csel	x21, x27, xzr, eq
	blr	x22
	add	x1, x19, x21
	mov	x0, x19
	blr	x22
	add	x1, sp, #96
	mov	x0, x20
	blr	x22
	b	LBB30_9
	.loh AdrpAdd	Lloh47, Lloh48
Lfunc_end30:
	.cfi_endproc
	.section	__TEXT,__const
	.p2align	1, 0x0
LJTI30_0:
	.short	(LBB30_9-LBB30_2)>>2
	.short	(LBB30_9-LBB30_2)>>2
	.short	(LBB30_2-LBB30_2)>>2
	.short	(LBB30_10-LBB30_2)>>2
	.short	(LBB30_11-LBB30_2)>>2
	.short	(LBB30_14-LBB30_2)>>2
	.short	(LBB30_18-LBB30_2)>>2
	.short	(LBB30_16-LBB30_2)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function sort.quad_swap__anon_14834
l_sort.quad_swap__anon_14834:           ; @sort.quad_swap__anon_14834
Lfunc_begin31:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 4192
	sub	sp, sp, #96
	.cfi_def_cfa_offset 4288
	.cfi_remember_state
	mov	x20, x6
	mov	x28, x0
	mov	x27, x4
	mov	x21, x3
	mov	x26, x2
	mov	x22, x1
	cmp	x1, #8
	stp	x5, x4, [sp, #424]              ; 16-byte Folded Spill
	str	x0, [sp, #376]                  ; 8-byte Folded Spill
	str	x6, [sp, #392]                  ; 8-byte Folded Spill
	stp	x2, x3, [sp, #408]              ; 16-byte Folded Spill
	str	x1, [sp, #48]                   ; 8-byte Folded Spill
	b.lo	LBB31_85
; %bb.1:                                ; %.lr.ph
	lsl	x8, x27, #1
	lsl	x9, x27, #2
	lsr	x19, x22, #3
	str	x8, [sp, #368]                  ; 8-byte Folded Spill
	add	x8, x8, x27
	stp	x8, x9, [sp, #320]              ; 16-byte Folded Spill
	add	x9, x9, x27
	lsl	x8, x8, #1
	str	x9, [sp, #312]                  ; 8-byte Folded Spill
	lsl	x9, x27, #3
	stp	x9, x8, [sp, #296]              ; 16-byte Folded Spill
	sub	x8, x9, x27
	str	x8, [sp, #288]                  ; 8-byte Folded Spill
	neg	x8, x27
	str	x8, [sp, #224]                  ; 8-byte Folded Spill
	neg	x8, x9
	str	x8, [sp, #184]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #376]                  ; 8-byte Folded Reload
	mov	x28, x8
	str	x8, [sp, #440]                  ; 8-byte Folded Spill
LBB31_2:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB31_13 Depth 2
                                        ;       Child Loop BB31_14 Depth 3
                                        ;         Child Loop BB31_25 Depth 4
	sub	x19, x19, #1
	mov	x0, x21
	mov	w1, #4
	str	x19, [sp, #384]                 ; 8-byte Folded Spill
	blr	x20
	add	x19, x28, x27
	mov	x0, x21
	mov	x1, x28
	mov	x2, x19
	blr	x26
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	mov	x20, x26
	add	x25, x28, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x25
	cset	w22, eq
	add	x26, x28, x8
	mov	x2, x26
	blr	x20
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	add	x27, x28, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x27
	cset	w23, eq
	add	x2, x28, x8
	str	x2, [sp, #400]                  ; 8-byte Folded Spill
	blr	x20
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	add	x1, x28, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	mov	x0, x21
	cset	w24, eq
	str	x1, [sp, #280]                  ; 8-byte Folded Spill
	add	x2, x28, x8
	blr	x20
	and	w9, w0, #0xff
	lsl	w8, w24, #2
	cmp	w9, #1
	orr	w8, w8, w23, lsl #1
	cset	w9, eq
	str	w24, [sp, #336]                 ; 4-byte Folded Spill
	str	w23, [sp, #360]                 ; 4-byte Folded Spill
	orr	w8, w8, w9, lsl #3
	str	w22, [sp, #344]                 ; 4-byte Folded Spill
	orr	w8, w8, w22
	str	w9, [sp, #352]                  ; 4-byte Folded Spill
	cbz	w8, LBB31_8
; %bb.3:                                ;   in Loop: Header=BB31_2 Depth=1
	cmp	w8, #15
	b.ne	LBB31_10
; %bb.4:                                ;   in Loop: Header=BB31_2 Depth=1
	mov	x0, x21
	mov	w1, #1
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x25
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	blr	x8
	ldr	w23, [sp, #336]                 ; 4-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_7
; %bb.5:                                ;   in Loop: Header=BB31_2 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	mov	x1, x26
	mov	x2, x27
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_7
; %bb.6:                                ;   in Loop: Header=BB31_2 Depth=1
	mov	x0, x21
	mov	w1, #1
	mov	w24, #1
	blr	x20
	ldp	x1, x8, [sp, #400]              ; 16-byte Folded Reload
	mov	x0, x21
	ldr	x2, [sp, #280]                  ; 8-byte Folded Reload
	blr	x8
	mov	x22, x28
	and	w8, w0, #0xff
	cmp	w8, #1
                                        ; kill: def $w24 killed $w24 killed $x24 def $x24
	b.eq	LBB31_12
LBB31_7:                                ; %.critedge4
                                        ;   in Loop: Header=BB31_2 Depth=1
	mov	w24, #2
	ldr	x22, [sp, #440]                 ; 8-byte Folded Reload
	b	LBB31_12
LBB31_8:                                ;   in Loop: Header=BB31_2 Depth=1
	mov	x0, x21
	mov	w1, #1
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x25
	ldr	x19, [sp, #408]                 ; 8-byte Folded Reload
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_48
; %bb.9:                                ;   in Loop: Header=BB31_2 Depth=1
	mov	x26, x19
	b	LBB31_49
LBB31_10:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x22, [sp, #440]                 ; 8-byte Folded Reload
	mov	w24, #2
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
LBB31_11:                               ; %.outer.preheader
                                        ;   in Loop: Header=BB31_2 Depth=1
	ldr	w23, [sp, #336]                 ; 4-byte Folded Reload
LBB31_12:                               ; %.outer.preheader
                                        ;   in Loop: Header=BB31_2 Depth=1
	ldr	x26, [sp, #408]                 ; 8-byte Folded Reload
	ldr	x27, [sp, #432]                 ; 8-byte Folded Reload
LBB31_13:                               ; %.outer
                                        ;   Parent Loop BB31_2 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB31_14 Depth 3
                                        ;         Child Loop BB31_25 Depth 4
	str	x22, [sp, #440]                 ; 8-byte Folded Spill
	mov	x22, x28
LBB31_14:                               ; %.backedge
                                        ;   Parent Loop BB31_2 Depth=1
                                        ;     Parent Loop BB31_13 Depth=2
                                        ; =>    This Loop Header: Depth=3
                                        ;         Child Loop BB31_25 Depth 4
	cbz	w24, LBB31_27
; %bb.15:                               ; %.backedge
                                        ;   in Loop: Header=BB31_14 Depth=3
	cmp	w24, #1
	b.ne	LBB31_50
; %bb.16:                               ;   in Loop: Header=BB31_14 Depth=3
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	ldr	x8, [sp, #384]                  ; 8-byte Folded Reload
	str	x22, [sp, #272]                 ; 8-byte Folded Spill
	cbz	x8, LBB31_60
; %bb.17:                               ;   in Loop: Header=BB31_14 Depth=3
	sub	x8, x8, #1
	mov	x0, x21
	mov	w1, #4
	str	x8, [sp, #384]                  ; 8-byte Folded Spill
	blr	x20
	add	x2, x22, x27
	mov	x0, x21
	mov	x1, x22
	str	x2, [sp, #280]                  ; 8-byte Folded Spill
	blr	x26
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	str	w0, [sp, #216]                  ; 4-byte Folded Spill
	and	w19, w0, #0xff
	mov	x0, x21
	add	x25, x22, x8
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x1, x25
	add	x28, x22, x8
	mov	x2, x28
	blr	x26
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	str	w0, [sp, #208]                  ; 4-byte Folded Spill
	add	x1, x22, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	mov	x0, x21
	cset	w23, ne
	str	x1, [sp, #264]                  ; 8-byte Folded Spill
	add	x2, x22, x8
	str	x2, [sp, #240]                  ; 8-byte Folded Spill
	blr	x26
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	mov	w24, w0
	mov	x0, x21
	add	x1, x22, x8
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	add	x2, x22, x8
	str	x1, [sp, #232]                  ; 8-byte Folded Spill
	blr	x26
	cmp	w19, #1
	and	w8, w24, #0xff
	cset	w9, ne
	str	w23, [sp, #360]                 ; 4-byte Folded Spill
	str	w24, [sp, #200]                 ; 4-byte Folded Spill
	str	w0, [sp, #192]                  ; 4-byte Folded Spill
	str	w9, [sp, #344]                  ; 4-byte Folded Spill
	csinc	w9, w23, wzr, eq
	cmp	w8, #1
	and	w8, w0, #0xff
	cset	w23, ne
	csinc	w9, w9, wzr, eq
	cmp	w8, #1
	cset	w8, ne
	str	w8, [sp, #352]                  ; 4-byte Folded Spill
	csinc	w8, w9, wzr, eq
	cmp	w8, #1
	b.eq	LBB31_22
; %bb.18:                               ;   in Loop: Header=BB31_14 Depth=3
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x22, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x22
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_22
; %bb.19:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	ldr	x1, [sp, #280]                  ; 8-byte Folded Reload
	mov	x2, x25
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_22
; %bb.20:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	mov	x1, x28
	ldr	x2, [sp, #264]                  ; 8-byte Folded Reload
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_22
; %bb.21:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	mov	w24, #1
	blr	x20
	ldp	x2, x1, [sp, #232]              ; 16-byte Folded Reload
	mov	x0, x21
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_14
LBB31_22:                               ; %.critedge25
                                        ;   in Loop: Header=BB31_14 Depth=3
	mov	x8, x22
	ldr	x22, [sp, #224]                 ; 8-byte Folded Reload
	ldr	x9, [sp, #440]                  ; 8-byte Folded Reload
	stp	x28, x25, [sp, #248]            ; 16-byte Folded Spill
	ldr	x10, [sp, #368]                 ; 8-byte Folded Reload
	str	w23, [sp, #336]                 ; 4-byte Folded Spill
	add	x11, x8, x22
	sub	x8, x11, x9
	udiv	x20, x8, x10
	str	x11, [sp, #400]                 ; 8-byte Folded Spill
	mul	x8, x20, x27
	add	x28, x9, x8
	sub	x19, x11, x8
	tbnz	w20, #0, LBB31_24
; %bb.23:                               ;   in Loop: Header=BB31_14 Depth=3
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x28
	ldr	x21, [sp, #424]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x28
	mov	x1, x19
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x19
	add	x28, x28, x22
	blr	x21
	add	x19, x19, x27
	sub	x20, x20, #1
LBB31_24:                               ; %._crit_edge.i
                                        ;   in Loop: Header=BB31_14 Depth=3
	mov	x21, xzr
	mov	x22, xzr
	lsr	x20, x20, #1
LBB31_25:                               ;   Parent Loop BB31_2 Depth=1
                                        ;     Parent Loop BB31_13 Depth=2
                                        ;       Parent Loop BB31_14 Depth=3
                                        ; =>      This Inner Loop Header: Depth=4
	ldr	x8, [sp, #400]                  ; 8-byte Folded Reload
	add	x0, sp, #4000
	ldr	x23, [sp, #424]                 ; 8-byte Folded Reload
	add	x27, x19, x21
	add	x25, x28, x22
	add	x24, x8, x22
	ldr	x8, [sp, #440]                  ; 8-byte Folded Reload
	add	x26, x8, x21
	mov	x1, x26
	blr	x23
	mov	x0, x26
	mov	x1, x24
	blr	x23
	add	x1, sp, #4000
	mov	x0, x24
	blr	x23
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x25
	blr	x23
	mov	x0, x25
	mov	x1, x27
	blr	x23
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x27
	blr	x23
	cbz	x20, LBB31_33
; %bb.26:                               ;   in Loop: Header=BB31_25 Depth=4
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	sub	x20, x20, #1
	sub	x22, x22, x8
	add	x21, x21, x8
	b	LBB31_25
LBB31_27:                               ;   in Loop: Header=BB31_14 Depth=3
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x22, x22, x8
	ldr	x8, [sp, #384]                  ; 8-byte Folded Reload
	cbz	x8, LBB31_62
; %bb.28:                               ;   in Loop: Header=BB31_14 Depth=3
	sub	x8, x8, #1
	mov	x0, x21
	mov	w1, #4
	str	x8, [sp, #384]                  ; 8-byte Folded Spill
	blr	x20
	add	x19, x22, x27
	mov	x0, x21
	mov	x1, x22
	mov	x2, x19
	blr	x26
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	mov	x28, x22
	add	x25, x22, x8
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x22, x20
	and	w20, w0, #0xff
	mov	x0, x21
	mov	x1, x25
	add	x2, x28, x8
	str	x2, [sp, #400]                  ; 8-byte Folded Spill
	blr	x26
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	add	x1, x28, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	mov	x0, x21
	cset	w23, eq
	str	x1, [sp, #336]                  ; 8-byte Folded Spill
	add	x2, x28, x8
	str	x2, [sp, #280]                  ; 8-byte Folded Spill
	blr	x26
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	mov	w24, w0
	mov	x0, x21
	mov	x27, x28
	add	x1, x28, x8
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	add	x2, x28, x8
	str	x1, [sp, #272]                  ; 8-byte Folded Spill
	blr	x26
	cmp	w20, #1
	and	w8, w24, #0xff
	cset	w10, eq
	csinc	w9, w23, wzr, ne
	cmp	w8, #1
	and	w8, w0, #0xff
	mov	w24, w23
	cset	w23, eq
	csinc	w9, w9, wzr, ne
	cmp	w8, #1
	cset	w28, eq
	csinc	w8, w9, wzr, ne
	cmp	w8, #1
	str	w24, [sp, #360]                 ; 4-byte Folded Spill
	str	w10, [sp, #344]                 ; 4-byte Folded Spill
	str	w28, [sp, #352]                 ; 4-byte Folded Spill
	b.ne	LBB31_37
; %bb.29:                               ;   in Loop: Header=BB31_14 Depth=3
	add	w8, w24, w10
	add	w9, w23, w28
	mov	w24, #2
	mov	x20, x22
	mov	x22, x27
	ldr	x27, [sp, #432]                 ; 8-byte Folded Reload
	add	w8, w8, w9
	cmp	w8, #4
	b.ne	LBB31_14
; %bb.30:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x25
	blr	x26
	mov	w24, #2
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_14
; %bb.31:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	ldr	x1, [sp, #400]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #336]                  ; 8-byte Folded Reload
	blr	x26
	mov	w24, #2
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_14
; %bb.32:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	mov	w19, #1
	blr	x20
	ldp	x2, x1, [sp, #272]              ; 16-byte Folded Reload
	mov	x0, x21
	blr	x26
	mov	w24, #2
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_14
	b	LBB31_44
LBB31_33:                               ; %sort.quad_reversal.exit
                                        ;   in Loop: Header=BB31_14 Depth=3
	ldr	w8, [sp, #360]                  ; 4-byte Folded Reload
	ldr	w9, [sp, #344]                  ; 4-byte Folded Reload
	ldr	w23, [sp, #336]                 ; 4-byte Folded Reload
	ldr	x27, [sp, #432]                 ; 8-byte Folded Reload
	add	w8, w8, w9
	ldr	w9, [sp, #352]                  ; 4-byte Folded Reload
	add	w9, w23, w9
	add	w8, w8, w9
	cmp	w8, #4
	b.ne	LBB31_40
; %bb.34:                               ;   in Loop: Header=BB31_14 Depth=3
	ldr	x21, [sp, #416]                 ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	mov	x0, x21
	blr	x20
	ldr	x25, [sp, #256]                 ; 8-byte Folded Reload
	mov	x0, x21
	ldr	x1, [sp, #280]                  ; 8-byte Folded Reload
	ldr	x26, [sp, #408]                 ; 8-byte Folded Reload
	mov	x2, x25
	blr	x26
	ldr	x22, [sp, #272]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	ldr	x19, [sp, #248]                 ; 8-byte Folded Reload
	cmp	w8, #1
	b.eq	LBB31_45
; %bb.35:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	mov	x1, x19
	ldr	x2, [sp, #264]                  ; 8-byte Folded Reload
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_45
; %bb.36:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldp	x2, x1, [sp, #232]              ; 16-byte Folded Reload
	mov	x0, x21
	blr	x26
	mov	w24, wzr
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_14
	b	LBB31_45
LBB31_37:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x22
	mov	x0, x21
	mov	x1, x19
	mov	x2, x25
	blr	x26
	mov	x20, x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_53
; %bb.38:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	ldr	x1, [sp, #400]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #336]                  ; 8-byte Folded Reload
	blr	x26
	mov	x22, x27
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_54
; %bb.39:                               ;   in Loop: Header=BB31_14 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldp	x2, x1, [sp, #272]              ; 16-byte Folded Reload
	mov	x0, x21
	blr	x26
	mov	w24, wzr
	ldr	x27, [sp, #432]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_14
	b	LBB31_56
LBB31_40:                               ; %sort.quad_reversal.exit
                                        ;   in Loop: Header=BB31_13 Depth=2
	ldp	x26, x21, [sp, #408]            ; 16-byte Folded Reload
	ldp	x19, x25, [sp, #248]            ; 16-byte Folded Reload
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #272]                 ; 8-byte Folded Reload
	cbnz	w8, LBB31_45
; %bb.41:                               ;   in Loop: Header=BB31_13 Depth=2
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	ldr	x1, [sp, #280]                  ; 8-byte Folded Reload
	mov	x2, x25
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_45
; %bb.42:                               ;   in Loop: Header=BB31_13 Depth=2
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	mov	x1, x19
	ldr	x2, [sp, #264]                  ; 8-byte Folded Reload
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_45
; %bb.43:                               ;   in Loop: Header=BB31_13 Depth=2
	mov	x0, x21
	mov	w1, #1
	mov	w24, #1
	blr	x20
	ldp	x2, x1, [sp, #232]              ; 16-byte Folded Reload
	mov	x0, x21
	blr	x26
	mov	x28, x22
	and	w8, w0, #0xff
	cmp	w8, #1
                                        ; kill: def $w24 killed $w24 killed $x24 def $x24
	b.eq	LBB31_13
	b	LBB31_45
LBB31_44:                               ;   in Loop: Header=BB31_13 Depth=2
	mov	w24, w19
	mov	x28, x22
	b	LBB31_13
LBB31_45:                               ; %.critedge37
                                        ;   in Loop: Header=BB31_2 Depth=1
	ldr	w8, [sp, #192]                  ; 4-byte Folded Reload
	mov	x24, x22
	ldr	w9, [sp, #200]                  ; 4-byte Folded Reload
	add	x0, sp, #3520
	ldr	x23, [sp, #424]                 ; 8-byte Folded Reload
	and	w21, w8, #0xff
	ldr	w8, [sp, #216]                  ; 4-byte Folded Reload
	and	w19, w9, #0xff
	and	w8, w8, #0xff
	cmp	w8, #1
	ldr	w8, [sp, #208]                  ; 4-byte Folded Reload
	csel	x22, xzr, x27, ne
	and	w20, w8, #0xff
	csel	x8, x27, xzr, ne
	add	x1, x24, x8
	blr	x23
	add	x1, x24, x22
	mov	x0, x24
	ldr	x22, [sp, #392]                 ; 8-byte Folded Reload
	blr	x23
	add	x1, sp, #3520
	ldr	x0, [sp, #280]                  ; 8-byte Folded Reload
	blr	x23
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	cmp	w20, #1
	ldr	x9, [sp, #432]                  ; 8-byte Folded Reload
	add	x0, sp, #3520
	csel	x8, x8, xzr, ne
	add	x1, x25, x8
	csel	x20, xzr, x9, ne
	blr	x23
	add	x1, x25, x20
	mov	x0, x25
	blr	x23
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	add	x1, sp, #3520
	add	x0, x25, x8
	blr	x23
	ldr	x24, [sp, #368]                 ; 8-byte Folded Reload
	cmp	w19, #1
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	add	x0, sp, #3520
	ldr	x9, [sp, #432]                  ; 8-byte Folded Reload
	add	x19, x25, x24
	csel	x8, x8, xzr, ne
	add	x1, x19, x8
	csel	x20, xzr, x9, ne
	blr	x23
	add	x1, x19, x20
	mov	x0, x19
	blr	x23
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	add	x1, sp, #3520
	add	x0, x19, x8
	blr	x23
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	cmp	w21, #1
	add	x19, x19, x24
	ldr	x9, [sp, #432]                  ; 8-byte Folded Reload
	add	x0, sp, #3520
	ldr	x21, [sp, #416]                 ; 8-byte Folded Reload
	csel	x8, x8, xzr, ne
	add	x1, x19, x8
	csel	x20, xzr, x9, ne
	blr	x23
	add	x1, x19, x20
	mov	x0, x19
	ldr	x27, [sp, #432]                 ; 8-byte Folded Reload
	mov	x20, x22
	mov	x22, x23
	blr	x23
	add	x0, x19, x27
	add	x1, sp, #3520
	blr	x23
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x8, x24, x8
	add	x28, x19, x8
	add	x19, x28, x27
	add	x24, x28, x24
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_57
; %bb.46:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x28, x8
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	add	x24, x28, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_57
; %bb.47:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x28, x8
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	add	x24, x28, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x26
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	ldr	x19, [sp, #384]                 ; 8-byte Folded Reload
	cmp	w8, #1
	b.eq	LBB31_58
	b	LBB31_59
LBB31_48:                               ;   in Loop: Header=BB31_2 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	mov	x1, x26
	mov	x2, x27
	blr	x19
	mov	x26, x19
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_51
LBB31_49:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x19, [sp, #384]                 ; 8-byte Folded Reload
	ldr	x27, [sp, #432]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	b	LBB31_58
LBB31_50:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	w8, [sp, #344]                  ; 4-byte Folded Reload
	add	x0, sp, #3520
	ldr	x21, [sp, #424]                 ; 8-byte Folded Reload
	tst	w8, #0xf
	csel	x8, x27, xzr, eq
	csel	x19, xzr, x27, eq
	add	x1, x22, x8
	blr	x21
	add	x1, x22, x19
	mov	x0, x22
	blr	x21
	add	x0, x22, x27
	add	x1, sp, #3520
	blr	x21
	ldr	w8, [sp, #360]                  ; 4-byte Folded Reload
	add	x0, sp, #3520
	ldr	x24, [sp, #368]                 ; 8-byte Folded Reload
	tst	w8, #0xf
	add	x19, x22, x24
	csel	x8, x27, xzr, eq
	add	x1, x19, x8
	mov	x22, x20
	csel	x20, xzr, x27, eq
	blr	x21
	add	x1, x19, x20
	mov	x0, x19
	blr	x21
	add	x0, x19, x27
	add	x1, sp, #3520
	blr	x21
	tst	w23, #0xf
	add	x19, x19, x24
	csel	x8, x27, xzr, eq
	add	x0, sp, #3520
	add	x1, x19, x8
	csel	x20, xzr, x27, eq
	blr	x21
	add	x1, x19, x20
	mov	x0, x19
	blr	x21
	add	x0, x19, x27
	add	x1, sp, #3520
	blr	x21
	ldr	w8, [sp, #352]                  ; 4-byte Folded Reload
	add	x19, x19, x24
	add	x0, sp, #3520
	tst	w8, #0xf
	csel	x8, x27, xzr, eq
	csel	x20, xzr, x27, eq
	add	x1, x19, x8
	blr	x21
	add	x1, x19, x20
	mov	x20, x22
	mov	x22, x21
	mov	x0, x19
	ldr	x21, [sp, #416]                 ; 8-byte Folded Reload
	blr	x22
	add	x0, x19, x27
	add	x1, sp, #3520
	blr	x22
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	add	x8, x24, x8
	add	x28, x19, x8
	b	LBB31_57
LBB31_51:                               ;   in Loop: Header=BB31_2 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x20
	mov	x0, x21
	ldr	x1, [sp, #400]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #280]                  ; 8-byte Folded Reload
	blr	x26
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_55
; %bb.52:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x22, [sp, #440]                 ; 8-byte Folded Reload
	mov	w24, wzr
	b	LBB31_11
LBB31_53:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	mov	x28, x27
	b	LBB31_55
LBB31_54:                               ;   in Loop: Header=BB31_2 Depth=1
	mov	x28, x22
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
LBB31_55:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x19, [sp, #384]                 ; 8-byte Folded Reload
	ldr	x27, [sp, #432]                 ; 8-byte Folded Reload
	b	LBB31_58
LBB31_56:                               ;   in Loop: Header=BB31_2 Depth=1
	mov	x28, x22
LBB31_57:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	ldr	x19, [sp, #384]                 ; 8-byte Folded Reload
LBB31_58:                               ; %.sink.split
                                        ;   in Loop: Header=BB31_2 Depth=1
	mov	x0, x21
	mov	w1, #16
	blr	x20
	add	x1, sp, #448
	mov	x0, x28
	mov	x2, x26
	mov	x3, x21
	mov	x4, x27
	ldr	x5, [sp, #424]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap_merge__anon_16478
LBB31_59:                               ;   in Loop: Header=BB31_2 Depth=1
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x28, x28, x8
	cbnz	x19, LBB31_2
	b	LBB31_85
LBB31_60:
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	and	x23, x8, #0x7
	cmp	x23, #7
	b.ne	LBB31_63
; %bb.61:
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x22, x8
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	add	x24, x22, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_64
	b	LBB31_78
LBB31_62:
	mov	x28, x22
	b	LBB31_84
LBB31_63:                               ; %.critedge55
	cmp	x23, #6
	b.lo	LBB31_65
LBB31_64:                               ; %.critedge55.thread
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x22, x8
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	add	x24, x22, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_78
	b	LBB31_66
LBB31_65:                               ; %.critedge57
	cmp	x23, #5
	b.ne	LBB31_67
LBB31_66:                               ; %.critedge57.thread
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x22, x8
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	add	x24, x22, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_78
	b	LBB31_68
LBB31_67:                               ; %.critedge59
	cmp	x23, #4
	b.lo	LBB31_69
LBB31_68:                               ; %.critedge59.thread
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x22, x8
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x24, x22, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_78
	b	LBB31_70
LBB31_69:                               ; %.critedge61
	cmp	x23, #3
	b.ne	LBB31_111
LBB31_70:                               ; %.critedge61.thread
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x22, x8
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	add	x24, x22, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_78
LBB31_71:                               ; %.critedge63.thread
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x22, x8
	blr	x20
	mov	x0, x21
	mov	x1, x22
	mov	x2, x19
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_78
LBB31_72:                               ; %.critedge65.thread
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x22, x8
	blr	x20
	mov	x0, x21
	mov	x1, x19
	mov	x2, x22
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_78
LBB31_73:                               ; %.critedge67
	mov	x8, x22
	ldr	x10, [sp, #368]                 ; 8-byte Folded Reload
	ldp	x22, x9, [sp, #432]             ; 16-byte Folded Reload
	madd	x8, x23, x22, x8
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
	add	x11, x8, x23
	sub	x8, x11, x9
	udiv	x20, x8, x10
	str	x11, [sp, #400]                 ; 8-byte Folded Spill
	mul	x8, x20, x22
	add	x19, x9, x8
	sub	x25, x11, x8
	tbnz	w20, #0, LBB31_75
; %bb.74:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x19
	ldr	x21, [sp, #424]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x19
	mov	x1, x25
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x19, x19, x23
	blr	x21
	add	x25, x25, x22
	sub	x20, x20, #1
LBB31_75:                               ; %._crit_edge.i344
	mov	x21, xzr
	mov	x23, xzr
	lsr	x22, x20, #1
	ldr	x20, [sp, #424]                 ; 8-byte Folded Reload
LBB31_76:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #400]                  ; 8-byte Folded Reload
	add	x0, sp, #4000
	add	x26, x25, x21
	add	x27, x19, x23
	add	x24, x8, x23
	ldr	x8, [sp, #440]                  ; 8-byte Folded Reload
	add	x28, x8, x21
	mov	x1, x28
	blr	x20
	mov	x0, x28
	mov	x1, x24
	blr	x20
	add	x1, sp, #4000
	mov	x0, x24
	blr	x20
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	blr	x20
	mov	x0, x27
	mov	x1, x26
	blr	x20
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x26
	blr	x20
	cbz	x22, LBB31_109
; %bb.77:                               ;   in Loop: Header=BB31_76 Depth=1
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	sub	x22, x22, #1
	sub	x23, x23, x8
	add	x21, x21, x8
	b	LBB31_76
LBB31_78:
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
	ldr	x10, [sp, #368]                 ; 8-byte Folded Reload
	add	x11, x22, x23
	ldp	x22, x9, [sp, #432]             ; 16-byte Folded Reload
	str	x11, [sp, #400]                 ; 8-byte Folded Spill
	sub	x8, x11, x9
	udiv	x20, x8, x10
	mul	x8, x20, x22
	add	x19, x9, x8
	sub	x25, x11, x8
	tbnz	w20, #0, LBB31_80
; %bb.79:
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x19
	ldr	x21, [sp, #424]                 ; 8-byte Folded Reload
	blr	x21
	mov	x0, x19
	mov	x1, x25
	blr	x21
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x25
	add	x19, x19, x23
	blr	x21
	add	x25, x25, x22
	sub	x20, x20, #1
LBB31_80:                               ; %._crit_edge.i332
	mov	x21, xzr
	mov	x23, xzr
	lsr	x22, x20, #1
	ldr	x20, [sp, #424]                 ; 8-byte Folded Reload
LBB31_81:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #400]                  ; 8-byte Folded Reload
	add	x0, sp, #4000
	add	x26, x25, x21
	add	x27, x19, x23
	add	x24, x8, x23
	ldr	x8, [sp, #440]                  ; 8-byte Folded Reload
	add	x28, x8, x21
	mov	x1, x28
	blr	x20
	mov	x0, x28
	mov	x1, x24
	blr	x20
	add	x1, sp, #4000
	mov	x0, x24
	blr	x20
	add	x0, sp, #1, lsl #12             ; =4096
	mov	x1, x27
	blr	x20
	mov	x0, x27
	mov	x1, x26
	blr	x20
	add	x1, sp, #1, lsl #12             ; =4096
	mov	x0, x26
	blr	x20
	cbz	x22, LBB31_83
; %bb.82:                               ;   in Loop: Header=BB31_81 Depth=1
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	sub	x22, x22, #1
	sub	x23, x23, x8
	add	x21, x21, x8
	b	LBB31_81
LBB31_83:                               ; %sort.quad_reversal.exit342
	ldp	x26, x21, [sp, #408]            ; 16-byte Folded Reload
	ldr	x28, [sp, #272]                 ; 8-byte Folded Reload
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	ldr	x27, [sp, #432]                 ; 8-byte Folded Reload
LBB31_84:                               ; %.loopexit
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
LBB31_85:                               ; %.loopexit
	and	x1, x22, #0x7
	add	x2, sp, #448
	mov	x0, x28
	mov	x3, x26
	mov	x4, x21
	mov	x5, x27
	ldr	x6, [sp, #424]                  ; 8-byte Folded Reload
	mov	x7, x20
	mov	x19, x27
	bl	l_sort.tail_swap__anon_14832
	ldr	x28, [sp, #376]                 ; 8-byte Folded Reload
LBB31_86:
	cmp	x22, #32
	b.hs	LBB31_93
LBB31_87:                               ; %._crit_edge
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	and	x24, x8, #0x1f
	cmp	x24, #8
	b.ls	LBB31_107
; %bb.88:                               ; %.preheader.lr.ph.i
	ldr	x8, [sp, #432]                  ; 8-byte Folded Reload
	mul	x19, x24, x8
	lsl	x8, x8, #3
	add	x9, x8, x28
	add	x23, x28, x19
	cmp	x9, x23
	b.hs	LBB31_92
; %bb.89:                               ; %.lr.ph.i
	ldr	x9, [sp, #432]                  ; 8-byte Folded Reload
	mov	x20, xzr
	add	x25, x28, x8
	lsl	x21, x9, #4
	add	x22, x28, x21
LBB31_90:                               ; =>This Inner Loop Header: Depth=1
	add	x0, x28, x20
	add	x8, x22, x20
	cmp	x8, x23
	b.hs	LBB31_101
; %bb.91:                               ;   in Loop: Header=BB31_90 Depth=1
	ldp	x6, x8, [sp, #416]              ; 16-byte Folded Reload
	add	x2, sp, #448
	mov	w1, #16
	mov	w3, #32
	mov	w4, #8
	mov	x5, x26
	ldr	x7, [sp, #432]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #392]                  ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
	add	x20, x20, x21
	add	x8, x25, x20
	cmp	x8, x23
	b.lo	LBB31_90
LBB31_92:                               ; %.loopexit.i
	cmp	x24, #17
	b.lo	LBB31_107
	b	LBB31_102
LBB31_93:                               ; %.lr.ph493
	lsl	x27, x19, #3
	lsl	x11, x19, #4
	sub	x8, x27, x19
	add	x9, x19, x19, lsl #1
	sub	x12, x11, x19
	mov	x10, x19
	mov	x15, x20
	lsr	x20, x22, #5
	stp	x8, x11, [sp, #336]             ; 16-byte Folded Spill
	mov	w8, #23
	str	x12, [sp, #56]                  ; 8-byte Folded Spill
	neg	x23, x19
	mul	x8, x19, x8
	str	x27, [sp, #368]                 ; 8-byte Folded Spill
	str	x23, [sp, #400]                 ; 8-byte Folded Spill
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	lsl	x8, x9, #3
	add	x9, sp, #448
	add	x13, x9, x11
	add	x10, x9, x12
	sub	x14, x13, x19
	add	x9, x9, x19
	add	x11, x14, x11
	add	x12, x13, x12
	str	x8, [sp, #32]                   ; 8-byte Folded Spill
	mov	x8, x19
	add	x8, x28, x19
	str	x13, [sp, #360]                 ; 8-byte Folded Spill
	stp	x11, x14, [sp, #296]            ; 16-byte Folded Spill
	lsl	x11, x19, #5
	str	x12, [sp, #312]                 ; 8-byte Folded Spill
	str	x8, [sp, #384]                  ; 8-byte Folded Spill
	stp	x10, x11, [sp, #320]            ; 16-byte Folded Spill
	sub	x11, x11, x19
	sub	x10, x10, x19
	stp	x9, x11, [sp, #280]             ; 16-byte Folded Spill
	add	x9, x9, x19
	stp	x9, x10, [sp, #264]             ; 16-byte Folded Spill
	sub	x10, x10, x19
	add	x9, x9, x19
	stp	x9, x10, [sp, #248]             ; 16-byte Folded Spill
	sub	x10, x10, x19
	add	x9, x9, x19
	stp	x9, x10, [sp, #232]             ; 16-byte Folded Spill
	sub	x10, x10, x19
	add	x9, x9, x19
	stp	x9, x10, [sp, #216]             ; 16-byte Folded Spill
	sub	x10, x10, x19
	add	x9, x9, x19
	stp	x9, x10, [sp, #200]             ; 16-byte Folded Spill
	sub	x10, x10, x19
	add	x9, x9, x19
	stp	x9, x10, [sp, #184]             ; 16-byte Folded Spill
	sub	x9, x10, x19
	sub	x10, x12, x19
	str	x9, [sp, #176]                  ; 8-byte Folded Spill
	add	x9, x13, x19
	stp	x10, x9, [sp, #160]             ; 16-byte Folded Spill
	add	x9, x9, x19
	sub	x10, x10, x19
	stp	x10, x9, [sp, #144]             ; 16-byte Folded Spill
	add	x9, x9, x19
	sub	x10, x10, x19
	stp	x10, x9, [sp, #128]             ; 16-byte Folded Spill
	add	x9, x9, x19
	sub	x10, x10, x19
	stp	x10, x9, [sp, #112]             ; 16-byte Folded Spill
	add	x9, x9, x19
	sub	x10, x10, x19
	stp	x10, x9, [sp, #96]              ; 16-byte Folded Spill
	add	x9, x9, x19
	sub	x10, x10, x19
	stp	x10, x9, [sp, #80]              ; 16-byte Folded Spill
	add	x9, x9, x19
	str	x9, [sp, #72]                   ; 8-byte Folded Spill
	sub	x9, x10, x19
	str	x9, [sp, #64]                   ; 8-byte Folded Spill
	b	LBB31_95
LBB31_94:                               ;   in Loop: Header=BB31_95 Depth=1
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	mov	x15, x22
	ldr	x9, [sp, #384]                  ; 8-byte Folded Reload
	subs	x20, x20, #1
	add	x28, x28, x8
	add	x9, x9, x8
	str	x9, [sp, #384]                  ; 8-byte Folded Spill
	b.eq	LBB31_87
LBB31_95:                               ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB31_99 Depth 2
	ldr	x8, [sp, #336]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x19, x28, x27
	mov	x22, x15
	add	x24, x28, x8
	blr	x15
	mov	x0, x21
	mov	x1, x24
	mov	x2, x19
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_98
; %bb.96:                               ;   in Loop: Header=BB31_95 Depth=1
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x24, x28, x8
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	add	x25, x28, x8
	blr	x22
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB31_98
; %bb.97:                               ;   in Loop: Header=BB31_95 Depth=1
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #1
	add	x24, x28, x8
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	add	x25, x28, x8
	blr	x22
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB31_94
LBB31_98:                               ; %.critedge69
                                        ;   in Loop: Header=BB31_95 Depth=1
	mov	x0, x21
	mov	w1, #16
	add	x24, x19, x23
	str	x20, [sp, #352]                 ; 8-byte Folded Spill
	add	x25, x24, x27
	blr	x22
	mov	x0, x21
	mov	x1, x28
	mov	x2, x19
	blr	x26
	ldp	x27, x22, [sp, #424]            ; 16-byte Folded Reload
	and	w8, w0, #0xff
	add	x0, sp, #448
	cmp	w8, #1
	mov	x20, x23
	csel	x1, x19, x28, eq
	mov	x23, x26
	add	x8, x1, x22
	csel	x26, x28, x8, eq
	csel	x19, x8, x19, eq
	blr	x27
	mov	x0, x21
	mov	x1, x26
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #280]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x19, x26, eq
	add	x8, x1, x22
	csel	x19, x8, x19, eq
	csel	x26, x26, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #320]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x20
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x27
	mov	x0, x21
	mov	x1, x26
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #264]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x19, x26, eq
	add	x8, x1, x22
	csel	x19, x8, x19, eq
	csel	x26, x26, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #272]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x20
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x27
	mov	x0, x21
	mov	x1, x26
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #248]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x19, x26, eq
	add	x8, x1, x22
	csel	x19, x8, x19, eq
	csel	x26, x26, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #256]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x20
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x27
	mov	x0, x21
	mov	x1, x26
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #232]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x19, x26, eq
	add	x8, x1, x22
	csel	x19, x8, x19, eq
	csel	x26, x26, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x20
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x27
	mov	x0, x21
	mov	x1, x26
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #216]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x19, x26, eq
	add	x8, x1, x22
	csel	x19, x8, x19, eq
	csel	x26, x26, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #224]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x20
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x27
	mov	x0, x21
	mov	x1, x26
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #200]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x19, x26, eq
	add	x8, x1, x22
	csel	x19, x8, x19, eq
	csel	x26, x26, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x20
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x27
	mov	x0, x21
	mov	x1, x26
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #184]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x19, x26, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #192]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x20
	csel	x19, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #176]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	blr	x27
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #16
	add	x19, x28, x8
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	add	x24, x19, x8
	add	x25, x24, x20
	add	x26, x25, x8
	ldr	x8, [sp, #392]                  ; 8-byte Folded Reload
	blr	x8
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #360]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	add	x8, x1, x22
	csel	x19, x19, x8, eq
	csel	x24, x8, x24, eq
	blr	x27
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #168]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	add	x8, x1, x22
	csel	x24, x8, x24, eq
	csel	x19, x19, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x25
	mov	x2, x26
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #312]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x20
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x27
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #152]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	add	x8, x1, x22
	csel	x24, x8, x24, eq
	csel	x19, x19, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x25
	mov	x2, x26
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #160]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x20
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x27
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #136]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	add	x8, x1, x22
	csel	x24, x8, x24, eq
	csel	x19, x19, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x25
	mov	x2, x26
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #144]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x20
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x27
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #120]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	add	x8, x1, x22
	csel	x24, x8, x24, eq
	csel	x19, x19, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x25
	mov	x2, x26
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #128]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x20
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x27
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #104]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	add	x8, x1, x22
	csel	x24, x8, x24, eq
	csel	x19, x19, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x25
	mov	x2, x26
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #112]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x20
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x27
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #88]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	add	x8, x1, x22
	csel	x24, x8, x24, eq
	csel	x19, x19, x8, eq
	blr	x27
	mov	x0, x21
	mov	x1, x25
	mov	x2, x26
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #96]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x20
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x27
	mov	x0, x21
	mov	x1, x19
	mov	x2, x24
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #72]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	blr	x27
	mov	x0, x21
	mov	x1, x25
	mov	x2, x26
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #80]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x20
	csel	x19, x26, x8, eq
	csel	x24, x8, x25, eq
	blr	x27
	mov	x0, x21
	mov	x1, x24
	mov	x2, x19
	blr	x23
	and	w8, w0, #0xff
	ldr	x0, [sp, #64]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x19, eq
	blr	x27
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	w1, #32
	add	x19, x28, x8
	ldr	x8, [sp, #392]                  ; 8-byte Folded Reload
	blr	x8
	ldr	x20, [sp, #360]                 ; 8-byte Folded Reload
	add	x1, sp, #448
	mov	x0, x21
	mov	x2, x20
	blr	x23
	and	w8, w0, #0xff
	add	x9, sp, #448
	cmp	w8, #1
	mov	x0, x28
	csel	x1, x20, x9, eq
	str	x28, [sp, #376]                 ; 8-byte Folded Spill
	add	x8, x1, x22
	csel	x26, x9, x8, eq
	csel	x28, x8, x20, eq
	blr	x27
	ldp	x27, x25, [sp, #296]            ; 16-byte Folded Reload
	mov	x21, #-15
	ldr	x24, [sp, #384]                 ; 8-byte Folded Reload
LBB31_99:                               ; %.cont.i404
                                        ;   Parent Loop BB31_95 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	str	x19, [sp, #440]                 ; 8-byte Folded Spill
	mov	x1, x26
	ldp	x23, x19, [sp, #408]            ; 16-byte Folded Reload
	mov	x2, x28
	mov	x0, x19
	blr	x23
	ldp	x22, x20, [sp, #424]            ; 16-byte Folded Reload
	and	w8, w0, #0xff
	mov	x0, x24
	cmp	w8, #1
	csel	x1, x28, x26, eq
	add	x8, x1, x20
	csel	x28, x8, x28, eq
	csel	x26, x26, x8, eq
	blr	x22
	mov	x0, x19
	mov	x1, x25
	mov	x2, x27
	ldr	x19, [sp, #440]                 ; 8-byte Folded Reload
	blr	x23
	and	w8, w0, #0xff
	ldr	x23, [sp, #400]                 ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x19
	csel	x1, x25, x27, eq
	add	x8, x1, x23
	csel	x27, x27, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x19, x19, x23
	add	x24, x24, x20
	adds	x21, x21, #1
	b.lo	LBB31_99
; %bb.100:                              ; %sort.parity_merge__anon_16476.exit406
                                        ;   in Loop: Header=BB31_95 Depth=1
	ldp	x26, x21, [sp, #408]            ; 16-byte Folded Reload
	mov	x1, x25
	mov	x2, x27
	mov	x0, x21
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	ldr	x8, [sp, #424]                  ; 8-byte Folded Reload
	csel	x1, x25, x27, eq
	blr	x8
	ldp	x27, x28, [sp, #368]            ; 16-byte Folded Reload
	ldp	x22, x23, [sp, #392]            ; 16-byte Folded Reload
	ldr	x20, [sp, #352]                 ; 8-byte Folded Reload
	b	LBB31_94
LBB31_101:
	ldr	x7, [sp, #432]                  ; 8-byte Folded Reload
	sub	x8, x19, x20
	add	x2, sp, #448
	mov	w3, #32
	mov	w4, #8
	mov	x5, x26
	udiv	x1, x8, x7
	ldr	x9, [sp, #392]                  ; 8-byte Folded Reload
	ldp	x6, x8, [sp, #416]              ; 16-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
	cmp	x24, #17
	b.lo	LBB31_107
LBB31_102:                              ; %.preheader.i.1
	ldr	x10, [sp, #432]                 ; 8-byte Folded Reload
	lsl	x8, x10, #4
	add	x9, x8, x28
	cmp	x9, x23
	b.hs	LBB31_107
; %bb.103:                              ; %.lr.ph.i.1
	lsl	x21, x10, #5
	mov	x20, xzr
	add	x22, x28, x21
	add	x24, x28, x8
LBB31_104:                              ; =>This Inner Loop Header: Depth=1
	add	x0, x28, x20
	add	x8, x22, x20
	cmp	x8, x23
	b.hs	LBB31_106
; %bb.105:                              ;   in Loop: Header=BB31_104 Depth=1
	ldp	x6, x8, [sp, #416]              ; 16-byte Folded Reload
	add	x2, sp, #448
	mov	w1, #32
	mov	w3, #32
	mov	w4, #16
	mov	x5, x26
	ldr	x7, [sp, #432]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #392]                  ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
	add	x20, x20, x21
	add	x8, x24, x20
	cmp	x8, x23
	b.lo	LBB31_104
	b	LBB31_107
LBB31_106:
	ldr	x7, [sp, #432]                  ; 8-byte Folded Reload
	sub	x8, x19, x20
	add	x2, sp, #448
	mov	w3, #32
	mov	w4, #16
	mov	x5, x26
	udiv	x1, x8, x7
	ldr	x9, [sp, #392]                  ; 8-byte Folded Reload
	ldp	x6, x8, [sp, #416]              ; 16-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
LBB31_107:                              ; %common.ret
	mov	w0, #1
LBB31_108:                              ; %common.ret
	add	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 192
	add	sp, sp, #96
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB31_109:                              ; %sort.quad_reversal.exit354
	.cfi_restore_state
	ldp	x19, x8, [sp, #432]             ; 16-byte Folded Reload
	ldp	x26, x21, [sp, #408]            ; 16-byte Folded Reload
	ldr	x28, [sp, #376]                 ; 8-byte Folded Reload
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	cmp	x8, x28
	b.ne	LBB31_86
; %bb.110:
	mov	w0, wzr
	b	LBB31_108
LBB31_111:                              ; %.critedge63
	cmp	x23, #2
	b.hs	LBB31_71
; %bb.112:                              ; %.critedge65
	cbnz	x23, LBB31_72
	b	LBB31_73
Lfunc_end31:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quad_merge__anon_14835
l_sort.quad_merge__anon_14835:          ; @sort.quad_merge__anon_14835
Lfunc_begin32:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #352
	.cfi_def_cfa_offset 352
	stp	x28, x27, [sp, #256]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #272]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #288]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #304]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #320]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #336]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	mul	x8, x6, x1
	mov	x25, x6
	ldr	x24, [sp, #352]
	mov	w28, #128
	cmp	x1, #128
	stp	x7, x4, [sp, #208]              ; 16-byte Folded Spill
	stp	x2, x3, [sp, #240]              ; 16-byte Folded Spill
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
	add	x8, x0, x8
	str	x0, [sp, #176]                  ; 8-byte Folded Spill
	str	x5, [sp, #224]                  ; 8-byte Folded Spill
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	str	x24, [sp, #200]                 ; 8-byte Folded Spill
	str	x1, [sp, #64]                   ; 8-byte Folded Spill
	b.lo	LBB32_25
; %bb.1:
	cmp	x3, #128
	b.lo	LBB32_25
; %bb.2:                                ; %.preheader.lr.ph
	mov	x8, x25
	lsl	x9, x25, #1
	mov	x22, x7
	mov	x23, x5
	add	x8, x9, x25
	mov	w28, #128
	str	x25, [sp, #232]                 ; 8-byte Folded Spill
	stp	x8, x9, [sp, #32]               ; 16-byte Folded Spill
LBB32_3:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB32_8 Depth 2
                                        ;     Child Loop BB32_16 Depth 2
                                        ;       Child Loop BB32_18 Depth 3
	lsr	x9, x28, #1
	ldr	x20, [sp, #176]                 ; 8-byte Folded Reload
	lsr	x27, x28, #2
	mul	x10, x28, x25
	sub	x8, x27, #1
	mul	x11, x9, x25
	str	x9, [sp, #104]                  ; 8-byte Folded Spill
	madd	x9, x27, x25, x20
	madd	x8, x25, x8, x20
	mov	x26, xzr
	ldr	x21, [sp, #48]                  ; 8-byte Folded Reload
	str	x28, [sp, #56]                  ; 8-byte Folded Spill
	mov	x28, x25
	str	x10, [sp, #168]                 ; 8-byte Folded Spill
	str	x9, [sp, #160]                  ; 8-byte Folded Spill
	lsl	x9, x27, #1
	str	x8, [sp, #152]                  ; 8-byte Folded Spill
	sub	x8, x9, #1
	ldr	x9, [sp, #40]                   ; 8-byte Folded Reload
	str	x20, [sp, #192]                 ; 8-byte Folded Spill
	madd	x9, x9, x27, x20
	str	x9, [sp, #144]                  ; 8-byte Folded Spill
	madd	x9, x25, x8, x20
	add	x8, x8, x27
	stp	x9, x11, [sp, #80]              ; 16-byte Folded Spill
	lsl	x9, x11, #1
	str	x9, [sp, #72]                   ; 8-byte Folded Spill
	ldr	x9, [sp, #32]                   ; 8-byte Folded Reload
	madd	x9, x9, x27, x20
	str	x9, [sp, #136]                  ; 8-byte Folded Spill
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	add	x9, x9, x11
	str	x9, [sp, #96]                   ; 8-byte Folded Spill
	madd	x9, x25, x8, x20
	add	x8, x20, x10
	stp	x8, x9, [sp, #120]              ; 16-byte Folded Spill
	b	LBB32_8
LBB32_4:                                ;   in Loop: Header=BB32_8 Depth=2
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x1, x19
	ldr	x2, [sp, #88]                   ; 8-byte Folded Reload
	bl	_memcpy
	ldr	x0, [sp, #96]                   ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x25
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
LBB32_5:                                ;   in Loop: Header=BB32_8 Depth=2
	mov	x5, x23
	mov	x6, x28
	mov	x7, x22
	str	x24, [sp]
	bl	l_sort.cross_merge__anon_14856
LBB32_6:                                ;   in Loop: Header=BB32_8 Depth=2
	ldr	x2, [sp, #104]                  ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x1, [sp, #240]                  ; 8-byte Folded Reload
	mov	x4, x25
	mov	x5, x23
	mov	x6, x28
	mov	x3, x2
	mov	x7, x22
	str	x24, [sp]
	bl	l_sort.cross_merge__anon_14856
LBB32_7:                                ; %sort.quad_merge_block__anon_16482.exit
                                        ;   in Loop: Header=BB32_8 Depth=2
	ldr	x10, [sp, #168]                 ; 8-byte Folded Reload
	ldr	x9, [sp, #192]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	add	x20, x20, x10
	add	x26, x26, x10
	add	x9, x9, x10
	sub	x21, x21, x10
	add	x8, x8, x26
	str	x9, [sp, #192]                  ; 8-byte Folded Spill
	ldr	x9, [sp, #112]                  ; 8-byte Folded Reload
	cmp	x8, x9
	b.hi	LBB32_13
LBB32_8:                                ;   Parent Loop BB32_3 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	mov	x0, x23
	mov	w1, #2
	add	x19, x8, x26
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	add	x28, x8, x26
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	add	x8, x8, x26
	str	x8, [sp, #184]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	add	x25, x8, x26
	blr	x24
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	mov	x0, x23
	mov	x2, x28
	ldr	x28, [sp, #216]                 ; 8-byte Folded Reload
	add	x1, x8, x26
	blr	x28
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	mov	x2, x25
	mov	x25, x28
	add	x1, x8, x26
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	cset	w23, ne
	blr	x28
	and	w8, w0, #0xff
Lloh49:
	adrp	x11, LJTI32_0@PAGE
Lloh50:
	add	x11, x11, LJTI32_0@PAGEOFF
	cmp	w8, #1
	cset	w8, ne
	orr	w8, w23, w8, lsl #1
	adr	x9, LBB32_4
	ldrb	w10, [x11, x8]
	add	x9, x9, x10, lsl #2
	ldr	x28, [sp, #232]                 ; 8-byte Folded Reload
	br	x9
LBB32_9:                                ;   in Loop: Header=BB32_8 Depth=2
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
	mov	x1, x19
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x27
	mov	x3, x27
	mov	x4, x25
	mov	x5, x23
	mov	x6, x28
	mov	x7, x22
	str	x24, [sp]
	bl	l_sort.cross_merge__anon_14856
	ldr	x0, [sp, #96]                   ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x25
	b	LBB32_5
LBB32_10:                               ;   in Loop: Header=BB32_8 Depth=2
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
	mov	x1, x19
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x2, x27
	mov	x3, x27
	mov	x4, x25
	mov	x5, x23
	mov	x6, x28
	mov	x7, x22
	str	x24, [sp]
	bl	l_sort.cross_merge__anon_14856
	ldp	x2, x0, [sp, #88]               ; 16-byte Folded Reload
	ldr	x1, [sp, #184]                  ; 8-byte Folded Reload
	bl	_memcpy
	b	LBB32_6
LBB32_11:                               ;   in Loop: Header=BB32_8 Depth=2
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
	mov	w1, #1
	mov	x0, x23
	blr	x24
	ldr	x8, [sp, #80]                   ; 8-byte Folded Reload
	mov	x0, x23
	ldr	x2, [sp, #184]                  ; 8-byte Folded Reload
	add	x1, x8, x26
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB32_7
; %bb.12:                               ;   in Loop: Header=BB32_8 Depth=2
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	mov	x1, x19
	ldr	x2, [sp, #72]                   ; 8-byte Folded Reload
	bl	_memcpy
	b	LBB32_6
LBB32_13:                               ;   in Loop: Header=BB32_3 Depth=1
	udiv	x19, x21, x28
	ldr	x3, [sp, #248]                  ; 8-byte Folded Reload
	cmp	x27, x19
	b.hs	LBB32_23
; %bb.14:                               ;   in Loop: Header=BB32_3 Depth=1
	cmp	x27, x3
	b.hi	LBB32_23
; %bb.15:                               ; %.preheader.lr.ph.i16
                                        ;   in Loop: Header=BB32_3 Depth=1
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	madd	x25, x19, x28, x20
	add	x9, x8, x26
	add	x8, x8, x26
	str	x9, [sp, #168]                  ; 8-byte Folded Spill
	str	x8, [sp, #184]                  ; 8-byte Folded Spill
LBB32_16:                               ; %.preheader.i18
                                        ;   Parent Loop BB32_3 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB32_18 Depth 3
	ldr	x9, [sp, #184]                  ; 8-byte Folded Reload
	mul	x8, x27, x28
	lsl	x21, x27, #1
	add	x9, x9, x8
	cmp	x9, x25
	b.hs	LBB32_21
; %bb.17:                               ; %.lr.ph.i19
                                        ;   in Loop: Header=BB32_16 Depth=2
	ldr	x9, [sp, #232]                  ; 8-byte Folded Reload
	mov	x28, xzr
	ldr	x23, [sp, #168]                 ; 8-byte Folded Reload
	mul	x26, x21, x9
	ldr	x9, [sp, #192]                  ; 8-byte Folded Reload
	add	x22, x9, x26
	add	x24, x9, x8
LBB32_18:                               ;   Parent Loop BB32_3 Depth=1
                                        ;     Parent Loop BB32_16 Depth=2
                                        ; =>    This Inner Loop Header: Depth=3
	add	x0, x20, x28
	add	x8, x22, x28
	cmp	x8, x25
	b.hs	LBB32_20
; %bb.19:                               ;   in Loop: Header=BB32_18 Depth=3
	ldp	x2, x3, [sp, #240]              ; 16-byte Folded Reload
	mov	x1, x21
	mov	x4, x27
	ldp	x5, x6, [sp, #216]              ; 16-byte Folded Reload
	ldr	x7, [sp, #232]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
	ldr	x3, [sp, #248]                  ; 8-byte Folded Reload
	add	x28, x28, x26
	add	x23, x23, x26
	add	x8, x24, x28
	cmp	x8, x25
	b.lo	LBB32_18
	b	LBB32_21
LBB32_20:                               ;   in Loop: Header=BB32_16 Depth=2
	ldp	x7, x2, [sp, #232]              ; 16-byte Folded Reload
	sub	x8, x25, x23
	mov	x4, x27
	ldp	x5, x6, [sp, #216]              ; 16-byte Folded Reload
	udiv	x1, x8, x7
	ldr	x3, [sp, #248]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
	ldr	x3, [sp, #248]                  ; 8-byte Folded Reload
LBB32_21:                               ; %.loopexit.i20
                                        ;   in Loop: Header=BB32_16 Depth=2
	ldr	x28, [sp, #232]                 ; 8-byte Folded Reload
	cmp	x21, x19
	b.hs	LBB32_23
; %bb.22:                               ; %.loopexit.i20
                                        ;   in Loop: Header=BB32_16 Depth=2
	mov	x27, x21
	cmp	x21, x3
	b.ls	LBB32_16
LBB32_23:                               ; %sort.tail_merge__anon_16481.exit22
                                        ;   in Loop: Header=BB32_3 Depth=1
	mov	x25, x28
	ldp	x28, x1, [sp, #56]              ; 16-byte Folded Reload
	lsl	x28, x28, #2
	cmp	x28, x1
	b.hi	LBB32_25
; %bb.24:                               ; %sort.tail_merge__anon_16481.exit22
                                        ;   in Loop: Header=BB32_3 Depth=1
	ldp	x24, x22, [sp, #200]            ; 16-byte Folded Reload
	cmp	x28, x3
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
	b.ls	LBB32_3
LBB32_25:                               ; %._crit_edge
	lsr	x21, x28, #2
	ldr	x26, [sp, #240]                 ; 8-byte Folded Reload
	ldr	x27, [sp, #112]                 ; 8-byte Folded Reload
	cmp	x21, x1
	b.hs	LBB32_34
; %bb.26:                               ; %._crit_edge
	cmp	x21, x3
	b.hi	LBB32_34
LBB32_27:                               ; %.preheader.i
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB32_29 Depth 2
	ldr	x9, [sp, #176]                  ; 8-byte Folded Reload
	mul	x8, x21, x25
	lsl	x22, x21, #1
	add	x9, x8, x9
	cmp	x9, x27
	b.hs	LBB32_32
; %bb.28:                               ; %.lr.ph.i
                                        ;   in Loop: Header=BB32_27 Depth=1
	ldr	x9, [sp, #176]                  ; 8-byte Folded Reload
	mul	x20, x22, x25
	mov	x19, xzr
	add	x23, x9, x8
	add	x24, x9, x20
LBB32_29:                               ;   Parent Loop BB32_27 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x8, x19
	add	x8, x24, x19
	cmp	x8, x27
	b.hs	LBB32_31
; %bb.30:                               ;   in Loop: Header=BB32_29 Depth=2
	ldp	x5, x6, [sp, #216]              ; 16-byte Folded Reload
	mov	x1, x22
	mov	x2, x26
	ldr	x3, [sp, #248]                  ; 8-byte Folded Reload
	mov	x4, x21
	mov	x7, x25
	ldr	x9, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
	ldr	x3, [sp, #248]                  ; 8-byte Folded Reload
	add	x19, x19, x20
	add	x8, x23, x19
	cmp	x8, x27
	b.lo	LBB32_29
	b	LBB32_32
LBB32_31:                               ;   in Loop: Header=BB32_27 Depth=1
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	mov	x7, x25
	ldp	x5, x6, [sp, #216]              ; 16-byte Folded Reload
	mov	x2, x26
	mov	x4, x21
	sub	x8, x8, x19
	ldr	x3, [sp, #248]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #200]                  ; 8-byte Folded Reload
	udiv	x1, x8, x25
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
	ldr	x3, [sp, #248]                  ; 8-byte Folded Reload
LBB32_32:                               ; %.loopexit.i
                                        ;   in Loop: Header=BB32_27 Depth=1
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	cmp	x22, x1
	b.hs	LBB32_34
; %bb.33:                               ; %.loopexit.i
                                        ;   in Loop: Header=BB32_27 Depth=1
	mov	x21, x22
	cmp	x22, x3
	b.ls	LBB32_27
LBB32_34:                               ; %sort.tail_merge__anon_16481.exit
	lsr	x0, x28, #1
	ldp	x29, x30, [sp, #336]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #320]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            ; 16-byte Folded Reload
	add	sp, sp, #352
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
	.loh AdrpAdd	Lloh49, Lloh50
Lfunc_end32:
	.cfi_endproc
	.section	__TEXT,__const
LJTI32_0:
	.byte	(LBB32_9-LBB32_4)>>2
	.byte	(LBB32_4-LBB32_4)>>2
	.byte	(LBB32_10-LBB32_4)>>2
	.byte	(LBB32_11-LBB32_4)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function sort.rotate_merge__anon_14836
l_sort.rotate_merge__anon_14836:        ; @sort.rotate_merge__anon_14836
Lfunc_begin33:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #176
	.cfi_def_cfa_offset 176
	stp	x28, x27, [sp, #80]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #160]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x26, x4
	mov	x22, x3
	mov	x23, x2
	mov	x25, x0
	ldr	x9, [sp, #184]
	ldr	x8, [sp, #176]
	cmp	x1, x4, lsl #1
	stp	x5, x6, [sp, #64]               ; 16-byte Folded Spill
	stp	x8, x9, [sp, #48]               ; 16-byte Folded Spill
	b.hi	LBB33_3
; %bb.1:
	sub	x8, x1, x26
	cmp	x8, x22
	b.hi	LBB33_3
; %bb.2:
	mov	x0, x25
	mov	x2, x23
	mov	x3, x22
	mov	x4, x26
	ldp	x5, x6, [sp, #64]               ; 16-byte Folded Reload
	mov	x7, x19
	ldp	x29, x30, [sp, #160]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #144]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             ; 16-byte Folded Reload
	ldr	x9, [sp, #56]                   ; 8-byte Folded Reload
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	stp	x8, x9, [sp, #176]
	add	sp, sp, #176
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_backwards_merge__anon_16483
LBB33_3:                                ; %.preheader21
	.cfi_restore_state
	cmp	x1, x26
	b.ls	LBB33_11
; %bb.4:
	mul	x8, x19, x1
	add	x24, x25, x8
	stp	x8, x1, [sp, #24]               ; 16-byte Folded Spill
	b	LBB33_7
LBB33_5:                                ;   in Loop: Header=BB33_7 Depth=1
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x1, x23
	ldp	x5, x6, [sp, #64]               ; 16-byte Folded Reload
	mov	x2, x22
	mov	x3, x26
	sub	x8, x8, x20
	mov	x7, x19
	ldr	x9, [sp, #56]                   ; 8-byte Folded Reload
	udiv	x8, x8, x19
	sub	x4, x8, x26
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.rotate_merge_block__anon_16484
LBB33_6:                                ; %.loopexit
                                        ;   in Loop: Header=BB33_7 Depth=1
	ldp	x1, x8, [sp, #32]               ; 16-byte Folded Reload
	mov	x26, x8
	cmp	x8, x1
	b.hs	LBB33_11
LBB33_7:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB33_9 Depth 2
	mul	x8, x26, x19
	lsl	x10, x26, #1
	add	x9, x8, x25
	cmp	x9, x24
	str	x10, [sp, #40]                  ; 8-byte Folded Spill
	b.hs	LBB33_6
; %bb.8:                                ; %.lr.ph
                                        ;   in Loop: Header=BB33_7 Depth=1
	ldr	x9, [sp, #40]                   ; 8-byte Folded Reload
	mov	x20, xzr
	add	x27, x25, x8
	mul	x21, x9, x19
	add	x28, x25, x21
LBB33_9:                                ;   Parent Loop BB33_7 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x0, x25, x20
	add	x8, x28, x20
	cmp	x8, x24
	b.hs	LBB33_5
; %bb.10:                               ;   in Loop: Header=BB33_9 Depth=2
	ldp	x5, x6, [sp, #64]               ; 16-byte Folded Reload
	mov	x1, x23
	mov	x2, x22
	mov	x3, x26
	mov	x4, x26
	mov	x7, x19
	ldr	x9, [sp, #56]                   ; 8-byte Folded Reload
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	stp	x8, x9, [sp]
	bl	l_sort.rotate_merge_block__anon_16484
	add	x20, x20, x21
	add	x8, x27, x20
	cmp	x8, x24
	b.lo	LBB33_9
	b	LBB33_6
LBB33_11:                               ; %common.ret1
	ldp	x29, x30, [sp, #160]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #144]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #176
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end33:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quadsort_stack_swap__anon_14837
l_sort.quadsort_stack_swap__anon_14837: ; @sort.quadsort_stack_swap__anon_14837
Lfunc_begin34:
	.cfi_startproc
; %bb.0:
	stp	x26, x25, [sp, #-80]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 80
	stp	x24, x23, [sp, #16]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	sub	sp, sp, #12, lsl #12            ; =49152
	.cfi_def_cfa_offset 49232
	sub	sp, sp, #16
	.cfi_def_cfa_offset 49248
	mov	x19, x6
	mov	x20, x5
	mov	x22, x3
	mov	x23, x2
	mov	x21, x4
	add	x2, sp, #16
	mov	w3, #512
	mov	x4, x23
	mov	x5, x22
	mov	x6, x20
	mov	x7, x19
	mov	x24, x1
	mov	x25, x0
	str	x21, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	add	x2, sp, #16
	mov	x0, x25
	mov	x1, x24
	mov	w3, #512
	mov	x5, x23
	mov	x6, x22
	mov	x7, x20
	stp	x19, x21, [sp]
	bl	l_sort.rotate_merge__anon_14836
	add	sp, sp, #12, lsl #12            ; =49152
	.cfi_def_cfa_offset 96
	add	sp, sp, #16
	.cfi_def_cfa_offset 80
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	ret
Lfunc_end34:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.tail_swap__anon_14838
l_sort.tail_swap__anon_14838:           ; @sort.tail_swap__anon_14838
Lfunc_begin35:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #288
	.cfi_def_cfa_offset 288
	stp	x28, x27, [sp, #192]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #208]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #224]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #272]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x23, x6
	mov	x26, x5
	mov	x21, x0
	cmp	x1, #8
	str	x2, [sp, #88]                   ; 8-byte Folded Spill
	b.hs	LBB35_3
; %bb.1:
Lloh51:
	adrp	x8, LJTI35_0@PAGE
Lloh52:
	add	x8, x8, LJTI35_0@PAGEOFF
	str	x26, [sp, #80]                  ; 8-byte Folded Spill
	adr	x9, LBB35_2
	ldrh	w10, [x8, x1, lsl #1]
	add	x9, x9, x10, lsl #2
	br	x9
LBB35_2:
	ldr	x19, [sp, #80]                  ; 8-byte Folded Reload
	mov	x0, x4
	mov	x1, x21
	add	x20, x21, x19
	mov	x2, x20
	blr	x3
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x21, x20, eq
	csel	x19, x19, xzr, eq
	blr	x23
	add	x1, x21, x19
	mov	x0, x21
	b	LBB35_15
LBB35_3:
	lsr	x9, x1, #1
	lsr	x20, x1, #2
	sub	x8, x1, x9
	mov	x0, x21
	lsr	x25, x8, #1
	mov	x1, x20
	mov	x5, x26
	mov	x6, x23
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	sub	x8, x8, x25
	str	x9, [sp, #56]                   ; 8-byte Folded Spill
	sub	x24, x9, x20
	mov	x22, x3
	mov	x27, x2
	str	x8, [sp, #80]                   ; 8-byte Folded Spill
	mov	x28, x4
	bl	l_sort.tail_swap__anon_14838
	madd	x19, x20, x26, x21
	mov	x1, x24
	mov	x2, x27
	mov	x3, x22
	mov	x0, x19
	mov	x4, x28
	mov	x5, x26
	mov	x6, x23
	bl	l_sort.tail_swap__anon_14838
	str	x24, [sp, #24]                  ; 8-byte Folded Spill
	madd	x24, x24, x26, x19
	mov	x1, x25
	mov	x2, x27
	mov	x0, x24
	mov	x3, x22
	mov	x4, x28
	mov	x5, x26
	mov	x6, x23
	bl	l_sort.tail_swap__anon_14838
	madd	x24, x25, x26, x24
	ldr	x1, [sp, #80]                   ; 8-byte Folded Reload
	mov	x2, x27
	mov	x3, x22
	mov	x0, x24
	mov	x4, x28
	mov	x5, x26
	mov	x6, x23
	str	x25, [sp, #32]                  ; 8-byte Folded Spill
	str	x23, [sp, #48]                  ; 8-byte Folded Spill
	bl	l_sort.tail_swap__anon_14838
	sub	x8, x20, #1
	mov	x0, x28
	mov	x2, x19
	madd	x1, x8, x26, x21
	blr	x22
	and	w8, w0, #0xff
	stp	x28, x21, [sp, #64]             ; 16-byte Folded Spill
	cmp	w8, #1
	b.ne	LBB35_5
; %bb.4:                                ; %..critedge_crit_edge
	ldr	x25, [sp, #56]                  ; 8-byte Folded Reload
	mov	x21, x22
	mul	x19, x25, x26
	b	LBB35_8
LBB35_5:
	ldr	x25, [sp, #56]                  ; 8-byte Folded Reload
	mov	x0, x28
	sub	x8, x25, #1
	mul	x19, x25, x26
	madd	x1, x8, x26, x21
	add	x2, x21, x19
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB35_7
; %bb.6:
	mov	x21, x22
	b	LBB35_8
LBB35_7:
	sub	x1, x24, x26
	mov	x0, x28
	mov	x2, x24
	mov	x21, x22
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB35_22
LBB35_8:                                ; %.critedge
	ldp	x22, x24, [sp, #64]             ; 16-byte Folded Reload
	mov	x2, x20
	mov	x4, x21
	ldr	x28, [sp, #88]                  ; 8-byte Folded Reload
	mov	x6, x26
	ldr	x20, [sp, #48]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #24]                   ; 8-byte Folded Reload
	mov	x5, x22
	mov	x0, x28
	mov	x1, x24
	mov	x7, x20
	bl	l_sort.parity_merge__anon_16486
	add	x0, x28, x19
	add	x1, x24, x19
	ldr	x2, [sp, #32]                   ; 8-byte Folded Reload
	mov	x4, x21
	ldr	x3, [sp, #80]                   ; 8-byte Folded Reload
	mov	x5, x22
	mov	x6, x26
	mov	x7, x20
	bl	l_sort.parity_merge__anon_16486
	mov	x0, x24
	mov	x1, x28
	mov	x2, x25
	mov	x4, x21
	mov	x5, x22
	mov	x6, x26
	mov	x7, x20
	ldr	x3, [sp, #40]                   ; 8-byte Folded Reload
	ldp	x29, x30, [sp, #272]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #256]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #224]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #208]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #192]            ; 16-byte Folded Reload
	add	sp, sp, #288
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.parity_merge__anon_16486
LBB35_9:
	.cfi_restore_state
	ldr	x25, [sp, #80]                  ; 8-byte Folded Reload
	mov	x0, x4
	mov	x1, x21
	mov	x24, x4
	mov	x22, x3
	add	x20, x21, x25
	mov	x2, x20
	blr	x3
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x21, x20, eq
	csel	x19, x25, xzr, eq
	blr	x23
	add	x1, x21, x19
	mov	x0, x21
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	blr	x23
	mov	x26, x21
	add	x21, x20, x25
	mov	x0, x24
	mov	x1, x20
	mov	x2, x21
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x19, x25, xzr, eq
	blr	x23
	add	x1, x20, x19
	mov	x0, x20
	blr	x23
	add	x1, sp, #96
	mov	x0, x21
	blr	x23
	mov	x0, x24
	mov	x1, x26
	mov	x2, x20
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x19, x25, xzr, eq
	b	LBB35_14
LBB35_10:
	ldr	x26, [sp, #80]                  ; 8-byte Folded Reload
	mov	x0, x4
	mov	x1, x21
	mov	x24, x4
	mov	x22, x3
	add	x20, x21, x26
	mov	x2, x20
	blr	x3
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x21, x20, eq
	csel	x19, x26, xzr, eq
	blr	x23
	add	x1, x21, x19
	mov	x0, x21
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	blr	x23
	lsl	x19, x26, #1
	mov	x0, x24
	add	x20, x21, x19
	add	x21, x20, x26
	mov	x1, x20
	mov	x2, x21
	blr	x22
	and	w8, w0, #0xff
	mov	x25, x23
	cmp	w8, #1
	add	x0, sp, #96
	csel	x1, x20, x21, eq
	csel	x23, x26, xzr, eq
	blr	x25
	add	x1, x20, x23
	mov	x0, x20
	blr	x25
	add	x1, sp, #96
	mov	x0, x21
	blr	x25
	sub	x21, x20, x26
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB35_22
; %bb.11:
	ldr	x27, [sp, #80]                  ; 8-byte Folded Reload
	add	x0, sp, #96
	mov	x1, x21
	mov	x26, x24
	neg	x23, x27
	blr	x25
	mov	x0, x21
	mov	x1, x20
	blr	x25
	add	x1, sp, #96
	mov	x0, x20
	blr	x25
	add	x20, x21, x23
	mov	x0, x24
	add	x21, x20, x27
	mov	x1, x20
	mov	x2, x21
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x24, x27, xzr, eq
	blr	x25
	add	x1, x20, x24
	mov	x0, x20
	blr	x25
	add	x1, sp, #96
	mov	x0, x21
	blr	x25
	add	x20, x20, x19
	mov	x0, x26
	add	x21, x20, x27
	mov	x1, x20
	mov	x2, x21
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x19, x27, xzr, eq
	blr	x25
	add	x1, x20, x19
	mov	x0, x20
	blr	x25
	add	x1, sp, #96
	mov	x0, x21
	blr	x25
	add	x20, x20, x23
	mov	x0, x26
	add	x21, x20, x27
	mov	x1, x20
	mov	x2, x21
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x19, x27, xzr, eq
	blr	x25
	add	x1, x20, x19
	mov	x0, x20
	blr	x25
	add	x1, sp, #96
	mov	x0, x21
	blr	x25
	b	LBB35_22
LBB35_12:
	ldr	x27, [sp, #80]                  ; 8-byte Folded Reload
	mov	x0, x4
	mov	x1, x21
	mov	x25, x4
	mov	x22, x3
	add	x20, x21, x27
	mov	x2, x20
	blr	x3
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x21, x20, eq
	csel	x19, x27, xzr, eq
	blr	x23
	add	x1, x21, x19
	mov	x0, x21
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	str	x20, [sp, #88]                  ; 8-byte Folded Spill
	blr	x23
	lsl	x19, x27, #1
	mov	x0, x25
	add	x26, x21, x19
	add	x24, x26, x27
	mov	x1, x26
	mov	x2, x24
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x26, x24, eq
	csel	x20, x27, xzr, eq
	blr	x23
	add	x1, x26, x20
	mov	x0, x26
	blr	x23
	add	x1, sp, #96
	mov	x0, x24
	str	x24, [sp, #56]                  ; 8-byte Folded Spill
	blr	x23
	sub	x28, x26, x27
	mov	x0, x25
	mov	x1, x28
	mov	x2, x26
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	str	x21, [sp, #72]                  ; 8-byte Folded Spill
	cset	w8, eq
	csel	x1, x28, x26, eq
	csel	x21, x27, xzr, eq
	str	w8, [sp, #48]                   ; 4-byte Folded Spill
	blr	x23
	add	x1, x28, x21
	mov	x0, x28
	blr	x23
	add	x1, sp, #96
	mov	x0, x26
	blr	x23
	add	x24, x28, x19
	mov	x0, x25
	add	x20, x24, x27
	mov	x1, x24
	mov	x2, x20
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x24, x20, eq
	csel	x19, x27, xzr, eq
	csetm	w21, eq
	blr	x23
	add	x1, x24, x19
	mov	x0, x24
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	blr	x23
	ldr	w8, [sp, #48]                   ; 4-byte Folded Reload
	ldr	x27, [sp, #72]                  ; 8-byte Folded Reload
	cmp	w8, w21
	b.eq	LBB35_22
; %bb.13:
	mov	x0, x25
	ldr	x25, [sp, #88]                  ; 8-byte Folded Reload
	mov	x1, x27
	mov	x21, x0
	mov	x2, x25
	str	x0, [sp, #64]                   ; 8-byte Folded Spill
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	ldr	x8, [sp, #80]                   ; 8-byte Folded Reload
	csel	x1, x27, x25, eq
	csel	x19, x8, xzr, eq
	blr	x23
	add	x1, x27, x19
	mov	x0, x27
	blr	x23
	add	x1, sp, #96
	mov	x0, x25
	blr	x23
	ldr	x25, [sp, #56]                  ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x26
	str	x22, [sp, #16]                  ; 8-byte Folded Spill
	mov	x2, x25
	blr	x22
	and	w8, w0, #0xff
	ldr	x21, [sp, #80]                  ; 8-byte Folded Reload
	cmp	w8, #1
	add	x0, sp, #96
	csel	x1, x26, x25, eq
	csel	x19, x21, xzr, eq
	blr	x23
	add	x1, x26, x19
	mov	x0, x26
	blr	x23
	add	x1, sp, #96
	mov	x0, x25
	blr	x23
	ldr	x25, [sp, #64]                  ; 8-byte Folded Reload
	mov	x1, x28
	mov	x2, x26
	mov	x0, x25
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x28, x26, eq
	csel	x19, x21, xzr, eq
	blr	x23
	add	x1, x28, x19
	mov	x0, x28
	blr	x23
	add	x1, sp, #96
	mov	x0, x26
	blr	x23
	mov	x0, x25
	mov	x1, x24
	mov	x2, x20
	ldr	x28, [sp, #16]                  ; 8-byte Folded Reload
	blr	x28
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x24, x20, eq
	csel	x19, x21, xzr, eq
	blr	x23
	add	x1, x24, x19
	mov	x0, x24
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	blr	x23
	ldr	x24, [sp, #88]                  ; 8-byte Folded Reload
	mov	x0, x25
	mov	x1, x27
	mov	x2, x24
	blr	x28
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x27, x24, eq
	csel	x19, x21, xzr, eq
	blr	x23
	add	x1, x27, x19
	mov	x0, x27
	blr	x23
	add	x1, sp, #96
	mov	x0, x24
	blr	x23
	ldr	x20, [sp, #56]                  ; 8-byte Folded Reload
	mov	x0, x25
	mov	x1, x26
	mov	x2, x20
	blr	x28
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x19, x21, xzr, eq
LBB35_14:                               ; %sort.tiny_sort__anon_16485.exit
	csel	x1, x26, x20, eq
	add	x0, sp, #96
	blr	x23
	add	x1, x26, x19
	mov	x0, x26
LBB35_15:                               ; %sort.tiny_sort__anon_16485.exit
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	blr	x23
	b	LBB35_22
LBB35_16:
	ldr	x25, [sp, #80]                  ; 8-byte Folded Reload
	mov	x0, x4
	mov	x1, x21
	mov	x24, x4
	mov	x22, x3
	add	x20, x21, x25
	mov	x2, x20
	blr	x3
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x21, x20, eq
	csel	x19, x25, xzr, eq
	blr	x23
	add	x1, x21, x19
	mov	x0, x21
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	str	x20, [sp, #56]                  ; 8-byte Folded Spill
	blr	x23
	lsl	x19, x25, #1
	mov	x0, x24
	add	x26, x21, x19
	add	x20, x26, x25
	mov	x1, x26
	mov	x2, x20
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	str	x21, [sp, #72]                  ; 8-byte Folded Spill
	csel	x1, x26, x20, eq
	csel	x21, x25, xzr, eq
	blr	x23
	add	x1, x26, x21
	mov	x0, x26
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	blr	x23
	add	x20, x26, x19
	mov	x0, x24
	add	x21, x20, x25
	mov	x1, x20
	mov	x2, x21
	blr	x22
	and	w8, w0, #0xff
	mov	x28, x23
	cmp	w8, #1
	add	x0, sp, #96
	csel	x1, x20, x21, eq
	csel	x23, x25, xzr, eq
	blr	x28
	add	x1, x20, x23
	mov	x0, x20
	blr	x28
	add	x1, sp, #96
	mov	x0, x21
	blr	x28
	add	x8, x19, x25
	mov	x0, x24
	sub	x20, x20, x8
	add	x21, x20, x25
	mov	x1, x20
	mov	x2, x21
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	cset	w23, eq
	csel	x27, x25, xzr, eq
	blr	x28
	add	x1, x20, x27
	mov	x0, x20
	blr	x28
	add	x1, sp, #96
	mov	x0, x21
	blr	x28
	add	x20, x20, x19
	mov	x0, x24
	add	x21, x20, x25
	mov	x1, x20
	mov	x2, x21
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x27, x25, xzr, eq
	cinc	w23, w23, eq
	blr	x28
	add	x1, x20, x27
	mov	x0, x20
	blr	x28
	add	x1, sp, #96
	mov	x0, x21
	blr	x28
	add	x20, x20, x19
	mov	x0, x24
	add	x21, x20, x25
	mov	x1, x20
	mov	x2, x21
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x27, x25, xzr, eq
	csetm	w25, eq
	blr	x28
	add	x1, x20, x27
	mov	x0, x20
	blr	x28
	add	x1, sp, #96
	mov	x0, x21
	ldr	x21, [sp, #72]                  ; 8-byte Folded Reload
	blr	x28
	cmp	w23, w25
	b.eq	LBB35_22
; %bb.17:                               ; %.cont110.i.i
	ldr	x27, [sp, #80]                  ; 8-byte Folded Reload
	mov	x0, x24
	mov	x24, x21
	mov	x2, x20
	mov	x25, x0
	sub	x21, x20, x27
	mov	x1, x21
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x21, x20, eq
	csel	x23, x27, xzr, eq
	blr	x28
	add	x1, x21, x23
	mov	x0, x21
	blr	x28
	add	x1, sp, #96
	mov	x0, x20
	blr	x28
	mov	x0, x25
	mov	x1, x24
	ldr	x2, [sp, #56]                   ; 8-byte Folded Reload
	mov	x20, x25
	mov	x23, x24
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x27, xzr, eq
	csel	x21, xzr, x27, eq
	add	x1, x24, x8
	ldr	x24, [sp, #88]                  ; 8-byte Folded Reload
	mov	x0, x24
	blr	x28
	add	x0, x24, x27
	add	x1, x23, x21
	str	x0, [sp, #32]                   ; 8-byte Folded Spill
	blr	x28
	add	x0, x24, x19
	mov	x1, x26
	str	x0, [sp, #40]                   ; 8-byte Folded Spill
	blr	x28
	ldr	x21, [sp, #48]                  ; 8-byte Folded Reload
	mov	x0, x25
	add	x23, x23, x21
	add	x2, x23, x27
	mov	x1, x23
	blr	x22
	and	w8, w0, #0xff
	add	x21, x24, x21
	cmp	w8, #1
	mov	x0, x21
	csel	x8, x27, xzr, eq
	csel	x25, xzr, x27, eq
	add	x1, x23, x8
	blr	x28
	lsl	x26, x27, #2
	add	x1, x23, x25
	add	x0, x24, x26
	blr	x28
	add	x23, x23, x19
	mov	x0, x20
	add	x2, x23, x27
	mov	x1, x23
	mov	x19, x20
	blr	x22
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	and	w9, w0, #0xff
	cmp	w9, #1
	csel	x9, x27, xzr, eq
	csel	x25, xzr, x27, eq
	add	x8, x8, x26
	add	x1, x23, x9
	mov	x0, x8
	blr	x28
	add	x8, x27, x27, lsl #1
	add	x1, x23, x25
	lsl	x8, x8, #1
	add	x20, x24, x8
	mov	x0, x20
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
	blr	x28
	mov	x0, x19
	mov	x1, x24
	mov	x2, x21
	blr	x22
	ldr	x26, [sp, #72]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x21, x24, eq
	mov	x0, x26
	add	x8, x1, x27
	csel	x23, x24, x8, eq
	csel	x21, x8, x21, eq
	blr	x28
	mov	x0, x19
	mov	x1, x23
	mov	x2, x21
	blr	x22
	ldr	x24, [sp, #56]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x21, x23, eq
	mov	x0, x24
	add	x8, x1, x27
	csel	x23, x23, x8, eq
	csel	x21, x8, x21, eq
	blr	x28
	mov	x0, x19
	mov	x1, x23
	mov	x2, x21
	add	x24, x24, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x24
	cmp	w8, #1
	csel	x1, x21, x23, eq
	blr	x28
	ldr	x23, [sp, #40]                  ; 8-byte Folded Reload
	mov	x0, x19
	mov	x2, x20
	mov	x1, x23
	blr	x22
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	add	x21, x26, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x0, x21
	csel	x1, x23, x20, eq
	cmp	w8, #1
	sub	x9, x1, x27
	csel	x23, x9, x23, eq
	csel	x20, x20, x9, eq
	blr	x28
	mov	x0, x19
	mov	x1, x23
	mov	x2, x20
	blr	x22
	and	w8, w0, #0xff
	sub	x21, x21, x27
	cmp	w8, #1
	mov	x0, x21
	csel	x1, x23, x20, eq
	cmp	w8, #1
	sub	x9, x1, x27
	csel	x23, x9, x23, eq
	csel	x20, x20, x9, eq
	blr	x28
	mov	x0, x19
	mov	x1, x23
	mov	x2, x20
	blr	x22
	and	w8, w0, #0xff
	sub	x21, x21, x27
	cmp	w8, #1
	mov	x0, x21
	csel	x1, x23, x20, eq
	cmp	w8, #1
	sub	x9, x1, x27
	csel	x23, x9, x23, eq
	csel	x20, x20, x9, eq
	blr	x28
	mov	x0, x19
	mov	x1, x23
	mov	x2, x20
	sub	x21, x21, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x1, x23, x20, eq
	blr	x28
	b	LBB35_22
LBB35_18:
	ldr	x27, [sp, #80]                  ; 8-byte Folded Reload
	mov	x0, x4
	mov	x1, x21
	mov	x28, x4
	mov	x26, x3
	add	x25, x21, x27
	mov	x2, x25
	blr	x3
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x21, x25, eq
	csel	x19, x27, xzr, eq
	blr	x23
	add	x1, x21, x19
	mov	x0, x21
	blr	x23
	add	x1, sp, #96
	mov	x0, x25
	blr	x23
	add	x20, x25, x27
	mov	x0, x28
	mov	x1, x25
	mov	x2, x20
	blr	x26
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x25, x20, eq
	csel	x19, x27, xzr, eq
	blr	x23
	add	x1, x25, x19
	mov	x0, x25
	blr	x23
	add	x1, sp, #96
	mov	x0, x20
	str	x20, [sp, #40]                  ; 8-byte Folded Spill
	blr	x23
	lsl	x22, x27, #1
	mov	x24, x23
	add	x8, x22, x27
	mov	x23, x21
	add	x20, x25, x8
	mov	x0, x28
	add	x21, x20, x27
	mov	x1, x20
	mov	x2, x21
	str	x8, [sp, #56]                   ; 8-byte Folded Spill
	blr	x26
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x19, x27, xzr, eq
	blr	x24
	add	x1, x20, x19
	mov	x0, x20
	blr	x24
	add	x1, sp, #96
	mov	x0, x21
	blr	x24
	sub	x21, x20, x27
	mov	x0, x28
	mov	x1, x21
	mov	x2, x20
	blr	x26
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x21, x20, eq
	csel	x19, x27, xzr, eq
	blr	x24
	add	x1, x21, x19
	mov	x0, x21
	blr	x24
	add	x1, sp, #96
	mov	x0, x20
	blr	x24
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	add	x20, x23, x22
	mov	x0, x28
	mov	x1, x20
	str	x22, [sp, #32]                  ; 8-byte Folded Spill
	mov	x22, x23
	add	x2, x23, x8
	blr	x26
	and	w19, w0, #0xff
	mov	x0, x28
	mov	x1, x23
	mov	x2, x25
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x21, x27, xzr, eq
	cmp	w19, #1
	b.ne	LBB35_20
; %bb.19:                               ; %.cont96.i.i
	ldr	x19, [sp, #88]                  ; 8-byte Folded Reload
	neg	x9, x27
	add	x1, x22, x21
	cmp	w8, #1
	mov	x23, x28
	str	x28, [sp, #64]                  ; 8-byte Folded Spill
	mov	x0, x19
	str	x9, [sp, #48]                   ; 8-byte Folded Spill
	csel	x28, xzr, x27, eq
	blr	x24
	add	x0, x19, x27
	add	x1, x22, x28
	blr	x24
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	mov	x1, x20
	add	x0, x19, x8
	str	x0, [sp, #32]                   ; 8-byte Folded Spill
	blr	x24
	lsl	x20, x27, #2
	mov	x0, x23
	add	x21, x22, x20
	add	x2, x21, x27
	mov	x1, x21
	blr	x26
	and	w9, w0, #0xff
	add	x8, x19, x20
	cmp	w9, #1
	mov	x0, x8
	csel	x9, x27, xzr, eq
	csel	x28, xzr, x27, eq
	add	x1, x21, x9
	blr	x24
	add	x8, x20, x27
	add	x1, x21, x28
	add	x20, x19, x8
	mov	x0, x20
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	blr	x24
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	add	x23, x19, x8
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	mov	x0, x23
	add	x1, x21, x8
	blr	x24
	ldr	x28, [sp, #64]                  ; 8-byte Folded Reload
	mov	x1, x19
	mov	x2, x23
	mov	x0, x28
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x22
	cmp	w8, #1
	csel	x1, x23, x19, eq
	add	x8, x1, x27
	csel	x21, x19, x8, eq
	csel	x23, x8, x23, eq
	blr	x24
	mov	x0, x28
	mov	x1, x21
	mov	x2, x23
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	mov	x25, x26
	csel	x1, x23, x21, eq
	mov	x26, x22
	add	x8, x1, x27
	csel	x21, x21, x8, eq
	csel	x22, x8, x23, eq
	blr	x24
	mov	x0, x28
	mov	x1, x21
	mov	x2, x22
	blr	x25
	and	w8, w0, #0xff
	ldr	x0, [sp, #40]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x22, x21, eq
	blr	x24
	ldp	x8, x19, [sp, #24]              ; 16-byte Folded Reload
	mov	x0, x28
	mov	x2, x20
	add	x21, x26, x8
	mov	x1, x19
	blr	x25
	and	w8, w0, #0xff
	mov	x9, x19
	cmp	w8, #1
	mov	x0, x21
	csel	x1, x19, x20, eq
	ldr	x19, [sp, #48]                  ; 8-byte Folded Reload
	add	x8, x1, x19
	csel	x22, x8, x9, eq
	csel	x20, x20, x8, eq
	blr	x24
	mov	x0, x28
	mov	x1, x22
	mov	x2, x20
	add	x21, x21, x19
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x1, x22, x20, eq
	add	x8, x1, x19
	csel	x22, x8, x22, eq
	csel	x20, x20, x8, eq
	blr	x24
	mov	x0, x28
	mov	x1, x22
	mov	x2, x20
	add	x21, x21, x19
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x22, x20, eq
	b	LBB35_21
LBB35_20:
	cmp	w8, #1
	add	x0, sp, #96
	csel	x1, x22, x25, eq
	blr	x24
	add	x1, x22, x21
	mov	x0, x22
	blr	x24
	add	x1, sp, #96
	mov	x0, x25
	blr	x24
	add	x20, x22, x27, lsl #2
	mov	x0, x28
	add	x21, x20, x27
	mov	x1, x20
	mov	x2, x21
	blr	x26
	and	w8, w0, #0xff
	add	x0, sp, #96
	cmp	w8, #1
	csel	x1, x20, x21, eq
	csel	x19, x27, xzr, eq
	blr	x24
	add	x1, x20, x19
	mov	x0, x20
	blr	x24
	add	x1, sp, #96
LBB35_21:                               ; %sort.tiny_sort__anon_16485.exit
	mov	x0, x21
	blr	x24
LBB35_22:                               ; %common.ret1
	ldp	x29, x30, [sp, #272]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #256]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #224]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #208]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #192]            ; 16-byte Folded Reload
	add	sp, sp, #288
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
	.loh AdrpAdd	Lloh51, Lloh52
Lfunc_end35:
	.cfi_endproc
	.section	__TEXT,__const
	.p2align	1, 0x0
LJTI35_0:
	.short	(LBB35_22-LBB35_2)>>2
	.short	(LBB35_22-LBB35_2)>>2
	.short	(LBB35_2-LBB35_2)>>2
	.short	(LBB35_9-LBB35_2)>>2
	.short	(LBB35_10-LBB35_2)>>2
	.short	(LBB35_12-LBB35_2)>>2
	.short	(LBB35_18-LBB35_2)>>2
	.short	(LBB35_16-LBB35_2)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function sort.quad_swap__anon_14839
l_sort.quad_swap__anon_14839:           ; @sort.quad_swap__anon_14839
Lfunc_begin36:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 4192
	sub	sp, sp, #64
	.cfi_def_cfa_offset 4256
	.cfi_remember_state
	mov	x21, x4
	mov	x27, x0
	mov	x22, x3
	mov	x20, x2
	mov	x19, x1
	cmp	x1, #8
	stp	x5, x4, [sp, #400]              ; 16-byte Folded Spill
	str	x0, [sp, #344]                  ; 8-byte Folded Spill
	stp	x3, x2, [sp, #384]              ; 16-byte Folded Spill
	str	x1, [sp, #32]                   ; 8-byte Folded Spill
	b.lo	LBB36_84
; %bb.1:                                ; %.lr.ph
	lsl	x8, x21, #1
	lsl	x9, x21, #2
	mov	x25, x8
	add	x8, x8, x21
	lsr	x26, x19, #3
	stp	x8, x9, [sp, #288]              ; 16-byte Folded Spill
	add	x9, x9, x21
	lsl	x8, x8, #1
	str	x25, [sp, #304]                 ; 8-byte Folded Spill
	str	x9, [sp, #280]                  ; 8-byte Folded Spill
	lsl	x9, x21, #3
	stp	x9, x8, [sp, #264]              ; 16-byte Folded Spill
	sub	x8, x9, x21
	str	x8, [sp, #256]                  ; 8-byte Folded Spill
	neg	x8, x21
	str	x8, [sp, #200]                  ; 8-byte Folded Spill
	neg	x8, x9
	str	x8, [sp, #160]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #344]                  ; 8-byte Folded Reload
	mov	x27, x8
	str	x8, [sp, #376]                  ; 8-byte Folded Spill
LBB36_2:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB36_11 Depth 2
                                        ;       Child Loop BB36_12 Depth 3
                                        ;         Child Loop BB36_23 Depth 4
	add	x28, x27, x21
	sub	x26, x26, #1
	mov	x0, x22
	mov	x1, x27
	mov	x2, x28
	str	x26, [sp, #352]                 ; 8-byte Folded Spill
	blr	x20
	and	w8, w0, #0xff
	add	x24, x27, x25
	cmp	w8, #1
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x1, x24
	cset	w19, eq
	add	x2, x27, x8
	str	x2, [sp, #368]                  ; 8-byte Folded Spill
	blr	x20
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x26, x27, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x1, x26
	cset	w25, eq
	add	x2, x27, x8
	str	x2, [sp, #360]                  ; 8-byte Folded Spill
	blr	x20
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	add	x1, x27, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	mov	x0, x22
	cset	w23, eq
	str	x1, [sp, #248]                  ; 8-byte Folded Spill
	add	x2, x27, x8
	blr	x20
	and	w9, w0, #0xff
	lsl	w8, w23, #2
	cmp	w9, #1
	orr	w8, w8, w25, lsl #1
	cset	w9, eq
	str	w23, [sp, #336]                 ; 4-byte Folded Spill
	str	w19, [sp, #320]                 ; 4-byte Folded Spill
	orr	w8, w8, w9, lsl #3
	orr	w8, w8, w19
	str	w9, [sp, #328]                  ; 4-byte Folded Spill
	cbz	w8, LBB36_43
; %bb.3:                                ;   in Loop: Header=BB36_2 Depth=1
	cmp	w8, #15
	str	w25, [sp, #312]                 ; 4-byte Folded Spill
	b.ne	LBB36_8
; %bb.4:                                ;   in Loop: Header=BB36_2 Depth=1
	mov	x0, x22
	mov	x1, x28
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_8
; %bb.5:                                ;   in Loop: Header=BB36_2 Depth=1
	mov	x0, x22
	ldr	x1, [sp, #368]                  ; 8-byte Folded Reload
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_8
; %bb.6:                                ;   in Loop: Header=BB36_2 Depth=1
	mov	x0, x22
	ldr	x1, [sp, #360]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #248]                  ; 8-byte Folded Reload
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_8
; %bb.7:                                ;   in Loop: Header=BB36_2 Depth=1
	str	x27, [sp, #376]                 ; 8-byte Folded Spill
	b	LBB36_9
LBB36_8:                                ; %.critedge4
                                        ;   in Loop: Header=BB36_2 Depth=1
	mov	w8, #2
LBB36_9:                                ; %.outer.preheader
                                        ;   in Loop: Header=BB36_2 Depth=1
	ldr	x19, [sp, #304]                 ; 8-byte Folded Reload
	ldr	x26, [sp, #352]                 ; 8-byte Folded Reload
LBB36_10:                               ; %.outer.preheader
                                        ;   in Loop: Header=BB36_2 Depth=1
	ldr	x9, [sp, #376]                  ; 8-byte Folded Reload
	str	x9, [sp, #360]                  ; 8-byte Folded Spill
LBB36_11:                               ; %.outer
                                        ;   Parent Loop BB36_2 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB36_12 Depth 3
                                        ;         Child Loop BB36_23 Depth 4
	ldr	x9, [sp, #360]                  ; 8-byte Folded Reload
	str	x27, [sp, #360]                 ; 8-byte Folded Spill
	str	x9, [sp, #376]                  ; 8-byte Folded Spill
LBB36_12:                               ; %.backedge
                                        ;   Parent Loop BB36_2 Depth=1
                                        ;     Parent Loop BB36_11 Depth=2
                                        ; =>    This Loop Header: Depth=3
                                        ;         Child Loop BB36_23 Depth 4
	cbz	w8, LBB36_25
; %bb.13:                               ; %.backedge
                                        ;   in Loop: Header=BB36_12 Depth=3
	cmp	w8, #1
	b.ne	LBB36_49
; %bb.14:                               ;   in Loop: Header=BB36_12 Depth=3
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	ldr	x27, [sp, #360]                 ; 8-byte Folded Reload
	add	x27, x27, x8
	str	x27, [sp, #360]                 ; 8-byte Folded Spill
	cbz	x26, LBB36_60
; %bb.15:                               ;   in Loop: Header=BB36_12 Depth=3
	add	x2, x27, x21
	mov	x0, x22
	mov	x1, x27
	sub	x26, x26, #1
	str	x2, [sp, #248]                  ; 8-byte Folded Spill
	blr	x20
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	add	x25, x27, x19
	mov	x23, x19
	str	w0, [sp, #192]                  ; 4-byte Folded Spill
	and	w19, w0, #0xff
	mov	x0, x22
	add	x2, x27, x8
	mov	x1, x25
	str	x2, [sp, #240]                  ; 8-byte Folded Spill
	blr	x20
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	str	w0, [sp, #184]                  ; 4-byte Folded Spill
	add	x1, x27, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	mov	x0, x22
	cset	w24, ne
	str	x1, [sp, #232]                  ; 8-byte Folded Spill
	add	x2, x27, x8
	str	x2, [sp, #216]                  ; 8-byte Folded Spill
	blr	x20
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	mov	w28, w0
	mov	x0, x22
	add	x1, x27, x8
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	add	x2, x27, x8
	str	x1, [sp, #208]                  ; 8-byte Folded Spill
	blr	x20
	cmp	w19, #1
	and	w8, w28, #0xff
	cset	w9, ne
	mov	x19, x23
	str	w28, [sp, #176]                 ; 4-byte Folded Spill
	str	w24, [sp, #312]                 ; 4-byte Folded Spill
	str	w9, [sp, #320]                  ; 4-byte Folded Spill
	csinc	w9, w24, wzr, eq
	cmp	w8, #1
	str	w0, [sp, #168]                  ; 4-byte Folded Spill
	cset	w8, ne
	csinc	w9, w9, wzr, eq
	str	w8, [sp, #336]                  ; 4-byte Folded Spill
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, ne
	str	w8, [sp, #328]                  ; 4-byte Folded Spill
	csinc	w8, w9, wzr, eq
	cmp	w8, #1
	b.eq	LBB36_20
; %bb.16:                               ;   in Loop: Header=BB36_12 Depth=3
	ldr	x8, [sp, #200]                  ; 8-byte Folded Reload
	mov	x0, x22
	ldr	x2, [sp, #360]                  ; 8-byte Folded Reload
	add	x1, x2, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_20
; %bb.17:                               ;   in Loop: Header=BB36_12 Depth=3
	mov	x0, x22
	ldr	x1, [sp, #248]                  ; 8-byte Folded Reload
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_20
; %bb.18:                               ;   in Loop: Header=BB36_12 Depth=3
	ldp	x2, x1, [sp, #232]              ; 16-byte Folded Reload
	mov	x0, x22
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_20
; %bb.19:                               ;   in Loop: Header=BB36_12 Depth=3
	ldp	x2, x1, [sp, #208]              ; 16-byte Folded Reload
	mov	x0, x22
	blr	x20
	mov	w8, #1
	and	w9, w0, #0xff
	cmp	w9, #1
	b.eq	LBB36_12
LBB36_20:                               ; %.critedge25
                                        ;   in Loop: Header=BB36_12 Depth=3
	ldr	x22, [sp, #200]                 ; 8-byte Folded Reload
	str	x25, [sp, #224]                 ; 8-byte Folded Spill
	ldr	x8, [sp, #360]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #376]                  ; 8-byte Folded Reload
	add	x10, x8, x22
	sub	x8, x10, x9
	udiv	x19, x8, x19
	str	x10, [sp, #368]                 ; 8-byte Folded Spill
	mul	x8, x19, x21
	add	x27, x9, x8
	sub	x28, x10, x8
	tbnz	w19, #0, LBB36_22
; %bb.21:                               ;   in Loop: Header=BB36_12 Depth=3
	add	x0, sp, #4064
	mov	x1, x27
	ldr	x20, [sp, #400]                 ; 8-byte Folded Reload
	blr	x20
	mov	x0, x27
	mov	x1, x28
	blr	x20
	add	x1, sp, #4064
	mov	x0, x28
	add	x27, x27, x22
	blr	x20
	add	x28, x28, x21
	sub	x19, x19, #1
LBB36_22:                               ; %._crit_edge.i
                                        ;   in Loop: Header=BB36_12 Depth=3
	mov	x22, xzr
	mov	x20, xzr
	lsr	x19, x19, #1
	str	x26, [sp, #352]                 ; 8-byte Folded Spill
LBB36_23:                               ;   Parent Loop BB36_2 Depth=1
                                        ;     Parent Loop BB36_11 Depth=2
                                        ;       Parent Loop BB36_12 Depth=3
                                        ; =>      This Inner Loop Header: Depth=4
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	add	x0, sp, #3968
	ldr	x21, [sp, #400]                 ; 8-byte Folded Reload
	add	x26, x28, x22
	add	x24, x27, x20
	add	x23, x8, x20
	ldr	x8, [sp, #376]                  ; 8-byte Folded Reload
	add	x25, x8, x22
	mov	x1, x25
	blr	x21
	mov	x0, x25
	mov	x1, x23
	blr	x21
	add	x1, sp, #3968
	mov	x0, x23
	blr	x21
	add	x0, sp, #4064
	mov	x1, x24
	blr	x21
	mov	x0, x24
	mov	x1, x26
	blr	x21
	add	x1, sp, #4064
	mov	x0, x26
	blr	x21
	cbz	x19, LBB36_31
; %bb.24:                               ;   in Loop: Header=BB36_23 Depth=4
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	sub	x19, x19, #1
	sub	x20, x20, x8
	add	x22, x22, x8
	b	LBB36_23
LBB36_25:                               ;   in Loop: Header=BB36_12 Depth=3
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	ldr	x27, [sp, #360]                 ; 8-byte Folded Reload
	add	x27, x27, x8
	cbz	x26, LBB36_83
; %bb.26:                               ;   in Loop: Header=BB36_12 Depth=3
	add	x23, x27, x21
	sub	x26, x26, #1
	mov	x0, x22
	mov	x1, x27
	mov	x2, x23
	str	x26, [sp, #352]                 ; 8-byte Folded Spill
	blr	x20
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	add	x24, x27, x19
	and	w21, w0, #0xff
	mov	x0, x22
	mov	x1, x24
	add	x25, x27, x8
	mov	x2, x25
	blr	x20
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x28, x27, x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x1, x28
	cset	w19, eq
	add	x2, x27, x8
	str	x2, [sp, #368]                  ; 8-byte Folded Spill
	blr	x20
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	mov	w26, w0
	mov	x0, x22
	str	x27, [sp, #360]                 ; 8-byte Folded Spill
	add	x1, x27, x8
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	add	x2, x27, x8
	str	x1, [sp, #248]                  ; 8-byte Folded Spill
	blr	x20
	cmp	w21, #1
	and	w8, w26, #0xff
	cset	w26, eq
	csinc	w9, w19, wzr, ne
	cmp	w8, #1
	and	w8, w0, #0xff
	cset	w21, eq
	csinc	w9, w9, wzr, ne
	cmp	w8, #1
	str	w19, [sp, #312]                 ; 4-byte Folded Spill
	cset	w27, eq
	csinc	w8, w9, wzr, ne
	cmp	w8, #1
	str	w21, [sp, #336]                 ; 4-byte Folded Spill
	str	w26, [sp, #320]                 ; 4-byte Folded Spill
	str	w27, [sp, #328]                 ; 4-byte Folded Spill
	b.ne	LBB36_35
; %bb.27:                               ;   in Loop: Header=BB36_12 Depth=3
	add	w8, w19, w26
	add	w9, w21, w27
	add	w9, w8, w9
	mov	w8, #2
	ldr	x26, [sp, #352]                 ; 8-byte Folded Reload
	cmp	w9, #4
	ldr	x19, [sp, #304]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #408]                 ; 8-byte Folded Reload
	b.ne	LBB36_12
; %bb.28:                               ;   in Loop: Header=BB36_12 Depth=3
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	mov	w8, #2
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB36_12
; %bb.29:                               ;   in Loop: Header=BB36_12 Depth=3
	mov	x0, x22
	mov	x1, x25
	mov	x2, x28
	blr	x20
	mov	w8, #2
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB36_12
; %bb.30:                               ;   in Loop: Header=BB36_12 Depth=3
	mov	x0, x22
	ldr	x1, [sp, #368]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #248]                  ; 8-byte Folded Reload
	blr	x20
	mov	w8, #2
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB36_12
	b	LBB36_42
LBB36_31:                               ; %sort.quad_reversal.exit
                                        ;   in Loop: Header=BB36_12 Depth=3
	ldr	w8, [sp, #312]                  ; 4-byte Folded Reload
	ldr	w9, [sp, #320]                  ; 4-byte Folded Reload
	ldr	w10, [sp, #328]                 ; 4-byte Folded Reload
	ldr	x19, [sp, #304]                 ; 8-byte Folded Reload
	add	w8, w8, w9
	ldr	w9, [sp, #336]                  ; 4-byte Folded Reload
	add	w9, w9, w10
	add	w8, w8, w9
	cmp	w8, #4
	b.ne	LBB36_38
; %bb.32:                               ;   in Loop: Header=BB36_12 Depth=3
	ldp	x22, x20, [sp, #384]            ; 16-byte Folded Reload
	ldr	x28, [sp, #224]                 ; 8-byte Folded Reload
	ldr	x1, [sp, #248]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x2, x28
	blr	x20
	ldr	x21, [sp, #408]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	ldr	x26, [sp, #352]                 ; 8-byte Folded Reload
	cmp	w8, #1
	b.eq	LBB36_46
; %bb.33:                               ;   in Loop: Header=BB36_12 Depth=3
	ldp	x2, x1, [sp, #232]              ; 16-byte Folded Reload
	mov	x0, x22
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_46
; %bb.34:                               ;   in Loop: Header=BB36_12 Depth=3
	ldp	x2, x1, [sp, #208]              ; 16-byte Folded Reload
	mov	x0, x22
	blr	x20
	mov	w8, wzr
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB36_12
	b	LBB36_46
LBB36_35:                               ;   in Loop: Header=BB36_12 Depth=3
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_53
; %bb.36:                               ;   in Loop: Header=BB36_12 Depth=3
	mov	x0, x22
	mov	x1, x25
	mov	x2, x28
	blr	x20
	ldr	x26, [sp, #352]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_54
; %bb.37:                               ;   in Loop: Header=BB36_12 Depth=3
	mov	x0, x22
	ldr	x1, [sp, #368]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #248]                  ; 8-byte Folded Reload
	blr	x20
	mov	w8, wzr
	ldr	x19, [sp, #304]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #408]                 ; 8-byte Folded Reload
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB36_12
	b	LBB36_56
LBB36_38:                               ; %sort.quad_reversal.exit
                                        ;   in Loop: Header=BB36_11 Depth=2
	ldp	x22, x20, [sp, #384]            ; 16-byte Folded Reload
	ldr	x21, [sp, #408]                 ; 8-byte Folded Reload
	ldr	x26, [sp, #352]                 ; 8-byte Folded Reload
	ldr	x28, [sp, #224]                 ; 8-byte Folded Reload
	cbnz	w8, LBB36_46
; %bb.39:                               ;   in Loop: Header=BB36_11 Depth=2
	mov	x0, x22
	ldr	x1, [sp, #248]                  ; 8-byte Folded Reload
	mov	x2, x28
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_46
; %bb.40:                               ;   in Loop: Header=BB36_11 Depth=2
	ldp	x2, x1, [sp, #232]              ; 16-byte Folded Reload
	mov	x0, x22
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_46
; %bb.41:                               ;   in Loop: Header=BB36_11 Depth=2
	ldp	x2, x1, [sp, #208]              ; 16-byte Folded Reload
	mov	x0, x22
	blr	x20
	mov	w8, #1
	ldr	x27, [sp, #360]                 ; 8-byte Folded Reload
	and	w9, w0, #0xff
	cmp	w9, #1
	b.eq	LBB36_11
	b	LBB36_46
LBB36_42:                               ;   in Loop: Header=BB36_11 Depth=2
	ldr	x27, [sp, #360]                 ; 8-byte Folded Reload
	mov	w8, #1
	b	LBB36_11
LBB36_43:                               ;   in Loop: Header=BB36_2 Depth=1
	mov	x0, x22
	mov	x1, x28
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_45
; %bb.44:                               ;   in Loop: Header=BB36_2 Depth=1
	mov	x0, x22
	ldr	x1, [sp, #368]                  ; 8-byte Folded Reload
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_50
LBB36_45:                               ;   in Loop: Header=BB36_2 Depth=1
	ldr	x19, [sp, #32]                  ; 8-byte Folded Reload
	ldr	x25, [sp, #304]                 ; 8-byte Folded Reload
	ldr	x26, [sp, #352]                 ; 8-byte Folded Reload
	b	LBB36_58
LBB36_46:                               ; %.critedge37
                                        ;   in Loop: Header=BB36_2 Depth=1
	ldr	w8, [sp, #168]                  ; 4-byte Folded Reload
	add	x0, sp, #3488
	ldr	w9, [sp, #176]                  ; 4-byte Folded Reload
	ldr	x23, [sp, #360]                 ; 8-byte Folded Reload
	and	w21, w8, #0xff
	ldr	w8, [sp, #192]                  ; 4-byte Folded Reload
	and	w19, w9, #0xff
	ldr	x9, [sp, #408]                  ; 8-byte Folded Reload
	and	w8, w8, #0xff
	cmp	w8, #1
	ldr	w8, [sp, #184]                  ; 4-byte Folded Reload
	csel	x22, xzr, x9, ne
	and	w20, w8, #0xff
	ldp	x24, x8, [sp, #400]             ; 16-byte Folded Reload
	csel	x8, x8, xzr, ne
	add	x1, x23, x8
	blr	x24
	add	x1, x23, x22
	mov	x0, x23
	ldr	x22, [sp, #384]                 ; 8-byte Folded Reload
	blr	x24
	add	x1, sp, #3488
	ldr	x0, [sp, #248]                  ; 8-byte Folded Reload
	blr	x24
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	cmp	w20, #1
	ldr	x9, [sp, #408]                  ; 8-byte Folded Reload
	add	x0, sp, #3488
	csel	x8, x8, xzr, ne
	add	x1, x28, x8
	csel	x20, xzr, x9, ne
	blr	x24
	add	x1, x28, x20
	mov	x0, x28
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	ldr	x25, [sp, #408]                 ; 8-byte Folded Reload
	blr	x24
	add	x0, x28, x25
	add	x1, sp, #3488
	blr	x24
	ldr	x8, [sp, #304]                  ; 8-byte Folded Reload
	cmp	w19, #1
	add	x0, sp, #3488
	csel	x19, xzr, x25, ne
	add	x23, x28, x8
	csel	x8, x25, xzr, ne
	add	x1, x23, x8
	blr	x24
	add	x1, x23, x19
	mov	x0, x23
	blr	x24
	add	x0, x23, x25
	add	x1, sp, #3488
	blr	x24
	cmp	w21, #1
	mov	x21, x25
	ldr	x25, [sp, #304]                 ; 8-byte Folded Reload
	csel	x8, x21, xzr, ne
	add	x0, sp, #3488
	csel	x19, xzr, x21, ne
	add	x23, x23, x25
	add	x1, x23, x8
	blr	x24
	add	x1, x23, x19
	mov	x0, x23
	blr	x24
	add	x0, x23, x21
	add	x1, sp, #3488
	blr	x24
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x8, x25, x8
	add	x27, x23, x8
	add	x1, x27, x21
	add	x2, x27, x25
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_57
; %bb.47:                               ;   in Loop: Header=BB36_2 Depth=1
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x1, x27, x8
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x2, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_57
; %bb.48:                               ;   in Loop: Header=BB36_2 Depth=1
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x1, x27, x8
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	add	x2, x27, x8
	blr	x20
	ldr	x19, [sp, #32]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_58
	b	LBB36_59
LBB36_49:                               ;   in Loop: Header=BB36_2 Depth=1
	ldr	w8, [sp, #320]                  ; 4-byte Folded Reload
	mov	x24, x19
	add	x0, sp, #3488
	ldr	x20, [sp, #400]                 ; 8-byte Folded Reload
	tst	w8, #0xf
	csel	x8, x21, xzr, eq
	csel	x19, xzr, x21, eq
	ldr	x21, [sp, #360]                 ; 8-byte Folded Reload
	add	x1, x21, x8
	blr	x20
	add	x1, x21, x19
	mov	x0, x21
	blr	x20
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	add	x1, sp, #3488
	add	x0, x21, x8
	blr	x20
	ldr	w8, [sp, #312]                  ; 4-byte Folded Reload
	add	x23, x21, x24
	ldr	x9, [sp, #408]                  ; 8-byte Folded Reload
	add	x0, sp, #3488
	tst	w8, #0xf
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	csel	x19, xzr, x9, eq
	csel	x8, x8, xzr, eq
	add	x1, x23, x8
	blr	x20
	add	x1, x23, x19
	mov	x0, x23
	blr	x20
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	add	x1, sp, #3488
	add	x0, x23, x8
	blr	x20
	ldr	w8, [sp, #336]                  ; 4-byte Folded Reload
	add	x23, x23, x24
	ldr	x9, [sp, #408]                  ; 8-byte Folded Reload
	add	x0, sp, #3488
	tst	w8, #0xf
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	csel	x19, xzr, x9, eq
	csel	x8, x8, xzr, eq
	add	x1, x23, x8
	blr	x20
	add	x1, x23, x19
	mov	x0, x23
	blr	x20
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	add	x1, sp, #3488
	add	x0, x23, x8
	blr	x20
	ldr	w8, [sp, #328]                  ; 4-byte Folded Reload
	add	x23, x23, x24
	ldr	x9, [sp, #408]                  ; 8-byte Folded Reload
	add	x0, sp, #3488
	tst	w8, #0xf
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	csel	x19, xzr, x9, eq
	csel	x8, x8, xzr, eq
	add	x1, x23, x8
	blr	x20
	add	x1, x23, x19
	mov	x19, x20
	mov	x0, x23
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #408]                 ; 8-byte Folded Reload
	blr	x19
	add	x0, x23, x21
	add	x1, sp, #3488
	blr	x19
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	mov	x25, x24
	ldr	x19, [sp, #32]                  ; 8-byte Folded Reload
	add	x8, x24, x8
	add	x27, x23, x8
	b	LBB36_58
LBB36_50:                               ;   in Loop: Header=BB36_2 Depth=1
	mov	x0, x22
	ldr	x1, [sp, #360]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #248]                  ; 8-byte Folded Reload
	str	w25, [sp, #312]                 ; 4-byte Folded Spill
	blr	x20
	ldr	x19, [sp, #304]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	ldr	x26, [sp, #352]                 ; 8-byte Folded Reload
	cmp	w8, #1
	b.ne	LBB36_52
; %bb.51:                               ;   in Loop: Header=BB36_2 Depth=1
	mov	x25, x19
	b	LBB36_57
LBB36_52:                               ;   in Loop: Header=BB36_2 Depth=1
	mov	w8, wzr
	b	LBB36_10
LBB36_53:                               ;   in Loop: Header=BB36_2 Depth=1
	ldp	x26, x27, [sp, #352]            ; 16-byte Folded Reload
	b	LBB36_55
LBB36_54:                               ;   in Loop: Header=BB36_2 Depth=1
	ldr	x27, [sp, #360]                 ; 8-byte Folded Reload
LBB36_55:                               ; %.sink.split
                                        ;   in Loop: Header=BB36_2 Depth=1
	ldr	x19, [sp, #32]                  ; 8-byte Folded Reload
	ldr	x25, [sp, #304]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #408]                 ; 8-byte Folded Reload
	b	LBB36_58
LBB36_56:                               ;   in Loop: Header=BB36_2 Depth=1
	mov	x25, x19
	ldr	x27, [sp, #360]                 ; 8-byte Folded Reload
LBB36_57:                               ; %.sink.split
                                        ;   in Loop: Header=BB36_2 Depth=1
	ldr	x19, [sp, #32]                  ; 8-byte Folded Reload
LBB36_58:                               ; %.sink.split
                                        ;   in Loop: Header=BB36_2 Depth=1
	add	x1, sp, #416
	mov	x0, x27
	mov	x2, x20
	mov	x3, x22
	mov	x4, x21
	ldr	x5, [sp, #400]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap_merge__anon_16478
LBB36_59:                               ;   in Loop: Header=BB36_2 Depth=1
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	add	x27, x27, x8
	cbnz	x26, LBB36_2
	b	LBB36_84
LBB36_60:
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	mov	x23, x21
	and	x21, x8, #0x7
	cmp	x21, #7
	b.ne	LBB36_62
; %bb.61:
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x1, x27, x8
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	add	x2, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_63
	b	LBB36_77
LBB36_62:                               ; %.critedge55
	cmp	x21, #6
	b.lo	LBB36_64
LBB36_63:                               ; %.critedge55.thread
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x1, x27, x8
	ldr	x8, [sp, #280]                  ; 8-byte Folded Reload
	add	x2, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_77
	b	LBB36_65
LBB36_64:                               ; %.critedge57
	cmp	x21, #5
	b.ne	LBB36_66
LBB36_65:                               ; %.critedge57.thread
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x1, x27, x8
	ldr	x8, [sp, #296]                  ; 8-byte Folded Reload
	add	x2, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_77
	b	LBB36_67
LBB36_66:                               ; %.critedge59
	cmp	x21, #4
	b.lo	LBB36_68
LBB36_67:                               ; %.critedge59.thread
	ldr	x8, [sp, #288]                  ; 8-byte Folded Reload
	add	x1, x27, x19
	mov	x0, x22
	add	x2, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_77
	b	LBB36_69
LBB36_68:                               ; %.critedge61
	cmp	x21, #3
	b.ne	LBB36_110
LBB36_69:                               ; %.critedge61.thread
	add	x1, x27, x23
	add	x2, x27, x19
	mov	x0, x22
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_77
LBB36_70:                               ; %.critedge63.thread
	add	x2, x27, x23
	mov	x0, x22
	mov	x1, x27
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_77
LBB36_71:                               ; %.critedge65.thread
	ldr	x8, [sp, #200]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x2, x27
	add	x1, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_77
LBB36_72:                               ; %.critedge67
	ldr	x22, [sp, #200]                 ; 8-byte Folded Reload
	madd	x8, x21, x23, x27
	ldr	x9, [sp, #376]                  ; 8-byte Folded Reload
	add	x10, x8, x22
	sub	x8, x10, x9
	udiv	x19, x8, x19
	str	x10, [sp, #368]                 ; 8-byte Folded Spill
	mul	x8, x19, x23
	add	x24, x9, x8
	sub	x25, x10, x8
	tbnz	w19, #0, LBB36_74
; %bb.73:
	add	x0, sp, #4064
	mov	x1, x24
	ldr	x20, [sp, #400]                 ; 8-byte Folded Reload
	mov	x21, x23
	blr	x20
	mov	x0, x24
	mov	x1, x25
	blr	x20
	add	x1, sp, #4064
	mov	x0, x25
	add	x24, x24, x22
	blr	x20
	add	x25, x25, x23
	sub	x19, x19, #1
LBB36_74:                               ; %._crit_edge.i344
	mov	x22, xzr
	mov	x21, xzr
	lsr	x20, x19, #1
	ldr	x19, [sp, #400]                 ; 8-byte Folded Reload
LBB36_75:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	add	x0, sp, #3968
	add	x26, x25, x22
	add	x27, x24, x21
	add	x23, x8, x21
	ldr	x8, [sp, #376]                  ; 8-byte Folded Reload
	add	x28, x8, x22
	mov	x1, x28
	blr	x19
	mov	x0, x28
	mov	x1, x23
	blr	x19
	add	x1, sp, #3968
	mov	x0, x23
	blr	x19
	add	x0, sp, #4064
	mov	x1, x27
	blr	x19
	mov	x0, x27
	mov	x1, x26
	blr	x19
	add	x1, sp, #4064
	mov	x0, x26
	blr	x19
	cbz	x20, LBB36_108
; %bb.76:                               ;   in Loop: Header=BB36_75 Depth=1
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	sub	x20, x20, #1
	sub	x21, x21, x8
	add	x22, x22, x8
	b	LBB36_75
LBB36_77:
	ldr	x22, [sp, #200]                 ; 8-byte Folded Reload
	ldr	x9, [sp, #376]                  ; 8-byte Folded Reload
	add	x10, x27, x22
	sub	x8, x10, x9
	udiv	x19, x8, x19
	str	x10, [sp, #368]                 ; 8-byte Folded Spill
	mul	x8, x19, x23
	add	x24, x9, x8
	sub	x26, x10, x8
	tbnz	w19, #0, LBB36_79
; %bb.78:
	add	x0, sp, #4064
	mov	x1, x24
	ldr	x20, [sp, #400]                 ; 8-byte Folded Reload
	mov	x21, x23
	blr	x20
	mov	x0, x24
	mov	x1, x26
	blr	x20
	add	x1, sp, #4064
	mov	x0, x26
	add	x24, x24, x22
	blr	x20
	add	x26, x26, x23
	sub	x19, x19, #1
LBB36_79:                               ; %._crit_edge.i332
	mov	x22, xzr
	mov	x21, xzr
	lsr	x20, x19, #1
	ldr	x19, [sp, #400]                 ; 8-byte Folded Reload
LBB36_80:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #368]                  ; 8-byte Folded Reload
	add	x0, sp, #3968
	add	x25, x26, x22
	add	x27, x24, x21
	add	x23, x8, x21
	ldr	x8, [sp, #376]                  ; 8-byte Folded Reload
	add	x28, x8, x22
	mov	x1, x28
	blr	x19
	mov	x0, x28
	mov	x1, x23
	blr	x19
	add	x1, sp, #3968
	mov	x0, x23
	blr	x19
	add	x0, sp, #4064
	mov	x1, x27
	blr	x19
	mov	x0, x27
	mov	x1, x25
	blr	x19
	add	x1, sp, #4064
	mov	x0, x25
	blr	x19
	cbz	x20, LBB36_82
; %bb.81:                               ;   in Loop: Header=BB36_80 Depth=1
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	sub	x20, x20, #1
	sub	x21, x21, x8
	add	x22, x22, x8
	b	LBB36_80
LBB36_82:                               ; %sort.quad_reversal.exit342
	ldp	x22, x20, [sp, #384]            ; 16-byte Folded Reload
	ldr	x27, [sp, #360]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #408]                 ; 8-byte Folded Reload
LBB36_83:                               ; %.loopexit
	ldr	x19, [sp, #32]                  ; 8-byte Folded Reload
LBB36_84:                               ; %.loopexit
	and	x1, x19, #0x7
	add	x2, sp, #416
	mov	x0, x27
	mov	x3, x20
	mov	x4, x22
	mov	x5, x21
	ldr	x6, [sp, #400]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14838
	ldr	x27, [sp, #344]                 ; 8-byte Folded Reload
LBB36_85:
	cmp	x19, #32
	b.hs	LBB36_92
LBB36_86:                               ; %._crit_edge
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	and	x24, x8, #0x1f
	cmp	x24, #8
	b.ls	LBB36_106
; %bb.87:                               ; %.preheader.lr.ph.i
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	mul	x21, x24, x8
	lsl	x8, x8, #3
	add	x9, x8, x27
	add	x23, x27, x21
	cmp	x9, x23
	b.hs	LBB36_91
; %bb.88:                               ; %.lr.ph.i
	ldr	x9, [sp, #408]                  ; 8-byte Folded Reload
	mov	x19, xzr
	add	x25, x27, x8
	lsl	x20, x9, #4
	add	x22, x27, x20
LBB36_89:                               ; =>This Inner Loop Header: Depth=1
	add	x0, x27, x19
	add	x8, x22, x19
	cmp	x8, x23
	b.hs	LBB36_100
; %bb.90:                               ;   in Loop: Header=BB36_89 Depth=1
	ldp	x6, x5, [sp, #384]              ; 16-byte Folded Reload
	add	x2, sp, #416
	mov	w1, #16
	ldp	x8, x7, [sp, #400]              ; 16-byte Folded Reload
	mov	w3, #32
	mov	w4, #8
	str	x8, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
	add	x19, x19, x20
	add	x8, x25, x19
	cmp	x8, x23
	b.lo	LBB36_89
LBB36_91:                               ; %.loopexit.i
	cmp	x24, #17
	b.lo	LBB36_106
	b	LBB36_101
LBB36_92:                               ; %.lr.ph493
	lsl	x25, x21, #3
	lsl	x10, x21, #4
	sub	x8, x25, x21
	add	x9, x21, x21, lsl #1
	sub	x11, x10, x21
	lsr	x19, x19, #5
	neg	x28, x21
	stp	x8, x10, [sp, #320]             ; 16-byte Folded Spill
	mov	w8, #23
	str	x11, [sp, #40]                  ; 8-byte Folded Spill
	mul	x8, x21, x8
	str	x28, [sp, #376]                 ; 8-byte Folded Spill
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	lsl	x8, x9, #3
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
	add	x8, sp, #416
	add	x12, x8, x10
	add	x9, x8, x11
	sub	x13, x12, x21
	add	x8, x8, x21
	add	x10, x13, x10
	add	x11, x12, x11
	str	x12, [sp, #352]                 ; 8-byte Folded Spill
	stp	x10, x13, [sp, #280]            ; 16-byte Folded Spill
	lsl	x10, x21, #5
	str	x11, [sp, #296]                 ; 8-byte Folded Spill
	stp	x9, x10, [sp, #304]             ; 16-byte Folded Spill
	sub	x10, x10, x21
	sub	x9, x9, x21
	stp	x8, x10, [sp, #264]             ; 16-byte Folded Spill
	add	x8, x8, x21
	stp	x8, x9, [sp, #248]              ; 16-byte Folded Spill
	sub	x9, x9, x21
	add	x8, x8, x21
	stp	x8, x9, [sp, #232]              ; 16-byte Folded Spill
	sub	x9, x9, x21
	add	x8, x8, x21
	stp	x8, x9, [sp, #216]              ; 16-byte Folded Spill
	sub	x9, x9, x21
	add	x8, x8, x21
	stp	x8, x9, [sp, #200]              ; 16-byte Folded Spill
	sub	x9, x9, x21
	add	x8, x8, x21
	stp	x8, x9, [sp, #184]              ; 16-byte Folded Spill
	sub	x9, x9, x21
	add	x8, x8, x21
	stp	x8, x9, [sp, #168]              ; 16-byte Folded Spill
	sub	x8, x9, x21
	sub	x9, x11, x21
	str	x8, [sp, #160]                  ; 8-byte Folded Spill
	add	x8, x12, x21
	stp	x9, x8, [sp, #144]              ; 16-byte Folded Spill
	add	x8, x8, x21
	sub	x9, x9, x21
	stp	x9, x8, [sp, #128]              ; 16-byte Folded Spill
	add	x8, x8, x21
	sub	x9, x9, x21
	stp	x9, x8, [sp, #112]              ; 16-byte Folded Spill
	add	x8, x8, x21
	sub	x9, x9, x21
	stp	x9, x8, [sp, #96]               ; 16-byte Folded Spill
	add	x8, x8, x21
	sub	x9, x9, x21
	stp	x9, x8, [sp, #80]               ; 16-byte Folded Spill
	add	x8, x8, x21
	sub	x9, x9, x21
	stp	x9, x8, [sp, #64]               ; 16-byte Folded Spill
	add	x8, x8, x21
	str	x8, [sp, #56]                   ; 8-byte Folded Spill
	sub	x8, x9, x21
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
	add	x8, x27, x21
	stp	x25, x8, [sp, #360]             ; 16-byte Folded Spill
	b	LBB36_94
LBB36_93:                               ;   in Loop: Header=BB36_94 Depth=1
	ldr	x8, [sp, #312]                  ; 8-byte Folded Reload
	subs	x19, x19, #1
	ldr	x9, [sp, #368]                  ; 8-byte Folded Reload
	add	x27, x27, x8
	add	x9, x9, x8
	str	x9, [sp, #368]                  ; 8-byte Folded Spill
	b.eq	LBB36_86
LBB36_94:                               ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB36_98 Depth 2
	ldr	x8, [sp, #320]                  ; 8-byte Folded Reload
	add	x23, x27, x25
	mov	x0, x22
	mov	x2, x23
	add	x1, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_97
; %bb.95:                               ;   in Loop: Header=BB36_94 Depth=1
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	mov	x0, x22
	add	x1, x27, x8
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	add	x2, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB36_97
; %bb.96:                               ;   in Loop: Header=BB36_94 Depth=1
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x0, x22
	add	x1, x27, x8
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	add	x2, x27, x8
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB36_93
LBB36_97:                               ; %.critedge69
                                        ;   in Loop: Header=BB36_94 Depth=1
	mov	x0, x22
	mov	x1, x27
	mov	x2, x23
	add	x24, x23, x28
	str	x19, [sp, #336]                 ; 8-byte Folded Spill
	add	x25, x24, x25
	blr	x20
	ldp	x21, x19, [sp, #400]            ; 16-byte Folded Reload
	and	w8, w0, #0xff
	add	x0, sp, #416
	cmp	w8, #1
	csel	x1, x23, x27, eq
	add	x8, x1, x19
	csel	x26, x27, x8, eq
	csel	x23, x8, x23, eq
	blr	x21
	mov	x0, x22
	mov	x1, x26
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #264]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x23, x26, eq
	add	x8, x1, x19
	csel	x23, x8, x23, eq
	csel	x26, x26, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #304]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x28
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	mov	x0, x22
	mov	x1, x26
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #248]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x23, x26, eq
	add	x8, x1, x19
	csel	x23, x8, x23, eq
	csel	x26, x26, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #256]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x28
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	mov	x0, x22
	mov	x1, x26
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #232]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x23, x26, eq
	add	x8, x1, x19
	csel	x23, x8, x23, eq
	csel	x26, x26, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #240]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x28
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	mov	x0, x22
	mov	x1, x26
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #216]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x23, x26, eq
	add	x8, x1, x19
	csel	x23, x8, x23, eq
	csel	x26, x26, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #224]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x28
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	mov	x0, x22
	mov	x1, x26
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #200]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x23, x26, eq
	add	x8, x1, x19
	csel	x23, x8, x23, eq
	csel	x26, x26, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #208]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x28
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	mov	x0, x22
	mov	x1, x26
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #184]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x23, x26, eq
	add	x8, x1, x19
	csel	x23, x8, x23, eq
	csel	x26, x26, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #192]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x28
	csel	x25, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	mov	x0, x22
	mov	x1, x26
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #168]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x23, x26, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #176]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x25, eq
	add	x8, x1, x28
	csel	x23, x25, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #160]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	blr	x21
	ldr	x8, [sp, #328]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x23, x27, x8
	ldr	x8, [sp, #360]                  ; 8-byte Folded Reload
	mov	x1, x23
	add	x24, x23, x8
	mov	x2, x24
	add	x25, x24, x28
	add	x26, x25, x8
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #352]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	add	x8, x1, x19
	csel	x23, x23, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #152]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x23, x23, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x25
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #296]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x28
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x21
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #136]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x23, x23, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x25
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #144]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x28
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x21
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #120]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x23, x23, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x25
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #128]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x28
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x21
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #104]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x23, x23, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x25
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #112]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x28
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x21
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #88]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x23, x23, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x25
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #96]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x28
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x21
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #72]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x23, x23, x8, eq
	blr	x21
	mov	x0, x22
	mov	x1, x25
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #80]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x28
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	blr	x21
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #56]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	blr	x21
	mov	x0, x22
	mov	x1, x25
	mov	x2, x26
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #64]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x25, x26, eq
	add	x8, x1, x28
	csel	x23, x26, x8, eq
	csel	x24, x8, x25, eq
	blr	x21
	mov	x0, x22
	mov	x1, x24
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	ldr	x0, [sp, #48]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x24, x23, eq
	blr	x21
	ldr	x23, [sp, #352]                 ; 8-byte Folded Reload
	add	x1, sp, #416
	ldr	x8, [sp, #272]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x2, x23
	add	x28, x27, x8
	blr	x20
	and	w8, w0, #0xff
	add	x9, sp, #416
	cmp	w8, #1
	mov	x0, x27
	csel	x1, x23, x9, eq
	str	x27, [sp, #344]                 ; 8-byte Folded Spill
	add	x8, x1, x19
	csel	x24, x9, x8, eq
	csel	x25, x8, x23, eq
	blr	x21
	ldp	x27, x23, [sp, #280]            ; 16-byte Folded Reload
	mov	x22, #-15
	ldr	x26, [sp, #368]                 ; 8-byte Folded Reload
LBB36_98:                               ; %.cont.i404
                                        ;   Parent Loop BB36_94 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	x20, x21, [sp, #384]            ; 16-byte Folded Reload
	mov	x1, x24
	mov	x2, x25
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	ldp	x19, x8, [sp, #400]             ; 16-byte Folded Reload
	csel	x1, x25, x24, eq
	add	x8, x1, x8
	csel	x25, x8, x25, eq
	csel	x24, x24, x8, eq
	blr	x19
	mov	x0, x20
	mov	x1, x23
	mov	x2, x27
	blr	x21
	and	w8, w0, #0xff
	ldr	x21, [sp, #376]                 ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x28
	csel	x1, x23, x27, eq
	add	x8, x1, x21
	csel	x27, x27, x8, eq
	csel	x23, x8, x23, eq
	blr	x19
	ldr	x8, [sp, #408]                  ; 8-byte Folded Reload
	add	x28, x28, x21
	adds	x22, x22, #1
	add	x26, x26, x8
	b.lo	LBB36_98
; %bb.99:                               ; %sort.parity_merge__anon_16486.exit406
                                        ;   in Loop: Header=BB36_94 Depth=1
	ldp	x22, x20, [sp, #384]            ; 16-byte Folded Reload
	mov	x1, x23
	mov	x2, x27
	mov	x0, x22
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	ldr	x8, [sp, #400]                  ; 8-byte Folded Reload
	csel	x1, x23, x27, eq
	blr	x8
	ldp	x19, x27, [sp, #336]            ; 16-byte Folded Reload
	ldr	x25, [sp, #360]                 ; 8-byte Folded Reload
	ldr	x28, [sp, #376]                 ; 8-byte Folded Reload
	b	LBB36_93
LBB36_100:
	ldr	x7, [sp, #408]                  ; 8-byte Folded Reload
	sub	x8, x21, x19
	ldp	x6, x5, [sp, #384]              ; 16-byte Folded Reload
	add	x2, sp, #416
	mov	w3, #32
	udiv	x1, x8, x7
	mov	w4, #8
	ldr	x8, [sp, #400]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
	cmp	x24, #17
	b.lo	LBB36_106
LBB36_101:                              ; %.preheader.i.1
	ldr	x10, [sp, #408]                 ; 8-byte Folded Reload
	lsl	x8, x10, #4
	add	x9, x8, x27
	cmp	x9, x23
	b.hs	LBB36_106
; %bb.102:                              ; %.lr.ph.i.1
	lsl	x20, x10, #5
	mov	x19, xzr
	add	x22, x27, x20
	add	x24, x27, x8
LBB36_103:                              ; =>This Inner Loop Header: Depth=1
	add	x0, x27, x19
	add	x8, x22, x19
	cmp	x8, x23
	b.hs	LBB36_105
; %bb.104:                              ;   in Loop: Header=BB36_103 Depth=1
	ldp	x6, x5, [sp, #384]              ; 16-byte Folded Reload
	add	x2, sp, #416
	mov	w1, #32
	ldp	x8, x7, [sp, #400]              ; 16-byte Folded Reload
	mov	w3, #32
	mov	w4, #16
	str	x8, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
	add	x19, x19, x20
	add	x8, x24, x19
	cmp	x8, x23
	b.lo	LBB36_103
	b	LBB36_106
LBB36_105:
	ldr	x7, [sp, #408]                  ; 8-byte Folded Reload
	sub	x8, x21, x19
	ldp	x6, x5, [sp, #384]              ; 16-byte Folded Reload
	add	x2, sp, #416
	mov	w3, #32
	udiv	x1, x8, x7
	mov	w4, #16
	ldr	x8, [sp, #400]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
LBB36_106:                              ; %common.ret
	mov	w0, #1
LBB36_107:                              ; %common.ret
	add	sp, sp, #1, lsl #12             ; =4096
	.cfi_def_cfa_offset 160
	add	sp, sp, #64
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB36_108:                              ; %sort.quad_reversal.exit354
	.cfi_restore_state
	ldp	x8, x22, [sp, #376]             ; 16-byte Folded Reload
	ldr	x27, [sp, #344]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #408]                 ; 8-byte Folded Reload
	ldr	x20, [sp, #392]                 ; 8-byte Folded Reload
	ldr	x19, [sp, #32]                  ; 8-byte Folded Reload
	cmp	x8, x27
	b.ne	LBB36_85
; %bb.109:
	mov	w0, wzr
	b	LBB36_107
LBB36_110:                              ; %.critedge63
	cmp	x21, #2
	b.hs	LBB36_70
; %bb.111:                              ; %.critedge65
	cbnz	x21, LBB36_71
	b	LBB36_72
Lfunc_end36:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quad_merge__anon_14840
l_sort.quad_merge__anon_14840:          ; @sort.quad_merge__anon_14840
Lfunc_begin37:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #320
	.cfi_def_cfa_offset 320
	stp	x28, x27, [sp, #224]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #240]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #256]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #272]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #288]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #304]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	mul	x8, x6, x1
	mov	x24, x6
	mov	w28, #128
	cmp	x1, #128
	stp	x4, x3, [sp, #208]              ; 16-byte Folded Spill
	stp	x5, x2, [sp, #184]              ; 16-byte Folded Spill
	str	x8, [sp, #32]                   ; 8-byte Folded Spill
	add	x8, x0, x8
	str	x0, [sp, #160]                  ; 8-byte Folded Spill
	str	x7, [sp, #176]                  ; 8-byte Folded Spill
	str	x8, [sp, #96]                   ; 8-byte Folded Spill
	str	x1, [sp, #48]                   ; 8-byte Folded Spill
	b.lo	LBB37_26
; %bb.1:
	cmp	x3, #128
	b.lo	LBB37_26
; %bb.2:                                ; %.preheader.lr.ph
	lsl	x8, x24, #1
	mov	x23, x5
	mov	w28, #128
	str	x24, [sp, #200]                 ; 8-byte Folded Spill
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	add	x8, x8, x24
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
LBB37_3:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB37_9 Depth 2
                                        ;     Child Loop BB37_17 Depth 2
                                        ;       Child Loop BB37_19 Depth 3
	lsr	x9, x28, #1
	ldr	x26, [sp, #160]                 ; 8-byte Folded Reload
	lsr	x27, x28, #2
	mul	x10, x28, x24
	sub	x8, x27, #1
	mul	x11, x9, x24
	str	x9, [sp, #88]                   ; 8-byte Folded Spill
	madd	x9, x27, x24, x26
	madd	x8, x24, x8, x26
	mov	x19, xzr
	mov	x25, x26
	ldr	x22, [sp, #32]                  ; 8-byte Folded Reload
	str	x28, [sp, #40]                  ; 8-byte Folded Spill
	str	x9, [sp, #144]                  ; 8-byte Folded Spill
	lsl	x9, x27, #1
	str	x8, [sp, #136]                  ; 8-byte Folded Spill
	sub	x8, x9, #1
	ldr	x9, [sp, #24]                   ; 8-byte Folded Reload
	str	x10, [sp, #152]                 ; 8-byte Folded Spill
	madd	x9, x9, x27, x26
	str	x9, [sp, #128]                  ; 8-byte Folded Spill
	madd	x9, x24, x8, x26
	add	x8, x8, x27
	stp	x9, x11, [sp, #64]              ; 16-byte Folded Spill
	lsl	x9, x11, #1
	str	x9, [sp, #56]                   ; 8-byte Folded Spill
	ldr	x9, [sp, #16]                   ; 8-byte Folded Reload
	madd	x9, x9, x27, x26
	str	x9, [sp, #120]                  ; 8-byte Folded Spill
	ldr	x9, [sp, #192]                  ; 8-byte Folded Reload
	add	x9, x9, x11
	str	x9, [sp, #80]                   ; 8-byte Folded Spill
	madd	x9, x24, x8, x26
	add	x8, x26, x10
	stp	x8, x9, [sp, #104]              ; 16-byte Folded Spill
	b	LBB37_9
LBB37_4:                                ;   in Loop: Header=BB37_9 Depth=2
	ldr	x0, [sp, #192]                  ; 8-byte Folded Reload
	mov	x1, x20
	ldr	x2, [sp, #72]                   ; 8-byte Folded Reload
	bl	_memcpy
	ldr	x21, [sp, #208]                 ; 8-byte Folded Reload
	mov	x1, x24
	ldr	x23, [sp, #184]                 ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x0, [sp, #80]                   ; 8-byte Folded Reload
	mov	x3, x27
	mov	x4, x21
	mov	x6, x25
	mov	x5, x23
	mov	x28, x20
	ldr	x20, [sp, #176]                 ; 8-byte Folded Reload
LBB37_5:                                ;   in Loop: Header=BB37_9 Depth=2
	mov	x7, x20
	bl	l_sort.cross_merge__anon_14859
LBB37_6:                                ;   in Loop: Header=BB37_9 Depth=2
	ldr	x1, [sp, #192]                  ; 8-byte Folded Reload
	mov	x24, x25
	ldr	x25, [sp, #168]                 ; 8-byte Folded Reload
LBB37_7:                                ;   in Loop: Header=BB37_9 Depth=2
	ldr	x2, [sp, #88]                   ; 8-byte Folded Reload
	mov	x0, x28
	mov	x4, x21
	mov	x5, x23
	mov	x6, x24
	mov	x7, x20
	mov	x3, x2
	bl	l_sort.cross_merge__anon_14859
LBB37_8:                                ; %sort.quad_merge_block__anon_16491.exit
                                        ;   in Loop: Header=BB37_9 Depth=2
	ldr	x9, [sp, #152]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	add	x26, x26, x9
	add	x19, x19, x9
	sub	x22, x22, x9
	add	x25, x25, x9
	ldr	x9, [sp, #96]                   ; 8-byte Folded Reload
	add	x8, x8, x19
	cmp	x8, x9
	b.hi	LBB37_14
LBB37_9:                                ;   Parent Loop BB37_3 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	mov	x0, x23
	ldr	x21, [sp, #208]                 ; 8-byte Folded Reload
	str	x25, [sp, #168]                 ; 8-byte Folded Spill
	add	x20, x8, x19
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	add	x2, x8, x19
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	add	x24, x8, x19
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	add	x28, x8, x19
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	add	x1, x8, x19
	blr	x21
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	mov	x2, x28
	add	x1, x8, x19
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	cset	w23, ne
	blr	x21
	and	w8, w0, #0xff
Lloh53:
	adrp	x11, LJTI37_0@PAGE
Lloh54:
	add	x11, x11, LJTI37_0@PAGEOFF
	cmp	w8, #1
	cset	w8, ne
	orr	w8, w23, w8, lsl #1
	adr	x9, LBB37_4
	ldrb	w10, [x11, x8]
	add	x9, x9, x10, lsl #2
	ldr	x25, [sp, #200]                 ; 8-byte Folded Reload
	br	x9
LBB37_10:                               ;   in Loop: Header=BB37_9 Depth=2
	ldp	x23, x0, [sp, #184]             ; 16-byte Folded Reload
	mov	x1, x20
	mov	x28, x20
	ldr	x21, [sp, #208]                 ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x20, [sp, #176]                 ; 8-byte Folded Reload
	mov	x3, x27
	mov	x5, x23
	mov	x6, x25
	mov	x4, x21
	mov	x7, x20
	bl	l_sort.cross_merge__anon_14859
	ldr	x0, [sp, #80]                   ; 8-byte Folded Reload
	mov	x1, x24
	mov	x2, x27
	mov	x3, x27
	mov	x4, x21
	mov	x5, x23
	mov	x6, x25
	b	LBB37_5
LBB37_11:                               ;   in Loop: Header=BB37_9 Depth=2
	ldp	x23, x0, [sp, #184]             ; 16-byte Folded Reload
	mov	x1, x20
	mov	x28, x20
	ldr	x21, [sp, #208]                 ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x20, [sp, #176]                 ; 8-byte Folded Reload
	mov	x3, x27
	mov	x5, x23
	mov	x6, x25
	mov	x4, x21
	mov	x7, x20
	bl	l_sort.cross_merge__anon_14859
	ldp	x2, x0, [sp, #72]               ; 16-byte Folded Reload
	mov	x1, x24
	bl	_memcpy
	b	LBB37_6
LBB37_12:                               ;   in Loop: Header=BB37_9 Depth=2
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x2, x24
	ldr	x23, [sp, #184]                 ; 8-byte Folded Reload
	ldr	x21, [sp, #208]                 ; 8-byte Folded Reload
	add	x1, x8, x19
	mov	x0, x23
	blr	x21
	mov	x24, x25
	ldr	x25, [sp, #168]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB37_8
; %bb.13:                               ;   in Loop: Header=BB37_9 Depth=2
	ldr	x28, [sp, #192]                 ; 8-byte Folded Reload
	mov	x1, x20
	ldr	x2, [sp, #56]                   ; 8-byte Folded Reload
	mov	x0, x28
	bl	_memcpy
	mov	x1, x28
	mov	x28, x20
	ldr	x20, [sp, #176]                 ; 8-byte Folded Reload
	b	LBB37_7
LBB37_14:                               ;   in Loop: Header=BB37_3 Depth=1
	udiv	x8, x22, x24
	ldr	x3, [sp, #216]                  ; 8-byte Folded Reload
	cmp	x27, x8
	str	x8, [sp, #168]                  ; 8-byte Folded Spill
	b.hs	LBB37_24
; %bb.15:                               ;   in Loop: Header=BB37_3 Depth=1
	cmp	x27, x3
	b.hi	LBB37_24
; %bb.16:                               ; %.preheader.lr.ph.i16
                                        ;   in Loop: Header=BB37_3 Depth=1
	ldr	x8, [sp, #168]                  ; 8-byte Folded Reload
	madd	x22, x8, x24, x26
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	add	x9, x8, x19
	add	x8, x8, x19
	stp	x9, x8, [sp, #144]              ; 16-byte Folded Spill
LBB37_17:                               ; %.preheader.i18
                                        ;   Parent Loop BB37_3 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB37_19 Depth 3
	ldr	x9, [sp, #152]                  ; 8-byte Folded Reload
	mul	x8, x27, x24
	lsl	x21, x27, #1
	add	x9, x9, x8
	cmp	x9, x22
	b.hs	LBB37_22
; %bb.18:                               ; %.lr.ph.i19
                                        ;   in Loop: Header=BB37_17 Depth=2
	ldr	x9, [sp, #200]                  ; 8-byte Folded Reload
	mov	x28, xzr
	add	x23, x25, x8
	ldr	x24, [sp, #144]                 ; 8-byte Folded Reload
	mul	x19, x21, x9
	add	x20, x25, x19
LBB37_19:                               ;   Parent Loop BB37_3 Depth=1
                                        ;     Parent Loop BB37_17 Depth=2
                                        ; =>    This Inner Loop Header: Depth=3
	add	x0, x26, x28
	add	x8, x20, x28
	cmp	x8, x22
	b.hs	LBB37_21
; %bb.20:                               ;   in Loop: Header=BB37_19 Depth=3
	ldp	x6, x2, [sp, #184]              ; 16-byte Folded Reload
	mov	x1, x21
	mov	x4, x27
	ldp	x5, x3, [sp, #208]              ; 16-byte Folded Reload
	ldr	x7, [sp, #200]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
	ldr	x3, [sp, #216]                  ; 8-byte Folded Reload
	add	x28, x28, x19
	add	x24, x24, x19
	add	x8, x23, x28
	cmp	x8, x22
	b.lo	LBB37_19
	b	LBB37_22
LBB37_21:                               ;   in Loop: Header=BB37_17 Depth=2
	ldp	x2, x7, [sp, #192]              ; 16-byte Folded Reload
	sub	x8, x22, x24
	mov	x4, x27
	ldp	x5, x3, [sp, #208]              ; 16-byte Folded Reload
	udiv	x1, x8, x7
	ldp	x8, x6, [sp, #176]              ; 16-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
	ldr	x3, [sp, #216]                  ; 8-byte Folded Reload
LBB37_22:                               ; %.loopexit.i20
                                        ;   in Loop: Header=BB37_17 Depth=2
	ldr	x8, [sp, #168]                  ; 8-byte Folded Reload
	ldr	x24, [sp, #200]                 ; 8-byte Folded Reload
	cmp	x21, x8
	b.hs	LBB37_24
; %bb.23:                               ; %.loopexit.i20
                                        ;   in Loop: Header=BB37_17 Depth=2
	mov	x27, x21
	cmp	x21, x3
	b.ls	LBB37_17
LBB37_24:                               ; %sort.tail_merge__anon_16490.exit22
                                        ;   in Loop: Header=BB37_3 Depth=1
	ldp	x28, x1, [sp, #40]              ; 16-byte Folded Reload
	lsl	x28, x28, #2
	cmp	x28, x1
	b.hi	LBB37_26
; %bb.25:                               ; %sort.tail_merge__anon_16490.exit22
                                        ;   in Loop: Header=BB37_3 Depth=1
	ldr	x23, [sp, #184]                 ; 8-byte Folded Reload
	cmp	x28, x3
	b.ls	LBB37_3
LBB37_26:                               ; %._crit_edge
	lsr	x21, x28, #2
	ldr	x26, [sp, #192]                 ; 8-byte Folded Reload
	ldr	x27, [sp, #96]                  ; 8-byte Folded Reload
	cmp	x21, x1
	b.hs	LBB37_35
; %bb.27:                               ; %._crit_edge
	cmp	x21, x3
	b.hi	LBB37_35
LBB37_28:                               ; %.preheader.i
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB37_30 Depth 2
	ldr	x9, [sp, #160]                  ; 8-byte Folded Reload
	mul	x8, x21, x24
	mov	x25, x24
	lsl	x22, x21, #1
	add	x9, x8, x9
	cmp	x9, x27
	b.hs	LBB37_33
; %bb.29:                               ; %.lr.ph.i
                                        ;   in Loop: Header=BB37_28 Depth=1
	ldr	x9, [sp, #160]                  ; 8-byte Folded Reload
	mul	x20, x22, x25
	mov	x19, xzr
	add	x23, x9, x8
	add	x24, x9, x20
LBB37_30:                               ;   Parent Loop BB37_28 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	add	x0, x8, x19
	add	x8, x24, x19
	cmp	x8, x27
	b.hs	LBB37_32
; %bb.31:                               ;   in Loop: Header=BB37_30 Depth=2
	ldp	x5, x3, [sp, #208]              ; 16-byte Folded Reload
	mov	x1, x22
	mov	x2, x26
	ldp	x8, x6, [sp, #176]              ; 16-byte Folded Reload
	mov	x4, x21
	mov	x7, x25
	str	x8, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
	ldr	x3, [sp, #216]                  ; 8-byte Folded Reload
	add	x19, x19, x20
	add	x8, x23, x19
	cmp	x8, x27
	b.lo	LBB37_30
	b	LBB37_33
LBB37_32:                               ;   in Loop: Header=BB37_28 Depth=1
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	mov	x7, x25
	ldp	x5, x3, [sp, #208]              ; 16-byte Folded Reload
	mov	x2, x26
	mov	x4, x21
	sub	x8, x8, x19
	udiv	x1, x8, x25
	ldp	x8, x6, [sp, #176]              ; 16-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
	ldr	x3, [sp, #216]                  ; 8-byte Folded Reload
LBB37_33:                               ; %.loopexit.i
                                        ;   in Loop: Header=BB37_28 Depth=1
	ldr	x1, [sp, #48]                   ; 8-byte Folded Reload
	cmp	x22, x1
	b.hs	LBB37_35
; %bb.34:                               ; %.loopexit.i
                                        ;   in Loop: Header=BB37_28 Depth=1
	mov	x24, x25
	mov	x21, x22
	cmp	x22, x3
	b.ls	LBB37_28
LBB37_35:                               ; %sort.tail_merge__anon_16490.exit
	lsr	x0, x28, #1
	ldp	x29, x30, [sp, #304]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #288]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #272]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #256]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #240]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #224]            ; 16-byte Folded Reload
	add	sp, sp, #320
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
	.loh AdrpAdd	Lloh53, Lloh54
Lfunc_end37:
	.cfi_endproc
	.section	__TEXT,__const
LJTI37_0:
	.byte	(LBB37_10-LBB37_4)>>2
	.byte	(LBB37_4-LBB37_4)>>2
	.byte	(LBB37_11-LBB37_4)>>2
	.byte	(LBB37_12-LBB37_4)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function sort.rotate_merge__anon_14841
l_sort.rotate_merge__anon_14841:        ; @sort.rotate_merge__anon_14841
Lfunc_begin38:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #160
	.cfi_def_cfa_offset 160
	stp	x28, x27, [sp, #64]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #80]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #96]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x26, x4
	mov	x22, x3
	mov	x23, x2
	mov	x25, x0
	ldr	x8, [sp, #160]
	cmp	x1, x4, lsl #1
	stp	x5, x6, [sp, #48]               ; 16-byte Folded Spill
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	b.hi	LBB38_3
; %bb.1:
	sub	x8, x1, x26
	cmp	x8, x22
	b.hi	LBB38_3
; %bb.2:
	mov	x0, x25
	mov	x2, x23
	mov	x3, x22
	mov	x4, x26
	ldp	x5, x6, [sp, #48]               ; 16-byte Folded Reload
	mov	x7, x19
	ldp	x29, x30, [sp, #144]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #128]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             ; 16-byte Folded Reload
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	str	x8, [sp, #160]
	add	sp, sp, #160
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_backwards_merge__anon_16492
LBB38_3:                                ; %.preheader21
	.cfi_restore_state
	cmp	x1, x26
	b.ls	LBB38_11
; %bb.4:
	mul	x8, x19, x1
	add	x28, x25, x8
	stp	x8, x1, [sp, #16]               ; 16-byte Folded Spill
	b	LBB38_7
LBB38_5:                                ;   in Loop: Header=BB38_7 Depth=1
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	mov	x1, x23
	ldp	x5, x6, [sp, #48]               ; 16-byte Folded Reload
	mov	x2, x22
	mov	x3, x26
	sub	x8, x8, x24
	mov	x7, x19
	udiv	x8, x8, x19
	sub	x4, x8, x26
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.rotate_merge_block__anon_16493
LBB38_6:                                ; %.loopexit
                                        ;   in Loop: Header=BB38_7 Depth=1
	ldp	x1, x8, [sp, #24]               ; 16-byte Folded Reload
	mov	x26, x8
	cmp	x8, x1
	b.hs	LBB38_11
LBB38_7:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB38_9 Depth 2
	mul	x8, x26, x19
	lsl	x10, x26, #1
	add	x9, x8, x25
	cmp	x9, x28
	str	x10, [sp, #32]                  ; 8-byte Folded Spill
	b.hs	LBB38_6
; %bb.8:                                ; %.lr.ph
                                        ;   in Loop: Header=BB38_7 Depth=1
	ldr	x9, [sp, #32]                   ; 8-byte Folded Reload
	mov	x24, xzr
	add	x21, x25, x8
	mul	x20, x9, x19
	add	x27, x25, x20
LBB38_9:                                ;   Parent Loop BB38_7 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x0, x25, x24
	add	x8, x27, x24
	cmp	x8, x28
	b.hs	LBB38_5
; %bb.10:                               ;   in Loop: Header=BB38_9 Depth=2
	ldp	x5, x6, [sp, #48]               ; 16-byte Folded Reload
	mov	x1, x23
	mov	x2, x22
	mov	x3, x26
	mov	x4, x26
	mov	x7, x19
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.rotate_merge_block__anon_16493
	add	x24, x24, x20
	add	x8, x21, x24
	cmp	x8, x28
	b.lo	LBB38_9
	b	LBB38_6
LBB38_11:                               ; %common.ret1
	ldp	x29, x30, [sp, #144]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #128]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             ; 16-byte Folded Reload
	add	sp, sp, #160
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end38:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quadsort_stack_swap__anon_14842
l_sort.quadsort_stack_swap__anon_14842: ; @sort.quadsort_stack_swap__anon_14842
Lfunc_begin39:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-80]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 80
	stp	x24, x23, [sp, #16]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	sub	sp, sp, #12, lsl #12            ; =49152
	.cfi_def_cfa_offset 49232
	sub	sp, sp, #16
	.cfi_def_cfa_offset 49248
	mov	x19, x5
	mov	x20, x4
	mov	x21, x3
	mov	x22, x2
	add	x2, sp, #16
	mov	w3, #512
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	mov	x23, x1
	mov	x24, x0
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	add	x2, sp, #16
	mov	x0, x24
	mov	x1, x23
	mov	w3, #512
	mov	x5, x22
	mov	x6, x21
	mov	x7, x20
	str	x19, [sp]
	bl	l_sort.rotate_merge__anon_14841
	add	sp, sp, #12, lsl #12            ; =49152
	.cfi_def_cfa_offset 96
	add	sp, sp, #16
	.cfi_def_cfa_offset 80
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end39:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.tail_swap__anon_14843
l_sort.tail_swap__anon_14843:           ; @sort.tail_swap__anon_14843
Lfunc_begin40:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x28, x27, [sp, #48]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x27, x4
	mov	x25, x2
	cmp	x1, #8
	stp	x0, x3, [sp, #24]               ; 16-byte Folded Spill
	str	x5, [sp, #40]                   ; 8-byte Folded Spill
	b.hs	LBB40_3
; %bb.1:
Lloh55:
	adrp	x8, LJTI40_0@PAGE
Lloh56:
	add	x8, x8, LJTI40_0@PAGEOFF
	mov	x26, x25
	adr	x9, LBB40_2
	ldrh	w10, [x8, x1, lsl #1]
	add	x9, x9, x10, lsl #2
	br	x9
LBB40_2:
	mov	x0, x27
	mov	w1, #1
	blr	x5
	ldp	x19, x8, [sp, #24]              ; 16-byte Folded Reload
	mov	x0, x27
	ldp	x1, x2, [x19]
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x9, [x19, w9, uxtw #3]
	stp	x8, x9, [x19]
	b	LBB40_17
LBB40_3:
	ldp	x21, x19, [sp, #24]             ; 16-byte Folded Reload
	lsr	x24, x1, #1
	lsr	x28, x1, #2
	sub	x8, x1, x24
	mov	x1, x28
	mov	x2, x25
	mov	x4, x27
	mov	x0, x21
	lsr	x26, x8, #1
	mov	x3, x19
	sub	x20, x24, x28
	str	x8, [sp, #8]                    ; 8-byte Folded Spill
	sub	x23, x8, x26
	bl	l_sort.tail_swap__anon_14843
	add	x21, x21, x28, lsl #3
	mov	x1, x20
	mov	x0, x21
	mov	x2, x25
	mov	x3, x19
	mov	x4, x27
	ldr	x5, [sp, #40]                   ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14843
	add	x22, x21, x20, lsl #3
	mov	x1, x26
	mov	x0, x22
	mov	x2, x25
	mov	x3, x19
	mov	x4, x27
	ldr	x5, [sp, #40]                   ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14843
	add	x22, x22, x26, lsl #3
	mov	x1, x23
	mov	x0, x22
	mov	x2, x25
	mov	x3, x19
	mov	x4, x27
	ldr	x5, [sp, #40]                   ; 8-byte Folded Reload
	str	x23, [sp]                       ; 8-byte Folded Spill
	str	x25, [sp, #16]                  ; 8-byte Folded Spill
	bl	l_sort.tail_swap__anon_14843
	mov	x0, x27
	mov	w1, #1
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x1, x2, [x21, #-8]
	mov	x0, x27
	blr	x19
	ldr	x9, [sp, #40]                   ; 8-byte Folded Reload
	lsl	x21, x24, #3
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB40_6
; %bb.4:
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x0, x27
	mov	w1, #1
	add	x19, x8, x21
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x1, x2, [x19, #-8]
	mov	x0, x27
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	blr	x8
	ldr	x9, [sp, #40]                   ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB40_6
; %bb.5:
	mov	x0, x27
	mov	w1, #1
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x1, x2, [x22, #-8]
	mov	x0, x27
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	blr	x8
	ldr	x9, [sp, #40]                   ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB40_17
LBB40_6:                                ; %.critedge
	ldp	x22, x19, [sp, #16]             ; 16-byte Folded Reload
	mov	x2, x28
	mov	x3, x20
	ldr	x23, [sp, #32]                  ; 8-byte Folded Reload
	mov	x5, x27
	mov	x6, x9
	mov	x20, x9
	mov	x0, x22
	mov	x1, x19
	mov	x4, x23
	bl	l_sort.parity_merge__anon_16495
	add	x0, x22, x21
	add	x1, x19, x21
	mov	x2, x26
	ldr	x3, [sp]                        ; 8-byte Folded Reload
	mov	x4, x23
	mov	x5, x27
	mov	x6, x20
	bl	l_sort.parity_merge__anon_16495
	mov	x0, x19
	mov	x1, x22
	mov	x2, x24
	mov	x4, x23
	mov	x5, x27
	mov	x6, x20
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             ; 16-byte Folded Reload
	ldr	x3, [sp, #8]                    ; 8-byte Folded Reload
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.parity_merge__anon_16495
LBB40_7:
	.cfi_restore_state
	mov	x0, x27
	mov	w1, #3
	blr	x5
	ldp	x19, x21, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	mov	x20, x19
	ldr	x1, [x19]
	ldr	x2, [x20, #8]!
	blr	x21
	and	w8, w0, #0xff
	ldr	x2, [x19, #16]
	cmp	w8, #1
	mov	x0, x27
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x1, [x19, w9, uxtw #3]
	str	x8, [x19]
	str	x1, [x20]
	blr	x21
	and	w9, w0, #0xff
	mov	w8, #16
	cmp	w9, #1
	mov	w9, #8
	cset	w10, eq
	csel	x8, x9, x8, eq
	ldr	x1, [x19]
	mov	x0, x27
	ldr	x2, [x20, w10, uxtw #3]
	ldr	x8, [x19, x8]
	str	x2, [x20]
	str	x8, [x19, #16]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x9, [x19, w9, uxtw #3]
	str	x8, [x19]
	str	x9, [x20]
	b	LBB40_17
LBB40_8:
	mov	x0, x27
	mov	w1, #3
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x19, x22, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	mov	x20, x19
	ldr	x1, [x19]
	ldr	x2, [x20, #8]!
	blr	x22
	and	w8, w0, #0xff
	mov	x21, x19
	cmp	w8, #1
	ldr	x2, [x19, #24]
	cset	w8, eq
	cset	w9, ne
	ldr	x1, [x21, #16]!
	mov	x0, x27
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x9, [x19, w9, uxtw #3]
	str	x8, [x19]
	str	x9, [x20]
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	mov	w9, #16
	cset	w10, eq
	csel	x8, x9, x8, eq
	ldr	x1, [x20]
	mov	x0, x27
	ldr	x2, [x21, w10, uxtw #3]
	ldr	x8, [x19, x8]
	str	x2, [x21]
	str	x8, [x19, #24]
	blr	x22
	ldr	x9, [sp, #40]                   ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB40_17
; %bb.9:
	mov	x0, x27
	mov	w1, #3
	blr	x9
	ldp	x19, x23, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	ldp	x8, x2, [x19, #8]
	ldr	x1, [x19]
	stp	x2, x8, [x19, #8]
	blr	x23
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldp	x1, x2, [x19, #16]
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x9, [x19, w9, uxtw #3]
	stp	x8, x9, [x19]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	mov	w22, #16
	cset	w9, eq
	csel	x8, x22, x8, eq
	ldr	x1, [x19, #8]
	mov	x0, x27
	ldr	x2, [x21, w9, uxtw #3]
	ldr	x8, [x19, x8]
	stp	x2, x8, [x19, #16]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #8
	cmp	w9, #1
	cset	w9, eq
	csel	x8, x8, x22, eq
	ldr	x9, [x20, w9, uxtw #3]
	ldr	x8, [x19, x8]
	stp	x9, x8, [x19, #8]
	b	LBB40_17
LBB40_10:
	mov	x0, x27
	mov	w1, #4
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x19, x23, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	mov	x21, x19
	ldr	x1, [x19]
	ldr	x2, [x21, #8]!
	blr	x23
	and	w8, w0, #0xff
	mov	x20, x19
	cmp	w8, #1
	mov	x22, x19
	cset	w8, eq
	cset	w9, ne
	ldr	x1, [x20, #16]!
	ldr	x2, [x22, #24]!
	ldr	x8, [x19, w8, uxtw #3]
	mov	x0, x27
	ldr	x9, [x19, w9, uxtw #3]
	str	x8, [x19]
	str	x9, [x21]
	blr	x23
	and	w8, w0, #0xff
	mov	w24, #24
	cmp	w8, #1
	mov	w25, #16
	cset	w8, eq
	csel	x9, x25, x24, eq
	ldr	x1, [x21]
	mov	x0, x27
	ldr	x2, [x20, w8, uxtw #3]
	ldr	x8, [x19, x9]
	str	x2, [x20]
	str	x8, [x22]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #8
	cmp	w9, #1
	ldr	x1, [x22]
	cset	w26, eq
	csel	x8, x8, x25, eq
	ldr	x2, [x19, #32]
	mov	x0, x27
	ldr	x9, [x21, w26, uxtw #3]
	ldr	x8, [x19, x8]
	str	x9, [x21]
	str	x8, [x20]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #32
	cmp	w9, #1
	ldr	x11, [sp, #40]                  ; 8-byte Folded Reload
	cset	w9, eq
	csel	x8, x24, x8, eq
	csetm	w10, eq
	cmp	w26, w10
	ldr	x9, [x22, w9, uxtw #3]
	ldr	x8, [x19, x8]
	str	x9, [x22]
	str	x8, [x19, #32]
	b.eq	LBB40_17
; %bb.11:
	mov	x0, x27
	mov	w1, #6
	blr	x11
	ldp	x19, x25, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	ldp	x1, x2, [x19]
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldp	x1, x2, [x19, #16]
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x9, [x19, w9, uxtw #3]
	stp	x8, x9, [x19]
	blr	x25
	and	w8, w0, #0xff
	mov	w23, #24
	cmp	w8, #1
	mov	w24, #16
	cset	w8, eq
	csel	x9, x24, x23, eq
	ldr	x1, [x19, #8]
	mov	x0, x27
	ldr	x2, [x20, w8, uxtw #3]
	ldr	x8, [x19, x9]
	stp	x2, x8, [x19, #16]
	blr	x25
	and	w9, w0, #0xff
	mov	w8, #8
	cmp	w9, #1
	mov	x0, x27
	cset	w9, eq
	csel	x8, x8, x24, eq
	ldp	x1, x2, [x19, #24]
	ldr	x9, [x21, w9, uxtw #3]
	ldr	x8, [x19, x8]
	stp	x9, x8, [x19, #8]
	blr	x25
	and	w9, w0, #0xff
	mov	w8, #32
	cmp	w9, #1
	mov	x0, x27
	cset	w9, eq
	csel	x8, x23, x8, eq
	ldp	x1, x2, [x19]
	ldr	x9, [x22, w9, uxtw #3]
	ldr	x8, [x19, x8]
	stp	x9, x8, [x19, #24]
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldp	x1, x2, [x19, #16]
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x9, [x19, w9, uxtw #3]
	stp	x8, x9, [x19]
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, eq
	csel	x9, x24, x23, eq
	ldr	x8, [x20, w8, uxtw #3]
	ldr	x9, [x19, x9]
	stp	x8, x9, [x19, #16]
	b	LBB40_17
LBB40_12:
	mov	x0, x27
	mov	w1, #6
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x19, x23, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	mov	x24, x19
	ldr	x1, [x19]
	ldr	x2, [x24, #8]!
	blr	x23
	and	w8, w0, #0xff
	mov	x25, x19
	cmp	w8, #1
	mov	x20, x19
	cset	w8, eq
	cset	w9, ne
	ldr	x1, [x25, #16]!
	ldr	x2, [x20, #24]!
	ldr	x8, [x19, w8, uxtw #3]
	mov	x0, x27
	ldr	x9, [x19, w9, uxtw #3]
	str	x8, [x19]
	str	x9, [x24]
	blr	x23
	and	w8, w0, #0xff
	mov	w9, #24
	cmp	w8, #1
	mov	w10, #16
	cset	w8, eq
	csel	x9, x10, x9, eq
	mov	x22, x19
	mov	x21, x19
	mov	x0, x27
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x19, x9]
	ldr	x1, [x22, #32]!
	ldr	x2, [x21, #40]!
	str	x8, [x25]
	str	x9, [x20]
	blr	x23
	and	w8, w0, #0xff
	mov	w9, #40
	cmp	w8, #1
	mov	w10, #32
	cset	w8, eq
	csel	x9, x10, x9, eq
	ldr	x1, [x24]
	mov	x0, x27
	ldr	x2, [x25]
	ldr	x8, [x22, w8, uxtw #3]
	ldr	x9, [x19, x9]
	str	x8, [x22]
	str	x9, [x21]
	blr	x23
	mov	x28, x27
	and	w27, w0, #0xff
	mov	w8, #8
	cmp	w27, #1
	mov	w10, #16
	cset	w9, eq
	csel	x8, x8, x10, eq
	ldr	x1, [x20]
	ldr	x2, [x22]
	mov	x0, x28
	ldr	x9, [x24, w9, uxtw #3]
	ldr	x8, [x19, x8]
	str	x9, [x24]
	str	x8, [x25]
	blr	x23
	and	w8, w0, #0xff
	mov	w9, #24
	cmp	w8, #1
	mov	w10, #32
	cset	w8, eq
	csel	x9, x9, x10, eq
	ldr	x1, [x21]
	mov	x0, x28
	ldr	x2, [x19, #48]
	cmp	w27, #1
	ldr	x10, [x20, w8, uxtw #3]
	cinc	w24, w8, eq
	ldr	x9, [x19, x9]
	str	x10, [x20]
	str	x9, [x22]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #48
	cmp	w9, #1
	mov	w10, #40
	cset	w9, eq
	csel	x8, x10, x8, eq
	ldr	x11, [sp, #40]                  ; 8-byte Folded Reload
	csetm	w10, eq
	cmp	w24, w10
	ldr	x9, [x21, w9, uxtw #3]
	ldr	x8, [x19, x8]
	str	x9, [x21]
	str	x8, [x19, #48]
	b.eq	LBB40_17
; %bb.13:                               ; %.cont110.i.i
	mov	x0, x28
	mov	w1, #11
	blr	x11
	ldp	x19, x24, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x28
	ldp	x1, x2, [x19, #32]
	blr	x24
	and	w9, w0, #0xff
	mov	w8, #40
	cmp	w9, #1
	mov	w9, #32
	cset	w10, eq
	csel	x8, x9, x8, eq
	ldp	x1, x2, [x19]
	mov	x0, x28
	ldr	x9, [x22, w10, uxtw #3]
	ldr	x8, [x19, x8]
	stp	x9, x8, [x19, #32]
	blr	x24
	and	w8, w0, #0xff
	mov	x22, x26
	cmp	w8, #1
	mov	x0, x28
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x19, w8, uxtw #3]
	str	x8, [x26]
	ldr	x8, [x19, w9, uxtw #3]
	str	x8, [x26, #8]
	ldr	x8, [x19, #16]
	str	x8, [x22, #16]!
	ldp	x1, x2, [x19, #24]
	blr	x24
	and	w8, w0, #0xff
	mov	x23, x26
	cmp	w8, #1
	mov	x0, x28
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x20, w8, uxtw #3]
	str	x8, [x23, #24]!
	ldr	x8, [x20, w9, uxtw #3]
	str	x8, [x26, #32]
	ldp	x1, x2, [x19, #40]
	blr	x24
	and	w8, w0, #0xff
	mov	x20, x26
	cmp	w8, #1
	ldr	x1, [x26]
	cset	w8, eq
	cset	w9, ne
	ldr	x2, [x23]
	mov	x0, x28
	ldr	x8, [x21, w8, uxtw #3]
	str	x8, [x26, #40]
	ldr	x8, [x21, w9, uxtw #3]
	str	x8, [x20, #48]!
	blr	x24
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	mov	x0, x28
	csel	x8, x8, xzr, eq
	csel	x9, x23, x26, eq
	add	x9, x9, #8
	csel	x21, x26, x9, eq
	csel	x23, x9, x23, eq
	ldr	x8, [x26, x8]
	str	x8, [x19]
	ldr	x1, [x21]
	ldr	x2, [x23]
	blr	x24
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x8, x23, x21, eq
	ldr	x9, [x8], #8
	csel	x21, x21, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [x19, #8]
	ldr	x1, [x21]
	ldr	x2, [x23]
	blr	x24
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x8, x23, x21, eq
	ldr	x8, [x8]
	str	x8, [x19, #16]
	ldr	x1, [x22]
	ldr	x2, [x20]
	blr	x24
	and	w9, w0, #0xff
	mov	w8, #48
	cmp	w9, #1
	mov	x0, x28
	csel	x10, x22, x20, eq
	cmp	w9, #1
	mov	w9, #16
	csel	x8, x9, x8, eq
	sub	x9, x10, #8
	csel	x21, x9, x22, eq
	csel	x20, x20, x9, eq
	ldr	x8, [x26, x8]
	str	x8, [x19, #48]
	ldr	x1, [x21]
	ldr	x2, [x20]
	blr	x24
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x8, x21, x20, eq
	ldr	x9, [x8], #-8
	csel	x21, x8, x21, eq
	csel	x20, x20, x8, eq
	str	x9, [x19, #40]
	ldr	x1, [x21]
	ldr	x2, [x20]
	blr	x24
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x8, x21, x20, eq
	ldr	x9, [x8], #-8
	csel	x21, x8, x21, eq
	csel	x20, x20, x8, eq
	str	x9, [x19, #32]
	ldr	x1, [x21]
	ldr	x2, [x20]
	blr	x24
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x21, x20, eq
	ldr	x8, [x8]
	str	x8, [x19, #24]
	b	LBB40_17
LBB40_14:
	mov	x0, x27
	mov	w1, #5
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x19, x23, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	mov	x20, x19
	ldr	x1, [x19]
	ldr	x2, [x20, #8]!
	blr	x23
	and	w8, w0, #0xff
	ldr	x2, [x19, #16]
	cmp	w8, #1
	mov	x0, x27
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x1, [x19, w9, uxtw #3]
	str	x8, [x19]
	str	x1, [x20]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #16
	cmp	w9, #1
	mov	w9, #8
	cset	w10, eq
	csel	x8, x9, x8, eq
	mov	x21, x19
	mov	x22, x19
	mov	x0, x27
	ldr	x9, [x20, w10, uxtw #3]
	ldr	x8, [x19, x8]
	ldr	x1, [x21, #32]!
	ldr	x2, [x22, #40]!
	str	x9, [x20]
	str	x8, [x19, #16]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #40
	cmp	w9, #1
	mov	w24, #32
	cset	w9, eq
	csel	x8, x24, x8, eq
	mov	x20, x19
	mov	x0, x27
	ldr	x2, [x21, w9, uxtw #3]
	ldr	x8, [x19, x8]
	ldr	x1, [x20, #24]!
	str	x2, [x21]
	str	x8, [x22]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	ldr	x1, [x19, #16]
	cset	w9, eq
	csel	x8, x8, x24, eq
	mov	x0, x27
	ldr	x2, [x20, w9, uxtw #3]
	ldr	x8, [x19, x8]
	str	x2, [x20]
	str	x8, [x21]
	blr	x23
	ldr	x9, [sp, #40]                   ; 8-byte Folded Reload
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	b.ne	LBB40_16
; %bb.15:                               ; %.cont96.i.i
	mov	w1, #8
	blr	x9
	ldp	x19, x25, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	ldp	x1, x2, [x19]
	blr	x25
	and	w8, w0, #0xff
	mov	x22, x26
	cmp	w8, #1
	mov	x0, x27
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x19, w8, uxtw #3]
	str	x8, [x26]
	ldr	x8, [x19, w9, uxtw #3]
	str	x8, [x26, #8]
	ldr	x8, [x19, #16]
	str	x8, [x22, #16]!
	ldp	x1, x2, [x19, #32]
	blr	x25
	and	w8, w0, #0xff
	mov	x23, x26
	cmp	w8, #1
	ldr	x1, [x26]
	cset	w8, eq
	cset	w9, ne
	mov	x0, x27
	ldr	x8, [x21, w8, uxtw #3]
	str	x8, [x26, #32]
	ldr	x8, [x21, w9, uxtw #3]
	mov	x21, x26
	str	x8, [x21, #40]!
	ldr	x2, [x19, #24]
	str	x2, [x23, #24]!
	blr	x25
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	mov	x0, x27
	csel	x8, x8, xzr, eq
	csel	x9, x23, x26, eq
	add	x9, x9, #8
	csel	x24, x26, x9, eq
	csel	x23, x9, x23, eq
	ldr	x8, [x26, x8]
	str	x8, [x19]
	ldr	x1, [x24]
	ldr	x2, [x23]
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	csel	x8, x23, x24, eq
	ldr	x9, [x8], #8
	csel	x24, x24, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [x19, #8]
	ldr	x1, [x24]
	ldr	x2, [x23]
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	csel	x8, x23, x24, eq
	ldr	x8, [x8]
	str	x8, [x19, #16]
	ldr	x1, [x22]
	ldr	x2, [x21]
	blr	x25
	and	w9, w0, #0xff
	mov	w8, #40
	cmp	w9, #1
	mov	x0, x27
	csel	x10, x22, x21, eq
	cmp	w9, #1
	mov	w9, #16
	csel	x8, x9, x8, eq
	sub	x9, x10, #8
	csel	x22, x9, x22, eq
	csel	x21, x21, x9, eq
	ldr	x8, [x26, x8]
	str	x8, [x19, #40]
	ldr	x1, [x22]
	ldr	x2, [x21]
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	csel	x8, x22, x21, eq
	ldr	x9, [x8], #-8
	csel	x22, x8, x22, eq
	csel	x21, x21, x8, eq
	str	x9, [x19, #32]
	ldr	x1, [x22]
	ldr	x2, [x21]
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x22, x21, eq
	ldr	x8, [x8]
	str	x8, [x20]
	b	LBB40_17
LBB40_16:
	mov	w1, #2
	blr	x9
	ldp	x19, x20, [sp, #24]             ; 16-byte Folded Reload
	mov	x0, x27
	ldp	x1, x2, [x19]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldp	x1, x2, [x19, #32]
	ldr	x8, [x19, w8, uxtw #3]
	ldr	x9, [x19, w9, uxtw #3]
	stp	x8, x9, [x19]
	blr	x20
	and	w9, w0, #0xff
	mov	w8, #40
	cmp	w9, #1
	mov	w9, #32
	cset	w10, eq
	csel	x8, x9, x8, eq
	ldr	x9, [x21, w10, uxtw #3]
	ldr	x8, [x19, x8]
	str	x9, [x19, #32]
	str	x8, [x22]
LBB40_17:                               ; %common.ret1
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
	.loh AdrpAdd	Lloh55, Lloh56
Lfunc_end40:
	.cfi_endproc
	.section	__TEXT,__const
	.p2align	1, 0x0
LJTI40_0:
	.short	(LBB40_17-LBB40_2)>>2
	.short	(LBB40_17-LBB40_2)>>2
	.short	(LBB40_2-LBB40_2)>>2
	.short	(LBB40_7-LBB40_2)>>2
	.short	(LBB40_8-LBB40_2)>>2
	.short	(LBB40_10-LBB40_2)>>2
	.short	(LBB40_14-LBB40_2)>>2
	.short	(LBB40_12-LBB40_2)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function sort.quad_swap__anon_14844
l_sort.quad_swap__anon_14844:           ; @sort.quad_swap__anon_14844
Lfunc_begin41:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #3216
	.cfi_def_cfa_offset 3312
	.cfi_remember_state
	mov	x27, x4
	mov	x21, x3
	mov	x22, x0
	mov	x20, x2
	mov	x24, x0
	cmp	x1, #8
	str	x1, [sp, #24]                   ; 8-byte Folded Spill
	b.lo	LBB41_109
; %bb.1:                                ; %.lr.ph100.preheader
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x24, x22
	mov	x25, x22
	lsr	x23, x8, #3
	b	LBB41_3
LBB41_2:                                ; %.critedge
                                        ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #16
	blr	x27
	add	x1, sp, #144
	mov	x0, x24
	mov	x2, x20
	mov	x3, x21
	bl	l_sort.quad_swap_merge__anon_16497
	add	x24, x24, #64
	cbz	x23, LBB41_109
LBB41_3:                                ; %.lr.ph100
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB41_10 Depth 2
                                        ;       Child Loop BB41_11 Depth 3
                                        ;         Child Loop BB41_49 Depth 4
                                        ;         Child Loop BB41_25 Depth 4
	mov	x0, x21
	mov	w1, #4
	sub	x23, x23, #1
	blr	x27
	ldp	x1, x2, [x24]
	mov	x0, x21
	blr	x20
	ldp	x1, x2, [x24, #16]
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	cset	w26, eq
	blr	x20
	ldp	x1, x2, [x24, #32]
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	cset	w19, eq
	blr	x20
	ldp	x1, x2, [x24, #48]
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	cset	w28, eq
	blr	x20
	and	w9, w0, #0xff
	lsl	w8, w28, #2
	cmp	w9, #1
	orr	w8, w8, w19, lsl #1
	cset	w9, eq
	orr	w8, w8, w9, lsl #3
	orr	w8, w8, w26
	str	w9, [sp, #128]                  ; 4-byte Folded Spill
	cbz	w8, LBB41_56
; %bb.4:                                ; %.lr.ph100
                                        ;   in Loop: Header=BB41_3 Depth=1
	cmp	w8, #15
	str	x23, [sp, #136]                 ; 8-byte Folded Spill
	str	w26, [sp, #120]                 ; 4-byte Folded Spill
	str	w28, [sp, #88]                  ; 4-byte Folded Spill
	b.ne	LBB41_8
; %bb.5:                                ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x24, #8]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_8
; %bb.6:                                ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x24, #24]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_8
; %bb.7:                                ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #1
	mov	w23, #1
	blr	x27
	ldp	x1, x2, [x24, #40]
	mov	x0, x21
	blr	x20
	mov	x26, x24
	and	w8, w0, #0xff
	cmp	w8, #1
                                        ; kill: def $w23 killed $w23 killed $x23 def $x23
	b.eq	LBB41_10
LBB41_8:                                ; %.critedge4
                                        ;   in Loop: Header=BB41_3 Depth=1
	mov	w23, #2
LBB41_9:                                ; %.outer.preheader
                                        ;   in Loop: Header=BB41_3 Depth=1
	mov	x26, x25
LBB41_10:                               ; %.outer
                                        ;   Parent Loop BB41_3 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB41_11 Depth 3
                                        ;         Child Loop BB41_49 Depth 4
                                        ;         Child Loop BB41_25 Depth 4
	mov	x8, x26
	mov	x26, x24
	str	x8, [sp, #80]                   ; 8-byte Folded Spill
	add	x8, x8, #8
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
LBB41_11:                               ; %.backedge
                                        ;   Parent Loop BB41_3 Depth=1
                                        ;     Parent Loop BB41_10 Depth=2
                                        ; =>    This Loop Header: Depth=3
                                        ;         Child Loop BB41_49 Depth 4
                                        ;         Child Loop BB41_25 Depth 4
	mov	x24, x27
	mov	x25, x26
	cbz	w23, LBB41_30
; %bb.12:                               ; %.backedge
                                        ;   in Loop: Header=BB41_11 Depth=3
	mov	x27, x24
	cmp	w23, #1
	b.ne	LBB41_66
; %bb.13:                               ;   in Loop: Header=BB41_11 Depth=3
	add	x28, x25, #64
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	cbz	x8, LBB41_67
; %bb.14:                               ;   in Loop: Header=BB41_11 Depth=3
	sub	x8, x8, #1
	mov	x0, x21
	mov	w1, #4
	str	x8, [sp, #136]                  ; 8-byte Folded Spill
	blr	x27
	ldp	x1, x2, [x25, #64]
	mov	x0, x21
	blr	x20
	mov	x8, x25
	str	w0, [sp, #56]                   ; 4-byte Folded Spill
	and	w19, w0, #0xff
	ldr	x2, [x25, #88]
	mov	x0, x21
	ldr	x1, [x8, #80]!
	str	x8, [sp, #72]                   ; 8-byte Folded Spill
	blr	x20
	mov	x9, x25
	str	w0, [sp, #48]                   ; 4-byte Folded Spill
	and	w8, w0, #0xff
	ldr	x2, [x25, #104]
	mov	x0, x21
	cmp	w8, #1
	ldr	x1, [x9, #96]!
	str	x9, [sp, #64]                   ; 8-byte Folded Spill
	cset	w23, ne
	blr	x20
	mov	x8, x25
	mov	w26, w0
	mov	x0, x21
	ldr	x1, [x8, #112]!
	ldr	x2, [x8, #8]
	str	x8, [sp, #32]                   ; 8-byte Folded Spill
	blr	x20
	cmp	w19, #1
	and	w8, w26, #0xff
	cset	w9, ne
	str	w26, [sp, #40]                  ; 4-byte Folded Spill
	mov	x26, x28
	mov	w28, w0
	mov	w19, w23
	str	w9, [sp, #120]                  ; 4-byte Folded Spill
	csinc	w9, w23, wzr, eq
	cmp	w8, #1
	cset	w8, ne
	csinc	w9, w9, wzr, eq
	str	w8, [sp, #88]                   ; 4-byte Folded Spill
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, ne
	str	w8, [sp, #128]                  ; 4-byte Folded Spill
	csinc	w8, w9, wzr, eq
	cmp	w8, #1
	b.eq	LBB41_19
; %bb.15:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #56]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_19
; %bb.16:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #72]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_19
; %bb.17:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #88]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_19
; %bb.18:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	mov	w23, #1
	blr	x27
	ldp	x1, x2, [x25, #104]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_11
LBB41_19:                               ; %.critedge25
                                        ;   in Loop: Header=BB41_11 Depth=3
	ldr	x4, [sp, #80]                   ; 8-byte Folded Reload
	add	x8, x25, #56
	sub	x12, x8, x4
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x4, x10
	sub	x10, x8, x10
	tbnz	w12, #4, LBB41_21
; %bb.20:                               ;   in Loop: Header=BB41_11 Depth=3
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB41_21:                               ; %._crit_edge.i
                                        ;   in Loop: Header=BB41_11 Depth=3
	ldr	x12, [x8]
	cmp	x9, #2
	ldr	x13, [x4]
	str	x12, [x4]
	str	x13, [x8]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB41_26
; %bb.22:                               ; %.lr.ph.preheader
                                        ;   in Loop: Header=BB41_11 Depth=3
	lsr	x12, x9, #1
	cmp	x9, #44
	b.hs	LBB41_39
LBB41_23:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x9, x12
	mov	x13, x4
	mov	x14, x11
	mov	x15, x10
LBB41_24:                               ; %.lr.ph.preheader465
                                        ;   in Loop: Header=BB41_11 Depth=3
	add	x10, x13, #8
	sub	x11, x14, #8
	add	x12, x15, #8
	sub	x8, x8, #8
LBB41_25:                               ; %.lr.ph
                                        ;   Parent Loop BB41_3 Depth=1
                                        ;     Parent Loop BB41_10 Depth=2
                                        ;       Parent Loop BB41_11 Depth=3
                                        ; =>      This Inner Loop Header: Depth=4
	ldr	x13, [x8]
	subs	x9, x9, #1
	ldr	x14, [x10]
	str	x13, [x10], #8
	str	x14, [x8], #-8
	ldr	x13, [x12]
	ldr	x14, [x11]
	str	x13, [x11], #-8
	str	x14, [x12], #8
	b.ne	LBB41_25
LBB41_26:                               ; %sort.quad_reversal.exit
                                        ;   in Loop: Header=BB41_11 Depth=3
	ldr	w8, [sp, #120]                  ; 4-byte Folded Reload
	ldr	w9, [sp, #88]                   ; 4-byte Folded Reload
	add	w8, w19, w8
	add	w8, w8, w9
	ldr	w9, [sp, #128]                  ; 4-byte Folded Reload
	add	w8, w8, w9
	cmp	w8, #4
	b.ne	LBB41_51
; %bb.27:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	mov	x27, x24
	blr	x24
	ldp	x1, x2, [x25, #72]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_60
; %bb.28:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #88]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_60
; %bb.29:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #104]
	mov	x0, x21
	blr	x20
	mov	w23, wzr
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_11
	b	LBB41_60
LBB41_30:                               ;   in Loop: Header=BB41_11 Depth=3
	add	x26, x25, #64
	mov	x27, x24
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	cbz	x8, LBB41_69
; %bb.31:                               ;   in Loop: Header=BB41_11 Depth=3
	sub	x8, x8, #1
	mov	x0, x21
	mov	w1, #4
	str	x8, [sp, #136]                  ; 8-byte Folded Spill
	blr	x27
	ldp	x1, x2, [x25, #64]
	mov	x0, x21
	blr	x20
	ldp	x1, x2, [x25, #80]
	and	w19, w0, #0xff
	mov	x0, x21
	blr	x20
	ldp	x1, x2, [x25, #96]
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	cset	w24, eq
	blr	x20
	ldp	x1, x2, [x25, #112]
	mov	w23, w0
	mov	x0, x21
	blr	x20
	cmp	w19, #1
	and	w8, w23, #0xff
	cset	w10, eq
	csinc	w9, w24, wzr, ne
	cmp	w8, #1
	and	w8, w0, #0xff
	cset	w11, eq
	csinc	w9, w9, wzr, ne
	cmp	w8, #1
	str	w10, [sp, #120]                 ; 4-byte Folded Spill
	cset	w12, eq
	csinc	w8, w9, wzr, ne
	cmp	w8, #1
	str	w11, [sp, #88]                  ; 4-byte Folded Spill
	str	w12, [sp, #128]                 ; 4-byte Folded Spill
	b.ne	LBB41_36
; %bb.32:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	w19, w24
	add	w8, w24, w10
	add	w9, w11, w12
	mov	w23, #2
	add	w8, w8, w9
	cmp	w8, #4
	b.ne	LBB41_11
; %bb.33:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #72]
	mov	x0, x21
	blr	x20
	mov	w23, #2
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_11
; %bb.34:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #88]
	mov	x0, x21
	blr	x20
	mov	w23, #2
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_11
; %bb.35:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	mov	w24, #1
	blr	x27
	ldp	x1, x2, [x25, #104]
	mov	x0, x21
	blr	x20
	mov	w23, #2
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_11
	b	LBB41_55
LBB41_36:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	mov	w19, w24
	blr	x27
	ldp	x1, x2, [x25, #72]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_63
; %bb.37:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #88]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_63
; %bb.38:                               ;   in Loop: Header=BB41_11 Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #104]
	mov	x0, x21
	blr	x20
	mov	w23, wzr
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_11
	b	LBB41_63
LBB41_39:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	sub	x13, x12, #1
	add	x15, x25, #48
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB41_23
; %bb.40:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB41_23
; %bb.41:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	lsr	x13, x13, #61
	cbnz	x13, LBB41_23
; %bb.42:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	ldr	x5, [sp, #16]                   ; 8-byte Folded Reload
	lsl	x14, x12, #3
	sub	x13, x25, x14
	sub	x1, x11, x14
	add	x17, x13, #56
	add	x2, x10, #8
	add	x0, x5, x14
	cmp	x5, x8
	ccmp	x17, x0, #2, lo
	add	x3, x2, x14
	cset	w13, lo
	cmp	x5, x11
	ccmp	x1, x0, #2, lo
	cset	w14, lo
	cmp	x2, x8
	ccmp	x17, x3, #2, lo
	cset	w15, lo
	cmp	x2, x11
	ccmp	x1, x3, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x1, x8, #2, lo
	cset	w17, lo
	cmp	x2, x0
	ccmp	x5, x3, #2, lo
	b.lo	LBB41_23
; %bb.43:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	tbnz	w13, #0, LBB41_23
; %bb.44:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	tbnz	w14, #0, LBB41_23
; %bb.45:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	tbnz	w15, #0, LBB41_23
; %bb.46:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	tbnz	w16, #0, LBB41_23
; %bb.47:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB41_11 Depth=3
	tbnz	w17, #0, LBB41_23
; %bb.48:                               ; %vector.ph
                                        ;   in Loop: Header=BB41_11 Depth=3
	and	x16, x12, #0x7ffffffffffffffe
	ubfx	x9, x9, #1, #1
	lsl	x17, x16, #3
	neg	x0, x16
	add	x13, x4, x17
	sub	x14, x11, x17
	add	x15, x10, x17
	sub	x8, x8, x17
	add	x10, x10, #8
	add	x17, x25, #40
	sub	x11, x11, #16
	ldr	x1, [sp, #16]                   ; 8-byte Folded Reload
LBB41_49:                               ; %vector.body
                                        ;   Parent Loop BB41_3 Depth=1
                                        ;     Parent Loop BB41_10 Depth=2
                                        ;       Parent Loop BB41_11 Depth=3
                                        ; =>      This Inner Loop Header: Depth=4
	ldr	q0, [x1]
	adds	x0, x0, #2
	ldr	q1, [x17]
	ldr	q2, [x11]
	ldr	q3, [x10]
	ext.16b	v1, v1, v1, #8
	ext.16b	v0, v0, v0, #8
	ext.16b	v3, v3, v3, #8
	ext.16b	v2, v2, v2, #8
	str	q1, [x1], #16
	str	q0, [x17], #-16
	str	q3, [x11], #-16
	str	q2, [x10], #16
	b.ne	LBB41_49
; %bb.50:                               ; %middle.block
                                        ;   in Loop: Header=BB41_11 Depth=3
	cmp	x12, x16
	b.ne	LBB41_24
	b	LBB41_26
LBB41_51:                               ; %sort.quad_reversal.exit
                                        ;   in Loop: Header=BB41_10 Depth=2
	mov	x27, x24
	cbnz	w8, LBB41_60
; %bb.52:                               ;   in Loop: Header=BB41_10 Depth=2
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #72]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_60
; %bb.53:                               ;   in Loop: Header=BB41_10 Depth=2
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #88]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_60
; %bb.54:                               ;   in Loop: Header=BB41_10 Depth=2
	mov	x0, x21
	mov	w1, #1
	mov	w23, #1
	blr	x27
	ldp	x1, x2, [x25, #104]
	mov	x0, x21
	blr	x20
	mov	x24, x26
	and	w8, w0, #0xff
	cmp	w8, #1
                                        ; kill: def $w23 killed $w23 killed $x23 def $x23
	b.eq	LBB41_10
	b	LBB41_60
LBB41_55:                               ;   in Loop: Header=BB41_10 Depth=2
	mov	w23, w24
	mov	x24, x26
	b	LBB41_10
LBB41_56:                               ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x24, #8]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_2
; %bb.57:                               ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x24, #24]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_2
; %bb.58:                               ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x24, #40]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_2
; %bb.59:                               ;   in Loop: Header=BB41_3 Depth=1
	str	x23, [sp, #136]                 ; 8-byte Folded Spill
	mov	w23, wzr
	str	w28, [sp, #88]                  ; 4-byte Folded Spill
	str	w26, [sp, #120]                 ; 4-byte Folded Spill
	b	LBB41_9
LBB41_60:                               ; %.critedge37
                                        ;   in Loop: Header=BB41_3 Depth=1
	and	w8, w28, #0xff
	ldr	w13, [sp, #56]                  ; 4-byte Folded Reload
	cmp	w8, #1
	ldr	w8, [sp, #40]                   ; 4-byte Folded Reload
	cset	w9, eq
	cset	w10, ne
	and	w13, w13, #0xff
	ldr	x16, [sp, #72]                  ; 8-byte Folded Reload
	and	w8, w8, #0xff
	mov	x0, x21
	cmp	w8, #1
	ldr	w8, [sp, #48]                   ; 4-byte Folded Reload
	cset	w11, eq
	cset	w12, ne
	mov	w1, #1
	and	w8, w8, #0xff
	cmp	w8, #1
	cset	w8, eq
	cset	w14, ne
	cmp	w13, #1
	cset	w13, eq
	cset	w15, ne
	ldr	x8, [x16, w8, uxtw #3]
	ldr	x14, [x16, w14, uxtw #3]
	ldr	x13, [x26, w13, uxtw #3]
	ldr	x15, [x26, w15, uxtw #3]
	ldr	x16, [sp, #64]                  ; 8-byte Folded Reload
	stp	x8, x14, [x25, #80]
	ldr	x11, [x16, w11, uxtw #3]
	stp	x13, x15, [x25, #64]
	ldr	x13, [sp, #32]                  ; 8-byte Folded Reload
	ldr	x12, [x16, w12, uxtw #3]
	ldr	x9, [x13, w9, uxtw #3]
	ldr	x8, [x13, w10, uxtw #3]
	stp	x11, x12, [x25, #96]
	stp	x9, x8, [x25, #112]
	blr	x27
	ldp	x1, x2, [x25, #72]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_63
; %bb.61:                               ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #88]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_63
; %bb.62:                               ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #104]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_64
LBB41_63:                               ; %.critedge21
                                        ;   in Loop: Header=BB41_3 Depth=1
	mov	x0, x21
	mov	w1, #16
	blr	x27
	add	x1, sp, #144
	mov	x0, x26
	mov	x2, x20
	mov	x3, x21
	bl	l_sort.quad_swap_merge__anon_16497
LBB41_64:                               ;   in Loop: Header=BB41_3 Depth=1
	add	x24, x25, #128
LBB41_65:                               ;   in Loop: Header=BB41_3 Depth=1
	ldr	x25, [sp, #80]                  ; 8-byte Folded Reload
	ldr	x23, [sp, #136]                 ; 8-byte Folded Reload
	cbnz	x23, LBB41_3
	b	LBB41_109
LBB41_66:                               ;   in Loop: Header=BB41_3 Depth=1
	ldr	w8, [sp, #120]                  ; 4-byte Folded Reload
	add	x14, x25, #32
	ldr	w13, [sp, #88]                  ; 4-byte Folded Reload
	mov	x0, x21
	ldr	w15, [sp, #128]                 ; 4-byte Folded Reload
	mov	w1, #16
	tst	w8, #0xf
	add	x8, x25, #16
	cset	w9, eq
	cset	w10, ne
	tst	w19, #0xf
	cset	w11, ne
	cset	w12, eq
	tst	w13, #0xf
	ldr	x9, [x25, w9, uxtw #3]
	ldr	x10, [x25, w10, uxtw #3]
	cset	w13, ne
	ldr	x12, [x8, w12, uxtw #3]
	ldr	x8, [x8, w11, uxtw #3]
	cset	w11, eq
	tst	w15, #0xf
	add	x15, x25, #48
	cset	w16, ne
	cset	w17, eq
	ldr	x13, [x14, w13, uxtw #3]
	stp	x10, x9, [x25]
	ldr	x9, [x14, w11, uxtw #3]
	stp	x8, x12, [x25, #16]
	ldr	x10, [x15, w16, uxtw #3]
	ldr	x8, [x15, w17, uxtw #3]
	stp	x13, x9, [x25, #32]
	stp	x10, x8, [x25, #48]
	blr	x27
	add	x1, sp, #144
	mov	x0, x25
	mov	x2, x20
	mov	x3, x21
	bl	l_sort.quad_swap_merge__anon_16497
	add	x24, x25, #64
	b	LBB41_65
LBB41_67:
	ldr	x19, [sp, #24]                  ; 8-byte Folded Reload
	and	x23, x19, #0x7
	cmp	x23, #7
	b.ne	LBB41_70
; %bb.68:
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #104]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_71
	b	LBB41_89
LBB41_69:
	mov	x24, x26
	b	LBB41_109
LBB41_70:                               ; %.critedge55
	cmp	x23, #6
	b.lo	LBB41_72
LBB41_71:                               ; %.critedge55.thread
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #96]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_89
	b	LBB41_73
LBB41_72:                               ; %.critedge57
	cmp	x23, #5
	b.ne	LBB41_74
LBB41_73:                               ; %.critedge57.thread
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #88]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_89
	b	LBB41_75
LBB41_74:                               ; %.critedge59
	cmp	x23, #4
	b.lo	LBB41_76
LBB41_75:                               ; %.critedge59.thread
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #80]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_89
	b	LBB41_77
LBB41_76:                               ; %.critedge61
	cmp	x23, #3
	b.ne	LBB41_133
LBB41_77:                               ; %.critedge61.thread
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #72]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_89
LBB41_78:                               ; %.critedge63.thread
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #64]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_89
LBB41_79:                               ; %.critedge65.thread
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x25, #56]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_89
LBB41_80:                               ; %.critedge67
	lsl	x13, x23, #3
	ldr	x11, [sp, #80]                  ; 8-byte Folded Reload
	add	x8, x28, x13
	sub	x8, x8, #8
	sub	x12, x8, x11
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x11, x10
	sub	x10, x8, x10
	tbnz	w12, #4, LBB41_82
; %bb.81:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x14, [x11]
	str	x12, [x11], #-8
	str	x14, [x10], #8
LBB41_82:                               ; %._crit_edge.i341
	ldr	x15, [sp, #80]                  ; 8-byte Folded Reload
	cmp	x9, #2
	ldr	x12, [x8]
	ldr	x14, [x15]
	str	x12, [x15]
	str	x14, [x8]
	ldr	x12, [x10]
	ldr	x14, [x11]
	str	x12, [x11]
	str	x14, [x10]
	b.lo	LBB41_87
; %bb.83:                               ; %.lr.ph112.preheader
	lsr	x12, x9, #1
	cmp	x9, #48
	b.hs	LBB41_135
LBB41_84:
	ldr	x14, [sp, #80]                  ; 8-byte Folded Reload
	mov	x9, x12
	mov	x15, x11
	mov	x16, x10
LBB41_85:                               ; %.lr.ph112.preheader463
	add	x10, x14, #8
	sub	x11, x15, #8
	add	x12, x16, #8
	sub	x8, x8, #8
LBB41_86:                               ; %.lr.ph112
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x8]
	subs	x9, x9, #1
	ldr	x14, [x10]
	str	x13, [x10], #8
	str	x14, [x8], #-8
	ldr	x13, [x12]
	ldr	x14, [x11]
	str	x13, [x11], #-8
	str	x14, [x12], #8
	b.ne	LBB41_86
LBB41_87:                               ; %sort.quad_reversal.exit350
	ldr	x8, [sp, #80]                   ; 8-byte Folded Reload
	cmp	x8, x22
	b.ne	LBB41_110
; %bb.88:
	mov	w0, wzr
	b	LBB41_132
LBB41_89:
	ldr	x5, [sp, #80]                   ; 8-byte Folded Reload
	add	x8, x25, #56
	sub	x12, x8, x5
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x5, x10
	sub	x10, x8, x10
	tbnz	w12, #4, LBB41_91
; %bb.90:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB41_91:                               ; %._crit_edge.i331
	ldr	x12, [x8]
	cmp	x9, #2
	ldr	x13, [x5]
	str	x12, [x5]
	str	x13, [x8]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB41_108
; %bb.92:                               ; %.lr.ph106.preheader
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB41_105
; %bb.93:                               ; %vector.scevcheck103
	sub	x13, x12, #1
	add	x15, x25, #48
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB41_105
; %bb.94:                               ; %vector.scevcheck103
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB41_105
; %bb.95:                               ; %vector.scevcheck103
	lsr	x13, x13, #61
	cbnz	x13, LBB41_105
; %bb.96:                               ; %vector.memcheck112
	lsl	x13, x12, #3
	add	x0, x5, #8
	add	x14, x13, #8
	sub	x15, x25, x13
	add	x1, x5, x14
	add	x17, x15, #56
	cmp	x0, x8
	sub	x2, x11, x13
	ccmp	x17, x1, #2, lo
	add	x3, x10, #8
	add	x4, x10, x14
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x8
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x8, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB41_105
; %bb.97:                               ; %vector.memcheck112
	tbnz	w13, #0, LBB41_105
; %bb.98:                               ; %vector.memcheck112
	tbnz	w14, #0, LBB41_105
; %bb.99:                               ; %vector.memcheck112
	tbnz	w15, #0, LBB41_105
; %bb.100:                              ; %vector.memcheck112
	tbnz	w16, #0, LBB41_105
; %bb.101:                              ; %vector.memcheck112
	tbnz	w17, #0, LBB41_105
; %bb.102:                              ; %vector.ph145
	and	x16, x12, #0x7ffffffffffffffe
	ubfx	x9, x9, #1, #1
	lsl	x17, x16, #3
	add	x0, x25, #40
	add	x13, x5, x17
	sub	x14, x11, x17
	add	x15, x10, x17
	sub	x8, x8, x17
	add	x17, x5, #8
	add	x10, x10, #8
	sub	x11, x11, #16
	neg	x1, x16
LBB41_103:                              ; %vector.body159
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x17]
	adds	x1, x1, #2
	ldr	q1, [x0]
	ldr	q2, [x11]
	ldr	q3, [x10]
	ext.16b	v1, v1, v1, #8
	ext.16b	v0, v0, v0, #8
	ext.16b	v3, v3, v3, #8
	ext.16b	v2, v2, v2, #8
	str	q1, [x17], #16
	str	q0, [x0], #-16
	str	q3, [x11], #-16
	str	q2, [x10], #16
	b.ne	LBB41_103
; %bb.104:                              ; %middle.block142
	cmp	x12, x16
	b.ne	LBB41_106
	b	LBB41_108
LBB41_105:
	mov	x9, x12
	mov	x13, x5
	mov	x14, x11
	mov	x15, x10
LBB41_106:                              ; %.lr.ph106.preheader464
	add	x10, x13, #8
	sub	x11, x14, #8
	add	x12, x15, #8
	sub	x8, x8, #8
LBB41_107:                              ; %.lr.ph106
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x8]
	subs	x9, x9, #1
	ldr	x14, [x10]
	str	x13, [x10], #8
	str	x14, [x8], #-8
	ldr	x13, [x12]
	ldr	x14, [x11]
	str	x13, [x11], #-8
	str	x14, [x12], #8
	b.ne	LBB41_107
LBB41_108:
	mov	x24, x28
LBB41_109:                              ; %.loopexit
	ldr	x19, [sp, #24]                  ; 8-byte Folded Reload
	add	x2, sp, #144
	mov	x0, x24
	mov	x3, x20
	mov	x4, x21
	mov	x5, x27
	and	x1, x19, #0x7
	bl	l_sort.tail_swap__anon_14843
LBB41_110:
	cmp	x19, #32
	str	x27, [sp, #96]                  ; 8-byte Folded Spill
	b.hs	LBB41_123
LBB41_111:                              ; %._crit_edge
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	and	x10, x8, #0x1f
	cmp	x10, #8
	b.ls	LBB41_131
; %bb.112:                              ; %.preheader.lr.ph.i
	lsl	x8, x10, #3
	mov	x25, x20
	add	x27, x22, x8
	mov	w23, #8
	stp	x8, x10, [sp, #128]             ; 16-byte Folded Spill
LBB41_113:                              ; %.preheader.i
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB41_115 Depth 2
	lsl	x8, x23, #3
	lsl	x24, x23, #1
	add	x9, x8, x22
	cmp	x9, x27
	b.hs	LBB41_118
; %bb.114:                              ; %.lr.ph.i
                                        ;   in Loop: Header=BB41_113 Depth=1
	mov	x26, x21
	lsl	x21, x23, #4
	mov	x9, x22
	mov	x19, xzr
	add	x22, x22, x8
	mov	x20, x9
	add	x28, x9, x21
LBB41_115:                              ;   Parent Loop BB41_113 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x0, x20, x19
	add	x8, x28, x19
	cmp	x8, x27
	b.hs	LBB41_119
; %bb.116:                              ;   in Loop: Header=BB41_115 Depth=2
	add	x2, sp, #144
	mov	x1, x24
	mov	w3, #32
	mov	x4, x23
	mov	x5, x25
	mov	x6, x26
	ldr	x7, [sp, #96]                   ; 8-byte Folded Reload
	bl	l_sort.partial_backwards_merge__anon_16502
	add	x19, x19, x21
	add	x8, x22, x19
	cmp	x8, x27
	b.lo	LBB41_115
; %bb.117:                              ;   in Loop: Header=BB41_113 Depth=1
	mov	x23, x24
	mov	x21, x26
	b	LBB41_120
LBB41_118:                              ; %.preheader..loopexit_crit_edge.i
                                        ;   in Loop: Header=BB41_113 Depth=1
	mov	x23, x24
	b	LBB41_121
LBB41_119:                              ;   in Loop: Header=BB41_113 Depth=1
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	add	x2, sp, #144
	mov	w3, #32
	mov	x4, x23
	mov	x5, x25
	mov	x6, x26
	sub	x8, x8, x19
	ldr	x7, [sp, #96]                   ; 8-byte Folded Reload
	lsr	x1, x8, #3
	mov	x21, x26
	bl	l_sort.partial_backwards_merge__anon_16502
	mov	x23, x24
LBB41_120:                              ; %.loopexit.i
                                        ;   in Loop: Header=BB41_113 Depth=1
	ldr	x10, [sp, #136]                 ; 8-byte Folded Reload
	mov	x22, x20
LBB41_121:                              ; %.loopexit.i
                                        ;   in Loop: Header=BB41_113 Depth=1
	mov	w0, #1
	cmp	x23, x10
	b.hs	LBB41_132
; %bb.122:                              ; %.loopexit.i
                                        ;   in Loop: Header=BB41_113 Depth=1
	cmp	x23, #33
	b.lo	LBB41_113
	b	LBB41_132
LBB41_123:                              ; %.lr.ph116
	add	x8, sp, #144
	lsr	x23, x19, #5
	add	x10, x8, #120
	add	x9, x8, #128
	stp	x20, x21, [sp, #104]            ; 16-byte Folded Spill
	stp	x9, x10, [sp, #72]              ; 16-byte Folded Spill
	add	x10, x8, #248
	add	x9, x8, #136
	stp	x9, x10, [sp, #56]              ; 16-byte Folded Spill
	orr	x10, x8, #0x8
	add	x9, x8, #16
	add	x8, x8, #24
	stp	x9, x10, [sp, #40]              ; 16-byte Folded Spill
	str	x8, [sp, #32]                   ; 8-byte Folded Spill
	b	LBB41_125
LBB41_124:                              ;   in Loop: Header=BB41_125 Depth=1
	subs	x23, x23, #1
	add	x22, x22, #256
	b.eq	LBB41_111
LBB41_125:                              ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB41_129 Depth 2
	mov	x0, x21
	mov	w1, #1
	blr	x27
	mov	x28, x22
	mov	x0, x21
	ldr	x1, [x28, #56]!
	mov	x19, x28
	ldr	x2, [x19, #8]!
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_128
; %bb.126:                              ;   in Loop: Header=BB41_125 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x22, #120]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB41_128
; %bb.127:                              ;   in Loop: Header=BB41_125 Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x27
	ldp	x1, x2, [x22, #184]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB41_124
LBB41_128:                              ; %.critedge69
                                        ;   in Loop: Header=BB41_125 Depth=1
	mov	x0, x21
	mov	w1, #16
	str	x23, [sp, #88]                  ; 8-byte Folded Spill
	blr	x27
	ldr	x1, [x22]
	mov	x0, x21
	ldr	x2, [x22, #64]
	blr	x20
	and	w8, w0, #0xff
	mov	x25, x21
	cmp	w8, #1
	mov	x0, x25
	csel	x8, x19, x22, eq
	ldr	x9, [x8], #8
	csel	x21, x22, x8, eq
	csel	x19, x8, x19, eq
	str	x9, [sp, #144]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x20
	and	w8, w0, #0xff
	mov	x24, x22
	cmp	w8, #1
	ldr	x1, [x22, #56]
	csel	x8, x19, x21, eq
	mov	x0, x25
	ldr	x2, [x22, #120]!
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #152]
	blr	x20
	and	w8, w0, #0xff
	mov	w10, #56
	cmp	w8, #1
	mov	x0, x25
	csel	x9, x28, x22, eq
	cmp	w8, #1
	mov	w8, #120
	sub	x9, x9, #8
	csel	x8, x10, x8, eq
	csel	x22, x22, x9, eq
	csel	x23, x9, x28, eq
	ldr	x8, [x24, x8]
	str	x8, [sp, #264]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #160]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #256]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #168]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #248]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #176]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #240]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #184]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #232]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #192]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #224]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x8, [x8]
	str	x8, [sp, #200]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x19, x8, x23, eq
	csel	x21, x22, x8, eq
	str	x9, [sp, #216]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	mov	w1, #16
	csel	x8, x19, x21, eq
	ldr	x8, [x8]
	str	x8, [sp, #208]
	blr	x27
	mov	x19, x24
	mov	x21, x24
	mov	x0, x25
	ldr	x1, [x19, #128]!
	ldr	x2, [x21, #192]!
	blr	x20
	and	w8, w0, #0xff
	mov	w9, #192
	cmp	w8, #1
	mov	w8, #128
	csel	x8, x9, x8, eq
	csel	x9, x21, x19, eq
	add	x9, x9, #8
	mov	x0, x25
	csel	x19, x19, x9, eq
	csel	x21, x9, x21, eq
	ldr	x8, [x24, x8]
	str	x8, [sp, #272]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x22, x24
	cmp	w8, #1
	mov	x23, x24
	csel	x8, x21, x19, eq
	mov	x0, x25
	ldr	x1, [x22, #184]!
	ldr	x2, [x23, #248]!
	ldr	x9, [x8], #8
	mov	x28, x24
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #280]
	blr	x20
	and	w8, w0, #0xff
	mov	w10, #184
	cmp	w8, #1
	mov	x0, x25
	csel	x9, x22, x23, eq
	cmp	w8, #1
	mov	w8, #248
	add	x24, sp, #144
	csel	x8, x10, x8, eq
	sub	x9, x9, #8
	add	x26, x24, #128
	csel	x23, x23, x9, eq
	csel	x22, x9, x22, eq
	ldr	x8, [x28, x8]
	str	x8, [sp, #392]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #288]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #384]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #296]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #376]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #304]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #368]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #312]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #360]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #320]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #352]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x8, [x8]
	str	x8, [sp, #328]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x19, x8, x22, eq
	csel	x21, x23, x8, eq
	str	x9, [sp, #344]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	mov	w1, #32
	csel	x8, x19, x21, eq
	ldr	x8, [x8]
	str	x8, [sp, #336]
	blr	x27
	ldr	x1, [sp, #144]
	mov	x0, x25
	ldr	x2, [sp, #272]
	blr	x20
	and	w8, w0, #0xff
	mov	w9, #16
	cmp	w8, #1
	mov	w10, #144
	csel	x9, x10, x9, eq
	csel	x8, x26, x24, eq
	ldp	x11, x10, [sp, #40]             ; 16-byte Folded Reload
	add	x9, x24, x9
	mov	w25, #248
	mov	w22, #8
	csel	x20, x24, x10, eq
	csel	x10, x10, x9, eq
	str	x10, [sp, #136]                 ; 8-byte Folded Spill
	orr	x10, x9, #0x8
	csel	x19, x11, x10, eq
	ldr	x10, [sp, #32]                  ; 8-byte Folded Reload
	add	x9, x9, #16
	ldr	x8, [x8]
	csel	x9, x10, x9, eq
	ldp	x10, x26, [sp, #56]             ; 16-byte Folded Reload
	str	x8, [x28]
	stp	x28, x9, [sp, #120]             ; 16-byte Folded Spill
	ldp	x9, x27, [sp, #72]              ; 16-byte Folded Reload
	csel	x24, x10, x9, eq
LBB41_129:                              ; %.cont.i397
                                        ;   Parent Loop BB41_125 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	x21, x23, [sp, #104]            ; 16-byte Folded Reload
	mov	x28, x20
	ldr	x2, [x24]
	ldr	x1, [x28], #16
	mov	x0, x23
	blr	x21
	and	w9, w0, #0xff
	add	x8, x20, #8
	cmp	w9, #1
	ldr	x10, [sp, #136]                 ; 8-byte Folded Reload
	csel	x9, x24, x20, eq
	csel	x11, x8, x19, eq
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	mov	x0, x23
	csel	x20, x20, x10, eq
	cset	w10, eq
	ldr	x9, [x9]
	csel	x19, x28, x8, eq
	ldr	x28, [sp, #120]                 ; 8-byte Folded Reload
	add	x8, x19, #8
	add	x24, x24, w10, uxtw #3
	str	x9, [x28, x22]
	ldr	x1, [x27]
	ldr	x2, [x26]
	stp	x8, x11, [sp, #128]             ; 16-byte Folded Spill
	blr	x21
	and	w8, w0, #0xff
	add	x22, x22, #8
	cmp	w8, #1
	csel	x8, x27, x26, eq
	ldr	x9, [x8], #-8
	csel	x26, x26, x8, eq
	csel	x27, x8, x27, eq
	str	x9, [x28, x25]
	sub	x25, x25, #8
	cmp	x25, #128
	b.ne	LBB41_129
; %bb.130:                              ; %sort.parity_merge__anon_16495.exit399
                                        ;   in Loop: Header=BB41_125 Depth=1
	ldp	x20, x21, [sp, #104]            ; 16-byte Folded Reload
	ldr	x1, [x27]
	ldr	x2, [x26]
	mov	x0, x21
	blr	x20
	and	w8, w0, #0xff
	ldr	x22, [sp, #120]                 ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x8, x27, x26, eq
	ldp	x23, x27, [sp, #88]             ; 16-byte Folded Reload
	ldr	x8, [x8]
	str	x8, [x22, x25]
	b	LBB41_124
LBB41_131:
	mov	w0, #1
LBB41_132:                              ; %common.ret
	add	sp, sp, #3216
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB41_133:                              ; %.critedge63
	.cfi_restore_state
	cmp	x23, #2
	b.hs	LBB41_78
; %bb.134:                              ; %.critedge65
	cbnz	x23, LBB41_79
	b	LBB41_80
LBB41_135:                              ; %vector.scevcheck174
	sub	x14, x12, #1
	add	x15, x13, x25
	add	x16, x15, #48
	lsl	x15, x14, #3
	sub	x17, x16, x15
	cmp	x17, x16
	b.hi	LBB41_84
; %bb.136:                              ; %vector.scevcheck174
	sub	x16, x11, #8
	sub	x15, x16, x15
	cmp	x15, x16
	b.hi	LBB41_84
; %bb.137:                              ; %vector.scevcheck174
	lsr	x14, x14, #61
	cbnz	x14, LBB41_84
; %bb.138:                              ; %vector.memcheck183
	ldr	x17, [sp, #80]                  ; 8-byte Folded Reload
	lsl	x14, x12, #3
	sub	x16, x13, x14
	add	x15, x14, #8
	add	x16, x16, x25
	sub	x3, x11, x14
	add	x1, x17, #8
	add	x2, x17, x15
	add	x0, x16, #56
	cmp	x1, x8
	ccmp	x0, x2, #2, lo
	add	x4, x10, #8
	add	x5, x10, x15
	cset	w14, lo
	cmp	x1, x11
	ccmp	x3, x2, #2, lo
	cset	w15, lo
	cmp	x4, x8
	ccmp	x0, x5, #2, lo
	cset	w16, lo
	cmp	x4, x11
	ccmp	x3, x5, #2, lo
	cset	w17, lo
	cmp	x0, x11
	ccmp	x3, x8, #2, lo
	cset	w0, lo
	cmp	x4, x2
	ccmp	x1, x5, #2, lo
	b.lo	LBB41_84
; %bb.139:                              ; %vector.memcheck183
	tbnz	w14, #0, LBB41_84
; %bb.140:                              ; %vector.memcheck183
	tbnz	w15, #0, LBB41_84
; %bb.141:                              ; %vector.memcheck183
	tbnz	w16, #0, LBB41_84
; %bb.142:                              ; %vector.memcheck183
	tbnz	w17, #0, LBB41_84
; %bb.143:                              ; %vector.memcheck183
	tbnz	w0, #0, LBB41_84
; %bb.144:                              ; %vector.ph216
	ldr	x1, [sp, #80]                   ; 8-byte Folded Reload
	and	x17, x12, #0x7ffffffffffffffe
	lsl	x0, x17, #3
	add	x13, x13, x25
	ubfx	x9, x9, #1, #1
	sub	x15, x11, x0
	add	x14, x1, x0
	add	x16, x10, x0
	sub	x8, x8, x0
	add	x0, x1, #8
	add	x10, x10, #8
	add	x13, x13, #40
	sub	x11, x11, #16
	neg	x1, x17
LBB41_145:                              ; %vector.body230
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x13]
	ldr	q2, [x11]
	ldr	q3, [x10]
	ext.16b	v1, v1, v1, #8
	ext.16b	v0, v0, v0, #8
	ext.16b	v3, v3, v3, #8
	ext.16b	v2, v2, v2, #8
	str	q1, [x0], #16
	str	q0, [x13], #-16
	str	q3, [x11], #-16
	str	q2, [x10], #16
	b.ne	LBB41_145
; %bb.146:                              ; %middle.block213
	cmp	x12, x17
	b.ne	LBB41_85
	b	LBB41_87
Lfunc_end41:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quad_merge__anon_14845
l_sort.quad_merge__anon_14845:          ; @sort.quad_merge__anon_14845
Lfunc_begin42:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #224
	.cfi_def_cfa_offset 224
	stp	x28, x27, [sp, #128]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #208]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	lsl	x8, x1, #3
	mov	x20, x5
	mov	x23, x1
	mov	x25, x0
	cmp	x1, #128
	stp	x4, x2, [sp, #96]               ; 16-byte Folded Spill
	stp	x8, x0, [sp, #8]                ; 16-byte Folded Spill
	add	x8, x0, x8
	stp	x6, x3, [sp, #112]              ; 16-byte Folded Spill
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
	mov	w8, #128
	b.lo	LBB42_28
; %bb.1:
	cmp	x3, #128
	b.lo	LBB42_28
; %bb.2:                                ; %.preheader.lr.ph
	mov	x19, x2
	mov	w8, #128
	str	x23, [sp]                       ; 8-byte Folded Spill
LBB42_3:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB42_8 Depth 2
                                        ;     Child Loop BB42_19 Depth 2
                                        ;       Child Loop BB42_21 Depth 3
	mov	w9, #6
	lsl	x10, x8, #3
	lsr	x27, x8, #2
	lsr	x11, x8, #1
	madd	x9, x8, x9, x25
	mov	x28, xzr
	ldr	x21, [sp, #8]                   ; 8-byte Folded Reload
	stp	x9, x10, [sp, #72]              ; 16-byte Folded Spill
	add	x9, x25, x8, lsl #1
	lsl	x8, x8, #2
	str	x9, [sp, #64]                   ; 8-byte Folded Spill
	add	x9, x19, x8
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	add	x8, x25, x8
	stp	x9, x11, [sp, #32]              ; 16-byte Folded Spill
	str	x8, [sp, #88]                   ; 8-byte Folded Spill
	add	x8, x25, x10
	str	x8, [sp, #56]                   ; 8-byte Folded Spill
	b	LBB42_8
LBB42_4:                                ;   in Loop: Header=BB42_8 Depth=2
	ldr	x25, [sp, #112]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x1, x26
	mov	x2, x27
	mov	x3, x27
	mov	x4, x23
	mov	x5, x20
	mov	x6, x25
	bl	l_sort.cross_merge__anon_14862
	ldp	x2, x0, [sp, #24]               ; 16-byte Folded Reload
	mov	x1, x22
	mov	x22, x25
	bl	_memcpy
LBB42_5:                                ;   in Loop: Header=BB42_8 Depth=2
	mov	x25, x24
LBB42_6:                                ;   in Loop: Header=BB42_8 Depth=2
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	mov	x0, x26
	mov	x1, x19
	mov	x4, x23
	mov	x5, x20
	mov	x6, x22
	mov	x3, x2
	bl	l_sort.cross_merge__anon_14862
LBB42_7:                                ; %sort.quad_merge_block__anon_16501.exit
                                        ;   in Loop: Header=BB42_8 Depth=2
	ldr	x8, [sp, #80]                   ; 8-byte Folded Reload
	add	x28, x28, x8
	sub	x21, x21, x8
	ldp	x9, x8, [sp, #48]               ; 16-byte Folded Reload
	add	x8, x8, x28
	cmp	x8, x9
	b.hi	LBB42_14
LBB42_8:                                ;   Parent Loop BB42_3 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x24, x25
	add	x26, x25, x28
	mov	x0, x20
	mov	w1, #2
	add	x19, x8, x28
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	add	x22, x8, x28
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	add	x25, x8, x28
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	blr	x8
	ldp	x1, x2, [x19, #-8]
	mov	x0, x20
	ldr	x23, [sp, #96]                  ; 8-byte Folded Reload
	blr	x23
	ldp	x1, x2, [x25, #-8]
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	cset	w19, ne
	blr	x23
	and	w8, w0, #0xff
Lloh57:
	adrp	x11, LJTI42_0@PAGE
Lloh58:
	add	x11, x11, LJTI42_0@PAGEOFF
	cmp	w8, #1
	cset	w8, ne
	orr	w8, w19, w8, lsl #1
	adr	x9, LBB42_4
	ldrb	w10, [x11, x8]
	add	x9, x9, x10, lsl #2
	ldr	x19, [sp, #104]                 ; 8-byte Folded Reload
	br	x9
LBB42_9:                                ;   in Loop: Header=BB42_8 Depth=2
	ldr	x25, [sp, #112]                 ; 8-byte Folded Reload
	mov	x0, x19
	mov	x1, x26
	mov	x2, x27
	mov	x3, x27
	mov	x4, x23
	mov	x5, x20
	mov	x6, x25
	bl	l_sort.cross_merge__anon_14862
	ldr	x0, [sp, #32]                   ; 8-byte Folded Reload
	mov	x1, x22
	mov	x22, x25
	mov	x2, x27
	mov	x3, x27
	mov	x4, x23
	mov	x5, x20
	mov	x6, x25
	b	LBB42_11
LBB42_10:                               ;   in Loop: Header=BB42_8 Depth=2
	mov	x0, x19
	mov	x1, x26
	ldr	x2, [sp, #24]                   ; 8-byte Folded Reload
	bl	_memcpy
	mov	x1, x22
	ldr	x22, [sp, #112]                 ; 8-byte Folded Reload
	ldr	x0, [sp, #32]                   ; 8-byte Folded Reload
	mov	x2, x27
	mov	x3, x27
	mov	x4, x23
	mov	x5, x20
	mov	x6, x22
LBB42_11:                               ;   in Loop: Header=BB42_8 Depth=2
	bl	l_sort.cross_merge__anon_14862
	b	LBB42_5
LBB42_12:                               ;   in Loop: Header=BB42_8 Depth=2
	mov	x0, x20
	mov	w1, #1
	ldr	x22, [sp, #112]                 ; 8-byte Folded Reload
	blr	x22
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	x0, x20
	add	x8, x8, x28
	ldp	x1, x2, [x8, #-8]
	blr	x23
	mov	x25, x24
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB42_7
; %bb.13:                               ;   in Loop: Header=BB42_8 Depth=2
	mov	x0, x19
	mov	x1, x26
	ldr	x2, [sp, #80]                   ; 8-byte Folded Reload
	bl	_memcpy
	b	LBB42_6
LBB42_14:                               ;   in Loop: Header=BB42_3 Depth=1
	lsr	x10, x21, #3
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
	cmp	x27, x10
	b.hs	LBB42_26
; %bb.15:                               ;   in Loop: Header=BB42_3 Depth=1
	cmp	x27, x3
	b.hi	LBB42_26
; %bb.16:                               ; %.preheader.lr.ph.i16
                                        ;   in Loop: Header=BB42_3 Depth=1
	and	x8, x21, #0xfffffffffffffff8
	add	x26, x25, x28
	add	x22, x26, x8
	stp	x8, x10, [sp, #80]              ; 16-byte Folded Spill
	b	LBB42_19
LBB42_17:                               ; %.preheader..loopexit_crit_edge.i20
                                        ;   in Loop: Header=BB42_19 Depth=2
	mov	x27, x21
	cmp	x27, x10
	b.hs	LBB42_26
LBB42_18:                               ; %.loopexit.i23
                                        ;   in Loop: Header=BB42_19 Depth=2
	cmp	x27, x3
	b.hi	LBB42_26
LBB42_19:                               ; %.preheader.i18
                                        ;   Parent Loop BB42_3 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB42_21 Depth 3
	lsl	x8, x27, #3
	lsl	x21, x27, #1
	add	x9, x26, x8
	cmp	x9, x22
	b.hs	LBB42_17
; %bb.20:                               ; %.lr.ph.i21
                                        ;   in Loop: Header=BB42_19 Depth=2
	mov	x9, x25
	lsl	x25, x27, #4
	add	x8, x9, x8
	add	x9, x9, x25
	mov	x24, xzr
	add	x19, x28, x8
	add	x23, x28, x9
LBB42_21:                               ;   Parent Loop BB42_3 Depth=1
                                        ;     Parent Loop BB42_19 Depth=2
                                        ; =>    This Inner Loop Header: Depth=3
	add	x0, x26, x24
	add	x8, x23, x24
	cmp	x8, x22
	b.hs	LBB42_24
; %bb.22:                               ;   in Loop: Header=BB42_21 Depth=3
	ldp	x5, x2, [sp, #96]               ; 16-byte Folded Reload
	mov	x1, x21
	mov	x4, x27
	ldp	x7, x3, [sp, #112]              ; 16-byte Folded Reload
	mov	x6, x20
	bl	l_sort.partial_backwards_merge__anon_16502
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
	add	x24, x24, x25
	add	x8, x19, x24
	cmp	x8, x22
	b.lo	LBB42_21
; %bb.23:                               ;   in Loop: Header=BB42_19 Depth=2
	ldr	x25, [sp, #16]                  ; 8-byte Folded Reload
	mov	x27, x21
	ldr	x19, [sp, #104]                 ; 8-byte Folded Reload
	b	LBB42_25
LBB42_24:                               ;   in Loop: Header=BB42_19 Depth=2
	ldp	x5, x19, [sp, #96]              ; 16-byte Folded Reload
	mov	x4, x27
	mov	x6, x20
	ldr	x8, [sp, #80]                   ; 8-byte Folded Reload
	ldp	x7, x3, [sp, #112]              ; 16-byte Folded Reload
	sub	x8, x8, x24
	mov	x2, x19
	lsr	x1, x8, #3
	bl	l_sort.partial_backwards_merge__anon_16502
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
	mov	x27, x21
	ldr	x25, [sp, #16]                  ; 8-byte Folded Reload
LBB42_25:                               ;   in Loop: Header=BB42_19 Depth=2
	ldr	x10, [sp, #88]                  ; 8-byte Folded Reload
	cmp	x27, x10
	b.lo	LBB42_18
LBB42_26:                               ; %sort.tail_merge__anon_16500.exit25
                                        ;   in Loop: Header=BB42_3 Depth=1
	ldr	x23, [sp]                       ; 8-byte Folded Reload
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	cmp	x8, x23
	b.hi	LBB42_28
; %bb.27:                               ; %sort.tail_merge__anon_16500.exit25
                                        ;   in Loop: Header=BB42_3 Depth=1
	cmp	x8, x3
	b.ls	LBB42_3
LBB42_28:                               ; %._crit_edge
	mov	x28, x8
	lsr	x21, x8, #2
	ldr	x27, [sp, #48]                  ; 8-byte Folded Reload
	cmp	x21, x23
	b.lo	LBB42_30
	b	LBB42_37
LBB42_29:                               ; %.preheader..loopexit_crit_edge.i
                                        ;   in Loop: Header=BB42_30 Depth=1
	mov	x21, x22
	cmp	x21, x23
	b.hs	LBB42_37
LBB42_30:                               ; %._crit_edge
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB42_33 Depth 2
	cmp	x21, x3
	b.hi	LBB42_37
; %bb.31:                               ; %.preheader.i
                                        ;   in Loop: Header=BB42_30 Depth=1
	lsl	x8, x21, #3
	lsl	x22, x21, #1
	add	x9, x8, x25
	cmp	x9, x27
	b.hs	LBB42_29
; %bb.32:                               ; %.lr.ph.i
                                        ;   in Loop: Header=BB42_30 Depth=1
	mov	x9, x25
	lsl	x25, x21, #4
	mov	x24, xzr
	add	x26, x9, x8
	add	x19, x9, x25
LBB42_33:                               ;   Parent Loop BB42_30 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	add	x0, x8, x24
	add	x8, x19, x24
	cmp	x8, x27
	b.hs	LBB42_35
; %bb.34:                               ;   in Loop: Header=BB42_33 Depth=2
	ldp	x5, x2, [sp, #96]               ; 16-byte Folded Reload
	mov	x1, x22
	mov	x4, x21
	ldp	x7, x3, [sp, #112]              ; 16-byte Folded Reload
	mov	x6, x20
	bl	l_sort.partial_backwards_merge__anon_16502
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
	add	x24, x24, x25
	add	x8, x26, x24
	cmp	x8, x27
	b.lo	LBB42_33
	b	LBB42_36
LBB42_35:                               ;   in Loop: Header=BB42_30 Depth=1
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x4, x21
	ldp	x5, x2, [sp, #96]               ; 16-byte Folded Reload
	mov	x6, x20
	ldp	x7, x3, [sp, #112]              ; 16-byte Folded Reload
	sub	x8, x8, x24
	lsr	x1, x8, #3
	bl	l_sort.partial_backwards_merge__anon_16502
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
LBB42_36:                               ;   in Loop: Header=BB42_30 Depth=1
	ldr	x25, [sp, #16]                  ; 8-byte Folded Reload
	mov	x21, x22
	cmp	x21, x23
	b.lo	LBB42_30
LBB42_37:                               ; %sort.tail_merge__anon_16500.exit
	lsr	x0, x28, #1
	ldp	x29, x30, [sp, #208]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #192]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            ; 16-byte Folded Reload
	add	sp, sp, #224
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
	.loh AdrpAdd	Lloh57, Lloh58
Lfunc_end42:
	.cfi_endproc
	.section	__TEXT,__const
LJTI42_0:
	.byte	(LBB42_9-LBB42_4)>>2
	.byte	(LBB42_10-LBB42_4)>>2
	.byte	(LBB42_4-LBB42_4)>>2
	.byte	(LBB42_12-LBB42_4)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function sort.rotate_merge__anon_14846
l_sort.rotate_merge__anon_14846:        ; @sort.rotate_merge__anon_14846
Lfunc_begin43:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x28, x27, [sp, #32]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x22, x4
	mov	x21, x5
	mov	x23, x3
	mov	x24, x2
	mov	x26, x0
	cmp	x1, x4, lsl #1
	stp	x6, x7, [sp, #16]               ; 16-byte Folded Spill
	b.hi	LBB43_3
; %bb.1:
	sub	x8, x1, x22
	cmp	x8, x23
	b.hi	LBB43_3
; %bb.2:
	mov	x0, x26
	mov	x2, x24
	mov	x3, x23
	mov	x4, x22
	mov	x5, x21
	ldp	x6, x7, [sp, #16]               ; 16-byte Folded Reload
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_backwards_merge__anon_16502
LBB43_3:                                ; %.preheader1
	.cfi_restore_state
	cmp	x1, x22
	b.ls	LBB43_11
; %bb.4:
	lsl	x8, x1, #3
	add	x28, x26, x8
	stp	x8, x1, [sp]                    ; 16-byte Folded Spill
	b	LBB43_7
LBB43_5:                                ;   in Loop: Header=BB43_7 Depth=1
	ldr	x8, [sp]                        ; 8-byte Folded Reload
	mov	x1, x24
	ldp	x6, x7, [sp, #16]               ; 16-byte Folded Reload
	mov	x2, x23
	mov	x3, x22
	sub	x8, x8, x27
	mov	x5, x21
	lsr	x8, x8, #3
	sub	x4, x8, x22
	bl	l_sort.rotate_merge_block__anon_16503
LBB43_6:                                ; %.loopexit
                                        ;   in Loop: Header=BB43_7 Depth=1
	ldr	x1, [sp, #8]                    ; 8-byte Folded Reload
	lsl	x22, x22, #1
	cmp	x22, x1
	b.hs	LBB43_11
LBB43_7:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB43_9 Depth 2
	lsl	x8, x22, #3
	add	x9, x8, x26
	cmp	x9, x28
	b.hs	LBB43_6
; %bb.8:                                ; %.lr.ph
                                        ;   in Loop: Header=BB43_7 Depth=1
	lsl	x25, x22, #4
	mov	x27, xzr
	add	x19, x26, x8
	add	x20, x26, x25
LBB43_9:                                ;   Parent Loop BB43_7 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x0, x26, x27
	add	x8, x20, x27
	cmp	x8, x28
	b.hs	LBB43_5
; %bb.10:                               ;   in Loop: Header=BB43_9 Depth=2
	ldp	x6, x7, [sp, #16]               ; 16-byte Folded Reload
	mov	x1, x24
	mov	x2, x23
	mov	x3, x22
	mov	x4, x22
	mov	x5, x21
	bl	l_sort.rotate_merge_block__anon_16503
	add	x27, x27, x25
	add	x8, x19, x27
	cmp	x8, x28
	b.lo	LBB43_9
	b	LBB43_6
LBB43_11:                               ; %common.ret1
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end43:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quadsort_stack_swap__anon_14847
l_sort.quadsort_stack_swap__anon_14847: ; @sort.quadsort_stack_swap__anon_14847
Lfunc_begin44:
	.cfi_startproc
; %bb.0:
	stp	x24, x23, [sp, #-64]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 64
	stp	x22, x21, [sp, #16]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	sub	sp, sp, #12, lsl #12            ; =49152
	.cfi_def_cfa_offset 49216
	mov	x19, x4
	mov	x20, x3
	mov	x21, x2
	mov	x2, sp
	mov	w3, #512
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	mov	x22, x1
	mov	x23, x0
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x2, sp
	mov	x0, x23
	mov	x1, x22
	mov	w3, #512
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	bl	l_sort.rotate_merge__anon_14846
	add	sp, sp, #12, lsl #12            ; =49152
	.cfi_def_cfa_offset 64
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp], #64             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	ret
Lfunc_end44:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.tail_swap__anon_14848
l_sort.tail_swap__anon_14848:           ; @sort.tail_swap__anon_14848
Lfunc_begin45:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x28, x27, [sp, #32]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x26, x0
	cmp	x1, #8
	stp	x4, x3, [sp, #16]               ; 16-byte Folded Spill
	str	x2, [sp, #8]                    ; 8-byte Folded Spill
	b.hs	LBB45_3
; %bb.1:
Lloh59:
	adrp	x8, LJTI45_0@PAGE
Lloh60:
	add	x8, x8, LJTI45_0@PAGEOFF
	mov	x25, x26
	adr	x9, LBB45_2
	ldrh	w10, [x8, x1, lsl #1]
	add	x9, x9, x10, lsl #2
	br	x9
LBB45_2:
	ldp	x1, x2, [x25]
	mov	x0, x4
	blr	x3
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x25, w9, uxtw #3]
	stp	x8, x9, [x25]
	b	LBB45_17
LBB45_3:
	lsr	x23, x1, #1
	lsr	x27, x1, #2
	sub	x24, x1, x23
	mov	x0, x26
	mov	x1, x27
	lsr	x25, x24, #1
	mov	x20, x2
	sub	x28, x23, x27
	sub	x22, x24, x25
	bl	l_sort.tail_swap__anon_14848
	ldp	x4, x3, [sp, #16]               ; 16-byte Folded Reload
	add	x21, x26, x27, lsl #3
	mov	x1, x28
	mov	x0, x21
	mov	x2, x20
	bl	l_sort.tail_swap__anon_14848
	ldp	x4, x3, [sp, #16]               ; 16-byte Folded Reload
	add	x19, x21, x28, lsl #3
	mov	x1, x25
	mov	x0, x19
	mov	x2, x20
	bl	l_sort.tail_swap__anon_14848
	ldp	x4, x3, [sp, #16]               ; 16-byte Folded Reload
	add	x19, x19, x25, lsl #3
	mov	x1, x22
	mov	x0, x19
	mov	x2, x20
	str	x22, [sp]                       ; 8-byte Folded Spill
	bl	l_sort.tail_swap__anon_14848
	ldp	x1, x2, [x21, #-8]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	blr	x8
	ldp	x10, x20, [sp, #16]             ; 16-byte Folded Reload
	lsl	x21, x23, #3
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB45_6
; %bb.4:
	add	x8, x26, x21
	mov	x0, x10
	ldp	x1, x2, [x8, #-8]
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x10, x20, [sp, #16]             ; 16-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB45_6
; %bb.5:
	ldp	x1, x2, [x19, #-8]
	mov	x0, x10
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	blr	x8
	ldp	x10, x20, [sp, #16]             ; 16-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB45_17
LBB45_6:                                ; %.critedge
	ldr	x22, [sp, #8]                   ; 8-byte Folded Reload
	mov	x1, x26
	mov	x2, x27
	mov	x3, x28
	mov	x4, x20
	mov	x5, x10
	mov	x0, x22
	mov	x19, x10
	bl	l_sort.parity_merge__anon_16505
	add	x0, x22, x21
	add	x1, x26, x21
	mov	x2, x25
	ldr	x3, [sp]                        ; 8-byte Folded Reload
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.parity_merge__anon_16505
	mov	x0, x26
	mov	x1, x22
	mov	x2, x23
	mov	x3, x24
	mov	x4, x20
	mov	x5, x19
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.parity_merge__anon_16505
LBB45_7:
	.cfi_restore_state
	mov	x20, x25
	ldr	x1, [x25]
	mov	x0, x4
	mov	x21, x3
	mov	x19, x4
	ldr	x2, [x20, #8]!
	blr	x3
	and	w8, w0, #0xff
	ldr	x2, [x25, #16]
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x1, [x25, w9, uxtw #3]
	str	x8, [x25]
	str	x1, [x20]
	blr	x21
	and	w9, w0, #0xff
	mov	w8, #16
	cmp	w9, #1
	mov	w9, #8
	cset	w10, eq
	csel	x8, x9, x8, eq
	ldr	x1, [x25]
	mov	x0, x19
	ldr	x2, [x20, w10, uxtw #3]
	ldr	x8, [x25, x8]
	str	x2, [x20]
	str	x8, [x25, #16]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x25, w9, uxtw #3]
	str	x8, [x25]
	str	x9, [x20]
	b	LBB45_17
LBB45_8:
	mov	x20, x25
	ldr	x1, [x25]
	mov	x0, x4
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	ldr	x2, [x20, #8]!
	blr	x8
	and	w8, w0, #0xff
	mov	x21, x25
	cmp	w8, #1
	ldr	x2, [x25, #24]
	cset	w8, eq
	cset	w9, ne
	ldr	x1, [x21, #16]!
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x25, w9, uxtw #3]
	str	x8, [x25]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x9, [x20]
	blr	x8
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	mov	w9, #16
	csel	x8, x9, x8, eq
	cset	w10, eq
	ldr	x1, [x20]
	ldr	x8, [x25, x8]
	ldr	x2, [x21, w10, uxtw #3]
	str	x8, [x25, #24]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x2, [x21]
	blr	x8
	ldp	x19, x22, [sp, #16]             ; 16-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB45_17
; %bb.9:
	ldp	x8, x2, [x25, #8]
	mov	x0, x19
	mov	x23, x22
	ldr	x1, [x25]
	stp	x2, x8, [x25, #8]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldp	x1, x2, [x25, #16]
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x25, w9, uxtw #3]
	stp	x8, x9, [x25]
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	mov	w22, #16
	cset	w9, eq
	csel	x8, x22, x8, eq
	ldr	x1, [x25, #8]
	mov	x0, x19
	ldr	x2, [x21, w9, uxtw #3]
	ldr	x8, [x25, x8]
	stp	x2, x8, [x25, #16]
	blr	x23
	and	w9, w0, #0xff
	mov	w8, #8
	cmp	w9, #1
	cset	w9, eq
	csel	x8, x8, x22, eq
	ldr	x9, [x20, w9, uxtw #3]
	ldr	x8, [x25, x8]
	stp	x9, x8, [x25, #8]
	b	LBB45_17
LBB45_10:
	mov	x21, x25
	ldr	x1, [x25]
	mov	x0, x4
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	ldr	x2, [x21, #8]!
	blr	x8
	and	w8, w0, #0xff
	mov	x20, x25
	cmp	w8, #1
	mov	x26, x25
	cset	w8, eq
	cset	w9, ne
	ldr	x1, [x20, #16]!
	ldr	x2, [x26, #24]!
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x25, w9, uxtw #3]
	str	x8, [x25]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x9, [x21]
	blr	x8
	and	w8, w0, #0xff
	mov	w23, #24
	cmp	w8, #1
	mov	w24, #16
	cset	w8, eq
	csel	x9, x24, x23, eq
	ldr	x1, [x21]
	ldr	x2, [x20, w8, uxtw #3]
	ldr	x8, [x25, x9]
	str	x2, [x20]
	str	x8, [x26]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	blr	x8
	and	w9, w0, #0xff
	mov	w8, #8
	cmp	w9, #1
	ldr	x1, [x26]
	csel	x8, x8, x24, eq
	cset	w27, eq
	ldr	x2, [x25, #32]
	ldr	x8, [x25, x8]
	ldr	x9, [x21, w27, uxtw #3]
	str	x8, [x20]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x9, [x21]
	blr	x8
	and	w9, w0, #0xff
	mov	w8, #32
	cmp	w9, #1
	cset	w9, eq
	csel	x8, x23, x8, eq
	ldp	x19, x22, [sp, #16]             ; 16-byte Folded Reload
	csetm	w10, eq
	ldr	x9, [x26, w9, uxtw #3]
	cmp	w27, w10
	ldr	x8, [x25, x8]
	str	x9, [x26]
	str	x8, [x25, #32]
	b.eq	LBB45_17
; %bb.11:
	ldp	x1, x2, [x25]
	mov	x0, x19
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldp	x1, x2, [x25, #16]
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x25, w9, uxtw #3]
	stp	x8, x9, [x25]
	blr	x22
	and	w8, w0, #0xff
	mov	w23, #24
	cmp	w8, #1
	mov	w24, #16
	cset	w8, eq
	csel	x9, x24, x23, eq
	ldr	x1, [x25, #8]
	mov	x0, x19
	ldr	x2, [x20, w8, uxtw #3]
	ldr	x8, [x25, x9]
	stp	x2, x8, [x25, #16]
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #8
	cmp	w9, #1
	mov	x0, x19
	cset	w9, eq
	csel	x8, x8, x24, eq
	ldp	x1, x2, [x25, #24]
	ldr	x9, [x21, w9, uxtw #3]
	ldr	x8, [x25, x8]
	stp	x9, x8, [x25, #8]
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #32
	cmp	w9, #1
	mov	x0, x19
	cset	w9, eq
	csel	x8, x23, x8, eq
	ldp	x1, x2, [x25]
	ldr	x9, [x26, w9, uxtw #3]
	ldr	x8, [x25, x8]
	stp	x9, x8, [x25, #24]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldp	x1, x2, [x25, #16]
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x25, w9, uxtw #3]
	stp	x8, x9, [x25]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, eq
	csel	x9, x24, x23, eq
	ldr	x8, [x20, w8, uxtw #3]
	ldr	x9, [x25, x9]
	stp	x8, x9, [x25, #16]
	b	LBB45_17
LBB45_12:
	mov	x24, x25
	ldr	x1, [x25]
	mov	x0, x4
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	ldr	x2, [x24, #8]!
	blr	x8
	and	w8, w0, #0xff
	mov	x28, x25
	cmp	w8, #1
	mov	x20, x25
	cset	w8, eq
	cset	w9, ne
	ldr	x1, [x28, #16]!
	ldr	x2, [x20, #24]!
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x9, [x25, w9, uxtw #3]
	str	x8, [x25]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x9, [x24]
	blr	x8
	and	w8, w0, #0xff
	mov	w19, #24
	cmp	w8, #1
	mov	w22, #16
	cset	w8, eq
	csel	x9, x22, x19, eq
	mov	x23, x25
	mov	x21, x25
	ldr	x8, [x28, w8, uxtw #3]
	ldr	x9, [x25, x9]
	ldr	x1, [x23, #32]!
	ldr	x2, [x21, #40]!
	str	x8, [x28]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x9, [x20]
	blr	x8
	and	w8, w0, #0xff
	mov	w9, #40
	cmp	w8, #1
	mov	w26, #32
	cset	w8, eq
	csel	x9, x26, x9, eq
	ldr	x1, [x24]
	ldr	x2, [x28]
	ldr	x8, [x23, w8, uxtw #3]
	ldr	x9, [x25, x9]
	str	x8, [x23]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x9, [x21]
	blr	x8
	and	w27, w0, #0xff
	mov	w8, #8
	cmp	w27, #1
	ldr	x1, [x20]
	csel	x8, x8, x22, eq
	cset	w9, eq
	ldr	x2, [x23]
	ldr	x8, [x25, x8]
	ldr	x9, [x24, w9, uxtw #3]
	str	x8, [x28]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x9, [x24]
	blr	x8
	and	w8, w0, #0xff
	ldr	x1, [x21]
	cmp	w8, #1
	ldr	x2, [x25, #48]
	cset	w8, eq
	csel	x9, x19, x26, eq
	cmp	w27, #1
	cinc	w24, w8, eq
	ldr	x10, [x20, w8, uxtw #3]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	ldr	x9, [x25, x9]
	str	x10, [x20]
	str	x9, [x23]
	blr	x8
	and	w9, w0, #0xff
	mov	w8, #48
	cmp	w9, #1
	mov	w10, #40
	cset	w9, eq
	csel	x8, x10, x8, eq
	ldp	x19, x22, [sp, #16]             ; 16-byte Folded Reload
	ldr	x2, [x21, w9, uxtw #3]
	csetm	w9, eq
	ldr	x8, [x25, x8]
	cmp	w24, w9
	str	x2, [x21]
	str	x8, [x25, #48]
	b.eq	LBB45_17
; %bb.13:                               ; %.cont110.i.i
	ldr	x1, [x25, #32]
	mov	x0, x19
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #40
	cmp	w9, #1
	mov	w9, #32
	cset	w10, eq
	csel	x8, x9, x8, eq
	ldp	x1, x2, [x25]
	mov	x0, x19
	ldr	x9, [x23, w10, uxtw #3]
	ldr	x8, [x25, x8]
	stp	x9, x8, [x25, #32]
	blr	x22
	and	w8, w0, #0xff
	ldr	x26, [sp, #8]                   ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	cset	w9, ne
	mov	x23, x26
	ldr	x8, [x25, w8, uxtw #3]
	str	x8, [x26]
	ldr	x8, [x25, w9, uxtw #3]
	str	x8, [x26, #8]
	ldr	x8, [x25, #16]
	str	x8, [x23, #16]!
	ldp	x1, x2, [x25, #24]
	blr	x22
	and	w8, w0, #0xff
	mov	x24, x26
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x20, w8, uxtw #3]
	str	x8, [x24, #24]!
	ldr	x8, [x20, w9, uxtw #3]
	str	x8, [x26, #32]
	ldp	x1, x2, [x25, #40]
	blr	x22
	and	w8, w0, #0xff
	mov	x20, x26
	cmp	w8, #1
	ldr	x1, [x26]
	cset	w8, eq
	cset	w9, ne
	ldr	x2, [x24]
	mov	x0, x19
	ldr	x8, [x21, w8, uxtw #3]
	str	x8, [x26, #40]
	ldr	x8, [x21, w9, uxtw #3]
	str	x8, [x20, #48]!
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	mov	x0, x19
	csel	x8, x8, xzr, eq
	csel	x9, x24, x26, eq
	add	x9, x9, #8
	csel	x21, x26, x9, eq
	csel	x24, x9, x24, eq
	ldr	x8, [x26, x8]
	str	x8, [x25]
	ldr	x1, [x21]
	ldr	x2, [x24]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x8, x24, x21, eq
	ldr	x9, [x8], #8
	csel	x21, x21, x8, eq
	csel	x24, x8, x24, eq
	str	x9, [x25, #8]
	ldr	x1, [x21]
	ldr	x2, [x24]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x8, x24, x21, eq
	ldr	x8, [x8]
	str	x8, [x25, #16]
	ldr	x1, [x23]
	ldr	x2, [x20]
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #48
	cmp	w9, #1
	mov	x0, x19
	csel	x10, x23, x20, eq
	cmp	w9, #1
	mov	w9, #16
	csel	x8, x9, x8, eq
	sub	x9, x10, #8
	csel	x21, x9, x23, eq
	csel	x20, x20, x9, eq
	ldr	x8, [x26, x8]
	str	x8, [x25, #48]
	ldr	x1, [x21]
	ldr	x2, [x20]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x8, x21, x20, eq
	ldr	x9, [x8], #-8
	csel	x21, x8, x21, eq
	csel	x20, x20, x8, eq
	str	x9, [x25, #40]
	ldr	x1, [x21]
	ldr	x2, [x20]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x8, x21, x20, eq
	ldr	x9, [x8], #-8
	csel	x21, x8, x21, eq
	csel	x20, x20, x8, eq
	str	x9, [x25, #32]
	ldr	x1, [x21]
	ldr	x2, [x20]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x21, x20, eq
	ldr	x8, [x8]
	str	x8, [x25, #24]
	b	LBB45_17
LBB45_14:
	mov	x24, x25
	ldr	x1, [x25]
	mov	x0, x4
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	ldr	x2, [x24, #8]!
	blr	x8
	and	w8, w0, #0xff
	ldr	x2, [x25, #16]
	cmp	w8, #1
	cset	w8, eq
	cset	w9, ne
	ldr	x8, [x25, w8, uxtw #3]
	ldr	x1, [x25, w9, uxtw #3]
	str	x8, [x25]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x1, [x24]
	blr	x8
	and	w9, w0, #0xff
	mov	w8, #16
	cmp	w9, #1
	mov	w9, #8
	csel	x8, x9, x8, eq
	cset	w10, eq
	mov	x21, x25
	mov	x23, x25
	ldr	x8, [x25, x8]
	ldr	x9, [x24, w10, uxtw #3]
	ldr	x1, [x21, #32]!
	ldr	x2, [x23, #40]!
	str	x8, [x25, #16]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x9, [x24]
	blr	x8
	and	w9, w0, #0xff
	mov	w8, #40
	cmp	w9, #1
	mov	w26, #32
	csel	x8, x26, x8, eq
	cset	w9, eq
	mov	x20, x25
	ldr	x8, [x25, x8]
	ldr	x2, [x21, w9, uxtw #3]
	ldr	x1, [x20, #24]!
	str	x8, [x23]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x2, [x21]
	blr	x8
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	ldr	x1, [x25, #16]
	csel	x8, x8, x26, eq
	cset	w9, eq
	ldr	x8, [x25, x8]
	ldr	x2, [x20, w9, uxtw #3]
	str	x8, [x21]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	str	x2, [x20]
	blr	x8
	and	w26, w0, #0xff
	ldr	x1, [x25]
	ldp	x0, x8, [sp, #16]               ; 16-byte Folded Reload
	ldr	x2, [x24]
	blr	x8
	and	w8, w0, #0xff
	ldp	x19, x22, [sp, #16]             ; 16-byte Folded Reload
	cmp	w8, #1
	cset	w8, ne
	cset	w9, eq
	ubfiz	x9, x9, #3, #32
	ubfiz	x8, x8, #3, #32
	cmp	w26, #1
	b.ne	LBB45_16
; %bb.15:                               ; %.cont96.i.i
	ldr	x9, [x25, x9]
	mov	x0, x19
	ldr	x27, [sp, #8]                   ; 8-byte Folded Reload
	mov	x26, x22
	str	x9, [x27]
	mov	x23, x27
	ldr	x8, [x25, x8]
	str	x8, [x27, #8]
	ldr	x8, [x25, #16]
	str	x8, [x23, #16]!
	ldp	x1, x2, [x25, #32]
	blr	x22
	and	w8, w0, #0xff
	mov	x24, x27
	cmp	w8, #1
	ldr	x1, [x27]
	cset	w8, eq
	cset	w9, ne
	mov	x0, x19
	ldr	x8, [x21, w8, uxtw #3]
	str	x8, [x27, #32]
	ldr	x8, [x21, w9, uxtw #3]
	mov	x21, x27
	str	x8, [x21, #40]!
	ldr	x2, [x25, #24]
	str	x2, [x24, #24]!
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #24
	cmp	w9, #1
	mov	x0, x19
	csel	x8, x8, xzr, eq
	csel	x9, x24, x27, eq
	add	x9, x9, #8
	csel	x22, x27, x9, eq
	csel	x24, x9, x24, eq
	ldr	x8, [x27, x8]
	str	x8, [x25]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x22, x22, x8, eq
	csel	x24, x8, x24, eq
	str	x9, [x25, #8]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x8, [x8]
	str	x8, [x25, #16]
	ldr	x1, [x23]
	ldr	x2, [x21]
	blr	x26
	and	w9, w0, #0xff
	mov	w8, #40
	cmp	w9, #1
	mov	x0, x19
	csel	x10, x23, x21, eq
	cmp	w9, #1
	mov	w9, #16
	csel	x8, x9, x8, eq
	sub	x9, x10, #8
	csel	x22, x9, x23, eq
	csel	x21, x21, x9, eq
	ldr	x8, [x27, x8]
	str	x8, [x25, #40]
	ldr	x1, [x22]
	ldr	x2, [x21]
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	csel	x8, x22, x21, eq
	ldr	x9, [x8], #-8
	csel	x22, x8, x22, eq
	csel	x21, x21, x8, eq
	str	x9, [x25, #32]
	ldr	x1, [x22]
	ldr	x2, [x21]
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x22, x21, eq
	ldr	x8, [x8]
	str	x8, [x20]
	b	LBB45_17
LBB45_16:
	ldp	x1, x2, [x25, #32]
	mov	x0, x19
	ldr	x9, [x25, x9]
	ldr	x8, [x25, x8]
	stp	x9, x8, [x25]
	blr	x22
	and	w9, w0, #0xff
	mov	w8, #40
	cmp	w9, #1
	mov	w9, #32
	cset	w10, eq
	csel	x8, x9, x8, eq
	ldr	x9, [x21, w10, uxtw #3]
	ldr	x8, [x25, x8]
	str	x9, [x25, #32]
	str	x8, [x23]
LBB45_17:                               ; %common.ret1
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
	.loh AdrpAdd	Lloh59, Lloh60
Lfunc_end45:
	.cfi_endproc
	.section	__TEXT,__const
	.p2align	1, 0x0
LJTI45_0:
	.short	(LBB45_17-LBB45_2)>>2
	.short	(LBB45_17-LBB45_2)>>2
	.short	(LBB45_2-LBB45_2)>>2
	.short	(LBB45_7-LBB45_2)>>2
	.short	(LBB45_8-LBB45_2)>>2
	.short	(LBB45_10-LBB45_2)>>2
	.short	(LBB45_14-LBB45_2)>>2
	.short	(LBB45_12-LBB45_2)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function sort.quad_swap__anon_14849
l_sort.quad_swap__anon_14849:           ; @sort.quad_swap__anon_14849
Lfunc_begin46:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #3200
	.cfi_def_cfa_offset 3296
	.cfi_remember_state
	mov	x20, x3
	mov	x21, x2
	mov	x23, x0
	mov	x19, x1
	cmp	x1, #8
	str	x0, [sp, #104]                  ; 8-byte Folded Spill
	str	x1, [sp, #16]                   ; 8-byte Folded Spill
	b.lo	LBB46_109
; %bb.1:                                ; %.lr.ph100.preheader
	ldr	x22, [sp, #104]                 ; 8-byte Folded Reload
	lsr	x25, x19, #3
	mov	x23, x22
	b	LBB46_3
LBB46_2:                                ; %.critedge
                                        ;   in Loop: Header=BB46_3 Depth=1
	add	x1, sp, #128
	mov	x0, x23
	mov	x2, x21
	mov	x3, x20
	bl	l_sort.quad_swap_merge__anon_16497
	add	x23, x23, #64
	cbz	x25, LBB46_109
LBB46_3:                                ; %.lr.ph100
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB46_10 Depth 2
                                        ;       Child Loop BB46_11 Depth 3
                                        ;         Child Loop BB46_49 Depth 4
                                        ;         Child Loop BB46_25 Depth 4
	ldp	x1, x2, [x23]
	mov	x0, x20
	sub	x25, x25, #1
	blr	x21
	ldp	x1, x2, [x23, #16]
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	cset	w27, eq
	blr	x21
	ldp	x1, x2, [x23, #32]
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	cset	w26, eq
	blr	x21
	ldp	x1, x2, [x23, #48]
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	cset	w28, eq
	blr	x21
	and	w9, w0, #0xff
	lsl	w8, w28, #2
	cmp	w9, #1
	orr	w8, w8, w26, lsl #1
	cset	w9, eq
	mov	w24, w27
	orr	w8, w8, w9, lsl #3
	orr	w8, w8, w27
	str	w9, [sp, #120]                  ; 4-byte Folded Spill
	cbz	w8, LBB46_56
; %bb.4:                                ; %.lr.ph100
                                        ;   in Loop: Header=BB46_3 Depth=1
	cmp	w8, #15
	str	w24, [sp, #112]                 ; 4-byte Folded Spill
	b.ne	LBB46_9
; %bb.5:                                ;   in Loop: Header=BB46_3 Depth=1
	ldp	x1, x2, [x23, #8]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_9
; %bb.6:                                ;   in Loop: Header=BB46_3 Depth=1
	ldp	x1, x2, [x23, #24]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_9
; %bb.7:                                ;   in Loop: Header=BB46_3 Depth=1
	ldp	x1, x2, [x23, #40]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_9
; %bb.8:                                ;   in Loop: Header=BB46_3 Depth=1
	mov	w19, w28
	mov	x22, x23
	b	LBB46_10
LBB46_9:                                ; %.critedge4
                                        ;   in Loop: Header=BB46_3 Depth=1
	mov	w19, w28
	mov	w8, #2
LBB46_10:                               ; %.outer
                                        ;   Parent Loop BB46_3 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB46_11 Depth 3
                                        ;         Child Loop BB46_49 Depth 4
                                        ;         Child Loop BB46_25 Depth 4
	mov	x9, x22
	mov	x22, x23
	str	x9, [sp, #80]                   ; 8-byte Folded Spill
	add	x9, x9, #8
	str	x9, [sp, #32]                   ; 8-byte Folded Spill
LBB46_11:                               ; %.backedge
                                        ;   Parent Loop BB46_3 Depth=1
                                        ;     Parent Loop BB46_10 Depth=2
                                        ; =>    This Loop Header: Depth=3
                                        ;         Child Loop BB46_49 Depth 4
                                        ;         Child Loop BB46_25 Depth 4
	mov	x24, x22
	cbz	w8, LBB46_30
; %bb.12:                               ; %.backedge
                                        ;   in Loop: Header=BB46_11 Depth=3
	cmp	w8, #1
	b.ne	LBB46_66
; %bb.13:                               ;   in Loop: Header=BB46_11 Depth=3
	add	x22, x24, #64
	cbz	x25, LBB46_67
; %bb.14:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #64]
	mov	x0, x20
	sub	x25, x25, #1
	blr	x21
	mov	x8, x24
	str	w0, [sp, #64]                   ; 4-byte Folded Spill
	and	w19, w0, #0xff
	ldr	x2, [x24, #88]
	mov	x0, x20
	ldr	x1, [x8, #80]!
	str	x8, [sp, #72]                   ; 8-byte Folded Spill
	blr	x21
	mov	x27, x24
	str	w0, [sp, #56]                   ; 4-byte Folded Spill
	and	w8, w0, #0xff
	ldr	x2, [x24, #104]
	mov	x0, x20
	cmp	w8, #1
	ldr	x1, [x27, #96]!
	cset	w26, ne
	blr	x21
	mov	x28, x24
	mov	w23, w0
	mov	x0, x20
	ldp	x1, x2, [x28, #112]!
	blr	x21
	cmp	w19, #1
	and	w8, w23, #0xff
	cset	w9, ne
	str	w23, [sp, #48]                  ; 4-byte Folded Spill
	str	w0, [sp, #40]                   ; 4-byte Folded Spill
	str	w9, [sp, #112]                  ; 4-byte Folded Spill
	csinc	w9, w26, wzr, eq
	cmp	w8, #1
	and	w8, w0, #0xff
	cset	w19, ne
	csinc	w9, w9, wzr, eq
	cmp	w8, #1
	cset	w8, ne
	str	w8, [sp, #120]                  ; 4-byte Folded Spill
	csinc	w8, w9, wzr, eq
	cmp	w8, #1
	b.eq	LBB46_19
; %bb.15:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #56]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_19
; %bb.16:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #72]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_19
; %bb.17:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #88]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_19
; %bb.18:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #104]
	mov	x0, x20
	blr	x21
	mov	w8, #1
	and	w9, w0, #0xff
	cmp	w9, #1
	b.eq	LBB46_11
LBB46_19:                               ; %.critedge25
                                        ;   in Loop: Header=BB46_11 Depth=3
	ldr	x4, [sp, #80]                   ; 8-byte Folded Reload
	add	x8, x24, #56
	sub	x12, x8, x4
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x4, x10
	sub	x10, x8, x10
	tbnz	w12, #4, LBB46_21
; %bb.20:                               ;   in Loop: Header=BB46_11 Depth=3
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB46_21:                               ; %._crit_edge.i
                                        ;   in Loop: Header=BB46_11 Depth=3
	ldr	x12, [x8]
	cmp	x9, #2
	ldr	x13, [x4]
	str	x12, [x4]
	str	x13, [x8]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.lo	LBB46_26
; %bb.22:                               ; %.lr.ph.preheader
                                        ;   in Loop: Header=BB46_11 Depth=3
	lsr	x12, x9, #1
	cmp	x9, #44
	b.hs	LBB46_39
LBB46_23:                               ;   in Loop: Header=BB46_11 Depth=3
	mov	x9, x12
	mov	x13, x4
	mov	x14, x11
	mov	x15, x10
LBB46_24:                               ; %.lr.ph.preheader465
                                        ;   in Loop: Header=BB46_11 Depth=3
	add	x10, x13, #8
	sub	x11, x14, #8
	add	x12, x15, #8
	sub	x8, x8, #8
LBB46_25:                               ; %.lr.ph
                                        ;   Parent Loop BB46_3 Depth=1
                                        ;     Parent Loop BB46_10 Depth=2
                                        ;       Parent Loop BB46_11 Depth=3
                                        ; =>      This Inner Loop Header: Depth=4
	ldr	x13, [x8]
	subs	x9, x9, #1
	ldr	x14, [x10]
	str	x13, [x10], #8
	str	x14, [x8], #-8
	ldr	x13, [x12]
	ldr	x14, [x11]
	str	x13, [x11], #-8
	str	x14, [x12], #8
	b.ne	LBB46_25
LBB46_26:                               ; %sort.quad_reversal.exit
                                        ;   in Loop: Header=BB46_11 Depth=3
	ldr	w8, [sp, #112]                  ; 4-byte Folded Reload
	ldr	w9, [sp, #120]                  ; 4-byte Folded Reload
	add	w8, w26, w8
	add	w8, w8, w19
	add	w8, w8, w9
	cmp	w8, #4
	b.ne	LBB46_51
; %bb.27:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #72]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_60
; %bb.28:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #88]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_60
; %bb.29:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #104]
	mov	x0, x20
	blr	x21
	mov	w8, wzr
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB46_11
	b	LBB46_60
LBB46_30:                               ;   in Loop: Header=BB46_11 Depth=3
	add	x22, x24, #64
	cbz	x25, LBB46_91
; %bb.31:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #64]
	mov	x0, x20
	sub	x25, x25, #1
	blr	x21
	ldp	x1, x2, [x24, #80]
	and	w19, w0, #0xff
	mov	x0, x20
	blr	x21
	ldp	x1, x2, [x24, #96]
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	cset	w26, eq
	blr	x21
	ldp	x1, x2, [x24, #112]
	mov	w23, w0
	mov	x0, x20
	blr	x21
	cmp	w19, #1
	and	w8, w23, #0xff
	cset	w12, eq
	csinc	w9, w26, wzr, ne
	cmp	w8, #1
	and	w8, w0, #0xff
	cset	w10, eq
	csinc	w9, w9, wzr, ne
	cmp	w8, #1
	str	w12, [sp, #112]                 ; 4-byte Folded Spill
	cset	w11, eq
	csinc	w8, w9, wzr, ne
	cmp	w8, #1
	str	w11, [sp, #120]                 ; 4-byte Folded Spill
	b.ne	LBB46_36
; %bb.32:                               ;   in Loop: Header=BB46_11 Depth=3
	add	w8, w26, w12
	add	w9, w10, w11
	mov	w19, w10
	add	w9, w8, w9
	mov	w8, #2
	cmp	w9, #4
	b.ne	LBB46_11
; %bb.33:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #72]
	mov	x0, x20
	blr	x21
	mov	w8, #2
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB46_11
; %bb.34:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #88]
	mov	x0, x20
	blr	x21
	mov	w8, #2
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB46_11
; %bb.35:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #104]
	mov	x0, x20
	blr	x21
	mov	w8, #2
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB46_11
	b	LBB46_55
LBB46_36:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #72]
	mov	x0, x20
	mov	w19, w10
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_63
; %bb.37:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #88]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_63
; %bb.38:                               ;   in Loop: Header=BB46_11 Depth=3
	ldp	x1, x2, [x24, #104]
	mov	x0, x20
	blr	x21
	mov	w8, wzr
	and	w9, w0, #0xff
	cmp	w9, #1
	b.ne	LBB46_11
	b	LBB46_63
LBB46_39:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	sub	x13, x12, #1
	add	x15, x24, #48
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB46_23
; %bb.40:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB46_23
; %bb.41:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	lsr	x13, x13, #61
	cbnz	x13, LBB46_23
; %bb.42:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	ldr	x5, [sp, #32]                   ; 8-byte Folded Reload
	lsl	x14, x12, #3
	sub	x13, x24, x14
	sub	x1, x11, x14
	add	x17, x13, #56
	add	x2, x10, #8
	add	x0, x5, x14
	cmp	x5, x8
	ccmp	x17, x0, #2, lo
	add	x3, x2, x14
	cset	w13, lo
	cmp	x5, x11
	ccmp	x1, x0, #2, lo
	cset	w14, lo
	cmp	x2, x8
	ccmp	x17, x3, #2, lo
	cset	w15, lo
	cmp	x2, x11
	ccmp	x1, x3, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x1, x8, #2, lo
	cset	w17, lo
	cmp	x2, x0
	ccmp	x5, x3, #2, lo
	b.lo	LBB46_23
; %bb.43:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	tbnz	w13, #0, LBB46_23
; %bb.44:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	tbnz	w14, #0, LBB46_23
; %bb.45:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	tbnz	w15, #0, LBB46_23
; %bb.46:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	tbnz	w16, #0, LBB46_23
; %bb.47:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB46_11 Depth=3
	tbnz	w17, #0, LBB46_23
; %bb.48:                               ; %vector.ph
                                        ;   in Loop: Header=BB46_11 Depth=3
	and	x16, x12, #0x7ffffffffffffffe
	ubfx	x9, x9, #1, #1
	lsl	x17, x16, #3
	neg	x0, x16
	add	x13, x4, x17
	sub	x14, x11, x17
	add	x15, x10, x17
	sub	x8, x8, x17
	add	x10, x10, #8
	add	x17, x24, #40
	sub	x11, x11, #16
	ldr	x1, [sp, #32]                   ; 8-byte Folded Reload
LBB46_49:                               ; %vector.body
                                        ;   Parent Loop BB46_3 Depth=1
                                        ;     Parent Loop BB46_10 Depth=2
                                        ;       Parent Loop BB46_11 Depth=3
                                        ; =>      This Inner Loop Header: Depth=4
	ldr	q0, [x1]
	adds	x0, x0, #2
	ldr	q1, [x17]
	ldr	q2, [x11]
	ldr	q3, [x10]
	ext.16b	v1, v1, v1, #8
	ext.16b	v0, v0, v0, #8
	ext.16b	v3, v3, v3, #8
	ext.16b	v2, v2, v2, #8
	str	q1, [x1], #16
	str	q0, [x17], #-16
	str	q3, [x11], #-16
	str	q2, [x10], #16
	b.ne	LBB46_49
; %bb.50:                               ; %middle.block
                                        ;   in Loop: Header=BB46_11 Depth=3
	cmp	x12, x16
	b.ne	LBB46_24
	b	LBB46_26
LBB46_51:                               ; %sort.quad_reversal.exit
                                        ;   in Loop: Header=BB46_10 Depth=2
	cbnz	w8, LBB46_60
; %bb.52:                               ;   in Loop: Header=BB46_10 Depth=2
	ldp	x1, x2, [x24, #72]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_60
; %bb.53:                               ;   in Loop: Header=BB46_10 Depth=2
	ldp	x1, x2, [x24, #88]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_60
; %bb.54:                               ;   in Loop: Header=BB46_10 Depth=2
	ldp	x1, x2, [x24, #104]
	mov	x0, x20
	blr	x21
	mov	w8, #1
	mov	x23, x22
	and	w9, w0, #0xff
	cmp	w9, #1
	b.eq	LBB46_10
	b	LBB46_60
LBB46_55:                               ;   in Loop: Header=BB46_10 Depth=2
	mov	w8, #1
	mov	x23, x22
	b	LBB46_10
LBB46_56:                               ;   in Loop: Header=BB46_3 Depth=1
	ldp	x1, x2, [x23, #8]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_2
; %bb.57:                               ;   in Loop: Header=BB46_3 Depth=1
	ldp	x1, x2, [x23, #24]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_2
; %bb.58:                               ;   in Loop: Header=BB46_3 Depth=1
	ldp	x1, x2, [x23, #40]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_2
; %bb.59:                               ;   in Loop: Header=BB46_3 Depth=1
	mov	w19, w28
	mov	w8, wzr
	str	w24, [sp, #112]                 ; 4-byte Folded Spill
	b	LBB46_10
LBB46_60:                               ; %.critedge37
                                        ;   in Loop: Header=BB46_3 Depth=1
	ldr	w8, [sp, #40]                   ; 4-byte Folded Reload
	mov	x0, x20
	ldr	w13, [sp, #64]                  ; 4-byte Folded Reload
	and	w8, w8, #0xff
	cmp	w8, #1
	ldr	w8, [sp, #48]                   ; 4-byte Folded Reload
	cset	w9, eq
	cset	w10, ne
	and	w13, w13, #0xff
	and	w8, w8, #0xff
	cmp	w8, #1
	ldr	w8, [sp, #56]                   ; 4-byte Folded Reload
	cset	w11, eq
	cset	w12, ne
	ldr	x9, [x28, w9, uxtw #3]
	and	w8, w8, #0xff
	cmp	w8, #1
	ldr	x11, [x27, w11, uxtw #3]
	cset	w8, eq
	cset	w14, ne
	cmp	w13, #1
	ldr	x12, [x27, w12, uxtw #3]
	cset	w15, ne
	cset	w13, eq
	ldr	x1, [x22, w15, uxtw #3]
	stp	x11, x12, [x24, #96]
	ldr	x15, [sp, #72]                  ; 8-byte Folded Reload
	ldr	x13, [x22, w13, uxtw #3]
	ldr	x2, [x15, w8, uxtw #3]
	ldr	x8, [x15, w14, uxtw #3]
	stp	x13, x1, [x24, #64]
	stp	x2, x8, [x24, #80]
	ldr	x8, [x28, w10, uxtw #3]
	stp	x9, x8, [x24, #112]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_63
; %bb.61:                               ;   in Loop: Header=BB46_3 Depth=1
	ldp	x1, x2, [x24, #88]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_63
; %bb.62:                               ;   in Loop: Header=BB46_3 Depth=1
	ldp	x1, x2, [x24, #104]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_64
LBB46_63:                               ; %.critedge21
                                        ;   in Loop: Header=BB46_3 Depth=1
	add	x1, sp, #128
	mov	x0, x22
	mov	x2, x21
	mov	x3, x20
	bl	l_sort.quad_swap_merge__anon_16497
LBB46_64:                               ;   in Loop: Header=BB46_3 Depth=1
	add	x23, x24, #128
LBB46_65:                               ;   in Loop: Header=BB46_3 Depth=1
	ldr	x22, [sp, #80]                  ; 8-byte Folded Reload
	ldr	x19, [sp, #16]                  ; 8-byte Folded Reload
	cbnz	x25, LBB46_3
	b	LBB46_109
LBB46_66:                               ;   in Loop: Header=BB46_3 Depth=1
	ldr	w8, [sp, #112]                  ; 4-byte Folded Reload
	add	x14, x24, #32
	ldr	w15, [sp, #120]                 ; 4-byte Folded Reload
	add	x1, sp, #128
	mov	x0, x24
	mov	x2, x21
	tst	w8, #0xf
	add	x8, x24, #16
	cset	w9, eq
	cset	w10, ne
	tst	w26, #0xf
	mov	x3, x20
	cset	w11, ne
	cset	w12, eq
	tst	w19, #0xf
	ldr	x9, [x24, w9, uxtw #3]
	ldr	x10, [x24, w10, uxtw #3]
	cset	w13, ne
	ldr	x12, [x8, w12, uxtw #3]
	ldr	x8, [x8, w11, uxtw #3]
	cset	w11, eq
	tst	w15, #0xf
	add	x15, x24, #48
	cset	w16, ne
	cset	w17, eq
	ldr	x13, [x14, w13, uxtw #3]
	stp	x10, x9, [x24]
	ldr	x9, [x14, w11, uxtw #3]
	stp	x8, x12, [x24, #16]
	ldr	x10, [x15, w16, uxtw #3]
	ldr	x8, [x15, w17, uxtw #3]
	stp	x13, x9, [x24, #32]
	stp	x10, x8, [x24, #48]
	bl	l_sort.quad_swap_merge__anon_16497
	add	x23, x24, #64
	b	LBB46_65
LBB46_67:
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	and	x23, x8, #0x7
	cmp	x23, #7
	b.ne	LBB46_69
; %bb.68:
	ldp	x1, x2, [x24, #104]
	mov	x0, x20
	blr	x21
	ldr	x25, [sp, #104]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_70
	b	LBB46_88
LBB46_69:                               ; %.critedge55
	ldr	x25, [sp, #104]                 ; 8-byte Folded Reload
	cmp	x23, #6
	b.lo	LBB46_71
LBB46_70:                               ; %.critedge55.thread
	ldp	x1, x2, [x24, #96]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_88
	b	LBB46_72
LBB46_71:                               ; %.critedge57
	cmp	x23, #5
	b.ne	LBB46_73
LBB46_72:                               ; %.critedge57.thread
	ldp	x1, x2, [x24, #88]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_88
	b	LBB46_74
LBB46_73:                               ; %.critedge59
	cmp	x23, #4
	b.lo	LBB46_75
LBB46_74:                               ; %.critedge59.thread
	ldp	x1, x2, [x24, #80]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_88
	b	LBB46_76
LBB46_75:                               ; %.critedge61
	cmp	x23, #3
	b.ne	LBB46_133
LBB46_76:                               ; %.critedge61.thread
	ldp	x1, x2, [x24, #72]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_88
LBB46_77:                               ; %.critedge63.thread
	ldp	x1, x2, [x24, #64]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_88
LBB46_78:                               ; %.critedge65.thread
	ldp	x1, x2, [x24, #56]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_88
LBB46_79:                               ; %.critedge67
	lsl	x13, x23, #3
	ldr	x6, [sp, #80]                   ; 8-byte Folded Reload
	add	x8, x22, x13
	sub	x8, x8, #8
	sub	x12, x8, x6
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x6, x10
	sub	x10, x8, x10
	tbnz	w12, #4, LBB46_81
; %bb.80:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x14, [x11]
	str	x12, [x11], #-8
	str	x14, [x10], #8
LBB46_81:                               ; %._crit_edge.i341
	ldr	x12, [x8]
	cmp	x9, #2
	ldr	x14, [x6]
	str	x12, [x6]
	str	x14, [x8]
	ldr	x12, [x10]
	ldr	x14, [x11]
	str	x12, [x11]
	str	x14, [x10]
	b.lo	LBB46_86
; %bb.82:                               ; %.lr.ph112.preheader
	lsr	x12, x9, #1
	cmp	x9, #48
	b.hs	LBB46_135
LBB46_83:
	mov	x9, x12
	mov	x14, x6
	mov	x15, x11
	mov	x16, x10
LBB46_84:                               ; %.lr.ph112.preheader463
	add	x10, x14, #8
	sub	x11, x15, #8
	add	x12, x16, #8
	sub	x8, x8, #8
LBB46_85:                               ; %.lr.ph112
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x8]
	subs	x9, x9, #1
	ldr	x14, [x10]
	str	x13, [x10], #8
	str	x14, [x8], #-8
	ldr	x13, [x12]
	ldr	x14, [x11]
	str	x13, [x11], #-8
	str	x14, [x12], #8
	b.ne	LBB46_85
LBB46_86:                               ; %sort.quad_reversal.exit350
	ldr	x19, [sp, #16]                  ; 8-byte Folded Reload
	cmp	x6, x25
	b.ne	LBB46_110
; %bb.87:
	mov	w0, wzr
	b	LBB46_132
LBB46_88:
	ldr	x5, [sp, #80]                   ; 8-byte Folded Reload
	add	x8, x24, #56
	sub	x12, x8, x5
	lsr	x9, x12, #4
	lsl	x10, x9, #3
	add	x11, x5, x10
	sub	x10, x8, x10
	tbnz	w12, #4, LBB46_90
; %bb.89:
	ldr	x12, [x10]
	sub	x9, x9, #1
	ldr	x13, [x11]
	str	x12, [x11], #-8
	str	x13, [x10], #8
LBB46_90:                               ; %._crit_edge.i331
	ldr	x12, [x8]
	cmp	x9, #2
	ldr	x13, [x5]
	str	x12, [x5]
	str	x13, [x8]
	ldr	x12, [x10]
	ldr	x13, [x11]
	str	x12, [x11]
	str	x13, [x10]
	b.hs	LBB46_92
LBB46_91:
	ldr	x19, [sp, #16]                  ; 8-byte Folded Reload
	b	LBB46_108
LBB46_92:                               ; %.lr.ph106.preheader
	lsr	x12, x9, #1
	cmp	x9, #48
	b.lo	LBB46_105
; %bb.93:                               ; %vector.scevcheck103
	sub	x13, x12, #1
	add	x15, x24, #48
	lsl	x14, x13, #3
	sub	x16, x15, x14
	cmp	x16, x15
	b.hi	LBB46_105
; %bb.94:                               ; %vector.scevcheck103
	sub	x15, x11, #8
	sub	x14, x15, x14
	cmp	x14, x15
	b.hi	LBB46_105
; %bb.95:                               ; %vector.scevcheck103
	lsr	x13, x13, #61
	cbnz	x13, LBB46_105
; %bb.96:                               ; %vector.memcheck112
	lsl	x13, x12, #3
	add	x0, x5, #8
	add	x14, x13, #8
	sub	x15, x24, x13
	add	x1, x5, x14
	add	x17, x15, #56
	cmp	x0, x8
	sub	x2, x11, x13
	ccmp	x17, x1, #2, lo
	add	x3, x10, #8
	add	x4, x10, x14
	cset	w13, lo
	cmp	x0, x11
	ccmp	x2, x1, #2, lo
	cset	w14, lo
	cmp	x3, x8
	ccmp	x17, x4, #2, lo
	cset	w15, lo
	cmp	x3, x11
	ccmp	x2, x4, #2, lo
	cset	w16, lo
	cmp	x17, x11
	ccmp	x2, x8, #2, lo
	cset	w17, lo
	cmp	x3, x1
	ccmp	x0, x4, #2, lo
	b.lo	LBB46_105
; %bb.97:                               ; %vector.memcheck112
	tbnz	w13, #0, LBB46_105
; %bb.98:                               ; %vector.memcheck112
	tbnz	w14, #0, LBB46_105
; %bb.99:                               ; %vector.memcheck112
	tbnz	w15, #0, LBB46_105
; %bb.100:                              ; %vector.memcheck112
	tbnz	w16, #0, LBB46_105
; %bb.101:                              ; %vector.memcheck112
	tbnz	w17, #0, LBB46_105
; %bb.102:                              ; %vector.ph145
	and	x16, x12, #0x7ffffffffffffffe
	ubfx	x9, x9, #1, #1
	lsl	x17, x16, #3
	add	x0, x24, #40
	add	x13, x5, x17
	sub	x14, x11, x17
	add	x15, x10, x17
	sub	x8, x8, x17
	add	x17, x5, #8
	add	x10, x10, #8
	sub	x11, x11, #16
	neg	x1, x16
LBB46_103:                              ; %vector.body159
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x17]
	adds	x1, x1, #2
	ldr	q1, [x0]
	ldr	q2, [x11]
	ldr	q3, [x10]
	ext.16b	v1, v1, v1, #8
	ext.16b	v0, v0, v0, #8
	ext.16b	v3, v3, v3, #8
	ext.16b	v2, v2, v2, #8
	str	q1, [x17], #16
	str	q0, [x0], #-16
	str	q3, [x11], #-16
	str	q2, [x10], #16
	b.ne	LBB46_103
; %bb.104:                              ; %middle.block142
	ldr	x19, [sp, #16]                  ; 8-byte Folded Reload
	cmp	x12, x16
	b.ne	LBB46_106
	b	LBB46_108
LBB46_105:
	mov	x9, x12
	mov	x13, x5
	mov	x14, x11
	mov	x15, x10
	ldr	x19, [sp, #16]                  ; 8-byte Folded Reload
LBB46_106:                              ; %.lr.ph106.preheader464
	add	x10, x13, #8
	sub	x11, x14, #8
	add	x12, x15, #8
	sub	x8, x8, #8
LBB46_107:                              ; %.lr.ph106
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x8]
	subs	x9, x9, #1
	ldr	x14, [x10]
	str	x13, [x10], #8
	str	x14, [x8], #-8
	ldr	x13, [x12]
	ldr	x14, [x11]
	str	x13, [x11], #-8
	str	x14, [x12], #8
	b.ne	LBB46_107
LBB46_108:
	mov	x23, x22
LBB46_109:                              ; %.loopexit
	and	x1, x19, #0x7
	add	x2, sp, #128
	mov	x0, x23
	mov	x3, x21
	mov	x4, x20
	bl	l_sort.tail_swap__anon_14848
	ldr	x25, [sp, #104]                 ; 8-byte Folded Reload
LBB46_110:
	cmp	x19, #32
	b.hs	LBB46_123
LBB46_111:                              ; %._crit_edge
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	and	x10, x8, #0x1f
	cmp	x10, #8
	b.ls	LBB46_131
; %bb.112:                              ; %.preheader.lr.ph.i
	lsl	x8, x10, #3
	mov	w22, #8
	add	x26, x25, x8
	stp	x8, x10, [sp, #112]             ; 16-byte Folded Spill
LBB46_113:                              ; %.preheader.i
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB46_115 Depth 2
	lsl	x8, x22, #3
	lsl	x23, x22, #1
	add	x9, x8, x25
	cmp	x9, x26
	b.hs	LBB46_118
; %bb.114:                              ; %.lr.ph.i
                                        ;   in Loop: Header=BB46_113 Depth=1
	mov	x9, x25
	mov	x25, x21
	lsl	x21, x22, #4
	mov	x19, xzr
	add	x27, x9, x8
	mov	x24, x9
	add	x28, x9, x21
LBB46_115:                              ;   Parent Loop BB46_113 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x0, x24, x19
	add	x8, x28, x19
	cmp	x8, x26
	b.hs	LBB46_119
; %bb.116:                              ;   in Loop: Header=BB46_115 Depth=2
	add	x2, sp, #128
	mov	x1, x23
	mov	w3, #32
	mov	x4, x22
	mov	x5, x25
	mov	x6, x20
	bl	l_sort.partial_backwards_merge__anon_16511
	add	x19, x19, x21
	add	x8, x27, x19
	cmp	x8, x26
	b.lo	LBB46_115
; %bb.117:                              ;   in Loop: Header=BB46_113 Depth=1
	mov	x22, x23
	mov	x21, x25
	b	LBB46_120
LBB46_118:                              ; %.preheader..loopexit_crit_edge.i
                                        ;   in Loop: Header=BB46_113 Depth=1
	mov	x22, x23
	b	LBB46_121
LBB46_119:                              ;   in Loop: Header=BB46_113 Depth=1
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	add	x2, sp, #128
	mov	w3, #32
	mov	x4, x22
	mov	x5, x25
	mov	x6, x20
	sub	x8, x8, x19
	mov	x21, x25
	lsr	x1, x8, #3
	bl	l_sort.partial_backwards_merge__anon_16511
	mov	x22, x23
LBB46_120:                              ; %.loopexit.i
                                        ;   in Loop: Header=BB46_113 Depth=1
	ldr	x10, [sp, #120]                 ; 8-byte Folded Reload
	mov	x25, x24
LBB46_121:                              ; %.loopexit.i
                                        ;   in Loop: Header=BB46_113 Depth=1
	mov	w0, #1
	cmp	x22, x10
	b.hs	LBB46_132
; %bb.122:                              ; %.loopexit.i
                                        ;   in Loop: Header=BB46_113 Depth=1
	cmp	x22, #33
	b.lo	LBB46_113
	b	LBB46_132
LBB46_123:                              ; %.lr.ph116
	add	x8, sp, #128
	lsr	x22, x19, #5
	add	x10, x8, #120
	add	x9, x8, #128
	mov	x28, x21
	stp	x20, x21, [sp, #88]             ; 16-byte Folded Spill
	stp	x9, x10, [sp, #64]              ; 16-byte Folded Spill
	add	x10, x8, #248
	add	x9, x8, #136
	stp	x9, x10, [sp, #48]              ; 16-byte Folded Spill
	orr	x10, x8, #0x8
	add	x9, x8, #16
	add	x8, x8, #24
	stp	x9, x10, [sp, #32]              ; 16-byte Folded Spill
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	b	LBB46_125
LBB46_124:                              ;   in Loop: Header=BB46_125 Depth=1
	subs	x22, x22, #1
	add	x25, x25, #256
	b.eq	LBB46_111
LBB46_125:                              ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB46_129 Depth 2
	mov	x24, x25
	mov	x0, x20
	ldr	x1, [x24, #56]!
	mov	x19, x24
	ldr	x2, [x19, #8]!
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_128
; %bb.126:                              ;   in Loop: Header=BB46_125 Depth=1
	ldp	x1, x2, [x25, #120]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB46_128
; %bb.127:                              ;   in Loop: Header=BB46_125 Depth=1
	ldp	x1, x2, [x25, #184]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB46_124
LBB46_128:                              ; %.critedge69
                                        ;   in Loop: Header=BB46_125 Depth=1
	ldr	x1, [x25]
	mov	x0, x20
	ldr	x2, [x25, #64]
	str	x22, [sp, #80]                  ; 8-byte Folded Spill
	blr	x21
	and	w8, w0, #0xff
	mov	x27, x21
	cmp	w8, #1
	mov	x0, x20
	csel	x8, x19, x25, eq
	ldr	x9, [x8], #8
	csel	x21, x25, x8, eq
	csel	x19, x8, x19, eq
	str	x9, [sp, #128]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x27
	and	w8, w0, #0xff
	mov	x22, x25
	cmp	w8, #1
	ldr	x1, [x25, #56]
	csel	x8, x19, x21, eq
	mov	x0, x20
	ldr	x2, [x22, #120]!
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #136]
	blr	x27
	and	w8, w0, #0xff
	mov	w10, #56
	cmp	w8, #1
	mov	x0, x20
	csel	x9, x24, x22, eq
	cmp	w8, #1
	mov	w8, #120
	sub	x9, x9, #8
	csel	x8, x10, x8, eq
	csel	x22, x22, x9, eq
	csel	x23, x9, x24, eq
	ldr	x8, [x25, x8]
	str	x8, [sp, #248]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #144]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #240]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #152]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #232]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #160]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #224]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #168]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #216]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x9, [x8], #8
	csel	x19, x8, x19, eq
	csel	x21, x21, x8, eq
	str	x9, [sp, #176]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x22, x22, x8, eq
	csel	x23, x8, x23, eq
	str	x9, [sp, #208]
	ldr	x1, [x21]
	ldr	x2, [x19]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x19, x21, eq
	ldr	x8, [x8]
	str	x8, [sp, #184]
	ldr	x1, [x23]
	ldr	x2, [x22]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x22, eq
	ldr	x9, [x8], #-8
	csel	x19, x8, x23, eq
	csel	x21, x22, x8, eq
	str	x9, [sp, #200]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x19, x21, eq
	mov	x19, x25
	mov	x21, x25
	ldr	x8, [x8]
	ldr	x1, [x19, #128]!
	ldr	x2, [x21, #192]!
	str	x8, [sp, #192]
	blr	x27
	and	w8, w0, #0xff
	mov	w9, #192
	cmp	w8, #1
	mov	w8, #128
	csel	x8, x9, x8, eq
	csel	x9, x21, x19, eq
	add	x9, x9, #8
	mov	x0, x20
	csel	x19, x19, x9, eq
	csel	x21, x9, x21, eq
	ldr	x8, [x25, x8]
	str	x8, [sp, #256]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	mov	x22, x25
	cmp	w8, #1
	mov	x23, x25
	csel	x8, x21, x19, eq
	mov	x0, x20
	ldr	x1, [x22, #184]!
	ldr	x2, [x23, #248]!
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #264]
	blr	x27
	and	w8, w0, #0xff
	mov	w10, #184
	cmp	w8, #1
	str	x25, [sp, #104]                 ; 8-byte Folded Spill
	csel	x9, x22, x23, eq
	cmp	w8, #1
	mov	w8, #248
	mov	x0, x20
	csel	x8, x10, x8, eq
	ldr	x10, [sp, #104]                 ; 8-byte Folded Reload
	add	x26, sp, #128
	sub	x9, x9, #8
	add	x25, x26, #128
	csel	x23, x23, x9, eq
	ldr	x8, [x10, x8]
	csel	x22, x9, x22, eq
	str	x8, [sp, #376]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #272]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #368]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #280]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #360]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #288]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #352]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #296]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #344]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x9, [x8], #8
	csel	x21, x8, x21, eq
	csel	x19, x19, x8, eq
	str	x9, [sp, #304]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x23, x23, x8, eq
	csel	x22, x8, x22, eq
	str	x9, [sp, #336]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x19, eq
	ldr	x8, [x8]
	str	x8, [sp, #312]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x27
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x22, x23, eq
	ldr	x9, [x8], #-8
	csel	x19, x8, x22, eq
	csel	x21, x23, x8, eq
	str	x9, [sp, #328]
	ldr	x1, [x19]
	ldr	x2, [x21]
	blr	x27
	and	w8, w0, #0xff
	ldr	x1, [sp, #128]
	cmp	w8, #1
	ldr	x2, [sp, #256]
	csel	x8, x19, x21, eq
	mov	x0, x20
	ldr	x8, [x8]
	str	x8, [sp, #320]
	blr	x27
	and	w8, w0, #0xff
	mov	w9, #16
	cmp	w8, #1
	mov	w10, #144
	csel	x9, x10, x9, eq
	csel	x8, x25, x26, eq
	ldp	x11, x10, [sp, #32]             ; 16-byte Folded Reload
	add	x9, x26, x9
	mov	w24, #248
	mov	w19, #8
	csel	x20, x26, x10, eq
	csel	x10, x10, x9, eq
	str	x10, [sp, #120]                 ; 8-byte Folded Spill
	orr	x10, x9, #0x8
	csel	x22, x11, x10, eq
	ldr	x10, [sp, #24]                  ; 8-byte Folded Reload
	add	x9, x9, #16
	ldr	x8, [x8]
	csel	x9, x10, x9, eq
	ldp	x10, x26, [sp, #48]             ; 16-byte Folded Reload
	str	x9, [sp, #112]                  ; 8-byte Folded Spill
	ldp	x9, x27, [sp, #64]              ; 16-byte Folded Reload
	csel	x23, x10, x9, eq
	ldr	x9, [sp, #104]                  ; 8-byte Folded Reload
	str	x8, [x9]
LBB46_129:                              ; %.cont.i397
                                        ;   Parent Loop BB46_125 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x25, x20
	ldr	x21, [sp, #88]                  ; 8-byte Folded Reload
	ldr	x2, [x23]
	ldr	x1, [x25], #16
	mov	x0, x21
	blr	x28
	and	w9, w0, #0xff
	add	x8, x20, #8
	cmp	w9, #1
	ldr	x10, [sp, #120]                 ; 8-byte Folded Reload
	csel	x9, x23, x20, eq
	csel	x11, x8, x22, eq
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	mov	x0, x21
	csel	x20, x20, x10, eq
	cset	w10, eq
	ldr	x9, [x9]
	csel	x22, x25, x8, eq
	ldr	x25, [sp, #104]                 ; 8-byte Folded Reload
	add	x8, x22, #8
	add	x23, x23, w10, uxtw #3
	str	x9, [x25, x19]
	ldr	x1, [x27]
	ldr	x2, [x26]
	stp	x8, x11, [sp, #112]             ; 16-byte Folded Spill
	blr	x28
	and	w8, w0, #0xff
	add	x19, x19, #8
	cmp	w8, #1
	csel	x8, x27, x26, eq
	ldr	x9, [x8], #-8
	csel	x26, x26, x8, eq
	csel	x27, x8, x27, eq
	str	x9, [x25, x24]
	sub	x24, x24, #8
	cmp	x24, #128
	b.ne	LBB46_129
; %bb.130:                              ; %sort.parity_merge__anon_16505.exit399
                                        ;   in Loop: Header=BB46_125 Depth=1
	ldp	x20, x21, [sp, #88]             ; 16-byte Folded Reload
	ldr	x1, [x27]
	ldr	x2, [x26]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	ldr	x22, [sp, #80]                  ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x8, x27, x26, eq
	ldr	x8, [x8]
	str	x8, [x25, x24]
	b	LBB46_124
LBB46_131:
	mov	w0, #1
LBB46_132:                              ; %common.ret
	add	sp, sp, #3200
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB46_133:                              ; %.critedge63
	.cfi_restore_state
	cmp	x23, #2
	b.hs	LBB46_77
; %bb.134:                              ; %.critedge65
	cbnz	x23, LBB46_78
	b	LBB46_79
LBB46_135:                              ; %vector.scevcheck174
	sub	x14, x12, #1
	add	x15, x13, x24
	add	x16, x15, #48
	lsl	x15, x14, #3
	sub	x17, x16, x15
	cmp	x17, x16
	b.hi	LBB46_83
; %bb.136:                              ; %vector.scevcheck174
	sub	x16, x11, #8
	sub	x15, x16, x15
	cmp	x15, x16
	b.hi	LBB46_83
; %bb.137:                              ; %vector.scevcheck174
	lsr	x14, x14, #61
	cbnz	x14, LBB46_83
; %bb.138:                              ; %vector.memcheck183
	lsl	x14, x12, #3
	add	x1, x6, #8
	sub	x16, x13, x14
	add	x15, x14, #8
	add	x16, x16, x24
	add	x2, x6, x15
	add	x0, x16, #56
	cmp	x1, x8
	ccmp	x0, x2, #2, lo
	sub	x3, x11, x14
	add	x4, x10, #8
	add	x5, x10, x15
	cset	w14, lo
	cmp	x1, x11
	ccmp	x3, x2, #2, lo
	cset	w15, lo
	cmp	x4, x8
	ccmp	x0, x5, #2, lo
	cset	w16, lo
	cmp	x4, x11
	ccmp	x3, x5, #2, lo
	cset	w17, lo
	cmp	x0, x11
	ccmp	x3, x8, #2, lo
	cset	w0, lo
	cmp	x4, x2
	ccmp	x1, x5, #2, lo
	b.lo	LBB46_83
; %bb.139:                              ; %vector.memcheck183
	tbnz	w14, #0, LBB46_83
; %bb.140:                              ; %vector.memcheck183
	tbnz	w15, #0, LBB46_83
; %bb.141:                              ; %vector.memcheck183
	tbnz	w16, #0, LBB46_83
; %bb.142:                              ; %vector.memcheck183
	tbnz	w17, #0, LBB46_83
; %bb.143:                              ; %vector.memcheck183
	tbnz	w0, #0, LBB46_83
; %bb.144:                              ; %vector.ph216
	and	x17, x12, #0x7ffffffffffffffe
	add	x13, x13, x24
	lsl	x0, x17, #3
	ubfx	x9, x9, #1, #1
	add	x14, x6, x0
	sub	x15, x11, x0
	add	x16, x10, x0
	sub	x8, x8, x0
	add	x0, x6, #8
	add	x10, x10, #8
	add	x13, x13, #40
	sub	x11, x11, #16
	neg	x1, x17
LBB46_145:                              ; %vector.body230
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x0]
	adds	x1, x1, #2
	ldr	q1, [x13]
	ldr	q2, [x11]
	ldr	q3, [x10]
	ext.16b	v1, v1, v1, #8
	ext.16b	v0, v0, v0, #8
	ext.16b	v3, v3, v3, #8
	ext.16b	v2, v2, v2, #8
	str	q1, [x0], #16
	str	q0, [x13], #-16
	str	q3, [x11], #-16
	str	q2, [x10], #16
	b.ne	LBB46_145
; %bb.146:                              ; %middle.block213
	cmp	x12, x17
	b.ne	LBB46_84
	b	LBB46_86
Lfunc_end46:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quad_merge__anon_14850
l_sort.quad_merge__anon_14850:          ; @sort.quad_merge__anon_14850
Lfunc_begin47:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #224
	.cfi_def_cfa_offset 224
	stp	x28, x27, [sp, #128]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #144]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #208]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	lsl	x8, x1, #3
	mov	x24, x5
	mov	x20, x4
	mov	x27, x1
	mov	x26, x0
	cmp	x1, #128
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
	add	x8, x0, x8
	str	x0, [sp, #32]                   ; 8-byte Folded Spill
	stp	x2, x3, [sp, #112]              ; 16-byte Folded Spill
	str	x8, [sp, #72]                   ; 8-byte Folded Spill
	mov	w8, #128
	b.lo	LBB47_28
; %bb.1:
	cmp	x3, #128
	b.lo	LBB47_28
; %bb.2:                                ; %.preheader.lr.ph
	mov	x19, x2
	mov	w8, #128
	str	x27, [sp, #8]                   ; 8-byte Folded Spill
LBB47_3:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB47_8 Depth 2
                                        ;     Child Loop BB47_17 Depth 2
                                        ;       Child Loop BB47_19 Depth 3
	lsr	x10, x8, #2
	lsr	x9, x8, #1
	lsl	x28, x8, #3
	mov	x22, xzr
	ldr	x27, [sp, #16]                  ; 8-byte Folded Reload
	stp	x10, x9, [sp, #56]              ; 16-byte Folded Spill
	mov	w9, #6
	madd	x10, x8, x9, x26
	add	x9, x26, x8, lsl #1
	lsl	x8, x8, #2
	stp	x9, x10, [sp, #88]              ; 16-byte Folded Spill
	add	x9, x19, x8
	stp	x8, x9, [sp, #40]               ; 16-byte Folded Spill
	add	x8, x26, x8
	str	x8, [sp, #104]                  ; 8-byte Folded Spill
	add	x8, x26, x28
	str	x8, [sp, #80]                   ; 8-byte Folded Spill
	b	LBB47_8
LBB47_4:                                ;   in Loop: Header=BB47_8 Depth=2
	mov	x0, x19
	mov	x1, x25
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	bl	_memcpy
	ldp	x0, x2, [sp, #48]               ; 16-byte Folded Reload
	mov	x1, x21
	mov	x3, x2
LBB47_5:                                ;   in Loop: Header=BB47_8 Depth=2
	mov	x4, x20
	mov	x5, x24
	bl	l_sort.cross_merge__anon_14865
LBB47_6:                                ;   in Loop: Header=BB47_8 Depth=2
	ldr	x2, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x25
	mov	x1, x19
	mov	x4, x20
	mov	x5, x24
	mov	x3, x2
	bl	l_sort.cross_merge__anon_14865
LBB47_7:                                ; %sort.quad_merge_block__anon_16510.exit
                                        ;   in Loop: Header=BB47_8 Depth=2
	ldp	x9, x8, [sp, #72]               ; 16-byte Folded Reload
	add	x22, x22, x28
	sub	x27, x27, x28
	add	x8, x8, x22
	cmp	x8, x9
	b.hi	LBB47_14
LBB47_8:                                ;   Parent Loop BB47_3 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	x0, x24
	ldr	x9, [sp, #104]                  ; 8-byte Folded Reload
	add	x25, x26, x22
	add	x8, x8, x22
	add	x21, x9, x22
	ldr	x9, [sp, #96]                   ; 8-byte Folded Reload
	ldp	x1, x2, [x8, #-8]
	add	x19, x9, x22
	blr	x20
	ldp	x1, x2, [x19, #-8]
	and	w8, w0, #0xff
	mov	x0, x24
	cmp	w8, #1
	cset	w23, ne
	blr	x20
	and	w8, w0, #0xff
Lloh61:
	adrp	x11, LJTI47_0@PAGE
Lloh62:
	add	x11, x11, LJTI47_0@PAGEOFF
	cmp	w8, #1
	cset	w8, ne
	orr	w8, w23, w8, lsl #1
	adr	x9, LBB47_4
	ldrb	w10, [x11, x8]
	add	x9, x9, x10, lsl #2
	ldr	x19, [sp, #112]                 ; 8-byte Folded Reload
	br	x9
LBB47_9:                                ;   in Loop: Header=BB47_8 Depth=2
	mov	x23, x22
	ldr	x22, [sp, #56]                  ; 8-byte Folded Reload
	mov	x0, x19
	mov	x1, x25
	mov	x4, x20
	mov	x5, x24
	mov	x2, x22
	mov	x3, x22
	bl	l_sort.cross_merge__anon_14865
	ldr	x0, [sp, #48]                   ; 8-byte Folded Reload
	mov	x1, x21
	mov	x2, x22
	mov	x3, x22
	mov	x22, x23
	b	LBB47_5
LBB47_10:                               ;   in Loop: Header=BB47_8 Depth=2
	ldr	x2, [sp, #56]                   ; 8-byte Folded Reload
	mov	x0, x19
	mov	x1, x25
	mov	x4, x20
	mov	x5, x24
	mov	x3, x2
	bl	l_sort.cross_merge__anon_14865
	ldp	x2, x0, [sp, #40]               ; 16-byte Folded Reload
	mov	x1, x21
	b	LBB47_13
LBB47_11:                               ;   in Loop: Header=BB47_8 Depth=2
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	mov	x0, x24
	add	x8, x8, x22
	ldp	x1, x2, [x8, #-8]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB47_7
; %bb.12:                               ;   in Loop: Header=BB47_8 Depth=2
	mov	x0, x19
	mov	x1, x25
	mov	x2, x28
LBB47_13:                               ;   in Loop: Header=BB47_8 Depth=2
	bl	_memcpy
	b	LBB47_6
LBB47_14:                               ;   in Loop: Header=BB47_3 Depth=1
	ldr	x10, [sp, #56]                  ; 8-byte Folded Reload
	lsr	x11, x27, #3
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
	cmp	x10, x11
	b.hs	LBB47_26
; %bb.15:                               ;   in Loop: Header=BB47_3 Depth=1
	cmp	x10, x3
	b.hi	LBB47_26
; %bb.16:                               ; %.preheader.lr.ph.i16
                                        ;   in Loop: Header=BB47_3 Depth=1
	and	x8, x27, #0xfffffffffffffff8
	add	x28, x26, x22
	add	x27, x28, x8
	str	x22, [sp, #24]                  ; 8-byte Folded Spill
	stp	x8, x11, [sp, #96]              ; 16-byte Folded Spill
LBB47_17:                               ; %.preheader.i18
                                        ;   Parent Loop BB47_3 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB47_19 Depth 3
	lsl	x8, x10, #3
	lsl	x21, x10, #1
	add	x9, x28, x8
	cmp	x9, x27
	b.hs	LBB47_22
; %bb.18:                               ; %.lr.ph.i21
                                        ;   in Loop: Header=BB47_17 Depth=2
	mov	x9, x26
	lsl	x23, x10, #4
	mov	x11, x22
	add	x8, x9, x8
	add	x9, x9, x23
	mov	x26, x24
	mov	x25, xzr
	mov	x22, x10
	add	x24, x11, x8
	add	x19, x11, x9
LBB47_19:                               ;   Parent Loop BB47_3 Depth=1
                                        ;     Parent Loop BB47_17 Depth=2
                                        ; =>    This Inner Loop Header: Depth=3
	add	x0, x28, x25
	add	x8, x19, x25
	cmp	x8, x27
	b.hs	LBB47_23
; %bb.20:                               ;   in Loop: Header=BB47_19 Depth=3
	ldp	x2, x3, [sp, #112]              ; 16-byte Folded Reload
	mov	x1, x21
	mov	x4, x22
	mov	x5, x20
	mov	x6, x26
	bl	l_sort.partial_backwards_merge__anon_16511
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
	add	x25, x25, x23
	add	x8, x24, x25
	cmp	x8, x27
	b.lo	LBB47_19
; %bb.21:                               ;   in Loop: Header=BB47_17 Depth=2
	mov	x10, x21
	mov	x24, x26
	ldr	x26, [sp, #32]                  ; 8-byte Folded Reload
	ldr	x19, [sp, #112]                 ; 8-byte Folded Reload
	b	LBB47_24
LBB47_22:                               ; %.preheader..loopexit_crit_edge.i20
                                        ;   in Loop: Header=BB47_17 Depth=2
	mov	x10, x21
	cmp	x10, x11
	b.lo	LBB47_25
	b	LBB47_26
LBB47_23:                               ;   in Loop: Header=BB47_17 Depth=2
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	mov	x4, x22
	ldp	x19, x3, [sp, #112]             ; 16-byte Folded Reload
	mov	x5, x20
	mov	x6, x26
	sub	x8, x8, x25
	mov	x24, x26
	lsr	x1, x8, #3
	mov	x2, x19
	bl	l_sort.partial_backwards_merge__anon_16511
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
	mov	x10, x21
	ldr	x26, [sp, #32]                  ; 8-byte Folded Reload
LBB47_24:                               ; %.loopexit.i23
                                        ;   in Loop: Header=BB47_17 Depth=2
	ldr	x22, [sp, #24]                  ; 8-byte Folded Reload
	ldr	x11, [sp, #104]                 ; 8-byte Folded Reload
	cmp	x10, x11
	b.hs	LBB47_26
LBB47_25:                               ; %.loopexit.i23
                                        ;   in Loop: Header=BB47_17 Depth=2
	cmp	x10, x3
	b.ls	LBB47_17
LBB47_26:                               ; %sort.tail_merge__anon_16509.exit25
                                        ;   in Loop: Header=BB47_3 Depth=1
	ldr	x27, [sp, #8]                   ; 8-byte Folded Reload
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	cmp	x8, x27
	b.hi	LBB47_28
; %bb.27:                               ; %sort.tail_merge__anon_16509.exit25
                                        ;   in Loop: Header=BB47_3 Depth=1
	cmp	x8, x3
	b.ls	LBB47_3
LBB47_28:                               ; %._crit_edge
	lsr	x21, x8, #2
	ldr	x28, [sp, #72]                  ; 8-byte Folded Reload
	cmp	x21, x27
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	b.lo	LBB47_30
	b	LBB47_37
LBB47_29:                               ; %.preheader..loopexit_crit_edge.i
                                        ;   in Loop: Header=BB47_30 Depth=1
	mov	x21, x25
	cmp	x21, x27
	b.hs	LBB47_37
LBB47_30:                               ; %._crit_edge
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB47_33 Depth 2
	cmp	x21, x3
	b.hi	LBB47_37
; %bb.31:                               ; %.preheader.i
                                        ;   in Loop: Header=BB47_30 Depth=1
	lsl	x8, x21, #3
	lsl	x25, x21, #1
	add	x9, x8, x26
	cmp	x9, x28
	b.hs	LBB47_29
; %bb.32:                               ; %.lr.ph.i
                                        ;   in Loop: Header=BB47_30 Depth=1
	lsl	x23, x21, #4
	mov	x9, x26
	mov	x22, xzr
	add	x26, x26, x8
	add	x19, x9, x23
LBB47_33:                               ;   Parent Loop BB47_30 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	add	x0, x8, x22
	add	x8, x19, x22
	cmp	x8, x28
	b.hs	LBB47_35
; %bb.34:                               ;   in Loop: Header=BB47_33 Depth=2
	ldp	x2, x3, [sp, #112]              ; 16-byte Folded Reload
	mov	x1, x25
	mov	x4, x21
	mov	x5, x20
	mov	x6, x24
	bl	l_sort.partial_backwards_merge__anon_16511
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
	add	x22, x22, x23
	add	x8, x26, x22
	cmp	x8, x28
	b.lo	LBB47_33
	b	LBB47_36
LBB47_35:                               ;   in Loop: Header=BB47_30 Depth=1
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	mov	x4, x21
	ldp	x2, x3, [sp, #112]              ; 16-byte Folded Reload
	mov	x5, x20
	mov	x6, x24
	sub	x8, x8, x22
	lsr	x1, x8, #3
	bl	l_sort.partial_backwards_merge__anon_16511
	ldr	x3, [sp, #120]                  ; 8-byte Folded Reload
LBB47_36:                               ;   in Loop: Header=BB47_30 Depth=1
	ldr	x26, [sp, #32]                  ; 8-byte Folded Reload
	mov	x21, x25
	cmp	x21, x27
	b.lo	LBB47_30
LBB47_37:                               ; %sort.tail_merge__anon_16509.exit
	ldp	x29, x30, [sp, #208]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #192]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #128]            ; 16-byte Folded Reload
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	lsr	x0, x8, #1
	add	sp, sp, #224
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
	.loh AdrpAdd	Lloh61, Lloh62
Lfunc_end47:
	.cfi_endproc
	.section	__TEXT,__const
LJTI47_0:
	.byte	(LBB47_9-LBB47_4)>>2
	.byte	(LBB47_4-LBB47_4)>>2
	.byte	(LBB47_10-LBB47_4)>>2
	.byte	(LBB47_11-LBB47_4)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function sort.rotate_merge__anon_14851
l_sort.rotate_merge__anon_14851:        ; @sort.rotate_merge__anon_14851
Lfunc_begin48:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x28, x27, [sp, #32]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x20, x5
	mov	x21, x4
	mov	x22, x3
	mov	x23, x2
	mov	x25, x0
	cmp	x1, x4, lsl #1
	str	x6, [sp, #24]                   ; 8-byte Folded Spill
	b.hi	LBB48_3
; %bb.1:
	sub	x8, x1, x21
	cmp	x8, x22
	b.hi	LBB48_3
; %bb.2:
	mov	x0, x25
	mov	x2, x23
	mov	x3, x22
	mov	x4, x21
	mov	x5, x20
	ldr	x6, [sp, #24]                   ; 8-byte Folded Reload
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_backwards_merge__anon_16511
LBB48_3:                                ; %.preheader1
	.cfi_restore_state
	cmp	x1, x21
	b.ls	LBB48_11
; %bb.4:
	lsl	x8, x1, #3
	add	x27, x25, x8
	stp	x8, x1, [sp, #8]                ; 16-byte Folded Spill
	b	LBB48_7
LBB48_5:                                ;   in Loop: Header=BB48_7 Depth=1
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x1, x23
	mov	x2, x22
	mov	x3, x21
	mov	x5, x20
	ldr	x6, [sp, #24]                   ; 8-byte Folded Reload
	sub	x8, x8, x28
	lsr	x8, x8, #3
	sub	x4, x8, x21
	bl	l_sort.rotate_merge_block__anon_16512
LBB48_6:                                ; %.loopexit
                                        ;   in Loop: Header=BB48_7 Depth=1
	ldr	x1, [sp, #16]                   ; 8-byte Folded Reload
	lsl	x21, x21, #1
	cmp	x21, x1
	b.hs	LBB48_11
LBB48_7:                                ; %.preheader
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB48_9 Depth 2
	lsl	x8, x21, #3
	add	x9, x8, x25
	cmp	x9, x27
	b.hs	LBB48_6
; %bb.8:                                ; %.lr.ph
                                        ;   in Loop: Header=BB48_7 Depth=1
	lsl	x26, x21, #4
	mov	x28, xzr
	add	x24, x25, x8
	add	x19, x25, x26
LBB48_9:                                ;   Parent Loop BB48_7 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x0, x25, x28
	add	x8, x19, x28
	cmp	x8, x27
	b.hs	LBB48_5
; %bb.10:                               ;   in Loop: Header=BB48_9 Depth=2
	mov	x1, x23
	mov	x2, x22
	mov	x3, x21
	mov	x4, x21
	mov	x5, x20
	ldr	x6, [sp, #24]                   ; 8-byte Folded Reload
	bl	l_sort.rotate_merge_block__anon_16512
	add	x28, x28, x26
	add	x8, x24, x28
	cmp	x8, x27
	b.lo	LBB48_9
	b	LBB48_6
LBB48_11:                               ; %common.ret1
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end48:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quadsort_stack_swap__anon_14852
l_sort.quadsort_stack_swap__anon_14852: ; @sort.quadsort_stack_swap__anon_14852
Lfunc_begin49:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-64]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 64
	stp	x22, x21, [sp, #16]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w27, -56
	.cfi_offset w28, -64
	sub	sp, sp, #12, lsl #12            ; =49152
	.cfi_def_cfa_offset 49216
	mov	x19, x3
	mov	x20, x2
	mov	x2, sp
	mov	w3, #512
	mov	x4, x20
	mov	x5, x19
	mov	x21, x1
	mov	x22, x0
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x2, sp
	mov	x0, x22
	mov	x1, x21
	mov	w3, #512
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.rotate_merge__anon_14851
	add	sp, sp, #12, lsl #12            ; =49152
	.cfi_def_cfa_offset 64
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #64             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end49:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.flux_partition__anon_14854
l_sort.flux_partition__anon_14854:      ; @sort.flux_partition__anon_14854
Lfunc_begin50:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #240
	.cfi_def_cfa_offset 240
	stp	x28, x27, [sp, #144]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #160]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #176]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #192]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #224]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	neg	x8, x7
	mov	x19, x7
	ldp	x21, x27, [sp, #240]
	mov	x22, x6
	mov	x26, x5
	stp	x8, x6, [sp, #48]               ; 16-byte Folded Spill
	add	x8, sp, #136
	mov	x23, x4
	mov	x20, x2
	mov	x25, x1
	mov	x4, xzr
	lsr	x8, x8, #4
	stp	x27, x7, [sp, #72]              ; 16-byte Folded Spill
	stp	x21, x1, [sp, #104]             ; 16-byte Folded Spill
	str	x0, [sp, #120]                  ; 8-byte Folded Spill
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
LBB50_1:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB50_4 Depth 2
                                        ;     Child Loop BB50_6 Depth 2
                                        ;     Child Loop BB50_17 Depth 2
                                        ;     Child Loop BB50_24 Depth 2
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	cmp	x23, #2049
	str	x23, [sp, #128]                 ; 8-byte Folded Spill
	str	x3, [sp, #64]                   ; 8-byte Folded Spill
	add	x28, x3, x8
	stp	x4, x28, [sp, #88]              ; 16-byte Folded Spill
	b.hs	LBB50_3
; %bb.2:                                ;   in Loop: Header=BB50_1 Depth=1
	mov	x24, x0
	mov	x0, x20
	mov	x1, x23
	mov	x2, x26
	mov	x3, x22
	mov	x4, x19
	mov	x5, x21
	mov	x6, x27
	mov	x7, x28
	bl	l_sort.median_of_nine__anon_16513
	b	LBB50_19
LBB50_3:                                ;   in Loop: Header=BB50_1 Depth=1
	mov	w8, #32
LBB50_4:                                ;   Parent Loop BB50_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x21, x8
	mul	x8, x8, x8
	mul	x9, x8, x21
	lsl	x8, x21, #1
	cmp	x9, x23
	b.lo	LBB50_4
; %bb.5:                                ;   in Loop: Header=BB50_1 Depth=1
	udiv	x8, x23, x21
	ldr	x10, [sp, #24]                  ; 8-byte Folded Reload
	cmp	x20, x0
	str	x20, [sp, #40]                  ; 8-byte Folded Spill
	csel	x28, x25, x0, eq
	ldr	x22, [sp, #104]                 ; 8-byte Folded Reload
	mov	x24, x28
	mul	x27, x8, x19
	udiv	x9, x10, x8
	str	x8, [sp, #136]
	msub	x9, x9, x8, x10
	madd	x20, x9, x19, x20
	subs	x9, x21, #1
	csinc	x23, x21, xzr, hi
	str	x9, [sp, #32]                   ; 8-byte Folded Spill
LBB50_6:                                ;   Parent Loop BB50_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x24
	mov	x1, x20
	blr	x22
	add	x20, x20, x27
	subs	x23, x23, #1
	add	x24, x24, x19
	b.ne	LBB50_6
; %bb.7:                                ;   in Loop: Header=BB50_1 Depth=1
	madd	x23, x21, x19, x28
	lsr	x24, x21, #1
	mov	x0, x28
	mov	x1, x24
	cmp	x21, #192
	b.hs	LBB50_9
; %bb.8:                                ;   in Loop: Header=BB50_1 Depth=1
	ldr	x22, [sp, #56]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x21, [sp, #104]                 ; 8-byte Folded Reload
	mov	x3, x26
	ldr	x27, [sp, #72]                  ; 8-byte Folded Reload
	mov	x5, x19
	mov	x4, x22
	mov	x6, x21
	mov	x7, x27
	bl	l_sort.tail_swap__anon_14832
	madd	x20, x24, x19, x28
	mov	x1, x24
	mov	x2, x23
	mov	x3, x26
	mov	x0, x20
	mov	x4, x22
	mov	x5, x19
	mov	x6, x21
	mov	x7, x27
	bl	l_sort.tail_swap__anon_14832
	b	LBB50_13
LBB50_9:                                ;   in Loop: Header=BB50_1 Depth=1
	ldr	x22, [sp, #56]                  ; 8-byte Folded Reload
	mov	x2, x26
	ldr	x21, [sp, #104]                 ; 8-byte Folded Reload
	mov	x4, x19
	ldr	x27, [sp, #72]                  ; 8-byte Folded Reload
	mov	x3, x22
	mov	x5, x21
	mov	x6, x27
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB50_11
; %bb.10:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	x0, x28
	mov	x1, x24
	mov	x2, x23
	mov	x3, x24
	mov	x4, x26
	mov	x5, x22
	mov	x6, x19
	mov	x7, x21
	str	x27, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x28
	mov	x1, x24
	mov	x2, x23
	mov	x3, x24
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	stp	x21, x27, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB50_11:                               ;   in Loop: Header=BB50_1 Depth=1
	madd	x20, x24, x19, x28
	mov	x1, x24
	mov	x2, x26
	mov	x3, x22
	mov	x0, x20
	mov	x4, x19
	mov	x5, x21
	mov	x6, x27
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB50_13
; %bb.12:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	x0, x20
	mov	x1, x24
	mov	x2, x23
	mov	x3, x24
	mov	x4, x26
	mov	x5, x22
	mov	x6, x19
	mov	x7, x21
	str	x27, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x24
	mov	x2, x23
	mov	x3, x24
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	stp	x21, x27, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB50_13:                               ; %sort.quadsort_swap__anon_14855.exit34.i
                                        ;   in Loop: Header=BB50_1 Depth=1
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	mov	x0, x22
	mov	w1, #1
	madd	x21, x8, x19, x28
	blr	x27
	mov	x0, x22
	mov	x1, x21
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB50_15
; %bb.14:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	w21, wzr
	b	LBB50_16
LBB50_15:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	x0, x22
	mov	w1, #1
	sub	x8, x24, #1
	madd	x21, x8, x19, x28
	blr	x27
	mov	x0, x22
	mov	x1, x21
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w21, ne
LBB50_16:                               ;   in Loop: Header=BB50_1 Depth=1
	clz	x8, x24
	mov	w9, #64
	sub	x1, x9, x8
	mov	x0, x22
	blr	x27
LBB50_17:                               ; %.lr.ph.i.i
                                        ;   Parent Loop BB50_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x22
	mov	x1, x28
	mov	x2, x20
	lsr	x23, x24, #1
	blr	x26
	mul	x8, x23, x19
	and	w9, w0, #0xff
	cmp	w9, #1
	csel	x9, x8, xzr, eq
	csel	x8, xzr, x8, eq
	add	x20, x20, x9
	add	x28, x28, x8
	cmp	x24, #4
	mov	x24, x23
	b.hs	LBB50_17
; %bb.18:                               ; %sort.median_of_cube_root__anon_16514.exit
                                        ;   in Loop: Header=BB50_1 Depth=1
	mov	x0, x22
	mov	x1, x28
	mov	x2, x20
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x28, x20, eq
	ldp	x28, x8, [sp, #96]              ; 16-byte Folded Reload
	mov	x0, x28
	blr	x8
	ldp	x24, x23, [sp, #120]            ; 16-byte Folded Reload
	ldr	x20, [sp, #40]                  ; 8-byte Folded Reload
	cbnz	w21, LBB50_54
LBB50_19:                               ;   in Loop: Header=BB50_1 Depth=1
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cbz	x8, LBB50_21
; %bb.20:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	x0, x22
	mov	w1, #1
	blr	x27
	mov	x0, x22
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB50_53
LBB50_21:                               ; %.critedge
                                        ;   in Loop: Header=BB50_1 Depth=1
	mov	x0, x22
	mov	x1, x23
	blr	x27
	cmp	x23, #8
	b.hs	LBB50_23
; %bb.22:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	x19, xzr
	mov	x21, x25
	mov	x8, x24
	b	LBB50_25
LBB50_23:                               ; %.cont82.i.preheader
                                        ;   in Loop: Header=BB50_1 Depth=1
	mov	x27, x19
	mov	x19, xzr
	mov	x8, x24
	mov	x21, x25
	mov	w24, #8
	mov	x25, x22
	ldr	x22, [sp, #104]                 ; 8-byte Folded Reload
LBB50_24:                               ; %.cont82.i
                                        ;   Parent Loop BB50_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x25
	mov	x1, x20
	mov	x2, x28
	mov	x23, x8
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x23, eq
	add	x8, x0, x27
	csel	x21, x8, x21, eq
	csel	x23, x23, x8, eq
	blr	x22
	add	x20, x20, x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x23, eq
	add	x8, x0, x27
	csel	x21, x8, x21, eq
	csel	x23, x23, x8, eq
	blr	x22
	add	x20, x20, x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x23, eq
	add	x8, x0, x27
	csel	x21, x8, x21, eq
	csel	x23, x23, x8, eq
	blr	x22
	add	x20, x20, x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x23, eq
	add	x8, x0, x27
	csel	x21, x8, x21, eq
	csel	x23, x23, x8, eq
	blr	x22
	add	x20, x20, x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x23, eq
	add	x8, x0, x27
	csel	x21, x8, x21, eq
	csel	x23, x23, x8, eq
	blr	x22
	add	x20, x20, x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x23, eq
	add	x8, x0, x27
	csel	x21, x8, x21, eq
	csel	x23, x23, x8, eq
	blr	x22
	add	x20, x20, x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x23, eq
	add	x8, x0, x27
	csel	x21, x8, x21, eq
	csel	x23, x23, x8, eq
	blr	x22
	add	x20, x20, x27
	mov	x0, x25
	mov	x1, x20
	mov	x2, x28
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x23, eq
	add	x8, x0, x27
	csel	x21, x8, x21, eq
	csel	x23, x23, x8, eq
	blr	x22
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	add	x20, x20, x27
	cmp	x21, x8
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	ccmp	x23, x8, #4, ne
	mov	x8, x23
	ldr	x23, [sp, #128]                 ; 8-byte Folded Reload
	csel	x19, x24, x19, eq
	add	x24, x24, #8
	cmp	x24, x23
	b.ls	LBB50_24
LBB50_25:                               ; %._crit_edge.i
                                        ;   in Loop: Header=BB50_1 Depth=1
	ands	x9, x23, #0x7
	str	x9, [sp, #88]                   ; 8-byte Folded Spill
	b.eq	LBB50_33
; %bb.26:                               ; %.cont.i
                                        ;   in Loop: Header=BB50_1 Depth=1
	ldr	x22, [sp, #56]                  ; 8-byte Folded Reload
	mov	x1, x20
	ldr	x2, [sp, #96]                   ; 8-byte Folded Reload
	mov	x28, x8
	mov	x0, x22
	blr	x26
	and	w24, w0, #0xff
	ldr	x27, [sp, #80]                  ; 8-byte Folded Reload
	cmp	w24, #1
	mov	x1, x20
	csel	x0, x21, x28, eq
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	add	x23, x0, x27
	csel	x28, x28, x23, eq
	blr	x8
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x8, #1
	b.eq	LBB50_34
; %bb.27:                               ; %.cont.i.1
                                        ;   in Loop: Header=BB50_1 Depth=1
	add	x20, x20, x27
	mov	x0, x22
	mov	x1, x20
	ldr	x2, [sp, #96]                   ; 8-byte Folded Reload
	cmp	w24, #1
	csel	x21, x23, x21, eq
	blr	x26
	and	w23, w0, #0xff
	mov	x1, x20
	cmp	w23, #1
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	csel	x0, x21, x28, eq
	add	x25, x0, x27
	csel	x28, x28, x25, eq
	blr	x8
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x8, #2
	b.eq	LBB50_34
; %bb.28:                               ; %.cont.i.2
                                        ;   in Loop: Header=BB50_1 Depth=1
	add	x20, x20, x27
	mov	x0, x22
	mov	x1, x20
	ldr	x2, [sp, #96]                   ; 8-byte Folded Reload
	cmp	w23, #1
	csel	x21, x25, x21, eq
	blr	x26
	and	w23, w0, #0xff
	mov	x1, x20
	cmp	w23, #1
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	csel	x0, x21, x28, eq
	add	x25, x0, x27
	csel	x28, x28, x25, eq
	blr	x8
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x8, #3
	b.eq	LBB50_34
; %bb.29:                               ; %.cont.i.3
                                        ;   in Loop: Header=BB50_1 Depth=1
	add	x20, x20, x27
	mov	x0, x22
	mov	x1, x20
	ldr	x2, [sp, #96]                   ; 8-byte Folded Reload
	cmp	w23, #1
	csel	x21, x25, x21, eq
	blr	x26
	and	w23, w0, #0xff
	mov	x1, x20
	cmp	w23, #1
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	csel	x0, x21, x28, eq
	add	x25, x0, x27
	csel	x28, x28, x25, eq
	blr	x8
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x8, #4
	b.eq	LBB50_34
; %bb.30:                               ; %.cont.i.4
                                        ;   in Loop: Header=BB50_1 Depth=1
	add	x20, x20, x27
	mov	x0, x22
	mov	x1, x20
	ldr	x2, [sp, #96]                   ; 8-byte Folded Reload
	cmp	w23, #1
	csel	x21, x25, x21, eq
	blr	x26
	and	w23, w0, #0xff
	mov	x1, x20
	cmp	w23, #1
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	csel	x0, x21, x28, eq
	add	x25, x0, x27
	csel	x28, x28, x25, eq
	blr	x8
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x8, #5
	b.eq	LBB50_34
; %bb.31:                               ; %.cont.i.5
                                        ;   in Loop: Header=BB50_1 Depth=1
	add	x20, x20, x27
	mov	x0, x22
	mov	x1, x20
	ldr	x2, [sp, #96]                   ; 8-byte Folded Reload
	cmp	w23, #1
	csel	x21, x25, x21, eq
	blr	x26
	and	w23, w0, #0xff
	mov	x1, x20
	cmp	w23, #1
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	csel	x0, x21, x28, eq
	add	x25, x0, x27
	csel	x28, x28, x25, eq
	blr	x8
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x8, #6
	b.eq	LBB50_34
; %bb.32:                               ; %.cont.i.6
                                        ;   in Loop: Header=BB50_1 Depth=1
	add	x20, x20, x27
	mov	x0, x22
	mov	x1, x20
	ldr	x2, [sp, #96]                   ; 8-byte Folded Reload
	cmp	w23, #1
	csel	x21, x25, x21, eq
	blr	x26
	and	w8, w0, #0xff
	mov	x1, x20
	cmp	w8, #1
	csel	x0, x21, x28, eq
	add	x8, x0, x27
	csel	x28, x28, x8, eq
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	blr	x8
	b	LBB50_34
LBB50_33:                               ;   in Loop: Header=BB50_1 Depth=1
	ldr	x22, [sp, #56]                  ; 8-byte Folded Reload
	mov	x28, x8
	ldr	x27, [sp, #80]                  ; 8-byte Folded Reload
LBB50_34:                               ; %._crit_edge173.i
                                        ;   in Loop: Header=BB50_1 Depth=1
	ldp	x11, x4, [sp, #120]             ; 16-byte Folded Reload
	sub	x8, x28, x11
	cmp	x19, x4, lsr #2
	udiv	x10, x8, x27
	sub	x24, x4, x10
	b.ls	LBB50_36
; %bb.35:                               ; %._crit_edge173.i
                                        ;   in Loop: Header=BB50_1 Depth=1
	cmp	x4, x10
	b.ne	LBB50_51
LBB50_36:                               ; %sort.flux_default_partition__anon_16516.exit
                                        ;   in Loop: Header=BB50_1 Depth=1
	cmp	x24, #97
	b.lo	LBB50_39
; %bb.37:                               ; %sort.flux_default_partition__anon_16516.exit
                                        ;   in Loop: Header=BB50_1 Depth=1
	lsr	x9, x24, #5
	cmp	x10, x9
	b.ls	LBB50_39
; %bb.38:                               ;   in Loop: Header=BB50_1 Depth=1
	ldp	x8, x19, [sp, #72]              ; 16-byte Folded Reload
	mov	x4, x24
	mov	x5, x26
	ldp	x21, x1, [sp, #104]             ; 16-byte Folded Reload
	mov	x6, x22
	mov	x20, x11
	ldr	x28, [sp, #96]                  ; 8-byte Folded Reload
	mov	x27, x8
	madd	x0, x10, x19, x11
	mov	x7, x19
	stp	x21, x8, [sp]
	mov	x25, x10
	mov	x2, x1
	mov	x3, x28
	mov	x23, x1
	bl	l_sort.flux_partition__anon_14854
	b	LBB50_45
LBB50_39:                               ;   in Loop: Header=BB50_1 Depth=1
	ldp	x23, x19, [sp, #72]             ; 16-byte Folded Reload
	ldr	x21, [sp, #112]                 ; 8-byte Folded Reload
	ldr	x28, [sp, #96]                  ; 8-byte Folded Reload
	cmp	x8, x19
	b.lo	LBB50_74
; %bb.40:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	x20, x11
	cmp	x4, x10
	b.eq	LBB50_64
; %bb.41:                               ;   in Loop: Header=BB50_1 Depth=1
	madd	x27, x10, x19, x20
	mov	x1, x21
	mul	x2, x24, x19
	mov	x25, x10
	mov	x0, x27
	bl	_memcpy
	cmp	x24, #95
	b.hi	LBB50_43
; %bb.42:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	x7, x23
	mov	x23, x21
	mov	x2, x21
	ldr	x21, [sp, #104]                 ; 8-byte Folded Reload
	mov	x0, x27
	mov	x1, x24
	mov	x3, x26
	mov	x4, x22
	mov	x5, x19
	mov	x6, x21
	mov	x27, x7
	bl	l_sort.tail_swap__anon_14832
	b	LBB50_45
LBB50_43:                               ;   in Loop: Header=BB50_1 Depth=1
	mov	x6, x23
	mov	x23, x21
	ldr	x21, [sp, #104]                 ; 8-byte Folded Reload
	mov	x0, x27
	mov	x1, x24
	mov	x2, x26
	mov	x3, x22
	mov	x4, x19
	mov	x5, x21
	str	x27, [sp, #128]                 ; 8-byte Folded Spill
	mov	x27, x6
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB50_45
; %bb.44:                               ;   in Loop: Header=BB50_1 Depth=1
	ldr	x0, [sp, #128]                  ; 8-byte Folded Reload
	mov	x1, x24
	mov	x2, x23
	mov	x3, x24
	mov	x4, x26
	mov	x5, x22
	mov	x6, x19
	mov	x7, x21
	str	x27, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	ldr	x0, [sp, #128]                  ; 8-byte Folded Reload
	mov	x1, x24
	ldr	x2, [sp, #112]                  ; 8-byte Folded Reload
	mov	x3, x24
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	stp	x21, x8, [sp]
	bl	l_sort.rotate_merge__anon_14836
LBB50_45:                               ; %sort.quadsort_swap__anon_14855.exit61
                                        ;   in Loop: Header=BB50_1 Depth=1
	cmp	x25, #97
	mov	x4, x25
	mov	x25, x23
	mov	x0, x20
	b.lo	LBB50_47
; %bb.46:                               ; %sort.quadsort_swap__anon_14855.exit61
                                        ;   in Loop: Header=BB50_1 Depth=1
	mov	x23, x4
	mov	x20, x0
	mov	x3, x28
	lsr	x8, x4, #5
	cmp	x24, x8
	b.hi	LBB50_1
LBB50_47:
	cmp	x4, #96
	b.hi	LBB50_66
; %bb.48:
	b.ne	LBB50_71
; %bb.49:
	mov	w1, #96
	mov	x2, x26
	mov	x3, x22
	mov	x4, x19
	mov	x5, x21
	mov	x6, x27
	mov	x20, x0
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB50_74
; %bb.50:
	mov	x21, x20
	mov	x0, x20
	ldr	x20, [sp, #104]                 ; 8-byte Folded Reload
	mov	w1, #96
	mov	x2, x25
	mov	w3, #96
	mov	x4, x26
	mov	x5, x22
	mov	x6, x19
	mov	x7, x20
	str	x27, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x21
	mov	w1, #96
	mov	x2, x25
	mov	w3, #96
	b	LBB50_69
LBB50_51:
	ldr	x19, [sp, #80]                  ; 8-byte Folded Reload
	mov	x28, x10
	ldr	x25, [sp, #112]                 ; 8-byte Folded Reload
	mov	x23, x11
	madd	x20, x10, x19, x11
	mul	x2, x24, x19
	mov	x1, x25
	mov	x0, x20
	bl	_memcpy
	cmp	x24, #95
	b.hi	LBB50_58
; %bb.52:
	ldr	x21, [sp, #72]                  ; 8-byte Folded Reload
	mov	x0, x20
	mov	x1, x24
	mov	x2, x25
	mov	x3, x26
	mov	x4, x22
	mov	x5, x19
	ldr	x6, [sp, #104]                  ; 8-byte Folded Reload
	mov	x7, x21
	bl	l_sort.tail_swap__anon_14832
	b	LBB50_60
LBB50_53:
	mov	x0, x24
	mov	x1, x25
	mov	x2, x24
	mov	x3, x28
	mov	x4, x23
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	str	x27, [sp, #8]
	b	LBB50_65
LBB50_54:
	cmp	x20, x25
	b.ne	LBB50_56
; %bb.55:
	mul	x2, x23, x19
	mov	x0, x24
	mov	x1, x25
	bl	_memcpy
LBB50_56:
	ldr	x6, [sp, #104]                  ; 8-byte Folded Reload
	cmp	x23, #95
	b.hi	LBB50_67
; %bb.57:
	mov	x0, x24
	mov	x1, x23
	mov	x2, x25
	mov	x3, x26
	mov	x4, x22
	mov	x5, x19
	b	LBB50_72
LBB50_58:
	ldr	x21, [sp, #72]                  ; 8-byte Folded Reload
	mov	x0, x20
	mov	x1, x24
	mov	x2, x26
	mov	x3, x22
	mov	x4, x19
	ldr	x5, [sp, #104]                  ; 8-byte Folded Reload
	mov	x6, x21
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB50_60
; %bb.59:
	ldr	x23, [sp, #104]                 ; 8-byte Folded Reload
	mov	x0, x20
	mov	x1, x24
	mov	x2, x25
	mov	x3, x24
	mov	x4, x26
	mov	x5, x22
	mov	x6, x19
	mov	x7, x23
	str	x21, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x20
	mov	x1, x24
	mov	x2, x25
	mov	x3, x24
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	stp	x23, x21, [sp]
	ldr	x23, [sp, #120]                 ; 8-byte Folded Reload
	bl	l_sort.rotate_merge__anon_14836
LBB50_60:                               ; %sort.quadsort_swap__anon_14855.exit.i
	mov	x1, x28
	cmp	x28, #95
	b.hi	LBB50_62
; %bb.61:
	mov	x0, x23
	mov	x2, x25
	mov	x3, x26
	mov	x4, x22
	mov	x5, x19
	ldr	x6, [sp, #104]                  ; 8-byte Folded Reload
	mov	x7, x21
	b	LBB50_73
LBB50_62:
	mov	x0, x23
	mov	x2, x26
	mov	x3, x22
	mov	x4, x19
	ldr	x5, [sp, #104]                  ; 8-byte Folded Reload
	mov	x6, x21
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB50_74
; %bb.63:
	ldr	x20, [sp, #104]                 ; 8-byte Folded Reload
	mov	x0, x23
	mov	x1, x28
	mov	x2, x25
	mov	x3, x28
	mov	x4, x26
	mov	x5, x22
	mov	x6, x19
	mov	x7, x20
	mov	x24, x28
	str	x21, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x23
	mov	x1, x28
	mov	x2, x25
	mov	x3, x28
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	str	x21, [sp, #8]
	b	LBB50_70
LBB50_64:
	mov	x0, x20
	mov	x1, x21
	mov	x2, x20
	mov	x3, x28
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	str	x23, [sp, #8]
LBB50_65:                               ; %common.ret
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.flux_reverse_partition__anon_16515
	b	LBB50_74
LBB50_66:
	mov	x1, x25
	mov	x2, x0
	mov	x3, x28
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	stp	x21, x27, [sp]
	bl	l_sort.flux_reverse_partition__anon_16515
	b	LBB50_74
LBB50_67:
	mov	x0, x24
	mov	x1, x23
	mov	x2, x26
	mov	x3, x22
	mov	x4, x19
	mov	x5, x6
	mov	x6, x27
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB50_74
; %bb.68:
	ldr	x20, [sp, #104]                 ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x23
	mov	x2, x25
	mov	x3, x23
	mov	x4, x26
	mov	x5, x22
	mov	x6, x19
	mov	x7, x20
	str	x27, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x24
	mov	x1, x23
	mov	x2, x25
	mov	x3, x23
LBB50_69:                               ; %common.ret
	mov	x5, x26
	mov	x6, x22
	mov	x7, x19
	str	x27, [sp, #8]
LBB50_70:                               ; %common.ret
	str	x20, [sp]
	bl	l_sort.rotate_merge__anon_14836
	b	LBB50_74
LBB50_71:
	mov	x1, x4
	mov	x2, x25
	mov	x3, x26
	mov	x4, x22
	mov	x5, x19
	mov	x6, x21
LBB50_72:                               ; %common.ret
	mov	x7, x27
LBB50_73:                               ; %common.ret
	bl	l_sort.tail_swap__anon_14832
LBB50_74:                               ; %common.ret
	ldp	x29, x30, [sp, #224]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #208]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #176]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #160]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #144]            ; 16-byte Folded Reload
	add	sp, sp, #240
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end50:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.cross_merge__anon_14856
l_sort.cross_merge__anon_14856:         ; @sort.cross_merge__anon_14856
Lfunc_begin51:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #368
	.cfi_def_cfa_offset 368
	stp	x28, x27, [sp, #272]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #288]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #304]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #320]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #336]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #352]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	madd	x8, x6, x2, x1
	mov	x19, x7
	mov	x23, x6
	mov	x27, x2
	sub	x24, x8, x6
	mov	x22, x1
	mov	x26, x3
	lsl	x9, x6, #4
	stp	x8, x0, [sp, #216]              ; 16-byte Folded Spill
	ldr	x8, [sp, #368]
	stp	x4, x5, [sp, #240]              ; 16-byte Folded Spill
	str	x9, [sp, #8]                    ; 8-byte Folded Spill
	str	x8, [sp, #232]                  ; 8-byte Folded Spill
	madd	x8, x6, x3, x24
	str	x6, [sp, #64]                   ; 8-byte Folded Spill
	str	x8, [sp, #88]                   ; 8-byte Folded Spill
	add	x8, x2, #1
	cmp	x8, x3
	b.lo	LBB51_7
; %bb.1:
	add	x8, x26, #1
	cmp	x8, x27
	b.lo	LBB51_7
; %bb.2:
	cmp	x27, #31
	b.ls	LBB51_7
; %bb.3:
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x21, [sp, #248]                 ; 8-byte Folded Reload
	sub	x20, x8, x23
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	mov	x0, x21
	add	x23, x22, x20
	blr	x8
	mov	x0, x21
	mov	x1, x23
	ldr	x2, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	ldr	x23, [sp, #64]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB51_7
; %bb.4:
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x21, [sp, #248]                 ; 8-byte Folded Reload
	add	x23, x8, x20
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	mov	x0, x21
	blr	x8
	mov	x0, x21
	mov	x1, x22
	mov	x2, x23
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	ldr	x23, [sp, #64]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB51_7
; %bb.5:
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x21, [sp, #248]                 ; 8-byte Folded Reload
	sub	x23, x8, x20
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	mov	x0, x21
	blr	x8
	mov	x0, x21
	mov	x1, x24
	mov	x2, x23
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	ldr	x23, [sp, #64]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB51_7
; %bb.6:
	neg	x8, x20
	ldr	x20, [sp, #248]                 ; 8-byte Folded Reload
	add	x23, x24, x8
	mov	w1, #1
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	mov	x0, x20
	blr	x8
	mov	x0, x20
	mov	x1, x23
	ldr	x2, [sp, #88]                   ; 8-byte Folded Reload
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	ldr	x23, [sp, #64]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB51_45
LBB51_7:                                ; %.critedge
	lsl	x9, x23, #3
	neg	x8, x23
	lsl	x10, x23, #1
	stp	x9, x19, [sp, #256]             ; 16-byte Folded Spill
	sub	x9, x9, x23
	str	x8, [sp, #96]                   ; 8-byte Folded Spill
	add	x8, x27, x26
	sub	x8, x8, #1
	str	x9, [sp, #104]                  ; 8-byte Folded Spill
	neg	x9, x9
	str	x9, [sp, #16]                   ; 8-byte Folded Spill
	ldr	x9, [sp, #224]                  ; 8-byte Folded Reload
	madd	x8, x8, x23, x9
	lsl	x9, x23, #2
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	add	x8, x10, x23
	stp	x8, x10, [sp, #48]              ; 16-byte Folded Spill
	lsl	x8, x8, #1
	stp	x8, x9, [sp, #32]               ; 16-byte Folded Spill
	add	x8, x9, x23
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	b	LBB51_9
LBB51_8:                                ; %.loopexit
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x23, [sp, #64]                  ; 8-byte Folded Reload
	ldr	x22, [sp, #208]                 ; 8-byte Folded Reload
LBB51_9:                                ; %.loopexit
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB51_11 Depth 2
                                        ;     Child Loop BB51_15 Depth 2
                                        ;     Child Loop BB51_21 Depth 2
                                        ;     Child Loop BB51_25 Depth 2
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	sub	x21, x24, x22
	str	x24, [sp, #72]                  ; 8-byte Folded Spill
	cmp	x21, x8
	b.le	LBB51_19
; %bb.10:                               ; %.preheader274.preheader
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x9, [sp, #104]                  ; 8-byte Folded Reload
	mov	x20, xzr
	ldr	x14, [sp, #224]                 ; 8-byte Folded Reload
	add	x26, x22, x23
	ldp	x13, x12, [sp, #24]             ; 16-byte Folded Reload
	add	x8, x14, x9
	add	x9, x22, x9
	ldp	x11, x10, [sp, #40]             ; 16-byte Folded Reload
	str	x8, [sp, #200]                  ; 8-byte Folded Spill
	add	x8, x14, x12
	str	x9, [sp, #208]                  ; 8-byte Folded Spill
	add	x9, x22, x12
	str	x8, [sp, #192]                  ; 8-byte Folded Spill
	add	x8, x14, x13
	str	x9, [sp, #144]                  ; 8-byte Folded Spill
	add	x9, x22, x13
	str	x8, [sp, #184]                  ; 8-byte Folded Spill
	add	x8, x14, x11
	str	x9, [sp, #136]                  ; 8-byte Folded Spill
	add	x9, x22, x11
	str	x8, [sp, #176]                  ; 8-byte Folded Spill
	add	x8, x14, x10
	str	x9, [sp, #128]                  ; 8-byte Folded Spill
	add	x9, x22, x10
	str	x8, [sp, #168]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	str	x9, [sp, #120]                  ; 8-byte Folded Spill
	add	x15, x14, x8
	add	x14, x14, x23
	add	x25, x22, x8
	stp	x14, x15, [sp, #152]            ; 16-byte Folded Spill
LBB51_11:                               ; %.preheader274
                                        ;   Parent Loop BB51_9 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	mov	x24, x22
	add	x27, x22, x20
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	mov	w1, #1
	add	x28, x8, x20
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x23, x8, x20
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	blr	x8
	mov	x0, x22
	mov	x1, x23
	ldr	x2, [sp, #216]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB51_14
; %bb.12:                               ;   in Loop: Header=BB51_11 Depth=2
	mov	x0, x28
	mov	x1, x27
	blr	x19
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	add	x1, x26, x20
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	add	x1, x25, x20
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #168]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #192]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #200]                  ; 8-byte Folded Reload
	mov	x1, x23
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	mov	x22, x24
	sub	x21, x21, x8
	add	x20, x20, x8
	cmp	x21, x8
	b.hi	LBB51_11
; %bb.13:                               ; %.loopexit.loopexit
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	add	x22, x22, x20
	ldp	x23, x24, [sp, #64]             ; 16-byte Folded Reload
	add	x8, x8, x20
	str	x8, [sp, #224]                  ; 8-byte Folded Spill
	b	LBB51_9
LBB51_14:                               ; %.preheader271
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	mov	x25, xzr
	ldr	x9, [sp, #72]                   ; 8-byte Folded Reload
	add	x8, x9, x8
	str	x8, [sp, #208]                  ; 8-byte Folded Spill
LBB51_15:                               ;   Parent Loop BB51_9 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	add	x26, x8, x25
	ldr	x8, [sp, #208]                  ; 8-byte Folded Reload
	mov	x0, x22
	add	x23, x8, x25
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	blr	x8
	mov	x0, x22
	mov	x1, x23
	ldr	x2, [sp, #88]                   ; 8-byte Folded Reload
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB51_18
; %bb.16:                               ;   in Loop: Header=BB51_15 Depth=2
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	mov	x0, x26
	add	x22, x23, x8
	mov	x1, x22
	blr	x19
	ldr	x19, [sp, #96]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	add	x22, x22, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x22
	blr	x8
	add	x22, x22, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x22, x22, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x22, x22, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x22, x22, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x1, x22, x19
	add	x22, x26, x19
	mov	x0, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x0, x22, x19
	ldr	x19, [sp, #264]                 ; 8-byte Folded Reload
	mov	x1, x23
	blr	x19
	ldr	x9, [sp, #256]                  ; 8-byte Folded Reload
	sub	x25, x25, x9
	add	x8, x21, x25
	cmp	x8, x9
	b.hi	LBB51_15
; %bb.17:                               ; %.loopexit.outer.loopexit
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	str	x28, [sp, #224]                 ; 8-byte Folded Spill
	ldp	x23, x24, [sp, #64]             ; 16-byte Folded Reload
	mov	x22, x27
	add	x8, x8, x25
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	add	x24, x24, x25
	b	LBB51_9
LBB51_18:                               ; %.loopexit272.loopexit
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldp	x23, x8, [sp, #64]              ; 16-byte Folded Reload
	mov	x22, x24
	str	x26, [sp, #112]                 ; 8-byte Folded Spill
	add	x22, x24, x20
	add	x8, x8, x25
	str	x8, [sp, #72]                   ; 8-byte Folded Spill
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	add	x8, x8, x20
	str	x8, [sp, #224]                  ; 8-byte Folded Spill
LBB51_19:                               ; %.loopexit272
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x21, [sp, #88]                  ; 8-byte Folded Reload
	ldr	x27, [sp, #216]                 ; 8-byte Folded Reload
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	sub	x26, x21, x27
	cmp	x26, x8
	b.le	LBB51_31
; %bb.20:                               ; %.preheader269.preheader
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x9, [sp, #104]                  ; 8-byte Folded Reload
	str	x22, [sp, #208]                 ; 8-byte Folded Spill
	ldr	x14, [sp, #224]                 ; 8-byte Folded Reload
	mov	x20, xzr
	ldp	x13, x12, [sp, #24]             ; 16-byte Folded Reload
	add	x22, x27, x23
	add	x8, x14, x9
	add	x9, x27, x9
	ldp	x11, x10, [sp, #40]             ; 16-byte Folded Reload
	str	x8, [sp, #192]                  ; 8-byte Folded Spill
	add	x8, x14, x12
	str	x9, [sp, #200]                  ; 8-byte Folded Spill
	add	x9, x27, x12
	ldr	x24, [sp, #72]                  ; 8-byte Folded Reload
	str	x8, [sp, #184]                  ; 8-byte Folded Spill
	add	x8, x14, x13
	str	x9, [sp, #136]                  ; 8-byte Folded Spill
	add	x9, x27, x13
	str	x8, [sp, #176]                  ; 8-byte Folded Spill
	add	x8, x14, x11
	str	x9, [sp, #128]                  ; 8-byte Folded Spill
	add	x9, x27, x11
	str	x8, [sp, #168]                  ; 8-byte Folded Spill
	add	x8, x14, x10
	str	x9, [sp, #120]                  ; 8-byte Folded Spill
	add	x9, x27, x10
	str	x8, [sp, #160]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	str	x9, [sp, #80]                   ; 8-byte Folded Spill
	add	x15, x14, x8
	add	x14, x14, x23
	add	x21, x27, x8
	stp	x14, x15, [sp, #144]            ; 16-byte Folded Spill
LBB51_21:                               ; %.preheader269
                                        ;   Parent Loop BB51_9 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x25, [sp, #248]                 ; 8-byte Folded Reload
	add	x28, x8, x20
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	mov	x0, x25
	add	x27, x8, x20
	ldr	x8, [sp, #200]                  ; 8-byte Folded Reload
	add	x23, x8, x20
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	blr	x8
	mov	x0, x25
	ldr	x1, [sp, #208]                  ; 8-byte Folded Reload
	mov	x2, x23
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB51_24
; %bb.22:                               ;   in Loop: Header=BB51_21 Depth=2
	mov	x0, x28
	mov	x1, x27
	blr	x19
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	add	x1, x22, x20
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	add	x1, x21, x20
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #80]                   ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #168]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #192]                  ; 8-byte Folded Reload
	mov	x1, x23
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #256]                  ; 8-byte Folded Reload
	sub	x26, x26, x8
	add	x20, x20, x8
	cmp	x26, x8
	b.hi	LBB51_21
; %bb.23:                               ; %.loopexit.outer.outer384.loopexit
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x8, [sp, #224]                  ; 8-byte Folded Reload
	add	x8, x8, x20
	str	x8, [sp, #224]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	add	x8, x8, x20
	str	x8, [sp, #216]                  ; 8-byte Folded Spill
	b	LBB51_8
LBB51_24:                               ; %.preheader266
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	mov	x21, xzr
	ldr	x9, [sp, #88]                   ; 8-byte Folded Reload
	add	x25, x9, x8
LBB51_25:                               ;   Parent Loop BB51_9 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x22, [sp, #248]                 ; 8-byte Folded Reload
	add	x20, x25, x21
	add	x23, x8, x21
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	mov	x0, x22
	blr	x8
	mov	x0, x22
	mov	x1, x24
	mov	x2, x20
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB51_28
; %bb.26:                               ;   in Loop: Header=BB51_25 Depth=2
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	mov	x0, x23
	add	x22, x20, x8
	mov	x1, x22
	blr	x19
	ldr	x19, [sp, #96]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	add	x22, x22, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x22
	blr	x8
	add	x22, x22, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x22, x22, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x22, x22, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x22, x22, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x1, x22, x19
	add	x22, x23, x19
	mov	x0, x22
	ldr	x8, [sp, #264]                  ; 8-byte Folded Reload
	blr	x8
	add	x0, x22, x19
	ldr	x19, [sp, #264]                 ; 8-byte Folded Reload
	mov	x1, x20
	blr	x19
	ldr	x9, [sp, #256]                  ; 8-byte Folded Reload
	sub	x21, x21, x9
	add	x8, x26, x21
	cmp	x8, x9
	b.hi	LBB51_25
; %bb.27:                               ; %.loopexit.outer.outer.loopexit
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	stp	x27, x28, [sp, #216]            ; 16-byte Folded Spill
	add	x8, x8, x21
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	add	x8, x8, x21
	str	x8, [sp, #88]                   ; 8-byte Folded Spill
	b	LBB51_8
LBB51_28:                               ; %.loopexit267.loopexit
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	x10, x23
	ldr	x23, [sp, #64]                  ; 8-byte Folded Reload
	ldr	x22, [sp, #208]                 ; 8-byte Folded Reload
	add	x21, x8, x21
LBB51_29:                               ; %.loopexit267
                                        ;   in Loop: Header=BB51_9 Depth=1
	ldr	x9, [sp, #8]                    ; 8-byte Folded Reload
	sub	x8, x10, x28
	cmp	x8, x9
	b.lo	LBB51_32
; %bb.30:                               ; %.cont46
                                        ;   in Loop: Header=BB51_9 Depth=1
	mov	x26, x21
	ldr	x21, [sp, #248]                 ; 8-byte Folded Reload
	mov	w1, #16
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	str	x10, [sp, #112]                 ; 8-byte Folded Spill
	mov	x0, x21
	blr	x8
	mov	x0, x21
	mov	x1, x22
	mov	x2, x27
	ldr	x25, [sp, #240]                 ; 8-byte Folded Reload
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x27, x22, eq
	add	x8, x1, x23
	csel	x20, x8, x27, eq
	csel	x22, x22, x8, eq
	blr	x19
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x24
	mov	x2, x26
	add	x8, x28, x8
	str	x8, [sp, #224]                  ; 8-byte Folded Spill
	blr	x25
	and	w8, w0, #0xff
	ldr	x23, [sp, #112]                 ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x9, x24
	csel	x1, x24, x26, eq
	ldr	x24, [sp, #96]                  ; 8-byte Folded Reload
	mov	x0, x23
	add	x8, x1, x24
	csel	x27, x26, x8, eq
	csel	x28, x8, x9, eq
	blr	x19
	mov	x0, x21
	mov	x1, x22
	mov	x2, x20
	add	x26, x23, x24
	blr	x25
	ldr	x23, [sp, #224]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	csel	x1, x20, x22, eq
	mov	x0, x23
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x22, x22, x8, eq
	blr	x19
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x28
	mov	x2, x27
	add	x23, x23, x8
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	csel	x1, x28, x27, eq
	add	x8, x1, x24
	csel	x27, x27, x8, eq
	csel	x28, x8, x28, eq
	blr	x19
	mov	x0, x21
	mov	x1, x22
	mov	x2, x20
	add	x26, x26, x24
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	csel	x1, x20, x22, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x22, x22, x8, eq
	blr	x19
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x28
	mov	x2, x27
	add	x23, x23, x8
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	csel	x1, x28, x27, eq
	add	x8, x1, x24
	csel	x27, x27, x8, eq
	csel	x28, x8, x28, eq
	blr	x19
	mov	x0, x21
	mov	x1, x22
	mov	x2, x20
	add	x26, x26, x24
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	csel	x1, x20, x22, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x22, x22, x8, eq
	blr	x19
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x28
	mov	x2, x27
	add	x23, x23, x8
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	csel	x1, x28, x27, eq
	add	x8, x1, x24
	csel	x27, x27, x8, eq
	csel	x28, x8, x28, eq
	blr	x19
	mov	x0, x21
	mov	x1, x22
	mov	x2, x20
	add	x26, x26, x24
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	csel	x1, x20, x22, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x22, x22, x8, eq
	blr	x19
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x28
	mov	x2, x27
	add	x23, x23, x8
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	csel	x1, x28, x27, eq
	add	x8, x1, x24
	csel	x27, x27, x8, eq
	csel	x28, x8, x28, eq
	blr	x19
	mov	x0, x21
	mov	x1, x22
	mov	x2, x20
	add	x26, x26, x24
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	csel	x1, x20, x22, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x22, x22, x8, eq
	blr	x19
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x28
	mov	x2, x27
	add	x23, x23, x8
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	csel	x1, x28, x27, eq
	add	x8, x1, x24
	csel	x27, x27, x8, eq
	csel	x28, x8, x28, eq
	blr	x19
	mov	x0, x21
	mov	x1, x22
	mov	x2, x20
	add	x26, x26, x24
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	csel	x1, x20, x22, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x22, x22, x8, eq
	blr	x19
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x28
	mov	x2, x27
	add	x23, x23, x8
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	csel	x1, x28, x27, eq
	add	x8, x1, x24
	csel	x27, x27, x8, eq
	csel	x28, x8, x28, eq
	blr	x19
	mov	x0, x21
	mov	x1, x22
	mov	x2, x20
	add	x26, x26, x24
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	csel	x1, x20, x22, eq
	add	x8, x1, x8
	csel	x9, x8, x20, eq
	csel	x22, x22, x8, eq
	str	x9, [sp, #216]                  ; 8-byte Folded Spill
	blr	x19
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x21
	mov	x1, x28
	mov	x2, x27
	add	x8, x23, x8
	ldr	x23, [sp, #64]                  ; 8-byte Folded Reload
	str	x8, [sp, #224]                  ; 8-byte Folded Spill
	blr	x25
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	csel	x1, x28, x27, eq
	add	x8, x1, x24
	csel	x9, x27, x8, eq
	csel	x20, x8, x28, eq
	str	x9, [sp, #88]                   ; 8-byte Folded Spill
	blr	x19
	add	x8, x26, x24
	mov	x24, x20
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	b	LBB51_9
LBB51_31:                               ;   in Loop: Header=BB51_9 Depth=1
	ldr	x28, [sp, #224]                 ; 8-byte Folded Reload
	ldr	x24, [sp, #72]                  ; 8-byte Folded Reload
	ldr	x10, [sp, #112]                 ; 8-byte Folded Reload
	b	LBB51_29
LBB51_32:                               ; %.preheader265
	cmp	x22, x24
	b.hi	LBB51_37
; %bb.33:                               ; %.preheader265
	cmp	x27, x21
	b.hi	LBB51_37
; %bb.34:
	ldr	x20, [sp, #248]                 ; 8-byte Folded Reload
LBB51_35:                               ; %.cont
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	ldr	x8, [sp, #232]                  ; 8-byte Folded Reload
	blr	x8
	mov	x0, x20
	mov	x1, x22
	mov	x2, x27
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x27, x22, eq
	add	x8, x1, x23
	csel	x27, x8, x27, eq
	csel	x22, x22, x8, eq
	blr	x19
	add	x28, x28, x23
	cmp	x22, x24
	b.hi	LBB51_37
; %bb.36:                               ; %.cont
                                        ;   in Loop: Header=BB51_35 Depth=1
	cmp	x27, x21
	b.ls	LBB51_35
LBB51_37:                               ; %.preheader264
	cmp	x22, x24
	b.hi	LBB51_41
; %bb.38:                               ; %.lr.ph.preheader
	mov	x20, xzr
LBB51_39:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x22, x20
	add	x0, x28, x20
	blr	x19
	add	x20, x20, x23
	add	x8, x22, x20
	cmp	x8, x24
	b.ls	LBB51_39
; %bb.40:                               ; %.preheader.loopexit
	add	x28, x28, x20
LBB51_41:                               ; %.preheader
	cmp	x27, x21
	b.hi	LBB51_44
; %bb.42:                               ; %.lr.ph314.preheader
	mov	x20, xzr
LBB51_43:                               ; %.lr.ph314
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x27, x20
	add	x0, x28, x20
	blr	x19
	add	x20, x20, x23
	add	x8, x27, x20
	cmp	x8, x21
	b.ls	LBB51_43
LBB51_44:                               ; %common.ret1
	ldp	x29, x30, [sp, #352]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #336]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #320]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #304]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #288]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #272]            ; 16-byte Folded Reload
	add	sp, sp, #368
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB51_45:
	.cfi_restore_state
	ldp	x0, x8, [sp, #224]              ; 16-byte Folded Reload
	mov	x1, x22
	mov	x2, x27
	mov	x3, x26
	mov	x6, x23
	ldp	x4, x5, [sp, #240]              ; 16-byte Folded Reload
	mov	x7, x19
	ldp	x29, x30, [sp, #352]            ; 16-byte Folded Reload
	str	x8, [sp, #368]
	ldp	x20, x19, [sp, #336]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #320]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #304]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #288]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #272]            ; 16-byte Folded Reload
	add	sp, sp, #368
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.parity_merge__anon_16476
Lfunc_end51:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.flux_partition__anon_14857
l_sort.flux_partition__anon_14857:      ; @sort.flux_partition__anon_14857
Lfunc_begin52:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #208
	.cfi_def_cfa_offset 208
	stp	x28, x27, [sp, #112]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #128]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	add	x8, sp, #104
	mov	x19, x7
	mov	x22, x6
	mov	x25, x5
	mov	x24, x3
	mov	x21, x1
	mov	x27, x0
	mov	x28, xzr
	ldr	x26, [sp, #208]
	neg	x9, x7
	lsr	x8, x8, #4
	str	x2, [sp, #96]                   ; 8-byte Folded Spill
	stp	x1, x0, [sp, #72]               ; 16-byte Folded Spill
	stp	x9, x6, [sp, #32]               ; 16-byte Folded Spill
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
	str	x26, [sp, #56]                  ; 8-byte Folded Spill
LBB52_1:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB52_4 Depth 2
                                        ;     Child Loop BB52_6 Depth 2
                                        ;     Child Loop BB52_16 Depth 2
                                        ;     Child Loop BB52_23 Depth 2
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	str	x28, [sp, #48]                  ; 8-byte Folded Spill
	cmp	x4, #2049
	str	x4, [sp, #88]                   ; 8-byte Folded Spill
	add	x28, x24, x8
	str	x28, [sp, #64]                  ; 8-byte Folded Spill
	b.hs	LBB52_3
; %bb.2:                                ;   in Loop: Header=BB52_1 Depth=1
	ldr	x23, [sp, #96]                  ; 8-byte Folded Reload
	mov	x1, x4
	mov	x2, x25
	mov	x3, x22
	mov	x4, x19
	mov	x5, x26
	mov	x0, x23
	mov	x6, x28
	bl	l_sort.median_of_nine__anon_16521
	b	LBB52_18
LBB52_3:                                ;   in Loop: Header=BB52_1 Depth=1
	mov	w8, #32
	str	x24, [sp, #24]                  ; 8-byte Folded Spill
LBB52_4:                                ;   Parent Loop BB52_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x20, x8
	mul	x8, x8, x8
	mul	x9, x8, x20
	lsl	x8, x20, #1
	cmp	x9, x4
	b.lo	LBB52_4
; %bb.5:                                ;   in Loop: Header=BB52_1 Depth=1
	udiv	x8, x4, x20
	ldr	x10, [sp, #16]                  ; 8-byte Folded Reload
	ldr	x22, [sp, #56]                  ; 8-byte Folded Reload
	mul	x26, x8, x19
	udiv	x9, x10, x8
	str	x8, [sp, #104]
	msub	x9, x9, x8, x10
	ldr	x10, [sp, #96]                  ; 8-byte Folded Reload
	cmp	x10, x27
	madd	x23, x9, x19, x10
	csel	x27, x21, x27, eq
	subs	x28, x20, #1
	csinc	x21, x20, xzr, hi
	mov	x24, x27
LBB52_6:                                ;   Parent Loop BB52_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x24
	mov	x1, x23
	blr	x22
	add	x23, x23, x26
	subs	x21, x21, #1
	add	x24, x24, x19
	b.ne	LBB52_6
; %bb.7:                                ;   in Loop: Header=BB52_1 Depth=1
	madd	x21, x20, x19, x27
	lsr	x23, x20, #1
	mov	x0, x27
	mov	x1, x23
	cmp	x20, #192
	b.hs	LBB52_9
; %bb.8:                                ;   in Loop: Header=BB52_1 Depth=1
	ldr	x22, [sp, #40]                  ; 8-byte Folded Reload
	mov	x2, x21
	ldr	x26, [sp, #56]                  ; 8-byte Folded Reload
	mov	x3, x25
	mov	x5, x19
	mov	x4, x22
	mov	x6, x26
	bl	l_sort.tail_swap__anon_14838
	madd	x24, x23, x19, x27
	mov	x1, x23
	mov	x2, x21
	mov	x3, x25
	mov	x0, x24
	mov	x4, x22
	mov	x5, x19
	mov	x6, x26
	bl	l_sort.tail_swap__anon_14838
	b	LBB52_13
LBB52_9:                                ;   in Loop: Header=BB52_1 Depth=1
	ldr	x22, [sp, #40]                  ; 8-byte Folded Reload
	mov	x2, x25
	ldr	x26, [sp, #56]                  ; 8-byte Folded Reload
	mov	x4, x19
	mov	x3, x22
	mov	x5, x26
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB52_11
; %bb.10:                               ;   in Loop: Header=BB52_1 Depth=1
	mov	x0, x27
	mov	x1, x23
	mov	x2, x21
	mov	x3, x23
	mov	x4, x25
	mov	x5, x22
	mov	x6, x19
	mov	x7, x26
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x27
	mov	x1, x23
	mov	x2, x21
	mov	x3, x23
	mov	x5, x25
	mov	x6, x22
	mov	x7, x19
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB52_11:                               ;   in Loop: Header=BB52_1 Depth=1
	madd	x24, x23, x19, x27
	mov	x1, x23
	mov	x2, x25
	mov	x3, x22
	mov	x0, x24
	mov	x4, x19
	mov	x5, x26
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB52_13
; %bb.12:                               ;   in Loop: Header=BB52_1 Depth=1
	mov	x0, x24
	mov	x1, x23
	mov	x2, x21
	mov	x3, x23
	mov	x4, x25
	mov	x5, x22
	mov	x6, x19
	mov	x7, x26
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x24
	mov	x1, x23
	mov	x2, x21
	mov	x3, x23
	mov	x5, x25
	mov	x6, x22
	mov	x7, x19
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB52_13:                               ; %sort.quadsort_swap__anon_14858.exit34.i
                                        ;   in Loop: Header=BB52_1 Depth=1
	madd	x1, x28, x19, x27
	mov	x0, x22
	mov	x2, x27
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB52_15
; %bb.14:                               ;   in Loop: Header=BB52_1 Depth=1
	mov	w20, wzr
	b	LBB52_16
LBB52_15:                               ;   in Loop: Header=BB52_1 Depth=1
	sub	x8, x23, #1
	mov	x0, x22
	mov	x2, x27
	madd	x1, x8, x19, x27
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w20, ne
LBB52_16:                               ; %.lr.ph.i.i
                                        ;   Parent Loop BB52_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x22
	mov	x1, x27
	mov	x2, x24
	lsr	x21, x23, #1
	blr	x25
	mul	x8, x21, x19
	and	w9, w0, #0xff
	cmp	w9, #1
	csel	x9, x8, xzr, eq
	csel	x8, xzr, x8, eq
	add	x24, x24, x9
	add	x27, x27, x8
	cmp	x23, #4
	mov	x23, x21
	b.hs	LBB52_16
; %bb.17:                               ; %sort.median_of_cube_root__anon_16522.exit
                                        ;   in Loop: Header=BB52_1 Depth=1
	mov	x0, x22
	mov	x1, x27
	mov	x2, x24
	blr	x25
	ldr	x28, [sp, #64]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x27, x24, eq
	mov	x0, x28
	blr	x26
	ldp	x21, x27, [sp, #72]             ; 16-byte Folded Reload
	ldr	x23, [sp, #96]                  ; 8-byte Folded Reload
	ldr	x24, [sp, #24]                  ; 8-byte Folded Reload
	cbnz	w20, LBB52_53
LBB52_18:                               ;   in Loop: Header=BB52_1 Depth=1
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	cbz	x8, LBB52_20
; %bb.19:                               ;   in Loop: Header=BB52_1 Depth=1
	mov	x0, x22
	mov	x1, x24
	mov	x2, x28
	blr	x25
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB52_52
LBB52_20:                               ; %.critedge
                                        ;   in Loop: Header=BB52_1 Depth=1
	ldr	x9, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x9, #8
	b.hs	LBB52_22
; %bb.21:                               ;   in Loop: Header=BB52_1 Depth=1
	mov	x8, xzr
	mov	x20, x21
	b	LBB52_24
LBB52_22:                               ; %.cont82.i.preheader
                                        ;   in Loop: Header=BB52_1 Depth=1
	mov	x8, xzr
	mov	x20, x21
	mov	w24, #8
LBB52_23:                               ; %.cont82.i
                                        ;   Parent Loop BB52_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x22
	mov	x1, x23
	mov	x2, x28
	str	x8, [sp, #96]                   ; 8-byte Folded Spill
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x27, eq
	add	x8, x0, x19
	csel	x20, x8, x20, eq
	csel	x21, x27, x8, eq
	blr	x26
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x28
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x21, eq
	add	x8, x0, x19
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x26
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x28
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x21, eq
	add	x8, x0, x19
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x26
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x28
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x21, eq
	add	x8, x0, x19
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x26
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x28
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x21, eq
	add	x8, x0, x19
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x26
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x28
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x21, eq
	add	x8, x0, x19
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x26
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x28
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x21, eq
	add	x8, x0, x19
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x26
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x28
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x21, eq
	add	x8, x0, x19
	csel	x20, x8, x20, eq
	csel	x27, x21, x8, eq
	blr	x26
	ldp	x8, x10, [sp, #72]              ; 16-byte Folded Reload
	add	x23, x23, x19
	cmp	x20, x8
	ldp	x9, x8, [sp, #88]               ; 16-byte Folded Reload
	ccmp	x27, x10, #4, ne
	csel	x8, x24, x8, eq
	add	x24, x24, #8
	cmp	x24, x9
	b.ls	LBB52_23
LBB52_24:                               ; %._crit_edge.i
                                        ;   in Loop: Header=BB52_1 Depth=1
	ands	x28, x9, #0x7
	str	x8, [sp, #96]                   ; 8-byte Folded Spill
	b.eq	LBB52_32
; %bb.25:                               ; %.cont.i
                                        ;   in Loop: Header=BB52_1 Depth=1
	ldr	x22, [sp, #40]                  ; 8-byte Folded Reload
	mov	x1, x23
	ldr	x24, [sp, #64]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x2, x24
	blr	x25
	and	w21, w0, #0xff
	mov	x1, x23
	cmp	w21, #1
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	csel	x0, x20, x27, eq
	add	x26, x0, x19
	csel	x27, x27, x26, eq
	blr	x8
	cmp	x28, #1
	b.eq	LBB52_33
; %bb.26:                               ; %.cont.i.1
                                        ;   in Loop: Header=BB52_1 Depth=1
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	cmp	w21, #1
	csel	x20, x26, x20, eq
	blr	x25
	and	w21, w0, #0xff
	mov	x1, x23
	cmp	w21, #1
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	csel	x0, x20, x27, eq
	add	x26, x0, x19
	csel	x27, x27, x26, eq
	blr	x8
	cmp	x28, #2
	b.eq	LBB52_33
; %bb.27:                               ; %.cont.i.2
                                        ;   in Loop: Header=BB52_1 Depth=1
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	cmp	w21, #1
	csel	x20, x26, x20, eq
	blr	x25
	and	w21, w0, #0xff
	mov	x1, x23
	cmp	w21, #1
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	csel	x0, x20, x27, eq
	add	x26, x0, x19
	csel	x27, x27, x26, eq
	blr	x8
	cmp	x28, #3
	b.eq	LBB52_33
; %bb.28:                               ; %.cont.i.3
                                        ;   in Loop: Header=BB52_1 Depth=1
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	cmp	w21, #1
	csel	x20, x26, x20, eq
	blr	x25
	and	w21, w0, #0xff
	mov	x1, x23
	cmp	w21, #1
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	csel	x0, x20, x27, eq
	add	x26, x0, x19
	csel	x27, x27, x26, eq
	blr	x8
	cmp	x28, #4
	b.eq	LBB52_33
; %bb.29:                               ; %.cont.i.4
                                        ;   in Loop: Header=BB52_1 Depth=1
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	cmp	w21, #1
	csel	x20, x26, x20, eq
	blr	x25
	and	w21, w0, #0xff
	mov	x1, x23
	cmp	w21, #1
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	csel	x0, x20, x27, eq
	add	x26, x0, x19
	csel	x27, x27, x26, eq
	blr	x8
	cmp	x28, #5
	b.eq	LBB52_33
; %bb.30:                               ; %.cont.i.5
                                        ;   in Loop: Header=BB52_1 Depth=1
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	cmp	w21, #1
	csel	x20, x26, x20, eq
	blr	x25
	and	w21, w0, #0xff
	mov	x1, x23
	cmp	w21, #1
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	csel	x0, x20, x27, eq
	add	x26, x0, x19
	csel	x27, x27, x26, eq
	blr	x8
	cmp	x28, #6
	b.eq	LBB52_33
; %bb.31:                               ; %.cont.i.6
                                        ;   in Loop: Header=BB52_1 Depth=1
	add	x23, x23, x19
	mov	x0, x22
	mov	x1, x23
	mov	x2, x24
	cmp	w21, #1
	csel	x20, x26, x20, eq
	blr	x25
	and	w8, w0, #0xff
	mov	x1, x23
	cmp	w8, #1
	csel	x0, x20, x27, eq
	add	x8, x0, x19
	csel	x27, x27, x8, eq
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	blr	x8
	b	LBB52_33
LBB52_32:                               ;   in Loop: Header=BB52_1 Depth=1
	ldr	x22, [sp, #40]                  ; 8-byte Folded Reload
	ldr	x24, [sp, #64]                  ; 8-byte Folded Reload
LBB52_33:                               ; %._crit_edge173.i
                                        ;   in Loop: Header=BB52_1 Depth=1
	ldp	x9, x4, [sp, #80]               ; 16-byte Folded Reload
	sub	x8, x27, x9
	mov	x27, x9
	ldr	x9, [sp, #96]                   ; 8-byte Folded Reload
	udiv	x28, x8, x19
	cmp	x9, x4, lsr #2
	sub	x23, x4, x28
	b.ls	LBB52_35
; %bb.34:                               ; %._crit_edge173.i
                                        ;   in Loop: Header=BB52_1 Depth=1
	cmp	x4, x28
	b.ne	LBB52_50
LBB52_35:                               ; %sort.flux_default_partition__anon_16524.exit
                                        ;   in Loop: Header=BB52_1 Depth=1
	cmp	x23, #97
	b.lo	LBB52_38
; %bb.36:                               ; %sort.flux_default_partition__anon_16524.exit
                                        ;   in Loop: Header=BB52_1 Depth=1
	lsr	x9, x23, #5
	cmp	x28, x9
	b.ls	LBB52_38
; %bb.37:                               ;   in Loop: Header=BB52_1 Depth=1
	ldr	x21, [sp, #72]                  ; 8-byte Folded Reload
	madd	x0, x28, x19, x27
	mov	x3, x24
	mov	x4, x23
	mov	x5, x25
	mov	x6, x22
	mov	x1, x21
	mov	x2, x21
	mov	x7, x19
	ldr	x26, [sp, #56]                  ; 8-byte Folded Reload
	str	x26, [sp]
	bl	l_sort.flux_partition__anon_14857
	b	LBB52_44
LBB52_38:                               ;   in Loop: Header=BB52_1 Depth=1
	ldr	x26, [sp, #56]                  ; 8-byte Folded Reload
	cmp	x8, x19
	ldr	x21, [sp, #72]                  ; 8-byte Folded Reload
	b.lo	LBB52_73
; %bb.39:                               ;   in Loop: Header=BB52_1 Depth=1
	cmp	x4, x28
	b.eq	LBB52_63
; %bb.40:                               ;   in Loop: Header=BB52_1 Depth=1
	madd	x24, x28, x19, x27
	mov	x1, x21
	mul	x2, x23, x19
	mov	x0, x24
	bl	_memcpy
	cmp	x23, #95
	b.hi	LBB52_42
; %bb.41:                               ;   in Loop: Header=BB52_1 Depth=1
	mov	x0, x24
	mov	x1, x23
	mov	x2, x21
	mov	x3, x25
	mov	x4, x22
	mov	x5, x19
	mov	x6, x26
	bl	l_sort.tail_swap__anon_14838
	b	LBB52_44
LBB52_42:                               ;   in Loop: Header=BB52_1 Depth=1
	mov	x0, x24
	mov	x1, x23
	mov	x2, x25
	mov	x3, x22
	mov	x4, x19
	mov	x5, x26
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB52_44
; %bb.43:                               ;   in Loop: Header=BB52_1 Depth=1
	mov	x0, x24
	mov	x1, x23
	mov	x2, x21
	mov	x3, x23
	mov	x4, x25
	mov	x5, x22
	mov	x6, x19
	mov	x7, x26
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x24
	mov	x1, x23
	mov	x2, x21
	mov	x3, x23
	mov	x5, x25
	mov	x6, x22
	mov	x7, x19
	str	x26, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB52_44:                               ; %sort.quadsort_swap__anon_14858.exit61
                                        ;   in Loop: Header=BB52_1 Depth=1
	ldr	x3, [sp, #64]                   ; 8-byte Folded Reload
	cmp	x28, #97
	b.lo	LBB52_46
; %bb.45:                               ; %sort.quadsort_swap__anon_14858.exit61
                                        ;   in Loop: Header=BB52_1 Depth=1
	mov	x4, x28
	mov	x24, x3
	lsr	x8, x28, #5
	str	x27, [sp, #96]                  ; 8-byte Folded Spill
	cmp	x23, x8
	b.hi	LBB52_1
LBB52_46:
	cmp	x28, #96
	b.hi	LBB52_64
; %bb.47:
	b.ne	LBB52_70
; %bb.48:
	mov	x0, x27
	mov	w1, #96
	mov	x2, x25
	mov	x3, x22
	mov	x4, x19
	mov	x5, x26
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB52_73
; %bb.49:
	mov	x0, x27
	mov	w1, #96
	mov	x2, x21
	mov	w3, #96
	mov	x4, x25
	mov	x5, x22
	mov	x6, x19
	mov	x7, x26
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x27
	mov	w1, #96
	mov	x2, x21
	mov	w3, #96
	b	LBB52_68
LBB52_50:
	ldr	x21, [sp, #72]                  ; 8-byte Folded Reload
	madd	x24, x28, x19, x27
	mul	x2, x23, x19
	mov	x0, x24
	mov	x1, x21
	bl	_memcpy
	cmp	x23, #95
	b.hi	LBB52_57
; %bb.51:
	ldr	x20, [sp, #56]                  ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x23
	mov	x2, x21
	mov	x3, x25
	mov	x4, x22
	mov	x5, x19
	mov	x6, x20
	bl	l_sort.tail_swap__anon_14838
	b	LBB52_59
LBB52_52:
	ldr	x4, [sp, #88]                   ; 8-byte Folded Reload
	mov	x0, x27
	mov	x1, x21
	mov	x2, x27
	mov	x3, x28
	b	LBB52_65
LBB52_53:
	cmp	x23, x21
	b.ne	LBB52_55
; %bb.54:
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	x0, x27
	mov	x1, x21
	mul	x2, x8, x19
	bl	_memcpy
LBB52_55:
	ldr	x1, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x1, #95
	b.hi	LBB52_66
; %bb.56:
	mov	x0, x27
	b	LBB52_71
LBB52_57:
	ldr	x20, [sp, #56]                  ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x23
	mov	x2, x25
	mov	x3, x22
	mov	x4, x19
	mov	x5, x20
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB52_59
; %bb.58:
	mov	x0, x24
	mov	x1, x23
	mov	x2, x21
	mov	x3, x23
	mov	x4, x25
	mov	x5, x22
	mov	x6, x19
	mov	x7, x20
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x24
	mov	x1, x23
	mov	x2, x21
	mov	x3, x23
	mov	x5, x25
	mov	x6, x22
	mov	x7, x19
	str	x20, [sp]
	bl	l_sort.rotate_merge__anon_14841
LBB52_59:                               ; %sort.quadsort_swap__anon_14858.exit.i
	cmp	x28, #95
	b.hi	LBB52_61
; %bb.60:
	mov	x0, x27
	mov	x1, x28
	mov	x2, x21
	mov	x3, x25
	mov	x4, x22
	mov	x5, x19
	mov	x6, x20
	b	LBB52_72
LBB52_61:
	mov	x0, x27
	mov	x1, x28
	mov	x2, x25
	mov	x3, x22
	mov	x4, x19
	mov	x5, x20
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB52_73
; %bb.62:
	mov	x0, x27
	mov	x1, x28
	mov	x2, x21
	mov	x3, x28
	mov	x4, x25
	mov	x5, x22
	mov	x6, x19
	mov	x7, x20
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x27
	mov	x1, x28
	mov	x2, x21
	mov	x3, x28
	mov	x5, x25
	mov	x6, x22
	mov	x7, x19
	str	x20, [sp]
	b	LBB52_69
LBB52_63:
	mov	x0, x27
	mov	x1, x21
	mov	x2, x27
	mov	x3, x24
	b	LBB52_65
LBB52_64:
	mov	x0, x27
	mov	x1, x21
	mov	x2, x27
	mov	x4, x28
LBB52_65:                               ; %common.ret
	mov	x5, x25
	mov	x6, x22
	mov	x7, x19
	str	x26, [sp]
	bl	l_sort.flux_reverse_partition__anon_16523
	b	LBB52_73
LBB52_66:
	mov	x0, x27
	mov	x2, x25
	mov	x3, x22
	mov	x4, x19
	mov	x5, x26
	bl	l_sort.quad_swap__anon_14839
	ldr	x20, [sp, #88]                  ; 8-byte Folded Reload
	tbz	w0, #0, LBB52_73
; %bb.67:
	mov	x0, x27
	mov	x1, x20
	mov	x2, x21
	mov	x3, x20
	mov	x4, x25
	mov	x5, x22
	mov	x6, x19
	mov	x7, x26
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x27
	mov	x1, x20
	mov	x2, x21
	mov	x3, x20
LBB52_68:                               ; %common.ret
	mov	x5, x25
	mov	x6, x22
	mov	x7, x19
	str	x26, [sp]
LBB52_69:                               ; %common.ret
	bl	l_sort.rotate_merge__anon_14841
	b	LBB52_73
LBB52_70:
	mov	x0, x27
	mov	x1, x28
LBB52_71:                               ; %common.ret
	mov	x2, x21
	mov	x3, x25
	mov	x4, x22
	mov	x5, x19
	mov	x6, x26
LBB52_72:                               ; %common.ret
	bl	l_sort.tail_swap__anon_14838
LBB52_73:                               ; %common.ret
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end52:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.cross_merge__anon_14859
l_sort.cross_merge__anon_14859:         ; @sort.cross_merge__anon_14859
Lfunc_begin53:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #352
	.cfi_def_cfa_offset 352
	stp	x28, x27, [sp, #256]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #272]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #288]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #304]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #320]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #336]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x27, x2
	madd	x2, x6, x2, x1
	mov	x19, x7
	mov	x23, x6
	sub	x8, x2, x6
	mov	x26, x3
	madd	x21, x6, x3, x8
	mov	x24, x8
	lsl	x9, x6, #4
	add	x8, x27, #1
	cmp	x8, x3
	stp	x4, x5, [sp, #224]              ; 16-byte Folded Spill
	str	x0, [sp, #216]                  ; 8-byte Folded Spill
	str	x9, [sp, #16]                   ; 8-byte Folded Spill
	b.lo	LBB53_7
; %bb.1:
	add	x8, x26, #1
	cmp	x8, x27
	b.lo	LBB53_7
; %bb.2:
	cmp	x27, #31
	b.ls	LBB53_7
; %bb.3:
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	mov	x22, x1
	mov	x25, x2
	sub	x20, x8, x23
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	add	x1, x1, x20
	blr	x8
	mov	x2, x25
	mov	x1, x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB53_7
; %bb.4:
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	add	x2, x25, x20
	mov	x1, x22
	blr	x8
	mov	x2, x25
	mov	x1, x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB53_7
; %bb.5:
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	sub	x2, x21, x20
	mov	x1, x24
	blr	x8
	mov	x2, x25
	mov	x1, x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB53_7
; %bb.6:
	neg	x8, x20
	mov	x2, x21
	add	x1, x24, x8
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	blr	x8
	mov	x2, x25
	mov	x1, x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB53_47
LBB53_7:                                ; %.critedge
	lsl	x9, x23, #3
	neg	x8, x23
	lsl	x10, x23, #1
	str	x23, [sp, #72]                  ; 8-byte Folded Spill
	stp	x9, x19, [sp, #240]             ; 16-byte Folded Spill
	sub	x9, x9, x23
	stp	x21, x8, [sp, #88]              ; 16-byte Folded Spill
	add	x8, x27, x26
	sub	x8, x8, #1
	mov	x21, x24
	str	x9, [sp, #104]                  ; 8-byte Folded Spill
	neg	x9, x9
	str	x9, [sp, #24]                   ; 8-byte Folded Spill
	ldr	x9, [sp, #216]                  ; 8-byte Folded Reload
	madd	x8, x8, x23, x9
	lsl	x9, x23, #2
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	add	x8, x10, x23
	stp	x8, x10, [sp, #56]              ; 16-byte Folded Spill
	lsl	x8, x8, #1
	stp	x8, x9, [sp, #40]               ; 16-byte Folded Spill
	add	x8, x9, x23
	str	x8, [sp, #32]                   ; 8-byte Folded Spill
	b	LBB53_10
LBB53_8:                                ; %.loopexit
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x23, [sp, #72]                  ; 8-byte Folded Reload
LBB53_9:                                ; %.loopexit
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x21, [sp, #80]                  ; 8-byte Folded Reload
LBB53_10:                               ; %.loopexit
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB53_12 Depth 2
                                        ;     Child Loop BB53_16 Depth 2
                                        ;     Child Loop BB53_22 Depth 2
                                        ;     Child Loop BB53_26 Depth 2
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	sub	x20, x21, x1
	str	x21, [sp, #80]                  ; 8-byte Folded Spill
	str	x2, [sp, #208]                  ; 8-byte Folded Spill
	cmp	x20, x8
	b.le	LBB53_32
; %bb.11:                               ; %.preheader12.preheader
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x9, [sp, #104]                  ; 8-byte Folded Reload
	mov	x25, xzr
	ldr	x14, [sp, #216]                 ; 8-byte Folded Reload
	add	x26, x1, x23
	ldp	x13, x12, [sp, #32]             ; 16-byte Folded Reload
	add	x8, x14, x9
	add	x9, x1, x9
	ldp	x11, x10, [sp, #48]             ; 16-byte Folded Reload
	str	x8, [sp, #192]                  ; 8-byte Folded Spill
	add	x8, x14, x12
	str	x9, [sp, #200]                  ; 8-byte Folded Spill
	add	x9, x1, x12
	str	x8, [sp, #184]                  ; 8-byte Folded Spill
	add	x8, x14, x13
	str	x9, [sp, #136]                  ; 8-byte Folded Spill
	add	x9, x1, x13
	add	x21, x1, x10
	str	x8, [sp, #176]                  ; 8-byte Folded Spill
	add	x8, x14, x11
	str	x9, [sp, #128]                  ; 8-byte Folded Spill
	add	x9, x1, x11
	str	x8, [sp, #168]                  ; 8-byte Folded Spill
	add	x8, x14, x10
	str	x9, [sp, #120]                  ; 8-byte Folded Spill
	str	x8, [sp, #160]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	add	x15, x14, x8
	add	x14, x14, x23
	add	x24, x1, x8
	stp	x14, x15, [sp, #144]            ; 16-byte Folded Spill
LBB53_12:                               ; %.preheader12
                                        ;   Parent Loop BB53_10 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	mov	x22, x1
	add	x27, x1, x25
	add	x28, x8, x25
	ldr	x8, [sp, #200]                  ; 8-byte Folded Reload
	add	x23, x8, x25
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	mov	x1, x23
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB53_15
; %bb.13:                               ;   in Loop: Header=BB53_12 Depth=2
	mov	x0, x28
	mov	x1, x27
	blr	x19
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	add	x1, x26, x25
	add	x0, x8, x25
	blr	x19
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	add	x1, x24, x25
	add	x0, x8, x25
	blr	x19
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	add	x1, x21, x25
	add	x0, x8, x25
	blr	x19
	ldr	x8, [sp, #168]                  ; 8-byte Folded Reload
	add	x0, x8, x25
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	add	x1, x8, x25
	blr	x19
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x8, x25
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	add	x1, x8, x25
	blr	x19
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	add	x0, x8, x25
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	add	x1, x8, x25
	blr	x19
	ldr	x8, [sp, #192]                  ; 8-byte Folded Reload
	mov	x1, x23
	add	x0, x8, x25
	blr	x19
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	mov	x1, x22
	ldr	x2, [sp, #208]                  ; 8-byte Folded Reload
	sub	x20, x20, x8
	add	x25, x25, x8
	cmp	x20, x8
	b.hi	LBB53_12
; %bb.14:                               ; %.loopexit.loopexit
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	add	x1, x1, x25
	add	x8, x8, x25
	str	x8, [sp, #216]                  ; 8-byte Folded Spill
	b	LBB53_8
LBB53_15:                               ; %.preheader9
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x24, xzr
	ldr	x9, [sp, #80]                   ; 8-byte Folded Reload
	add	x8, x9, x8
	str	x8, [sp, #200]                  ; 8-byte Folded Spill
LBB53_16:                               ;   Parent Loop BB53_10 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	ldr	x2, [sp, #88]                   ; 8-byte Folded Reload
	add	x26, x8, x24
	ldr	x8, [sp, #200]                  ; 8-byte Folded Reload
	add	x23, x8, x24
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	mov	x1, x23
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB53_19
; %bb.17:                               ;   in Loop: Header=BB53_16 Depth=2
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	mov	x0, x26
	add	x21, x23, x8
	mov	x1, x21
	blr	x19
	ldr	x19, [sp, #96]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	add	x21, x21, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x21
	blr	x8
	add	x21, x21, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x21, x21, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x21, x21, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x21, x21, x19
	add	x26, x26, x19
	mov	x0, x26
	mov	x1, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x1, x21, x19
	add	x21, x26, x19
	mov	x0, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x0, x21, x19
	ldr	x19, [sp, #248]                 ; 8-byte Folded Reload
	mov	x1, x23
	blr	x19
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	sub	x24, x24, x9
	add	x8, x20, x24
	cmp	x8, x9
	b.hi	LBB53_16
; %bb.18:                               ; %.loopexit.outer.loopexit
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	str	x28, [sp, #216]                 ; 8-byte Folded Spill
	ldp	x23, x21, [sp, #72]             ; 16-byte Folded Reload
	mov	x1, x27
	add	x8, x8, x24
	ldr	x2, [sp, #208]                  ; 8-byte Folded Reload
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	add	x21, x21, x24
	b	LBB53_10
LBB53_19:                               ; %.loopexit10.loopexit
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldp	x23, x8, [sp, #72]              ; 16-byte Folded Reload
	mov	x1, x22
	mov	x10, x26
	add	x1, x22, x25
	add	x8, x8, x24
	str	x8, [sp, #80]                   ; 8-byte Folded Spill
	ldp	x2, x8, [sp, #208]              ; 16-byte Folded Reload
	add	x8, x8, x25
	str	x8, [sp, #216]                  ; 8-byte Folded Spill
LBB53_20:                               ; %.loopexit10
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	sub	x25, x8, x2
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	cmp	x25, x8
	b.le	LBB53_33
; %bb.21:                               ; %.preheader7.preheader
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x9, [sp, #104]                  ; 8-byte Folded Reload
	str	x10, [sp, #112]                 ; 8-byte Folded Spill
	ldr	x14, [sp, #216]                 ; 8-byte Folded Reload
	mov	x20, xzr
	ldp	x13, x12, [sp, #32]             ; 16-byte Folded Reload
	add	x22, x2, x23
	add	x8, x14, x9
	add	x9, x2, x9
	ldp	x11, x10, [sp, #48]             ; 16-byte Folded Reload
	str	x8, [sp, #192]                  ; 8-byte Folded Spill
	add	x8, x14, x12
	str	x9, [sp, #200]                  ; 8-byte Folded Spill
	add	x9, x2, x12
	str	x8, [sp, #184]                  ; 8-byte Folded Spill
	add	x8, x14, x13
	str	x9, [sp, #136]                  ; 8-byte Folded Spill
	add	x9, x2, x13
	add	x21, x2, x10
	str	x8, [sp, #176]                  ; 8-byte Folded Spill
	add	x8, x14, x11
	str	x9, [sp, #128]                  ; 8-byte Folded Spill
	add	x9, x2, x11
	str	x8, [sp, #168]                  ; 8-byte Folded Spill
	add	x8, x14, x10
	str	x9, [sp, #120]                  ; 8-byte Folded Spill
	str	x8, [sp, #160]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	add	x15, x14, x8
	add	x14, x14, x23
	add	x24, x2, x8
	stp	x14, x15, [sp, #144]            ; 16-byte Folded Spill
LBB53_22:                               ; %.preheader7
                                        ;   Parent Loop BB53_10 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	add	x27, x2, x20
	mov	x26, x1
	add	x28, x8, x20
	ldr	x8, [sp, #200]                  ; 8-byte Folded Reload
	add	x23, x8, x20
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	mov	x2, x23
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB53_25
; %bb.23:                               ;   in Loop: Header=BB53_22 Depth=2
	mov	x0, x28
	mov	x1, x27
	blr	x19
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	add	x1, x22, x20
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #152]                  ; 8-byte Folded Reload
	add	x1, x24, x20
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #160]                  ; 8-byte Folded Reload
	add	x1, x21, x20
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #168]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #176]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #184]                  ; 8-byte Folded Reload
	add	x0, x8, x20
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	add	x1, x8, x20
	blr	x19
	ldr	x8, [sp, #192]                  ; 8-byte Folded Reload
	mov	x1, x23
	add	x0, x8, x20
	blr	x19
	ldr	x8, [sp, #240]                  ; 8-byte Folded Reload
	mov	x1, x26
	ldr	x2, [sp, #208]                  ; 8-byte Folded Reload
	sub	x25, x25, x8
	add	x20, x20, x8
	cmp	x25, x8
	b.hi	LBB53_22
; %bb.24:                               ; %.loopexit.outer.outer122.loopexit
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x8, [sp, #216]                  ; 8-byte Folded Reload
	add	x2, x2, x20
	add	x8, x8, x20
	str	x8, [sp, #216]                  ; 8-byte Folded Spill
	b	LBB53_8
LBB53_25:                               ; %.preheader4
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x24, xzr
	ldr	x9, [sp, #88]                   ; 8-byte Folded Reload
	add	x22, x9, x8
LBB53_26:                               ;   Parent Loop BB53_10 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	add	x20, x22, x24
	ldr	x1, [sp, #80]                   ; 8-byte Folded Reload
	mov	x2, x20
	add	x23, x8, x24
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB53_29
; %bb.27:                               ;   in Loop: Header=BB53_26 Depth=2
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	mov	x0, x23
	add	x21, x20, x8
	mov	x1, x21
	blr	x19
	ldr	x19, [sp, #96]                  ; 8-byte Folded Reload
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	add	x21, x21, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x21
	blr	x8
	add	x21, x21, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x21, x21, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x21, x21, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x21, x21, x19
	add	x23, x23, x19
	mov	x0, x23
	mov	x1, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x1, x21, x19
	add	x21, x23, x19
	mov	x0, x21
	ldr	x8, [sp, #248]                  ; 8-byte Folded Reload
	blr	x8
	add	x0, x21, x19
	ldr	x19, [sp, #248]                 ; 8-byte Folded Reload
	mov	x1, x20
	blr	x19
	ldr	x9, [sp, #240]                  ; 8-byte Folded Reload
	sub	x24, x24, x9
	add	x8, x25, x24
	cmp	x8, x9
	b.hi	LBB53_26
; %bb.28:                               ; %.loopexit.outer.outer.loopexit
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	mov	x2, x27
	ldr	x23, [sp, #72]                  ; 8-byte Folded Reload
	str	x28, [sp, #216]                 ; 8-byte Folded Spill
	mov	x1, x26
	add	x8, x8, x24
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	add	x8, x8, x24
	str	x8, [sp, #88]                   ; 8-byte Folded Spill
	b	LBB53_9
LBB53_29:                               ; %.loopexit5.loopexit
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	x10, x23
	ldr	x23, [sp, #72]                  ; 8-byte Folded Reload
	mov	x1, x26
	add	x8, x8, x24
	str	x8, [sp, #88]                   ; 8-byte Folded Spill
LBB53_30:                               ; %.loopexit5
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldr	x9, [sp, #16]                   ; 8-byte Folded Reload
	sub	x8, x10, x28
	cmp	x8, x9
	b.lo	LBB53_34
; %bb.31:                               ; %.cont46.preheader
                                        ;   in Loop: Header=BB53_10 Depth=1
	ldp	x26, x24, [sp, #224]            ; 16-byte Folded Reload
	mov	x2, x27
	str	x10, [sp, #112]                 ; 8-byte Folded Spill
	mov	x21, x1
	mov	x0, x24
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x27, x21, eq
	add	x8, x1, x23
	csel	x20, x8, x27, eq
	csel	x21, x21, x8, eq
	blr	x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x24
	add	x8, x28, x8
	ldp	x28, x25, [sp, #80]             ; 16-byte Folded Reload
	str	x8, [sp, #216]                  ; 8-byte Folded Spill
	mov	x1, x28
	mov	x2, x25
	blr	x26
	ldr	x23, [sp, #112]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x22, [sp, #96]                  ; 8-byte Folded Reload
	csel	x1, x28, x25, eq
	mov	x0, x23
	add	x8, x1, x22
	csel	x27, x25, x8, eq
	csel	x25, x8, x28, eq
	blr	x19
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	add	x28, x23, x22
	blr	x26
	ldr	x23, [sp, #216]                 ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	csel	x1, x20, x21, eq
	mov	x0, x23
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x25
	mov	x2, x27
	add	x23, x23, x8
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x25, x27, eq
	add	x8, x1, x22
	csel	x27, x27, x8, eq
	csel	x25, x8, x25, eq
	blr	x19
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	add	x28, x28, x22
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	csel	x1, x20, x21, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x25
	mov	x2, x27
	add	x23, x23, x8
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x25, x27, eq
	add	x8, x1, x22
	csel	x27, x27, x8, eq
	csel	x25, x8, x25, eq
	blr	x19
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	add	x28, x28, x22
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	csel	x1, x20, x21, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x25
	mov	x2, x27
	add	x23, x23, x8
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x25, x27, eq
	add	x8, x1, x22
	csel	x27, x27, x8, eq
	csel	x25, x8, x25, eq
	blr	x19
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	add	x28, x28, x22
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	csel	x1, x20, x21, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x25
	mov	x2, x27
	add	x23, x23, x8
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x25, x27, eq
	add	x8, x1, x22
	csel	x27, x27, x8, eq
	csel	x25, x8, x25, eq
	blr	x19
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	add	x28, x28, x22
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	csel	x1, x20, x21, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x25
	mov	x2, x27
	add	x23, x23, x8
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x25, x27, eq
	add	x8, x1, x22
	csel	x27, x27, x8, eq
	csel	x25, x8, x25, eq
	blr	x19
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	add	x28, x28, x22
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	csel	x1, x20, x21, eq
	add	x8, x1, x8
	csel	x20, x8, x20, eq
	csel	x21, x21, x8, eq
	blr	x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x25
	mov	x2, x27
	add	x23, x23, x8
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x25, x27, eq
	add	x8, x1, x22
	csel	x27, x27, x8, eq
	csel	x25, x8, x25, eq
	blr	x19
	mov	x0, x24
	mov	x1, x21
	mov	x2, x20
	add	x28, x28, x22
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	csel	x1, x20, x21, eq
	add	x8, x1, x8
	csel	x9, x8, x20, eq
	csel	x20, x21, x8, eq
	str	x9, [sp, #208]                  ; 8-byte Folded Spill
	blr	x19
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x25
	mov	x2, x27
	add	x8, x23, x8
	ldr	x23, [sp, #72]                  ; 8-byte Folded Reload
	str	x8, [sp, #216]                  ; 8-byte Folded Spill
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x25, x27, eq
	add	x8, x1, x22
	csel	x9, x27, x8, eq
	csel	x21, x8, x25, eq
	str	x9, [sp, #88]                   ; 8-byte Folded Spill
	blr	x19
	add	x8, x28, x22
	ldr	x2, [sp, #208]                  ; 8-byte Folded Reload
	mov	x1, x20
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	b	LBB53_10
LBB53_32:                               ;   in Loop: Header=BB53_10 Depth=1
	ldr	x10, [sp, #112]                 ; 8-byte Folded Reload
	b	LBB53_20
LBB53_33:                               ;   in Loop: Header=BB53_10 Depth=1
	ldr	x28, [sp, #216]                 ; 8-byte Folded Reload
	mov	x27, x2
	b	LBB53_30
LBB53_34:                               ; %.preheader2
	ldr	x24, [sp, #80]                  ; 8-byte Folded Reload
	cmp	x1, x24
	b.hi	LBB53_40
; %bb.35:                               ; %.preheader2
	ldr	x21, [sp, #88]                  ; 8-byte Folded Reload
LBB53_36:                               ; %.cont
                                        ; =>This Inner Loop Header: Depth=1
	cmp	x27, x21
	b.hi	LBB53_38
; %bb.37:                               ; %.cont
                                        ;   in Loop: Header=BB53_36 Depth=1
	ldp	x8, x0, [sp, #224]              ; 16-byte Folded Reload
	mov	x2, x27
	mov	x20, x1
	blr	x8
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	csel	x1, x27, x20, eq
	add	x8, x1, x23
	csel	x27, x8, x27, eq
	csel	x20, x20, x8, eq
	blr	x19
	mov	x1, x20
	add	x28, x28, x23
	cmp	x20, x24
	b.ls	LBB53_36
LBB53_38:                               ; %.preheader1
	cmp	x1, x24
	b.ls	LBB53_41
LBB53_39:                               ; %.preheader
	cmp	x27, x21
	b.ls	LBB53_44
	b	LBB53_46
LBB53_40:
	ldr	x21, [sp, #88]                  ; 8-byte Folded Reload
	cmp	x1, x24
	b.hi	LBB53_39
LBB53_41:                               ; %.lr.ph.preheader
	mov	x20, xzr
LBB53_42:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	mov	x22, x1
	add	x1, x1, x20
	add	x0, x28, x20
	blr	x19
	mov	x1, x22
	add	x20, x20, x23
	add	x8, x22, x20
	cmp	x8, x24
	b.ls	LBB53_42
; %bb.43:                               ; %.preheader.loopexit
	add	x28, x28, x20
	cmp	x27, x21
	b.hi	LBB53_46
LBB53_44:                               ; %.lr.ph52.preheader
	mov	x20, xzr
LBB53_45:                               ; %.lr.ph52
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x27, x20
	add	x0, x28, x20
	blr	x19
	add	x20, x20, x23
	add	x8, x27, x20
	cmp	x8, x21
	b.ls	LBB53_45
LBB53_46:                               ; %common.ret1
	ldp	x29, x30, [sp, #336]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #320]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            ; 16-byte Folded Reload
	add	sp, sp, #352
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB53_47:
	.cfi_restore_state
	ldp	x0, x4, [sp, #216]              ; 16-byte Folded Reload
	mov	x2, x27
	mov	x3, x26
	mov	x6, x23
	mov	x7, x19
	ldp	x29, x30, [sp, #336]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #320]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #272]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #256]            ; 16-byte Folded Reload
	ldr	x5, [sp, #232]                  ; 8-byte Folded Reload
	add	sp, sp, #352
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.parity_merge__anon_16486
Lfunc_end53:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.flux_partition__anon_14860
l_sort.flux_partition__anon_14860:      ; @sort.flux_partition__anon_14860
Lfunc_begin54:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #1040
	.cfi_def_cfa_offset 1136
	add	x8, sp, #176
	mov	x20, x6
	orr	x9, x8, #0x8
	lsr	x10, x8, #4
	mov	x21, x5
	mov	x25, x4
	mov	x26, x2
	mov	x23, x1
	str	x9, [sp, #120]                  ; 8-byte Folded Spill
	add	x9, x8, #16
	stp	xzr, x7, [sp, #136]             ; 16-byte Folded Spill
	stp	x1, x0, [sp, #152]              ; 16-byte Folded Spill
	stp	x9, x10, [sp, #40]              ; 16-byte Folded Spill
	add	x10, x8, #32
	add	x9, x8, #40
	add	x8, x8, #48
	stp	x9, x10, [sp, #24]              ; 16-byte Folded Spill
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
LBB54_1:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB54_4 Depth 2
                                        ;     Child Loop BB54_6 Depth 2
                                        ;     Child Loop BB54_17 Depth 2
                                        ;     Child Loop BB54_24 Depth 2
	sub	x24, x3, #8
	cmp	x25, #2049
	str	x3, [sp, #128]                  ; 8-byte Folded Spill
	b.hs	LBB54_3
; %bb.2:                                ;   in Loop: Header=BB54_1 Depth=1
	and	w8, w25, #0xffff
	mov	w9, #58255
	ldr	x19, [x26]
	mov	x0, x20
	mul	w8, w8, w9
	mov	w1, #4
	lsr	w8, w8, #19
	ubfiz	x8, x8, #3, #32
	add	x9, x26, x8
	add	x10, x9, x8
	add	x11, x10, x8
	ldr	x27, [x9]
	add	x9, x11, x8
	ldr	x28, [x10]
	add	x10, x9, x8
	ldr	x22, [x11]
	add	x11, x10, x8
	ldr	x13, [x9]
	add	x9, x11, x8
	ldr	x12, [x10]
	stp	x19, x27, [sp, #176]
	ldr	x10, [x11]
	stp	x28, x22, [sp, #192]
	stp	x13, x12, [sp, #208]
	str	x10, [sp, #224]
	str	x10, [sp, #88]                  ; 8-byte Folded Spill
	ldr	x10, [x9]
	stp	x13, x12, [sp, #64]             ; 16-byte Folded Spill
	str	x10, [sp, #232]
	ldr	x8, [x9, x8]
	str	x10, [sp, #80]                  ; 8-byte Folded Spill
	str	x8, [sp, #104]                  ; 8-byte Folded Spill
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	blr	x8
	mov	x0, x20
	mov	x1, x19
	mov	x2, x27
	blr	x21
	and	w8, w0, #0xff
	add	x23, sp, #176
	cmp	w8, #1
	mov	x0, x20
	cset	w8, eq
	cset	w9, ne
	mov	x1, x28
	mov	x2, x22
	orr	x8, x23, x8, lsl #3
	orr	x9, x23, x9, lsl #3
	ldr	x19, [x8]
	ldr	x27, [x9]
	stp	x19, x27, [sp, #176]
	blr	x21
	and	w8, w0, #0xff
	str	x25, [sp, #112]                 ; 8-byte Folded Spill
	cmp	w8, #1
	ldr	x25, [sp, #40]                  ; 8-byte Folded Reload
	cset	w8, eq
	cset	w9, ne
	mov	x0, x20
	mov	x1, x19
	ldr	x2, [x25, w8, uxtw #3]
	ldr	x22, [x25, w9, uxtw #3]
	stp	x2, x22, [sp, #192]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	mov	x1, x27
	cset	w8, ne
	mov	x2, x22
	ubfiz	x8, x8, #4, #32
	ldr	x8, [x23, x8]
	str	x8, [sp, #96]                   ; 8-byte Folded Spill
	str	x8, [sp, #192]
	blr	x21
	and	w8, w0, #0xff
	ldr	x9, [sp, #120]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x20
	cset	w8, eq
	mov	w1, #4
	ubfiz	x8, x8, #4, #32
	ldr	x23, [sp, #144]                 ; 8-byte Folded Reload
	ldr	x8, [x9, x8]
	str	x8, [sp, #56]                   ; 8-byte Folded Spill
	str	x8, [sp, #184]
	blr	x23
	ldp	x1, x2, [sp, #64]               ; 16-byte Folded Reload
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	ldr	x28, [sp, #32]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x20
	cset	w8, eq
	cset	w9, ne
	ldp	x2, x1, [sp, #80]               ; 16-byte Folded Reload
	ldr	x22, [x28, w8, uxtw #3]
	ldr	x27, [x28, w9, uxtw #3]
	stp	x22, x27, [sp, #208]
	blr	x21
	and	w8, w0, #0xff
	ldr	x10, [sp, #16]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x20
	cset	w8, eq
	cset	w9, ne
	mov	x1, x22
	ldr	x2, [x10, w8, uxtw #3]
	ldr	x19, [x10, w9, uxtw #3]
	stp	x2, x19, [sp, #224]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	mov	x1, x27
	cset	w8, ne
	mov	x2, x19
	ubfiz	x8, x8, #4, #32
	ldr	x28, [x28, x8]
	str	x28, [sp, #224]
	blr	x21
	and	w8, w0, #0xff
	ldr	x9, [sp, #24]                   ; 8-byte Folded Reload
	cmp	w8, #1
	ldr	x27, [sp, #104]                 ; 8-byte Folded Reload
	cset	w8, eq
	mov	x0, x20
	ubfiz	x8, x8, #4, #32
	mov	w1, #4
	str	x27, [sp, #200]
	ldr	x19, [x9, x8]
	str	x19, [sp, #176]
	blr	x23
	mov	x0, x20
	mov	x1, x19
	ldr	x2, [sp, #56]                   ; 8-byte Folded Reload
	blr	x21
	and	w8, w0, #0xff
	add	x10, sp, #176
	cmp	w8, #1
	mov	x0, x20
	cset	w8, eq
	cset	w9, ne
	ldr	x1, [sp, #96]                   ; 8-byte Folded Reload
	mov	x2, x27
	orr	x8, x10, x8, lsl #3
	orr	x9, x10, x9, lsl #3
	ldr	x19, [x8]
	ldr	x22, [x9]
	stp	x19, x22, [sp, #176]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	mov	x1, x19
	cset	w8, eq
	cset	w9, ne
	ldr	x2, [x25, w8, uxtw #3]
	ldr	x27, [x25, w9, uxtw #3]
	ldr	x25, [sp, #112]                 ; 8-byte Folded Reload
	stp	x2, x27, [sp, #192]
	blr	x21
	and	w8, w0, #0xff
	add	x9, sp, #176
	cmp	w8, #1
	mov	x0, x20
	cset	w8, ne
	mov	x1, x22
	ubfiz	x8, x8, #4, #32
	mov	x2, x27
	ldr	x19, [x9, x8]
	str	x19, [sp, #192]
	blr	x21
	and	w8, w0, #0xff
	ldr	x9, [sp, #120]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x20
	cset	w8, eq
	mov	w1, #3
	ubfiz	x8, x8, #4, #32
	ldr	x22, [x9, x8]
	stp	x28, x22, [sp, #176]
	blr	x23
	mov	x0, x20
	mov	x1, x28
	mov	x2, x22
	ldr	x23, [sp, #152]                 ; 8-byte Folded Reload
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	mov	x1, x28
	mov	x2, x19
	cmp	w8, #1
	cset	w27, eq
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	mov	x1, x22
	mov	x2, x19
	cmp	w8, #1
	cset	w28, ne
	blr	x21
	and	w9, w0, #0xff
	eor	w8, w27, w28
	cmp	w9, #1
	ldr	x28, [sp, #160]                 ; 8-byte Folded Reload
	cset	w9, eq
	eor	w9, w27, w9
	add	x8, x9, x8
	add	x9, sp, #176
	ldr	x8, [x9, x8, lsl #3]
	str	x8, [x24]
	b	LBB54_19
LBB54_3:                                ;   in Loop: Header=BB54_1 Depth=1
	mov	w8, #32
LBB54_4:                                ;   Parent Loop BB54_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x28, x8
	mul	x8, x8, x8
	mul	x9, x8, x28
	lsl	x8, x28, #1
	cmp	x9, x25
	b.lo	LBB54_4
; %bb.5:                                ;   in Loop: Header=BB54_1 Depth=1
	udiv	x12, x25, x28
	ldr	x10, [sp, #48]                  ; 8-byte Folded Reload
	mov	x8, xzr
	ldr	x27, [sp, #144]                 ; 8-byte Folded Reload
	udiv	x9, x10, x12
	str	x12, [sp, #176]
	msub	x9, x9, x12, x10
	ldr	x10, [sp, #160]                 ; 8-byte Folded Reload
	cmp	x26, x10
	add	x9, x26, x9, lsl #3
	csel	x19, x23, x10, eq
	cmp	x28, #1
	lsl	x10, x12, #3
	csinc	x11, x28, xzr, hi
LBB54_6:                                ;   Parent Loop BB54_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x12, [x9]
	add	x9, x9, x10
	str	x12, [x19, x8, lsl #3]
	add	x8, x8, #1
	cmp	x11, x8
	b.ne	LBB54_6
; %bb.7:                                ;   in Loop: Header=BB54_1 Depth=1
	lsl	x8, x28, #3
	lsr	x23, x28, #1
	add	x22, x19, x8
	cmp	x28, #192
	str	x8, [sp, #112]                  ; 8-byte Folded Spill
	b.hs	LBB54_9
; %bb.8:                                ;   in Loop: Header=BB54_1 Depth=1
	mov	x0, x19
	mov	x1, x23
	mov	x2, x22
	mov	x3, x21
	mov	x4, x20
	mov	x5, x27
	bl	l_sort.tail_swap__anon_14843
	lsl	x8, x28, #2
	mov	x1, x23
	add	x28, x19, x8
	mov	x2, x22
	mov	x0, x28
	mov	x3, x21
	mov	x4, x20
	mov	x5, x27
	str	x8, [sp, #104]                  ; 8-byte Folded Spill
	bl	l_sort.tail_swap__anon_14843
	b	LBB54_13
LBB54_9:                                ;   in Loop: Header=BB54_1 Depth=1
	mov	x0, x19
	mov	x1, x23
	mov	x2, x21
	mov	x3, x20
	mov	x4, x27
	str	x22, [sp, #96]                  ; 8-byte Folded Spill
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB54_11
; %bb.10:                               ;   in Loop: Header=BB54_1 Depth=1
	ldr	x22, [sp, #96]                  ; 8-byte Folded Reload
	mov	x0, x19
	mov	x1, x23
	mov	x3, x23
	mov	x4, x21
	mov	x5, x20
	mov	x2, x22
	mov	x6, x27
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x19
	mov	x1, x23
	mov	x2, x22
	mov	x3, x23
	mov	x5, x21
	mov	x6, x20
	mov	x7, x27
	bl	l_sort.rotate_merge__anon_14846
LBB54_11:                               ;   in Loop: Header=BB54_1 Depth=1
	lsl	x8, x28, #2
	mov	x1, x23
	add	x28, x19, x8
	mov	x2, x21
	mov	x0, x28
	mov	x3, x20
	mov	x4, x27
	str	x8, [sp, #104]                  ; 8-byte Folded Spill
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB54_13
; %bb.12:                               ;   in Loop: Header=BB54_1 Depth=1
	ldr	x22, [sp, #96]                  ; 8-byte Folded Reload
	mov	x0, x28
	mov	x1, x23
	mov	x3, x23
	mov	x4, x21
	mov	x5, x20
	mov	x2, x22
	mov	x6, x27
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x28
	mov	x1, x23
	mov	x2, x22
	mov	x3, x23
	mov	x5, x21
	mov	x6, x20
	mov	x7, x27
	bl	l_sort.rotate_merge__anon_14846
LBB54_13:                               ; %sort.quadsort_swap__anon_14861.exit34.i
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	mov	x0, x20
	mov	w1, #1
	add	x22, x8, x19
	blr	x27
	ldur	x1, [x22, #-8]
	mov	x0, x20
	ldr	x2, [x19]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB54_15
; %bb.14:                               ;   in Loop: Header=BB54_1 Depth=1
	mov	w22, wzr
	b	LBB54_16
LBB54_15:                               ;   in Loop: Header=BB54_1 Depth=1
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	mov	x0, x20
	mov	w1, #1
	add	x22, x8, x19
	blr	x27
	ldur	x1, [x22, #-8]
	mov	x0, x20
	ldr	x2, [x19]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w22, ne
LBB54_16:                               ;   in Loop: Header=BB54_1 Depth=1
	clz	x8, x23
	mov	w9, #64
	sub	x1, x9, x8
	mov	x0, x20
	blr	x27
LBB54_17:                               ; %.lr.ph.i.i
                                        ;   Parent Loop BB54_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x1, [x19]
	mov	x0, x20
	ldr	x2, [x28]
	lsr	x27, x23, #1
	blr	x21
	and	w9, w0, #0xff
	lsl	x8, x27, #3
	cmp	w9, #1
	csel	x9, x8, xzr, eq
	csel	x8, xzr, x8, eq
	add	x28, x28, x9
	add	x19, x19, x8
	cmp	x23, #4
	mov	x23, x27
	b.hs	LBB54_17
; %bb.18:                               ; %sort.median_of_cube_root__anon_16530.exit
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x1, [x19]
	mov	x0, x20
	ldr	x2, [x28]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x19, x28, eq
	ldp	x23, x28, [sp, #152]            ; 16-byte Folded Reload
	ldr	x8, [x8]
	str	x8, [x24]
	cbnz	w22, LBB54_52
LBB54_19:                               ;   in Loop: Header=BB54_1 Depth=1
	ldp	x8, x19, [sp, #136]             ; 16-byte Folded Reload
	cbz	x8, LBB54_21
; %bb.20:                               ;   in Loop: Header=BB54_1 Depth=1
	mov	x0, x20
	mov	w1, #1
	blr	x19
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	mov	x0, x20
	ldp	x2, x1, [x8, #-8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB54_51
LBB54_21:                               ; %.critedge
                                        ;   in Loop: Header=BB54_1 Depth=1
	mov	x0, x20
	mov	x1, x25
	blr	x19
	cmp	x25, #8
	b.hs	LBB54_23
; %bb.22:                               ;   in Loop: Header=BB54_1 Depth=1
	mov	x22, xzr
	mov	x19, x28
	mov	x28, x23
	b	LBB54_25
LBB54_23:                               ; %.cont82.i.preheader
                                        ;   in Loop: Header=BB54_1 Depth=1
	mov	x22, xzr
	mov	x19, x28
	mov	x28, x23
	mov	w27, #8
LBB54_24:                               ; %.cont82.i
                                        ;   Parent Loop BB54_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x1, [x26]
	mov	x0, x20
	ldr	x2, [x24]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x28, x19, eq
	str	x8, [x9], #8
	ldr	x1, [x26, #8]
	csel	x23, x9, x28, eq
	ldr	x2, [x24]
	csel	x19, x19, x9, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26, #8]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x23, x19, eq
	str	x8, [x9], #8
	ldr	x1, [x26, #16]
	csel	x23, x9, x23, eq
	ldr	x2, [x24]
	csel	x19, x19, x9, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26, #16]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x23, x19, eq
	str	x8, [x9], #8
	ldr	x1, [x26, #24]
	csel	x23, x9, x23, eq
	ldr	x2, [x24]
	csel	x19, x19, x9, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26, #24]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x23, x19, eq
	str	x8, [x9], #8
	ldr	x1, [x26, #32]
	csel	x23, x9, x23, eq
	ldr	x2, [x24]
	csel	x19, x19, x9, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26, #32]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x23, x19, eq
	str	x8, [x9], #8
	ldr	x1, [x26, #40]
	csel	x23, x9, x23, eq
	ldr	x2, [x24]
	csel	x19, x19, x9, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26, #40]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x23, x19, eq
	str	x8, [x9], #8
	ldr	x1, [x26, #48]
	csel	x23, x9, x23, eq
	ldr	x2, [x24]
	csel	x19, x19, x9, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26, #48]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x23, x19, eq
	str	x8, [x9], #8
	ldr	x1, [x26, #56]
	csel	x23, x9, x23, eq
	ldr	x2, [x24]
	csel	x19, x19, x9, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26, #56]
	cmp	w9, #1
	add	x26, x26, #64
	csel	x9, x23, x19, eq
	str	x8, [x9], #8
	csel	x28, x9, x23, eq
	csel	x19, x19, x9, eq
	ldp	x23, x8, [sp, #152]             ; 16-byte Folded Reload
	cmp	x28, x23
	ccmp	x19, x8, #4, ne
	csel	x22, x27, x22, eq
	add	x27, x27, #8
	cmp	x27, x25
	b.ls	LBB54_24
LBB54_25:                               ; %._crit_edge.i
                                        ;   in Loop: Header=BB54_1 Depth=1
	ands	x27, x25, #0x7
	b.eq	LBB54_33
; %bb.26:                               ; %.cont.i
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x1, [x26]
	mov	x0, x20
	ldr	x2, [x24]
	blr	x21
	and	w9, w0, #0xff
	ldr	x10, [x26]
	cmp	w9, #1
	csel	x8, x28, x19, eq
	str	x10, [x8], #8
	csel	x19, x19, x8, eq
	cmp	x27, #1
	b.eq	LBB54_33
; %bb.27:                               ; %.cont.i.1
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x1, [x26, #8]
	mov	x0, x20
	ldr	x2, [x24]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x10, [x26, #8]
	cmp	w9, #1
	csel	x8, x28, x19, eq
	str	x10, [x8], #8
	csel	x19, x19, x8, eq
	cmp	x27, #2
	b.eq	LBB54_33
; %bb.28:                               ; %.cont.i.2
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x1, [x26, #16]
	mov	x0, x20
	ldr	x2, [x24]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x10, [x26, #16]
	cmp	w9, #1
	csel	x8, x28, x19, eq
	str	x10, [x8], #8
	csel	x19, x19, x8, eq
	cmp	x27, #3
	b.eq	LBB54_33
; %bb.29:                               ; %.cont.i.3
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x1, [x26, #24]
	mov	x0, x20
	ldr	x2, [x24]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x10, [x26, #24]
	cmp	w9, #1
	csel	x8, x28, x19, eq
	str	x10, [x8], #8
	csel	x19, x19, x8, eq
	cmp	x27, #4
	b.eq	LBB54_33
; %bb.30:                               ; %.cont.i.4
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x1, [x26, #32]
	mov	x0, x20
	ldr	x2, [x24]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x10, [x26, #32]
	cmp	w9, #1
	csel	x8, x28, x19, eq
	str	x10, [x8], #8
	csel	x19, x19, x8, eq
	cmp	x27, #5
	b.eq	LBB54_33
; %bb.31:                               ; %.cont.i.5
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x1, [x26, #40]
	mov	x0, x20
	ldr	x2, [x24]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x10, [x26, #40]
	cmp	w9, #1
	csel	x8, x28, x19, eq
	str	x10, [x8], #8
	csel	x19, x19, x8, eq
	cmp	x27, #6
	b.eq	LBB54_33
; %bb.32:                               ; %.cont.i.6
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x1, [x26, #48]
	mov	x0, x20
	ldr	x2, [x24]
	cmp	w9, #1
	csel	x23, x8, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x26, #48]
	cmp	w9, #1
	csel	x9, x23, x19, eq
	ldr	x23, [sp, #152]                 ; 8-byte Folded Reload
	str	x8, [x9], #8
	csel	x19, x19, x9, eq
LBB54_33:                               ; %._crit_edge14.i
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x28, [sp, #160]                 ; 8-byte Folded Reload
	cmp	x22, x25, lsr #2
	sub	x27, x19, x28
	lsr	x26, x27, #3
	sub	x19, x25, x26
	b.ls	LBB54_35
; %bb.34:                               ; %._crit_edge14.i
                                        ;   in Loop: Header=BB54_1 Depth=1
	cmp	x25, x26
	b.ne	LBB54_49
LBB54_35:                               ; %sort.flux_default_partition__anon_16532.exit
                                        ;   in Loop: Header=BB54_1 Depth=1
	cmp	x19, #97
	str	x26, [sp, #136]                 ; 8-byte Folded Spill
	b.lo	LBB54_38
; %bb.36:                               ; %sort.flux_default_partition__anon_16532.exit
                                        ;   in Loop: Header=BB54_1 Depth=1
	lsr	x8, x19, #5
	cmp	x26, x8
	b.ls	LBB54_38
; %bb.37:                               ;   in Loop: Header=BB54_1 Depth=1
	and	x8, x27, #0xfffffffffffffff8
	mov	x1, x23
	add	x0, x28, x8
	mov	x2, x23
	mov	x3, x24
	mov	x4, x19
	mov	x5, x21
	mov	x6, x20
	ldr	x7, [sp, #144]                  ; 8-byte Folded Reload
	bl	l_sort.flux_partition__anon_14860
	b	LBB54_44
LBB54_38:                               ;   in Loop: Header=BB54_1 Depth=1
	cmp	x27, #8
	b.lo	LBB54_72
; %bb.39:                               ;   in Loop: Header=BB54_1 Depth=1
	cmp	x25, x26
	b.eq	LBB54_64
; %bb.40:                               ;   in Loop: Header=BB54_1 Depth=1
	and	x8, x27, #0xfffffffffffffff8
	lsl	x2, x19, #3
	add	x25, x28, x8
	mov	x1, x23
	mov	x0, x25
	bl	_memcpy
	cmp	x19, #95
	b.hi	LBB54_42
; %bb.41:                               ;   in Loop: Header=BB54_1 Depth=1
	mov	x0, x25
	mov	x1, x19
	mov	x2, x23
	mov	x3, x21
	mov	x4, x20
	ldr	x5, [sp, #144]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14843
	b	LBB54_44
LBB54_42:                               ;   in Loop: Header=BB54_1 Depth=1
	mov	x0, x25
	mov	x1, x19
	mov	x2, x21
	mov	x3, x20
	ldr	x4, [sp, #144]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB54_44
; %bb.43:                               ;   in Loop: Header=BB54_1 Depth=1
	ldr	x22, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x25
	mov	x1, x19
	mov	x2, x23
	mov	x3, x19
	mov	x4, x21
	mov	x5, x20
	mov	x6, x22
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x25
	mov	x1, x19
	mov	x2, x23
	mov	x3, x19
	mov	x5, x21
	mov	x6, x20
	mov	x7, x22
	bl	l_sort.rotate_merge__anon_14846
LBB54_44:                               ; %sort.quadsort_swap__anon_14861.exit63
                                        ;   in Loop: Header=BB54_1 Depth=1
	cmp	x27, #776
	b.lo	LBB54_46
; %bb.45:                               ; %sort.quadsort_swap__anon_14861.exit63
                                        ;   in Loop: Header=BB54_1 Depth=1
	ldr	x25, [sp, #136]                 ; 8-byte Folded Reload
	mov	x26, x28
	mov	x3, x24
	lsr	x8, x27, #8
	cmp	x19, x8
	b.hi	LBB54_1
LBB54_46:
	cmp	x27, #775
	b.hi	LBB54_65
; %bb.47:
	cmp	x27, #767
	b.hi	LBB54_69
; %bb.48:
	ldr	x1, [sp, #136]                  ; 8-byte Folded Reload
	mov	x0, x28
	b	LBB54_60
LBB54_49:
	and	x8, x27, #0xfffffffffffffff8
	lsl	x2, x19, #3
	add	x24, x28, x8
	mov	x1, x23
	mov	x0, x24
	bl	_memcpy
	cmp	x19, #95
	b.hi	LBB54_56
; %bb.50:
	mov	x0, x24
	mov	x1, x19
	mov	x2, x23
	mov	x3, x21
	mov	x4, x20
	ldr	x5, [sp, #144]                  ; 8-byte Folded Reload
	bl	l_sort.tail_swap__anon_14843
	b	LBB54_58
LBB54_51:
	mov	x0, x28
	mov	x1, x23
	mov	x2, x28
	mov	x3, x24
	mov	x4, x25
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	bl	l_sort.flux_reverse_partition__anon_16531
	b	LBB54_72
LBB54_52:
	cmp	x26, x23
	b.ne	LBB54_54
; %bb.53:
	lsl	x2, x25, #3
	mov	x0, x28
	mov	x1, x23
	bl	_memcpy
LBB54_54:
	ldr	x5, [sp, #144]                  ; 8-byte Folded Reload
	cmp	x25, #95
	b.hi	LBB54_67
; %bb.55:
	mov	x0, x28
	mov	x1, x25
	b	LBB54_61
LBB54_56:
	mov	x0, x24
	mov	x1, x19
	mov	x2, x21
	mov	x3, x20
	ldr	x4, [sp, #144]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB54_58
; %bb.57:
	ldr	x22, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x24
	mov	x1, x19
	mov	x2, x23
	mov	x3, x19
	mov	x4, x21
	mov	x5, x20
	mov	x6, x22
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x24
	mov	x1, x19
	mov	x2, x23
	mov	x3, x19
	mov	x5, x21
	mov	x6, x20
	mov	x7, x22
	bl	l_sort.rotate_merge__anon_14846
LBB54_58:                               ; %sort.quadsort_swap__anon_14861.exit.i
	cmp	x27, #767
	b.hi	LBB54_62
; %bb.59:
	mov	x0, x28
	mov	x1, x26
LBB54_60:                               ; %common.ret
	ldr	x5, [sp, #144]                  ; 8-byte Folded Reload
LBB54_61:                               ; %common.ret
	mov	x2, x23
	mov	x3, x21
	mov	x4, x20
	bl	l_sort.tail_swap__anon_14843
	b	LBB54_72
LBB54_62:
	mov	x0, x28
	mov	x1, x26
	mov	x2, x21
	mov	x3, x20
	ldr	x4, [sp, #144]                  ; 8-byte Folded Reload
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB54_72
; %bb.63:
	ldr	x19, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x28
	mov	x1, x26
	mov	x2, x23
	mov	x3, x26
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x28
	mov	x1, x26
	mov	x2, x23
	mov	x3, x26
	b	LBB54_71
LBB54_64:
	mov	x0, x28
	mov	x1, x23
	mov	x2, x28
	mov	x3, x24
	mov	x4, x25
	b	LBB54_66
LBB54_65:
	ldr	x4, [sp, #136]                  ; 8-byte Folded Reload
	mov	x0, x28
	mov	x1, x23
	mov	x2, x28
	mov	x3, x24
LBB54_66:                               ; %common.ret
	mov	x5, x21
	mov	x6, x20
	ldr	x7, [sp, #144]                  ; 8-byte Folded Reload
	bl	l_sort.flux_reverse_partition__anon_16531
	b	LBB54_72
LBB54_67:
	mov	x0, x28
	mov	x1, x25
	mov	x2, x21
	mov	x3, x20
	mov	x4, x5
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB54_72
; %bb.68:
	ldr	x19, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x28
	mov	x1, x25
	mov	x2, x23
	mov	x3, x25
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x28
	mov	x1, x25
	mov	x2, x23
	mov	x3, x25
	b	LBB54_71
LBB54_69:
	ldp	x22, x4, [sp, #136]             ; 16-byte Folded Reload
	mov	x0, x28
	mov	x2, x21
	mov	x3, x20
	mov	x1, x22
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB54_72
; %bb.70:
	ldr	x19, [sp, #144]                 ; 8-byte Folded Reload
	mov	x0, x28
	mov	x1, x22
	mov	x2, x23
	mov	x3, x22
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x28
	mov	x1, x22
	mov	x2, x23
	mov	x3, x22
LBB54_71:                               ; %common.ret
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	bl	l_sort.rotate_merge__anon_14846
LBB54_72:                               ; %common.ret
	add	sp, sp, #1040
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end54:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.cross_merge__anon_14862
l_sort.cross_merge__anon_14862:         ; @sort.cross_merge__anon_14862
Lfunc_begin55:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x28, x27, [sp, #32]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	add	x26, x1, x2, lsl #3
	mov	x20, x6
	sub	x8, x26, #8
	mov	x21, x5
	mov	x25, x2
	mov	x23, x1
	mov	x27, x3
	mov	x22, x4
	mov	x19, x0
	add	x24, x8, x3, lsl #3
	str	x8, [sp, #8]                    ; 8-byte Folded Spill
	add	x8, x2, #1
	cmp	x8, x3
	b.lo	LBB55_7
; %bb.1:
	add	x8, x27, #1
	cmp	x8, x25
	b.lo	LBB55_7
; %bb.2:
	cmp	x25, #31
	b.ls	LBB55_7
; %bb.3:
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldr	x1, [x23, #120]
	mov	x0, x21
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB55_7
; %bb.4:
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldr	x1, [x23]
	mov	x0, x21
	ldr	x2, [x26, #120]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB55_7
; %bb.5:
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x21
	ldur	x2, [x24, #-120]
	ldr	x1, [x8]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB55_7
; %bb.6:
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x21
	ldr	x2, [x24]
	ldur	x1, [x8, #-120]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB55_39
LBB55_7:                                ; %.critedge
	add	x8, x27, x25
	ldr	x27, [sp, #8]                   ; 8-byte Folded Reload
	str	x24, [sp, #16]                  ; 8-byte Folded Spill
	add	x8, x19, x8, lsl #3
	sub	x28, x8, #8
LBB55_8:                                ; %.loopexit.outer
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB55_9 Depth 2
                                        ;       Child Loop BB55_10 Depth 3
                                        ;     Child Loop BB55_13 Depth 2
                                        ;     Child Loop BB55_18 Depth 2
                                        ;     Child Loop BB55_22 Depth 2
	str	x28, [sp, #24]                  ; 8-byte Folded Spill
LBB55_9:                                ; %.loopexit
                                        ;   Parent Loop BB55_8 Depth=1
                                        ; =>  This Loop Header: Depth=2
                                        ;       Child Loop BB55_10 Depth 3
	sub	x25, x27, x23
	cmp	x25, #65
	b.lt	LBB55_28
LBB55_10:                               ; %.preheader11
                                        ;   Parent Loop BB55_8 Depth=1
                                        ;     Parent Loop BB55_9 Depth=2
                                        ; =>    This Inner Loop Header: Depth=3
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldr	x1, [x23, #56]
	mov	x0, x21
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB55_12
; %bb.11:                               ;   in Loop: Header=BB55_10 Depth=3
	ldr	x8, [x23]
	sub	x25, x25, #64
	cmp	x25, #65
	str	x8, [x19]
	ldr	x8, [x23, #8]
	str	x8, [x19, #8]
	ldr	x8, [x23, #16]
	str	x8, [x19, #16]
	ldr	x8, [x23, #24]
	str	x8, [x19, #24]
	ldr	x8, [x23, #32]
	str	x8, [x19, #32]
	ldr	x8, [x23, #40]
	str	x8, [x19, #40]
	ldr	x8, [x23, #48]
	str	x8, [x19, #48]
	ldr	x8, [x23, #56]
	add	x23, x23, #64
	str	x8, [x19, #56]
	add	x19, x19, #64
	b.hs	LBB55_10
	b	LBB55_9
LBB55_12:                               ; %.preheader8.loopexit
                                        ;   in Loop: Header=BB55_8 Depth=1
	mov	x24, x22
	mov	x22, x20
	mov	x20, x27
	mov	x27, xzr
LBB55_13:                               ; %.preheader8
                                        ;   Parent Loop BB55_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x21
	mov	w1, #1
	add	x28, x20, x27
	blr	x22
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	mov	x0, x21
	ldur	x1, [x28, #-56]
	ldr	x2, [x8]
	blr	x24
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB55_16
; %bb.14:                               ;   in Loop: Header=BB55_13 Depth=2
	ldr	x9, [sp, #24]                   ; 8-byte Folded Reload
	ldr	x8, [x28]
	add	x9, x9, x27
	sub	x27, x27, #64
	add	x10, x25, x27
	cmp	x10, #65
	str	x8, [x9]
	ldur	x8, [x28, #-8]
	stur	x8, [x9, #-8]
	ldur	x8, [x28, #-16]
	stur	x8, [x9, #-16]
	ldur	x8, [x28, #-24]
	stur	x8, [x9, #-24]
	ldur	x8, [x28, #-32]
	stur	x8, [x9, #-32]
	ldur	x8, [x28, #-40]
	stur	x8, [x9, #-40]
	ldur	x8, [x28, #-48]
	stur	x8, [x9, #-48]
	ldur	x8, [x28, #-56]
	stur	x8, [x9, #-56]
	b.hs	LBB55_13
; %bb.15:                               ; %.loopexit.outer.loopexit
                                        ;   in Loop: Header=BB55_8 Depth=1
	ldr	x28, [sp, #24]                  ; 8-byte Folded Reload
	add	x28, x28, x27
	add	x27, x20, x27
	mov	x20, x22
	mov	x22, x24
	b	LBB55_8
LBB55_16:                               ; %.loopexit9.loopexit
                                        ;   in Loop: Header=BB55_8 Depth=1
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x20, x22
	mov	x22, x24
	add	x8, x8, x27
	mov	x27, x28
	ldr	x28, [sp, #16]                  ; 8-byte Folded Reload
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
LBB55_17:                               ; %.loopexit9
                                        ;   in Loop: Header=BB55_8 Depth=1
	sub	x25, x28, x26
	cmp	x25, #65
	b.lt	LBB55_29
LBB55_18:                               ; %.preheader6
                                        ;   Parent Loop BB55_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldr	x1, [x23]
	mov	x0, x21
	ldr	x2, [x26, #56]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB55_21
; %bb.19:                               ;   in Loop: Header=BB55_18 Depth=2
	ldr	x8, [x26]
	sub	x25, x25, #64
	cmp	x25, #65
	str	x8, [x19]
	ldr	x8, [x26, #8]
	str	x8, [x19, #8]
	ldr	x8, [x26, #16]
	str	x8, [x19, #16]
	ldr	x8, [x26, #24]
	str	x8, [x19, #24]
	ldr	x8, [x26, #32]
	str	x8, [x19, #32]
	ldr	x8, [x26, #40]
	str	x8, [x19, #40]
	ldr	x8, [x26, #48]
	str	x8, [x19, #48]
	ldr	x8, [x26, #56]
	add	x26, x26, #64
	str	x8, [x19, #56]
	add	x19, x19, #64
	b.hs	LBB55_18
; %bb.20:                               ;   in Loop: Header=BB55_8 Depth=1
	ldr	x28, [sp, #24]                  ; 8-byte Folded Reload
	b	LBB55_8
LBB55_21:                               ; %.preheader3.loopexit
                                        ;   in Loop: Header=BB55_8 Depth=1
	str	x27, [sp, #8]                   ; 8-byte Folded Spill
	mov	x27, xzr
LBB55_22:                               ; %.preheader3
                                        ;   Parent Loop BB55_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x21
	mov	w1, #1
	add	x28, x28, x27
	blr	x20
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x21
	ldur	x2, [x28, #-56]
	ldr	x1, [x8]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB55_25
; %bb.23:                               ;   in Loop: Header=BB55_22 Depth=2
	ldr	x9, [sp, #24]                   ; 8-byte Folded Reload
	ldr	x8, [x28]
	add	x9, x9, x27
	sub	x27, x27, #64
	add	x10, x25, x27
	cmp	x10, #65
	str	x8, [x9]
	ldur	x8, [x28, #-8]
	stur	x8, [x9, #-8]
	ldur	x8, [x28, #-16]
	stur	x8, [x9, #-16]
	ldur	x8, [x28, #-24]
	stur	x8, [x9, #-24]
	ldur	x8, [x28, #-32]
	stur	x8, [x9, #-32]
	ldur	x8, [x28, #-40]
	stur	x8, [x9, #-40]
	ldur	x8, [x28, #-48]
	stur	x8, [x9, #-48]
	ldur	x8, [x28, #-56]
	ldr	x28, [sp, #16]                  ; 8-byte Folded Reload
	stur	x8, [x9, #-56]
	b.hs	LBB55_22
; %bb.24:                               ; %.loopexit.outer.outer.loopexit
                                        ;   in Loop: Header=BB55_8 Depth=1
	mov	x8, x28
	ldr	x28, [sp, #24]                  ; 8-byte Folded Reload
	add	x8, x8, x27
	add	x28, x28, x27
	ldr	x27, [sp, #8]                   ; 8-byte Folded Reload
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
	b	LBB55_8
LBB55_25:                               ; %.loopexit4.loopexit
                                        ;   in Loop: Header=BB55_8 Depth=1
	ldr	x24, [sp, #24]                  ; 8-byte Folded Reload
	str	x28, [sp, #16]                  ; 8-byte Folded Spill
	add	x24, x24, x27
	ldr	x27, [sp, #8]                   ; 8-byte Folded Reload
	mov	x28, x24
LBB55_26:                               ; %.loopexit4
                                        ;   in Loop: Header=BB55_8 Depth=1
	sub	x8, x28, x19
	cmp	x8, #127
	b.ls	LBB55_30
; %bb.27:                               ; %.cont46
                                        ;   in Loop: Header=BB55_8 Depth=1
	mov	x0, x21
	mov	w1, #16
	blr	x20
	ldr	x1, [x23]
	mov	x0, x21
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	ldr	x24, [sp, #16]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x21
	csel	x8, x26, x23, eq
	ldr	x9, [x8], #8
	csel	x25, x8, x26, eq
	csel	x23, x23, x8, eq
	str	x9, [x19]
	ldr	x1, [x27]
	ldr	x2, [x24]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x27, x24, eq
	ldr	x9, [x8], #-8
	csel	x26, x24, x8, eq
	csel	x24, x8, x27, eq
	str	x9, [x28]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x25, x23, eq
	ldr	x9, [x8], #8
	csel	x25, x8, x25, eq
	csel	x23, x23, x8, eq
	str	x9, [x19, #8]
	ldr	x1, [x24]
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x24, x26, eq
	ldr	x9, [x8], #-8
	csel	x26, x26, x8, eq
	csel	x24, x8, x24, eq
	stur	x9, [x28, #-8]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x25, x23, eq
	ldr	x9, [x8], #8
	csel	x25, x8, x25, eq
	csel	x23, x23, x8, eq
	str	x9, [x19, #16]
	ldr	x1, [x24]
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x24, x26, eq
	ldr	x9, [x8], #-8
	csel	x26, x26, x8, eq
	csel	x24, x8, x24, eq
	stur	x9, [x28, #-16]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x25, x23, eq
	ldr	x9, [x8], #8
	csel	x25, x8, x25, eq
	csel	x23, x23, x8, eq
	str	x9, [x19, #24]
	ldr	x1, [x24]
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x24, x26, eq
	ldr	x9, [x8], #-8
	csel	x26, x26, x8, eq
	csel	x24, x8, x24, eq
	stur	x9, [x28, #-24]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x25, x23, eq
	ldr	x9, [x8], #8
	csel	x25, x8, x25, eq
	csel	x23, x23, x8, eq
	str	x9, [x19, #32]
	ldr	x1, [x24]
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x24, x26, eq
	ldr	x9, [x8], #-8
	csel	x26, x26, x8, eq
	csel	x24, x8, x24, eq
	stur	x9, [x28, #-32]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x25, x23, eq
	ldr	x9, [x8], #8
	csel	x25, x8, x25, eq
	csel	x23, x23, x8, eq
	str	x9, [x19, #40]
	ldr	x1, [x24]
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x24, x26, eq
	ldr	x9, [x8], #-8
	csel	x26, x26, x8, eq
	csel	x24, x8, x24, eq
	stur	x9, [x28, #-40]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x25, x23, eq
	ldr	x9, [x8], #8
	csel	x25, x8, x25, eq
	csel	x23, x23, x8, eq
	str	x9, [x19, #48]
	ldr	x1, [x24]
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x24, x26, eq
	ldr	x9, [x8], #-8
	csel	x27, x26, x8, eq
	csel	x24, x8, x24, eq
	stur	x9, [x28, #-48]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x21
	cmp	w8, #1
	csel	x8, x25, x23, eq
	ldr	x9, [x8], #8
	csel	x26, x8, x25, eq
	csel	x23, x23, x8, eq
	str	x9, [x19, #56]
	add	x19, x19, #64
	ldr	x1, [x24]
	ldr	x2, [x27]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x24, x27, eq
	ldr	x9, [x8], #-8
	csel	x10, x27, x8, eq
	csel	x27, x8, x24, eq
	stur	x9, [x28, #-56]
	sub	x28, x28, #64
	str	x10, [sp, #16]                  ; 8-byte Folded Spill
	b	LBB55_8
LBB55_28:                               ;   in Loop: Header=BB55_8 Depth=1
	ldr	x28, [sp, #16]                  ; 8-byte Folded Reload
	b	LBB55_17
LBB55_29:                               ;   in Loop: Header=BB55_8 Depth=1
	ldr	x28, [sp, #24]                  ; 8-byte Folded Reload
	b	LBB55_26
LBB55_30:                               ; %.preheader2
	cmp	x23, x27
	b.hi	LBB55_38
; %bb.31:                               ; %.preheader2
	ldr	x24, [sp, #16]                  ; 8-byte Folded Reload
	cmp	x26, x24
	b.hi	LBB55_33
LBB55_32:                               ; %.cont
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x20
	ldr	x1, [x23]
	mov	x0, x21
	ldr	x2, [x26]
	blr	x22
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x26, x23, eq
	ldr	x9, [x8], #8
	csel	x23, x23, x8, eq
	csel	x26, x8, x26, eq
	cmp	x23, x27
	ccmp	x26, x24, #2, ls
	str	x9, [x19], #8
	b.ls	LBB55_32
LBB55_33:                               ; %.preheader1
	cmp	x23, x27
	b.hi	LBB55_35
LBB55_34:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [x23], #8
	cmp	x23, x27
	str	x8, [x19], #8
	b.ls	LBB55_34
LBB55_35:                               ; %.preheader
	cmp	x26, x24
	b.hi	LBB55_37
LBB55_36:                               ; %.lr.ph47
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [x26], #8
	cmp	x26, x24
	str	x8, [x19], #8
	b.ls	LBB55_36
LBB55_37:                               ; %common.ret1
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB55_38:
	.cfi_restore_state
	ldr	x24, [sp, #16]                  ; 8-byte Folded Reload
	cmp	x23, x27
	b.ls	LBB55_34
	b	LBB55_35
LBB55_39:
	mov	x0, x19
	mov	x1, x23
	mov	x2, x25
	mov	x3, x27
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.parity_merge__anon_16495
Lfunc_end55:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.flux_partition__anon_14863
l_sort.flux_partition__anon_14863:      ; @sort.flux_partition__anon_14863
Lfunc_begin56:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #1024
	.cfi_def_cfa_offset 1120
	add	x8, sp, #160
	mov	x19, x6
	orr	x9, x8, #0x8
	lsr	x10, x8, #4
	mov	x20, x5
	mov	x24, x4
	mov	x25, x2
	mov	x21, x1
	str	x9, [sp, #112]                  ; 8-byte Folded Spill
	add	x9, x8, #16
	mov	x22, x0
	mov	x28, xzr
	stp	x1, x0, [sp, #136]              ; 16-byte Folded Spill
	stp	x9, x10, [sp, #40]              ; 16-byte Folded Spill
	add	x10, x8, #32
	add	x9, x8, #40
	add	x8, x8, #48
	stp	x9, x10, [sp, #24]              ; 16-byte Folded Spill
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
LBB56_1:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB56_4 Depth 2
                                        ;     Child Loop BB56_6 Depth 2
                                        ;     Child Loop BB56_16 Depth 2
                                        ;     Child Loop BB56_23 Depth 2
	sub	x23, x3, #8
	cmp	x24, #2049
	stp	x3, x28, [sp, #120]             ; 16-byte Folded Spill
	b.hs	LBB56_3
; %bb.2:                                ;   in Loop: Header=BB56_1 Depth=1
	and	w8, w24, #0xffff
	mov	w9, #58255
	ldr	x1, [x25]
	mov	x0, x19
	mul	w8, w8, w9
	lsr	w8, w8, #19
	ubfiz	x8, x8, #3, #32
	add	x9, x25, x8
	add	x10, x9, x8
	add	x11, x10, x8
	ldr	x2, [x9]
	add	x9, x11, x8
	ldr	x26, [x10]
	add	x10, x9, x8
	ldr	x21, [x11]
	add	x11, x10, x8
	ldr	x13, [x9]
	add	x9, x11, x8
	ldr	x12, [x10]
	stp	x1, x2, [sp, #160]
	ldr	x10, [x11]
	stp	x26, x21, [sp, #176]
	stp	x13, x12, [sp, #192]
	str	x10, [sp, #208]
	str	x10, [sp, #80]                  ; 8-byte Folded Spill
	ldr	x10, [x9]
	stp	x13, x12, [sp, #56]             ; 16-byte Folded Spill
	str	x10, [sp, #216]
	ldr	x8, [x9, x8]
	str	x10, [sp, #72]                  ; 8-byte Folded Spill
	str	x8, [sp, #96]                   ; 8-byte Folded Spill
	blr	x20
	and	w8, w0, #0xff
	add	x22, sp, #160
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	cset	w9, ne
	mov	x1, x26
	mov	x2, x21
	orr	x8, x22, x8, lsl #3
	orr	x9, x22, x9, lsl #3
	ldr	x27, [x8]
	ldr	x28, [x9]
	stp	x27, x28, [sp, #160]
	blr	x20
	and	w8, w0, #0xff
	str	x24, [sp, #104]                 ; 8-byte Folded Spill
	cmp	w8, #1
	ldr	x24, [sp, #40]                  ; 8-byte Folded Reload
	cset	w8, eq
	cset	w9, ne
	mov	x0, x19
	mov	x1, x27
	ldr	x2, [x24, w8, uxtw #3]
	ldr	x21, [x24, w9, uxtw #3]
	stp	x2, x21, [sp, #176]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	mov	x1, x28
	cset	w8, ne
	mov	x2, x21
	ubfiz	x8, x8, #4, #32
	ldr	x8, [x22, x8]
	str	x8, [sp, #88]                   ; 8-byte Folded Spill
	str	x8, [sp, #176]
	blr	x20
	and	w8, w0, #0xff
	ldr	x9, [sp, #112]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	ubfiz	x8, x8, #4, #32
	ldp	x1, x2, [sp, #56]               ; 16-byte Folded Reload
	ldr	x22, [x9, x8]
	str	x22, [sp, #168]
	blr	x20
	and	w8, w0, #0xff
	ldr	x28, [sp, #32]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	cset	w9, ne
	ldp	x2, x1, [sp, #72]               ; 16-byte Folded Reload
	ldr	x21, [x28, w8, uxtw #3]
	ldr	x27, [x28, w9, uxtw #3]
	stp	x21, x27, [sp, #192]
	blr	x20
	and	w8, w0, #0xff
	ldr	x10, [sp, #16]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	cset	w9, ne
	mov	x1, x21
	ldr	x2, [x10, w8, uxtw #3]
	ldr	x26, [x10, w9, uxtw #3]
	stp	x2, x26, [sp, #208]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	mov	x1, x27
	cset	w8, ne
	mov	x2, x26
	ubfiz	x8, x8, #4, #32
	ldr	x28, [x28, x8]
	str	x28, [sp, #208]
	blr	x20
	and	w8, w0, #0xff
	ldr	x9, [sp, #24]                   ; 8-byte Folded Reload
	cmp	w8, #1
	ldr	x27, [sp, #96]                  ; 8-byte Folded Reload
	cset	w8, eq
	mov	x0, x19
	ubfiz	x8, x8, #4, #32
	mov	x2, x22
	str	x27, [sp, #184]
	ldr	x1, [x9, x8]
	str	x1, [sp, #160]
	blr	x20
	and	w8, w0, #0xff
	add	x10, sp, #160
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	cset	w9, ne
	ldr	x1, [sp, #88]                   ; 8-byte Folded Reload
	mov	x2, x27
	orr	x8, x10, x8, lsl #3
	orr	x9, x10, x9, lsl #3
	ldr	x21, [x8]
	ldr	x26, [x9]
	stp	x21, x26, [sp, #160]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	mov	x1, x21
	cset	w8, eq
	cset	w9, ne
	ldr	x2, [x24, w8, uxtw #3]
	ldr	x27, [x24, w9, uxtw #3]
	ldr	x24, [sp, #104]                 ; 8-byte Folded Reload
	stp	x2, x27, [sp, #176]
	blr	x20
	and	w8, w0, #0xff
	add	x9, sp, #160
	cmp	w8, #1
	mov	x0, x19
	cset	w8, ne
	mov	x1, x26
	ubfiz	x8, x8, #4, #32
	mov	x2, x27
	ldr	x21, [x9, x8]
	str	x21, [sp, #176]
	blr	x20
	and	w8, w0, #0xff
	ldr	x9, [sp, #112]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x19
	cset	w8, eq
	mov	x1, x28
	ubfiz	x8, x8, #4, #32
	ldr	x26, [x9, x8]
	mov	x2, x26
	stp	x28, x26, [sp, #160]
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x19
	mov	x1, x28
	mov	x2, x21
	cmp	w8, #1
	cset	w27, eq
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x19
	mov	x1, x26
	mov	x2, x21
	cmp	w8, #1
	cset	w28, ne
	blr	x20
	and	w9, w0, #0xff
	eor	w8, w27, w28
	cmp	w9, #1
	cset	w9, eq
	eor	w9, w27, w9
	add	x8, x9, x8
	add	x9, sp, #160
	ldp	x22, x28, [sp, #136]            ; 16-byte Folded Reload
	ldr	x2, [x9, x8, lsl #3]
	str	x2, [x23]
	b	LBB56_18
LBB56_3:                                ;   in Loop: Header=BB56_1 Depth=1
	mov	w8, #32
LBB56_4:                                ;   Parent Loop BB56_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x27, x8
	mul	x8, x8, x8
	mul	x9, x8, x27
	lsl	x8, x27, #1
	cmp	x9, x24
	b.lo	LBB56_4
; %bb.5:                                ;   in Loop: Header=BB56_1 Depth=1
	udiv	x12, x24, x27
	ldr	x10, [sp, #48]                  ; 8-byte Folded Reload
	cmp	x25, x22
	mov	x8, xzr
	csel	x28, x21, x22, eq
	cmp	x27, #1
	csinc	x11, x27, xzr, hi
	udiv	x9, x10, x12
	str	x12, [sp, #160]
	msub	x9, x9, x12, x10
	lsl	x10, x12, #3
	add	x9, x25, x9, lsl #3
LBB56_6:                                ;   Parent Loop BB56_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x12, [x9]
	add	x9, x9, x10
	str	x12, [x28, x8, lsl #3]
	add	x8, x8, #1
	cmp	x11, x8
	b.ne	LBB56_6
; %bb.7:                                ;   in Loop: Header=BB56_1 Depth=1
	lsl	x22, x27, #3
	lsr	x21, x27, #1
	add	x26, x28, x22
	mov	x0, x28
	mov	x1, x21
	cmp	x27, #192
	b.hs	LBB56_9
; %bb.8:                                ;   in Loop: Header=BB56_1 Depth=1
	mov	x2, x26
	mov	x3, x20
	mov	x4, x19
	bl	l_sort.tail_swap__anon_14848
	mov	x2, x26
	lsl	x26, x27, #2
	add	x27, x28, x26
	mov	x1, x21
	mov	x0, x27
	mov	x3, x20
	mov	x4, x19
	bl	l_sort.tail_swap__anon_14848
	b	LBB56_13
LBB56_9:                                ;   in Loop: Header=BB56_1 Depth=1
	mov	x2, x20
	mov	x3, x19
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB56_11
; %bb.10:                               ;   in Loop: Header=BB56_1 Depth=1
	mov	x0, x28
	mov	x1, x21
	mov	x2, x26
	mov	x3, x21
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x28
	mov	x1, x21
	mov	x2, x26
	mov	x3, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.rotate_merge__anon_14851
LBB56_11:                               ;   in Loop: Header=BB56_1 Depth=1
	str	x26, [sp, #104]                 ; 8-byte Folded Spill
	lsl	x26, x27, #2
	add	x27, x28, x26
	mov	x1, x21
	mov	x0, x27
	mov	x2, x20
	mov	x3, x19
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB56_13
; %bb.12:                               ;   in Loop: Header=BB56_1 Depth=1
	mov	x0, x27
	mov	x1, x21
	ldr	x2, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x21
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x27
	mov	x1, x21
	ldr	x2, [sp, #104]                  ; 8-byte Folded Reload
	mov	x3, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.rotate_merge__anon_14851
LBB56_13:                               ; %sort.quadsort_swap__anon_14864.exit34.i
                                        ;   in Loop: Header=BB56_1 Depth=1
	add	x8, x22, x28
	ldr	x2, [x28]
	mov	x0, x19
	ldur	x1, [x8, #-8]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB56_15
; %bb.14:                               ;   in Loop: Header=BB56_1 Depth=1
	str	wzr, [sp, #104]                 ; 4-byte Folded Spill
	b	LBB56_16
LBB56_15:                               ;   in Loop: Header=BB56_1 Depth=1
	add	x8, x26, x28
	ldr	x2, [x28]
	mov	x0, x19
	ldur	x1, [x8, #-8]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	cset	w8, ne
	str	w8, [sp, #104]                  ; 4-byte Folded Spill
LBB56_16:                               ; %.lr.ph.i.i
                                        ;   Parent Loop BB56_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x1, [x28]
	mov	x0, x19
	ldr	x2, [x27]
	lsr	x26, x21, #1
	blr	x20
	and	w9, w0, #0xff
	lsl	x8, x26, #3
	cmp	w9, #1
	csel	x9, x8, xzr, eq
	csel	x8, xzr, x8, eq
	add	x27, x27, x9
	add	x28, x28, x8
	cmp	x21, #4
	mov	x21, x26
	b.hs	LBB56_16
; %bb.17:                               ; %sort.median_of_cube_root__anon_16538.exit
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x1, [x28]
	mov	x0, x19
	ldr	x2, [x27]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x28, x27, eq
	ldp	x22, x28, [sp, #136]            ; 16-byte Folded Reload
	ldr	x2, [x8]
	ldr	w8, [sp, #104]                  ; 4-byte Folded Reload
	str	x2, [x23]
	cbnz	w8, LBB56_50
LBB56_18:                               ;   in Loop: Header=BB56_1 Depth=1
	ldr	x8, [sp, #128]                  ; 8-byte Folded Reload
	cbz	x8, LBB56_20
; %bb.19:                               ;   in Loop: Header=BB56_1 Depth=1
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	mov	x0, x19
	ldr	x1, [x8]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB56_49
LBB56_20:                               ; %.critedge
                                        ;   in Loop: Header=BB56_1 Depth=1
	cmp	x24, #8
	b.hs	LBB56_22
; %bb.21:                               ;   in Loop: Header=BB56_1 Depth=1
	mov	x21, xzr
	mov	x26, x28
	mov	x28, x22
	b	LBB56_24
LBB56_22:                               ; %.cont82.i.preheader
                                        ;   in Loop: Header=BB56_1 Depth=1
	mov	x21, xzr
	mov	x26, x28
	mov	x28, x22
	mov	w27, #8
LBB56_23:                               ; %.cont82.i
                                        ;   Parent Loop BB56_1 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x1, [x25]
	mov	x0, x19
	ldr	x2, [x23]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x28, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x25, #8]
	csel	x28, x9, x28, eq
	ldr	x2, [x23]
	csel	x26, x26, x9, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25, #8]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x28, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x25, #16]
	csel	x28, x9, x28, eq
	ldr	x2, [x23]
	csel	x26, x26, x9, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25, #16]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x28, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x25, #24]
	csel	x28, x9, x28, eq
	ldr	x2, [x23]
	csel	x26, x26, x9, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25, #24]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x28, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x25, #32]
	csel	x28, x9, x28, eq
	ldr	x2, [x23]
	csel	x26, x26, x9, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25, #32]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x28, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x25, #40]
	csel	x28, x9, x28, eq
	ldr	x2, [x23]
	csel	x26, x26, x9, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25, #40]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x28, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x25, #48]
	csel	x28, x9, x28, eq
	ldr	x2, [x23]
	csel	x26, x26, x9, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25, #48]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x28, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x25, #56]
	csel	x28, x9, x28, eq
	ldr	x2, [x23]
	csel	x26, x26, x9, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25, #56]
	cmp	w9, #1
	add	x25, x25, #64
	csel	x9, x28, x26, eq
	str	x8, [x9], #8
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	csel	x28, x9, x28, eq
	csel	x26, x26, x9, eq
	cmp	x28, x22
	ccmp	x26, x8, #4, ne
	csel	x21, x27, x21, eq
	add	x27, x27, #8
	cmp	x27, x24
	b.ls	LBB56_23
LBB56_24:                               ; %._crit_edge.i
                                        ;   in Loop: Header=BB56_1 Depth=1
	ands	x27, x24, #0x7
	b.eq	LBB56_32
; %bb.25:                               ; %.cont.i
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x1, [x25]
	mov	x0, x19
	ldr	x2, [x23]
	blr	x20
	and	w9, w0, #0xff
	ldr	x10, [x25]
	cmp	w9, #1
	csel	x8, x28, x26, eq
	str	x10, [x8], #8
	csel	x26, x26, x8, eq
	cmp	x27, #1
	b.eq	LBB56_32
; %bb.26:                               ; %.cont.i.1
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x1, [x25, #8]
	mov	x0, x19
	ldr	x2, [x23]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x10, [x25, #8]
	cmp	w9, #1
	csel	x8, x28, x26, eq
	str	x10, [x8], #8
	csel	x26, x26, x8, eq
	cmp	x27, #2
	b.eq	LBB56_32
; %bb.27:                               ; %.cont.i.2
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x1, [x25, #16]
	mov	x0, x19
	ldr	x2, [x23]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x10, [x25, #16]
	cmp	w9, #1
	csel	x8, x28, x26, eq
	str	x10, [x8], #8
	csel	x26, x26, x8, eq
	cmp	x27, #3
	b.eq	LBB56_32
; %bb.28:                               ; %.cont.i.3
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x1, [x25, #24]
	mov	x0, x19
	ldr	x2, [x23]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x10, [x25, #24]
	cmp	w9, #1
	csel	x8, x28, x26, eq
	str	x10, [x8], #8
	csel	x26, x26, x8, eq
	cmp	x27, #4
	b.eq	LBB56_32
; %bb.29:                               ; %.cont.i.4
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x1, [x25, #32]
	mov	x0, x19
	ldr	x2, [x23]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x10, [x25, #32]
	cmp	w9, #1
	csel	x8, x28, x26, eq
	str	x10, [x8], #8
	csel	x26, x26, x8, eq
	cmp	x27, #5
	b.eq	LBB56_32
; %bb.30:                               ; %.cont.i.5
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x1, [x25, #40]
	mov	x0, x19
	ldr	x2, [x23]
	cmp	w9, #1
	csel	x28, x8, x28, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x10, [x25, #40]
	cmp	w9, #1
	csel	x8, x28, x26, eq
	str	x10, [x8], #8
	csel	x26, x26, x8, eq
	cmp	x27, #6
	b.eq	LBB56_32
; %bb.31:                               ; %.cont.i.6
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x1, [x25, #48]
	mov	x0, x19
	ldr	x2, [x23]
	cmp	w9, #1
	csel	x27, x8, x28, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x25, #48]
	cmp	w9, #1
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
LBB56_32:                               ; %._crit_edge14.i
                                        ;   in Loop: Header=BB56_1 Depth=1
	ldr	x22, [sp, #144]                 ; 8-byte Folded Reload
	cmp	x21, x24, lsr #2
	sub	x27, x26, x22
	lsr	x28, x27, #3
	sub	x26, x24, x28
	b.ls	LBB56_34
; %bb.33:                               ; %._crit_edge14.i
                                        ;   in Loop: Header=BB56_1 Depth=1
	cmp	x24, x28
	b.ne	LBB56_47
LBB56_34:                               ; %sort.flux_default_partition__anon_16540.exit
                                        ;   in Loop: Header=BB56_1 Depth=1
	cmp	x26, #97
	b.lo	LBB56_37
; %bb.35:                               ; %sort.flux_default_partition__anon_16540.exit
                                        ;   in Loop: Header=BB56_1 Depth=1
	lsr	x8, x26, #5
	cmp	x28, x8
	b.ls	LBB56_37
; %bb.36:                               ;   in Loop: Header=BB56_1 Depth=1
	ldr	x21, [sp, #136]                 ; 8-byte Folded Reload
	and	x8, x27, #0xfffffffffffffff8
	add	x0, x22, x8
	mov	x3, x23
	mov	x4, x26
	mov	x5, x20
	mov	x1, x21
	mov	x2, x21
	mov	x6, x19
	bl	l_sort.flux_partition__anon_14863
	b	LBB56_43
LBB56_37:                               ;   in Loop: Header=BB56_1 Depth=1
	ldr	x21, [sp, #136]                 ; 8-byte Folded Reload
	cmp	x27, #8
	b.lo	LBB56_67
; %bb.38:                               ;   in Loop: Header=BB56_1 Depth=1
	cmp	x24, x28
	b.eq	LBB56_60
; %bb.39:                               ;   in Loop: Header=BB56_1 Depth=1
	and	x8, x27, #0xfffffffffffffff8
	lsl	x2, x26, #3
	add	x24, x22, x8
	mov	x1, x21
	mov	x0, x24
	bl	_memcpy
	cmp	x26, #95
	b.hi	LBB56_41
; %bb.40:                               ;   in Loop: Header=BB56_1 Depth=1
	mov	x0, x24
	mov	x1, x26
	mov	x2, x21
	mov	x3, x20
	mov	x4, x19
	bl	l_sort.tail_swap__anon_14848
	b	LBB56_43
LBB56_41:                               ;   in Loop: Header=BB56_1 Depth=1
	mov	x0, x24
	mov	x1, x26
	mov	x2, x20
	mov	x3, x19
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB56_43
; %bb.42:                               ;   in Loop: Header=BB56_1 Depth=1
	mov	x0, x24
	mov	x1, x26
	mov	x2, x21
	mov	x3, x26
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x24
	mov	x1, x26
	mov	x2, x21
	mov	x3, x26
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.rotate_merge__anon_14851
LBB56_43:                               ; %sort.quadsort_swap__anon_14864.exit63
                                        ;   in Loop: Header=BB56_1 Depth=1
	cmp	x27, #776
	b.lo	LBB56_45
; %bb.44:                               ; %sort.quadsort_swap__anon_14864.exit63
                                        ;   in Loop: Header=BB56_1 Depth=1
	mov	x24, x28
	mov	x25, x22
	mov	x3, x23
	lsr	x8, x27, #8
	cmp	x26, x8
	b.hi	LBB56_1
LBB56_45:
	cmp	x27, #775
	b.ls	LBB56_55
; %bb.46:
	mov	x0, x22
	mov	x1, x21
	mov	x2, x22
	mov	x3, x23
	mov	x4, x28
	b	LBB56_62
LBB56_47:
	ldr	x21, [sp, #136]                 ; 8-byte Folded Reload
	and	x8, x27, #0xfffffffffffffff8
	add	x23, x22, x8
	lsl	x2, x26, #3
	mov	x0, x23
	mov	x1, x21
	bl	_memcpy
	cmp	x26, #95
	b.hi	LBB56_53
; %bb.48:
	mov	x0, x23
	mov	x1, x26
	mov	x2, x21
	mov	x3, x20
	mov	x4, x19
	bl	l_sort.tail_swap__anon_14848
	b	LBB56_55
LBB56_49:
	mov	x0, x28
	mov	x1, x22
	mov	x2, x28
	b	LBB56_61
LBB56_50:
	cmp	x25, x22
	b.eq	LBB56_63
; %bb.51:
	cmp	x24, #95
	b.hi	LBB56_64
LBB56_52:
	mov	x0, x28
	mov	x1, x24
	mov	x2, x22
	b	LBB56_57
LBB56_53:
	mov	x0, x23
	mov	x1, x26
	mov	x2, x20
	mov	x3, x19
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB56_55
; %bb.54:
	mov	x0, x23
	mov	x1, x26
	mov	x2, x21
	mov	x3, x26
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x23
	mov	x1, x26
	mov	x2, x21
	mov	x3, x26
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.rotate_merge__anon_14851
LBB56_55:                               ; %sort.quadsort_swap__anon_14864.exit.i
	cmp	x27, #767
	b.hi	LBB56_58
; %bb.56:
	mov	x0, x22
	mov	x1, x28
	mov	x2, x21
LBB56_57:                               ; %common.ret
	mov	x3, x20
	mov	x4, x19
	bl	l_sort.tail_swap__anon_14848
	b	LBB56_67
LBB56_58:
	mov	x0, x22
	mov	x1, x28
	mov	x2, x20
	mov	x3, x19
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB56_67
; %bb.59:
	mov	x0, x22
	mov	x1, x28
	mov	x2, x21
	mov	x3, x28
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x22
	mov	x1, x28
	mov	x2, x21
	mov	x3, x28
	b	LBB56_66
LBB56_60:
	mov	x0, x22
	mov	x1, x21
	mov	x2, x22
LBB56_61:                               ; %common.ret
	mov	x3, x23
	mov	x4, x24
LBB56_62:                               ; %common.ret
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.flux_reverse_partition__anon_16539
	b	LBB56_67
LBB56_63:
	lsl	x2, x24, #3
	mov	x0, x28
	mov	x1, x22
	bl	_memcpy
	cmp	x24, #95
	b.ls	LBB56_52
LBB56_64:
	mov	x0, x28
	mov	x1, x24
	mov	x2, x20
	mov	x3, x19
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB56_67
; %bb.65:
	mov	x0, x28
	mov	x1, x24
	mov	x2, x22
	mov	x3, x24
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x28
	mov	x1, x24
	mov	x2, x22
	mov	x3, x24
LBB56_66:                               ; %common.ret
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.rotate_merge__anon_14851
LBB56_67:                               ; %common.ret
	add	sp, sp, #1024
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end56:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.cross_merge__anon_14865
l_sort.cross_merge__anon_14865:         ; @sort.cross_merge__anon_14865
Lfunc_begin57:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x28, x27, [sp, #16]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	add	x25, x1, x2, lsl #3
	mov	x20, x5
	sub	x28, x25, #8
	mov	x21, x4
	add	x8, x28, x3, lsl #3
	mov	x24, x2
	mov	x22, x1
	mov	x27, x3
	mov	x19, x0
	str	x8, [sp, #8]                    ; 8-byte Folded Spill
	add	x8, x2, #1
	cmp	x8, x3
	b.lo	LBB57_7
; %bb.1:
	add	x8, x27, #1
	cmp	x8, x24
	b.lo	LBB57_7
; %bb.2:
	cmp	x24, #31
	b.ls	LBB57_7
; %bb.3:
	ldr	x1, [x22, #120]
	mov	x0, x20
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB57_7
; %bb.4:
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x25, #120]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB57_7
; %bb.5:
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x20
	ldr	x1, [x28]
	ldur	x2, [x8, #-120]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB57_7
; %bb.6:
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x20
	ldur	x1, [x28, #-120]
	ldr	x2, [x8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB57_38
LBB57_7:                                ; %.critedge
	add	x8, x27, x24
	add	x8, x19, x8, lsl #3
	sub	x27, x8, #8
LBB57_8:                                ; %.loopexit
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB57_9 Depth 2
                                        ;     Child Loop BB57_12 Depth 2
                                        ;     Child Loop BB57_17 Depth 2
                                        ;     Child Loop BB57_21 Depth 2
	sub	x24, x28, x22
	cmp	x24, #65
	b.lt	LBB57_27
LBB57_9:                                ; %.preheader12
                                        ;   Parent Loop BB57_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x1, [x22, #56]
	mov	x0, x20
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB57_11
; %bb.10:                               ;   in Loop: Header=BB57_9 Depth=2
	ldr	x8, [x22]
	sub	x24, x24, #64
	cmp	x24, #65
	str	x8, [x19]
	ldr	x8, [x22, #8]
	str	x8, [x19, #8]
	ldr	x8, [x22, #16]
	str	x8, [x19, #16]
	ldr	x8, [x22, #24]
	str	x8, [x19, #24]
	ldr	x8, [x22, #32]
	str	x8, [x19, #32]
	ldr	x8, [x22, #40]
	str	x8, [x19, #40]
	ldr	x8, [x22, #48]
	str	x8, [x19, #48]
	ldr	x8, [x22, #56]
	add	x22, x22, #64
	str	x8, [x19, #56]
	add	x19, x19, #64
	b.hs	LBB57_9
	b	LBB57_8
LBB57_11:                               ; %.preheader9.loopexit
                                        ;   in Loop: Header=BB57_8 Depth=1
	mov	x23, x28
	mov	x26, x27
	mov	x28, xzr
LBB57_12:                               ; %.preheader9
                                        ;   Parent Loop BB57_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x27, x23, x28
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x20
	ldur	x1, [x27, #-56]
	ldr	x2, [x8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB57_15
; %bb.13:                               ;   in Loop: Header=BB57_12 Depth=2
	ldr	x8, [x27]
	add	x9, x26, x28
	sub	x28, x28, #64
	add	x10, x24, x28
	str	x8, [x9]
	cmp	x10, #65
	ldur	x8, [x27, #-8]
	stur	x8, [x9, #-8]
	ldur	x8, [x27, #-16]
	stur	x8, [x9, #-16]
	ldur	x8, [x27, #-24]
	stur	x8, [x9, #-24]
	ldur	x8, [x27, #-32]
	stur	x8, [x9, #-32]
	ldur	x8, [x27, #-40]
	stur	x8, [x9, #-40]
	ldur	x8, [x27, #-48]
	stur	x8, [x9, #-48]
	ldur	x8, [x27, #-56]
	stur	x8, [x9, #-56]
	b.hs	LBB57_12
; %bb.14:                               ; %.loopexit.outer.loopexit
                                        ;   in Loop: Header=BB57_8 Depth=1
	mov	x27, x26
	add	x27, x26, x28
	add	x28, x23, x28
	b	LBB57_8
LBB57_15:                               ; %.loopexit10.loopexit
                                        ;   in Loop: Header=BB57_8 Depth=1
	add	x26, x26, x28
	mov	x28, x27
LBB57_16:                               ; %.loopexit10
                                        ;   in Loop: Header=BB57_8 Depth=1
	ldr	x27, [sp, #8]                   ; 8-byte Folded Reload
	sub	x24, x27, x25
	cmp	x24, #65
	b.lt	LBB57_28
LBB57_17:                               ; %.preheader7
                                        ;   Parent Loop BB57_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x25, #56]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB57_20
; %bb.18:                               ;   in Loop: Header=BB57_17 Depth=2
	ldr	x8, [x25]
	sub	x24, x24, #64
	cmp	x24, #65
	str	x8, [x19]
	ldr	x8, [x25, #8]
	str	x8, [x19, #8]
	ldr	x8, [x25, #16]
	str	x8, [x19, #16]
	ldr	x8, [x25, #24]
	str	x8, [x19, #24]
	ldr	x8, [x25, #32]
	str	x8, [x19, #32]
	ldr	x8, [x25, #40]
	str	x8, [x19, #40]
	ldr	x8, [x25, #48]
	str	x8, [x19, #48]
	ldr	x8, [x25, #56]
	add	x25, x25, #64
	str	x8, [x19, #56]
	add	x19, x19, #64
	b.hs	LBB57_17
; %bb.19:                               ;   in Loop: Header=BB57_8 Depth=1
	mov	x27, x26
	b	LBB57_8
LBB57_20:                               ; %.preheader4.loopexit
                                        ;   in Loop: Header=BB57_8 Depth=1
	mov	x23, x28
	mov	x28, xzr
LBB57_21:                               ; %.preheader4
                                        ;   Parent Loop BB57_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x27, x27, x28
	ldr	x1, [x23]
	mov	x0, x20
	ldur	x2, [x27, #-56]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB57_24
; %bb.22:                               ;   in Loop: Header=BB57_21 Depth=2
	ldr	x8, [x27]
	add	x9, x26, x28
	sub	x28, x28, #64
	add	x10, x24, x28
	str	x8, [x9]
	cmp	x10, #65
	ldur	x8, [x27, #-8]
	stur	x8, [x9, #-8]
	ldur	x8, [x27, #-16]
	stur	x8, [x9, #-16]
	ldur	x8, [x27, #-24]
	stur	x8, [x9, #-24]
	ldur	x8, [x27, #-32]
	stur	x8, [x9, #-32]
	ldur	x8, [x27, #-40]
	stur	x8, [x9, #-40]
	ldur	x8, [x27, #-48]
	stur	x8, [x9, #-48]
	ldur	x8, [x27, #-56]
	ldr	x27, [sp, #8]                   ; 8-byte Folded Reload
	stur	x8, [x9, #-56]
	b.hs	LBB57_21
; %bb.23:                               ; %.loopexit.outer.outer.loopexit
                                        ;   in Loop: Header=BB57_8 Depth=1
	mov	x8, x27
	mov	x27, x26
	add	x8, x8, x28
	add	x27, x26, x28
	mov	x28, x23
	str	x8, [sp, #8]                    ; 8-byte Folded Spill
	b	LBB57_8
LBB57_24:                               ; %.loopexit5.loopexit
                                        ;   in Loop: Header=BB57_8 Depth=1
	add	x26, x26, x28
	str	x27, [sp, #8]                   ; 8-byte Folded Spill
	mov	x27, x26
	mov	x28, x23
LBB57_25:                               ; %.loopexit5
                                        ;   in Loop: Header=BB57_8 Depth=1
	sub	x8, x27, x19
	cmp	x8, #128
	b.lo	LBB57_29
; %bb.26:                               ; %.cont46.preheader
                                        ;   in Loop: Header=BB57_8 Depth=1
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	ldr	x23, [sp, #8]                   ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x20
	csel	x8, x25, x22, eq
	ldr	x9, [x8], #8
	csel	x24, x8, x25, eq
	csel	x22, x22, x8, eq
	str	x9, [x19]
	ldr	x1, [x28]
	ldr	x2, [x23]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x28, x23, eq
	ldr	x9, [x8], #-8
	csel	x25, x23, x8, eq
	csel	x23, x8, x28, eq
	str	x9, [x27]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x24, x8, x24, eq
	csel	x22, x22, x8, eq
	str	x9, [x19, #8]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x25, eq
	ldr	x9, [x8], #-8
	csel	x25, x25, x8, eq
	csel	x23, x8, x23, eq
	stur	x9, [x27, #-8]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x24, x8, x24, eq
	csel	x22, x22, x8, eq
	str	x9, [x19, #16]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x25, eq
	ldr	x9, [x8], #-8
	csel	x25, x25, x8, eq
	csel	x23, x8, x23, eq
	stur	x9, [x27, #-16]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x24, x8, x24, eq
	csel	x22, x22, x8, eq
	str	x9, [x19, #24]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x25, eq
	ldr	x9, [x8], #-8
	csel	x25, x25, x8, eq
	csel	x23, x8, x23, eq
	stur	x9, [x27, #-24]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x24, x8, x24, eq
	csel	x22, x22, x8, eq
	str	x9, [x19, #32]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x25, eq
	ldr	x9, [x8], #-8
	csel	x25, x25, x8, eq
	csel	x23, x8, x23, eq
	stur	x9, [x27, #-32]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x24, x8, x24, eq
	csel	x22, x22, x8, eq
	str	x9, [x19, #40]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x25, eq
	ldr	x9, [x8], #-8
	csel	x25, x25, x8, eq
	csel	x23, x8, x23, eq
	stur	x9, [x27, #-40]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x24, x8, x24, eq
	csel	x22, x22, x8, eq
	str	x9, [x19, #48]
	ldr	x1, [x23]
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x25, eq
	ldr	x9, [x8], #-8
	csel	x26, x25, x8, eq
	csel	x28, x8, x23, eq
	stur	x9, [x27, #-48]
	ldr	x1, [x22]
	ldr	x2, [x24]
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x25, x8, x24, eq
	csel	x22, x22, x8, eq
	str	x9, [x19, #56]
	add	x19, x19, #64
	ldr	x1, [x28]
	ldr	x2, [x26]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x28, x26, eq
	ldr	x9, [x8], #-8
	csel	x10, x26, x8, eq
	csel	x28, x8, x28, eq
	stur	x9, [x27, #-56]
	sub	x27, x27, #64
	str	x10, [sp, #8]                   ; 8-byte Folded Spill
	b	LBB57_8
LBB57_27:                               ;   in Loop: Header=BB57_8 Depth=1
	mov	x26, x27
	b	LBB57_16
LBB57_28:                               ;   in Loop: Header=BB57_8 Depth=1
	mov	x27, x26
	b	LBB57_25
LBB57_29:                               ; %.preheader2
	cmp	x22, x28
	b.hi	LBB57_37
; %bb.30:                               ; %.preheader2
	ldr	x23, [sp, #8]                   ; 8-byte Folded Reload
	cmp	x25, x23
	b.hi	LBB57_32
LBB57_31:                               ; %.cont
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x25, x22, eq
	ldr	x9, [x8], #8
	csel	x22, x22, x8, eq
	csel	x25, x8, x25, eq
	cmp	x22, x28
	ccmp	x25, x23, #2, ls
	str	x9, [x19], #8
	b.ls	LBB57_31
LBB57_32:                               ; %.preheader1
	cmp	x22, x28
	b.hi	LBB57_34
LBB57_33:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [x22], #8
	cmp	x22, x28
	str	x8, [x19], #8
	b.ls	LBB57_33
LBB57_34:                               ; %.preheader
	cmp	x25, x23
	b.hi	LBB57_36
LBB57_35:                               ; %.lr.ph48
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [x25], #8
	cmp	x25, x23
	str	x8, [x19], #8
	b.ls	LBB57_35
LBB57_36:                               ; %common.ret1
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB57_37:
	.cfi_restore_state
	ldr	x23, [sp, #8]                   ; 8-byte Folded Reload
	cmp	x22, x28
	b.ls	LBB57_33
	b	LBB57_34
LBB57_38:
	mov	x0, x19
	mov	x1, x22
	mov	x2, x24
	mov	x3, x27
	mov	x4, x21
	mov	x5, x20
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.parity_merge__anon_16505
Lfunc_end57:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.parity_merge__anon_16476
l_sort.parity_merge__anon_16476:        ; @sort.parity_merge__anon_16476
Lfunc_begin58:
	.cfi_startproc
; %bb.0:                                ; %._crit_edge
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x28, x27, [sp, #48]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	madd	x27, x6, x2, x1
	sub	x28, x2, #1
	add	x8, x28, x3
	mov	x25, x2
	sub	x21, x27, x6
	mov	x26, x1
	madd	x22, x6, x3, x21
	mov	x19, x0
	madd	x23, x8, x6, x0
	ldr	x8, [sp, #144]
	cmp	x2, x3
	stp	x6, x7, [sp, #32]               ; 16-byte Folded Spill
	b.hs	LBB58_2
; %bb.1:                                ; %.cont16
	mov	x0, x5
	mov	w1, #1
	mov	x24, x5
	mov	x20, x4
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	blr	x8
	mov	x0, x24
	mov	x1, x26
	mov	x2, x27
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x19
	cmp	w8, #1
	ldp	x8, x2, [sp, #32]               ; 16-byte Folded Reload
	csel	x1, x27, x26, eq
	add	x8, x1, x8
	csel	x27, x8, x27, eq
	csel	x26, x26, x8, eq
	blr	x2
	ldp	x8, x9, [sp, #24]               ; 16-byte Folded Reload
	add	x19, x19, x9
	b	LBB58_3
LBB58_2:
	mov	x24, x5
	mov	x20, x4
LBB58_3:                                ; %.cont25
	lsl	x1, x25, #1
	mov	x0, x24
	blr	x8
	mov	x0, x24
	mov	x1, x26
	mov	x2, x27
	str	x24, [sp, #8]                   ; 8-byte Folded Spill
	str	x20, [sp, #24]                  ; 8-byte Folded Spill
	blr	x20
	and	w20, w0, #0xff
	mov	x0, x19
	cmp	w20, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x25, x27, x26, eq
	mov	x1, x25
	blr	x2
	cbz	x28, LBB58_6
; %bb.4:                                ; %.cont.preheader
	ldr	x11, [sp, #32]                  ; 8-byte Folded Reload
	cmp	w20, #1
	ldr	x24, [sp, #8]                   ; 8-byte Folded Reload
	ldr	x20, [sp, #32]                  ; 8-byte Folded Reload
	add	x8, x25, x11
	neg	x10, x11
	csel	x26, x26, x8, eq
	csel	x27, x8, x27, eq
	add	x25, x19, x11
	str	x10, [sp, #16]                  ; 8-byte Folded Spill
LBB58_5:                                ; %.cont
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x24
	mov	x1, x26
	mov	x2, x27
	ldr	x19, [sp, #24]                  ; 8-byte Folded Reload
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x27, x26, eq
	add	x8, x1, x20
	csel	x27, x8, x27, eq
	csel	x26, x26, x8, eq
	blr	x2
	mov	x0, x24
	mov	x1, x21
	mov	x2, x22
	blr	x19
	and	w8, w0, #0xff
	ldr	x19, [sp, #16]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x23
	csel	x1, x21, x22, eq
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	add	x8, x1, x19
	csel	x22, x22, x8, eq
	csel	x21, x8, x21, eq
	blr	x2
	add	x23, x23, x19
	add	x25, x25, x20
	subs	x28, x28, #1
	b.ne	LBB58_5
	b	LBB58_7
LBB58_6:
	ldr	x24, [sp, #8]                   ; 8-byte Folded Reload
LBB58_7:                                ; %.cont50
	mov	x0, x24
	mov	x1, x21
	mov	x2, x22
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	blr	x8
	mov	w8, w0
	mov	x0, x23
	and	w8, w8, #0xff
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x21, x22, eq
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	br	x2
Lfunc_end58:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quad_swap_merge__anon_16478
l_sort.quad_swap_merge__anon_16478:     ; @sort.quad_swap_merge__anon_16478
Lfunc_begin59:
	.cfi_startproc
; %bb.0:                                ; %.cont19
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x28, x27, [sp, #48]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	lsl	x8, x4, #1
	mov	x22, x0
	add	x24, x0, x8
	mov	x20, x2
	mov	x23, x1
	mov	x0, x3
	mov	x1, x22
	mov	x2, x24
	str	x5, [sp, #40]                   ; 8-byte Folded Spill
	mov	x19, x4
	mov	x21, x3
	mov	x28, x8
	str	x8, [sp, #8]                    ; 8-byte Folded Spill
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x23
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x24, x22, eq
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x25, x22, x8, eq
	blr	x2
	mov	x0, x21
	mov	x1, x25
	mov	x2, x24
	add	x26, x23, x19
	mov	x27, x23
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x24, x25, eq
	blr	x2
	add	x23, x28, x19
	add	x25, x22, x19
	add	x26, x22, x23
	mov	x0, x21
	mov	x1, x25
	mov	x2, x26
	str	x22, [sp, #32]                  ; 8-byte Folded Spill
	blr	x20
	and	w8, w0, #0xff
	add	x24, x27, x23
	cmp	w8, #1
	mov	x0, x24
	csel	x1, x25, x26, eq
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	sub	x9, x1, x19
	cmp	w8, #1
	mov	x22, x27
	stp	x25, x24, [sp, #16]             ; 16-byte Folded Spill
	csel	x26, x26, x9, eq
	csel	x27, x9, x25, eq
	blr	x2
	mov	x0, x21
	mov	x1, x27
	mov	x2, x26
	sub	x28, x24, x19
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x27, x26, eq
	blr	x2
	ldr	x9, [sp, #32]                   ; 8-byte Folded Reload
	lsl	x8, x19, #2
	add	x26, x22, x8
	mov	x0, x21
	add	x27, x9, x8
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x1, x27
	add	x28, x27, x8
	mov	x2, x28
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x28, x27, eq
	add	x8, x1, x19
	csel	x28, x8, x28, eq
	csel	x24, x27, x8, eq
	blr	x2
	mov	x0, x21
	mov	x1, x24
	mov	x2, x28
	add	x25, x26, x19
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x28, x24, eq
	blr	x2
	add	x24, x27, x19
	add	x25, x27, x23
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	blr	x20
	and	w8, w0, #0xff
	add	x27, x26, x23
	cmp	w8, #1
	mov	x0, x27
	csel	x1, x24, x25, eq
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	sub	x9, x1, x19
	cmp	w8, #1
	csel	x25, x25, x9, eq
	csel	x24, x9, x24, eq
	blr	x2
	mov	x0, x21
	mov	x1, x24
	mov	x2, x25
	sub	x27, x27, x19
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x24, x25, eq
	blr	x2
	mov	x0, x21
	mov	x1, x22
	mov	x2, x26
	mov	x23, x22
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x1, x26, x22, eq
	ldp	x22, x2, [sp, #32]              ; 16-byte Folded Reload
	add	x8, x1, x19
	csel	x24, x8, x26, eq
	csel	x25, x23, x8, eq
	mov	x0, x22
	blr	x2
	mov	x0, x21
	mov	x1, x25
	mov	x2, x24
	blr	x20
	ldr	x26, [sp, #16]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x24, x25, eq
	mov	x0, x26
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x25, x25, x8, eq
	blr	x2
	mov	x0, x21
	mov	x1, x25
	mov	x2, x24
	add	x26, x26, x19
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x24, x25, eq
	add	x8, x1, x19
	csel	x24, x8, x24, eq
	csel	x25, x25, x8, eq
	blr	x2
	mov	x0, x21
	mov	x1, x25
	mov	x2, x24
	add	x26, x26, x19
	blr	x20
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x24, x25, eq
	blr	x2
	lsl	x8, x19, #3
	ldr	x25, [sp, #24]                  ; 8-byte Folded Reload
	sub	x24, x8, x19
	mov	x0, x21
	add	x23, x23, x24
	mov	x1, x25
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	add	x22, x22, x24
	cmp	w8, #1
	mov	x0, x22
	csel	x1, x25, x23, eq
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	sub	x9, x1, x19
	cmp	w8, #1
	csel	x23, x23, x9, eq
	csel	x24, x9, x25, eq
	blr	x2
	mov	x0, x21
	mov	x1, x24
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	sub	x22, x22, x19
	cmp	w8, #1
	mov	x0, x22
	csel	x1, x24, x23, eq
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	sub	x9, x1, x19
	cmp	w8, #1
	csel	x23, x23, x9, eq
	csel	x24, x9, x24, eq
	blr	x2
	mov	x0, x21
	mov	x1, x24
	mov	x2, x23
	blr	x20
	and	w8, w0, #0xff
	sub	x22, x22, x19
	cmp	w8, #1
	mov	x0, x22
	csel	x1, x24, x23, eq
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	sub	x9, x1, x19
	cmp	w8, #1
	csel	x23, x23, x9, eq
	csel	x24, x9, x24, eq
	blr	x2
	mov	x0, x21
	mov	x1, x24
	mov	x2, x23
	blr	x20
	and	w9, w0, #0xff
	sub	x8, x22, x19
	cmp	w9, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x24, x23, eq
	mov	x0, x8
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	br	x2
Lfunc_end59:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_backwards_merge__anon_16483
l_sort.partial_backwards_merge__anon_16483: ; @sort.partial_backwards_merge__anon_16483
Lfunc_begin60:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #288
	.cfi_def_cfa_offset 288
	stp	x28, x27, [sp, #192]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #208]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #224]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #240]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #256]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #272]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	subs	x26, x1, x4
	str	x2, [sp, #112]                  ; 8-byte Folded Spill
	b.eq	LBB60_44
; %bb.1:
	sub	x8, x4, #1
	mov	x22, x1
	mov	x24, x0
	mov	w1, #1
	mul	x8, x8, x7
	mov	x20, x7
	mov	x19, x6
	mov	x28, x4
	add	x27, x0, x8
	mov	x0, x6
	mov	x23, x5
	mov	x25, x3
	str	x8, [sp, #120]                  ; 8-byte Folded Spill
	ldp	x21, x8, [sp, #288]
	stp	x8, x27, [sp, #144]             ; 8-byte Folded Spill
	blr	x8
	add	x2, x27, x20
	mov	x0, x19
	mov	x1, x27
	blr	x23
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB60_44
; %bb.2:
	cmp	x22, x25
	stp	x19, x23, [sp, #128]            ; 16-byte Folded Spill
	str	x24, [sp, #80]                  ; 8-byte Folded Spill
	b.hi	LBB60_5
; %bb.3:
	cmp	x26, #64
	b.lo	LBB60_5
; %bb.4:
	ldr	x23, [sp, #112]                 ; 8-byte Folded Reload
	mov	x2, x28
	ldr	x19, [sp, #80]                  ; 8-byte Folded Reload
	mov	x3, x26
	ldp	x5, x4, [sp, #128]              ; 16-byte Folded Reload
	mov	x0, x23
	mov	x6, x20
	mov	x1, x19
	mov	x7, x21
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	str	x8, [sp]
	bl	l_sort.cross_merge__anon_14856
	mul	x2, x20, x22
	mov	x0, x19
	mov	x1, x23
	ldp	x29, x30, [sp, #272]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #256]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #224]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #208]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #192]            ; 16-byte Folded Reload
	add	sp, sp, #288
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_memcpy
LBB60_5:
	.cfi_restore_state
	.cfi_remember_state
	ldr	x9, [sp, #80]                   ; 8-byte Folded Reload
	sub	x8, x22, #1
	ldr	x22, [sp, #112]                 ; 8-byte Folded Reload
	mul	x2, x26, x20
	madd	x1, x20, x28, x9
	mov	x28, x9
	mov	x0, x22
	madd	x25, x8, x20, x9
	bl	_memcpy
	sub	x8, x26, #1
	ldr	x10, [sp, #120]                 ; 8-byte Folded Reload
	lsl	x9, x20, #4
	str	x20, [sp, #120]                 ; 8-byte Folded Spill
	mul	x8, x8, x20
	cmp	x10, x9
	add	x26, x22, x8
	str	x26, [sp, #168]
	b.le	LBB60_24
; %bb.6:
	ldr	x19, [sp, #144]                 ; 8-byte Folded Reload
	cmp	x8, x9
	b.le	LBB60_25
; %bb.7:                                ; %.preheader29.lr.ph
	add	x8, x28, x9
	neg	x10, x20, lsl #1
	neg	x24, x20
	str	x8, [sp, #56]                   ; 8-byte Folded Spill
	add	x8, x22, x9
	stp	x10, x9, [sp, #96]              ; 16-byte Folded Spill
	str	x8, [sp, #72]                   ; 8-byte Folded Spill
	sub	x8, x20, x9
	sub	x9, x9, x20
	str	x8, [sp, #32]                   ; 8-byte Folded Spill
	str	x9, [sp, #88]                   ; 8-byte Folded Spill
LBB60_8:                                ; %.preheader29
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB60_9 Depth 2
                                        ;     Child Loop BB60_12 Depth 2
                                        ;     Child Loop BB60_17 Depth 2
	mov	x23, xzr
	add	x19, x26, x8
LBB60_9:                                ;   Parent Loop BB60_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x20, [sp, #128]                 ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	add	x28, x25, x23
	add	x22, x19, x23
	mov	x0, x20
	blr	x8
	mov	x0, x20
	mov	x1, x27
	mov	x2, x22
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB60_11
; %bb.10:                               ;   in Loop: Header=BB60_9 Depth=2
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	x0, x28
	add	x20, x22, x8
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x24
	add	x28, x28, x24
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x0, x28, x24
	mov	x1, x22
	blr	x21
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #72]                   ; 8-byte Folded Reload
	sub	x23, x23, x8
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	add	x8, x20, x8
	cmp	x8, x9
	b.hi	LBB60_9
	b	LBB60_23
LBB60_11:                               ; %.preheader27
                                        ;   in Loop: Header=BB60_8 Depth=1
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	mov	x22, xzr
	add	x9, x26, x23
	add	x8, x27, x8
	str	x9, [sp, #168]
	stp	x8, x9, [sp, #40]               ; 16-byte Folded Spill
LBB60_12:                               ;   Parent Loop BB60_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x19, [sp, #128]                 ; 8-byte Folded Reload
	add	x20, x8, x22
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	mov	x0, x19
	blr	x8
	mov	x0, x19
	mov	x1, x20
	ldr	x2, [sp, #48]                   ; 8-byte Folded Reload
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB60_14
; %bb.13:                               ;   in Loop: Header=BB60_12 Depth=2
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	mov	x9, x20
	str	x20, [sp, #64]                  ; 8-byte Folded Spill
	add	x20, x28, x22
	mov	x0, x20
	add	x19, x9, x8
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x24
	add	x20, x20, x24
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x0, x20, x24
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	blr	x21
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #56]                   ; 8-byte Folded Reload
	sub	x22, x22, x8
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	add	x8, x19, x8
	cmp	x8, x9
	b.hi	LBB60_12
	b	LBB60_26
LBB60_14:                               ; %.preheader26
                                        ;   in Loop: Header=BB60_8 Depth=1
	add	x9, x25, x23
	add	x8, x27, x22
	add	x25, x9, x22
	mov	x20, #-8
	ldr	x23, [sp, #128]                 ; 8-byte Folded Reload
	ldr	x19, [sp, #144]                 ; 8-byte Folded Reload
	str	x8, [sp, #152]
	b	LBB60_17
LBB60_15:                               ;   in Loop: Header=BB60_17 Depth=2
	mov	x0, x25
	mov	x1, x28
	blr	x21
	add	x19, x25, x24
	mov	x1, x22
	mov	x0, x19
	blr	x21
	add	x8, x22, x24
	add	x25, x19, x24
	str	x8, [sp, #168]
LBB60_16:                               ;   in Loop: Header=BB60_17 Depth=2
	cmn	x20, #1
	add	x20, x20, #1
	ldr	x19, [sp, #144]                 ; 8-byte Folded Reload
	b.hs	LBB60_21
LBB60_17:                               ;   Parent Loop BB60_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x28, [sp, #168]
	mov	x0, x23
	mov	w1, #1
	ldr	x26, [sp, #152]
	add	x22, x28, x24
	blr	x19
	mov	x0, x23
	mov	x1, x26
	mov	x2, x22
	ldr	x27, [sp, #136]                 ; 8-byte Folded Reload
	blr	x27
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB60_15
; %bb.18:                               ;   in Loop: Header=BB60_17 Depth=2
	mov	x0, x23
	mov	w1, #1
	str	x22, [sp, #48]                  ; 8-byte Folded Spill
	add	x22, x26, x24
	blr	x19
	mov	x0, x23
	mov	x1, x22
	mov	x2, x28
	str	x22, [sp, #64]                  ; 8-byte Folded Spill
	blr	x27
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB60_20
; %bb.19:                               ;   in Loop: Header=BB60_17 Depth=2
	mov	x0, x25
	mov	x1, x26
	blr	x21
	ldr	x22, [sp, #64]                  ; 8-byte Folded Reload
	add	x19, x25, x24
	mov	x0, x19
	mov	x1, x22
	blr	x21
	add	x8, x22, x24
	ldr	x23, [sp, #128]                 ; 8-byte Folded Reload
	add	x25, x19, x24
	str	x8, [sp, #152]
	b	LBB60_16
LBB60_20:                               ; %select.end352
                                        ;   in Loop: Header=BB60_17 Depth=2
	ldr	x23, [sp, #128]                 ; 8-byte Folded Reload
	mov	w1, #2
	mov	x0, x23
	blr	x19
	mov	x0, x23
	mov	x1, x26
	mov	x2, x28
	blr	x27
	ldr	x9, [sp, #120]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	add	x19, x25, x24
	mov	x1, x28
	csel	x8, xzr, x9, eq
	csel	x25, x9, xzr, eq
	add	x0, x19, x8
	blr	x21
	add	x0, x19, x25
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	mov	x1, x26
	str	x22, [sp, #168]
	blr	x21
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	mov	x0, x23
	mov	x2, x22
	add	x19, x19, x24
	str	x1, [sp, #152]
	blr	x27
	and	w8, w0, #0xff
	add	x9, sp, #152
	cmp	w8, #1
	add	x8, sp, #168
	csel	x22, x9, x8, eq
	mov	x0, x19
	ldr	x1, [x22]
	blr	x21
	ldr	x8, [x22]
	add	x25, x19, x24
	add	x8, x8, x24
	str	x8, [x22]
	b	LBB60_16
LBB60_21:                               ; %.loopexit
                                        ;   in Loop: Header=BB60_8 Depth=1
	ldr	x27, [sp, #152]
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	ldr	x26, [sp, #168]
	cmp	x27, x8
	b.ls	LBB60_45
; %bb.22:                               ; %.loopexit
                                        ;   in Loop: Header=BB60_8 Depth=1
	ldp	x8, x28, [sp, #72]              ; 16-byte Folded Reload
	ldr	x20, [sp, #120]                 ; 8-byte Folded Reload
	cmp	x26, x8
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	b.hi	LBB60_8
	b	LBB60_25
LBB60_23:                               ; %.loopexit30
	add	x26, x26, x23
	add	x25, x25, x23
	str	x26, [sp, #168]
	b	LBB60_27
LBB60_24:
	ldr	x19, [sp, #144]                 ; 8-byte Folded Reload
LBB60_25:                               ; %.loopexit31
	str	x25, [sp, #160]
	b	LBB60_28
LBB60_26:                               ; %.loopexit28
	add	x27, x27, x22
	add	x8, x25, x23
	add	x25, x8, x22
	add	x26, x26, x23
	str	x27, [sp, #152]
LBB60_27:
	ldr	x20, [sp, #120]                 ; 8-byte Folded Reload
	str	x25, [sp, #160]
	ldr	x28, [sp, #80]                  ; 8-byte Folded Reload
	ldr	x19, [sp, #144]                 ; 8-byte Folded Reload
LBB60_28:
	ldr	x24, [sp, #112]                 ; 8-byte Folded Reload
	add	x22, x24, x20
	cmp	x22, x26
	b.hs	LBB60_36
; %bb.29:
	add	x23, x28, x20
	cmp	x23, x27
	b.hs	LBB60_36
; %bb.30:                               ; %.lr.ph
	neg	x24, x20
	ldr	x28, [sp, #136]                 ; 8-byte Folded Reload
LBB60_31:                               ; =>This Inner Loop Header: Depth=1
	ldr	x27, [sp, #128]                 ; 8-byte Folded Reload
	add	x0, sp, #160
	ldr	x9, [sp, #80]                   ; 8-byte Folded Reload
	add	x1, sp, #176
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	add	x2, sp, #152
	add	x3, sp, #184
	add	x4, sp, #168
	mov	x5, x28
	mov	x6, x27
	mov	x7, x20
	stp	x9, x8, [sp, #176]
	stp	x21, x19, [sp]
	bl	l_sort.partial_forward_merge_right_tail_2__anon_16701
	tbnz	w0, #0, LBB60_34
; %bb.32:                               ; %select.end348
                                        ;   in Loop: Header=BB60_31 Depth=1
	mov	x0, x27
	mov	w1, #2
	blr	x19
	ldr	x19, [sp, #152]
	mov	x0, x27
	ldr	x20, [sp, #168]
	mov	x1, x19
	mov	x2, x20
	blr	x28
	and	w9, w0, #0xff
	ldr	x8, [sp, #160]
	cmp	w9, #1
	ldr	x9, [sp, #120]                  ; 8-byte Folded Reload
	mov	x1, x20
	add	x25, x8, x24
	ldr	x8, [sp, #120]                  ; 8-byte Folded Reload
	csel	x9, xzr, x9, eq
	add	x0, x25, x9
	csel	x26, x8, xzr, eq
	blr	x21
	add	x20, x20, x24
	add	x0, x25, x26
	mov	x1, x19
	str	x20, [sp, #168]
	blr	x21
	add	x1, x19, x24
	mov	x0, x27
	mov	x2, x20
	add	x19, x25, x24
	str	x1, [sp, #152]
	blr	x28
	and	w8, w0, #0xff
	add	x9, sp, #168
	cmp	w8, #1
	add	x8, sp, #152
	csel	x20, x8, x9, eq
	mov	x0, x19
	ldr	x1, [x20]
	blr	x21
	ldr	x8, [x20]
	add	x25, x19, x24
	add	x8, x8, x24
	str	x25, [sp, #160]
	str	x8, [x20]
	ldr	x20, [sp, #120]                 ; 8-byte Folded Reload
	ldp	x19, x27, [sp, #144]            ; 8-byte Folded Reload
	ldr	x26, [sp, #168]
	cmp	x22, x26
	b.hs	LBB60_35
; %bb.33:                               ; %select.end348
                                        ;   in Loop: Header=BB60_31 Depth=1
	cmp	x23, x27
	b.lo	LBB60_31
	b	LBB60_35
LBB60_34:                               ; %.._crit_edge.loopexit_crit_edge
	ldp	x25, x26, [sp, #160]
	ldr	x27, [sp, #152]
LBB60_35:                               ; %._crit_edge.loopexit
	ldr	x24, [sp, #112]                 ; 8-byte Folded Reload
	ldr	x28, [sp, #80]                  ; 8-byte Folded Reload
LBB60_36:                               ; %._crit_edge
	cmp	x26, x24
	b.lo	LBB60_41
; %bb.37:                               ; %._crit_edge
	cmp	x27, x28
	b.lo	LBB60_41
; %bb.38:                               ; %.lr.ph55
	neg	x19, x20
	add	x20, sp, #168
	add	x22, sp, #152
LBB60_39:                               ; %select.end
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x23, [sp, #128]                 ; 8-byte Folded Reload
	mov	w1, #1
	ldr	x8, [sp, #144]                  ; 8-byte Folded Reload
	mov	x0, x23
	blr	x8
	mov	x0, x23
	mov	x1, x27
	mov	x2, x26
	ldr	x8, [sp, #136]                  ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x23, x22, x20, eq
	ldr	x1, [x23]
	blr	x21
	ldr	x8, [x23]
	add	x25, x25, x19
	add	x8, x8, x19
	str	x8, [x23]
	ldr	x26, [sp, #168]
	cmp	x26, x24
	b.lo	LBB60_41
; %bb.40:                               ; %select.end
                                        ;   in Loop: Header=BB60_39 Depth=1
	ldr	x27, [sp, #152]
	cmp	x27, x28
	b.hs	LBB60_39
LBB60_41:                               ; %.preheader
	ldr	x20, [sp, #120]                 ; 8-byte Folded Reload
	cmp	x26, x24
	b.lo	LBB60_44
; %bb.42:                               ; %.lr.ph62.preheader
	mov	x19, xzr
LBB60_43:                               ; %.lr.ph62
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x26, x19
	add	x0, x25, x19
	blr	x21
	sub	x19, x19, x20
	add	x8, x26, x19
	cmp	x8, x24
	b.hs	LBB60_43
LBB60_44:                               ; %common.ret1
	ldp	x29, x30, [sp, #272]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #256]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #240]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #224]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #208]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #192]            ; 16-byte Folded Reload
	add	sp, sp, #288
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB60_45:
	.cfi_restore_state
	ldr	x20, [sp, #120]                 ; 8-byte Folded Reload
	str	x25, [sp, #160]
	ldr	x28, [sp, #80]                  ; 8-byte Folded Reload
	b	LBB60_28
Lfunc_end60:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.rotate_merge_block__anon_16484
l_sort.rotate_merge_block__anon_16484:  ; @sort.rotate_merge_block__anon_16484
Lfunc_begin61:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #208
	.cfi_def_cfa_offset 208
	stp	x28, x27, [sp, #112]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #128]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	ldp	x8, x25, [sp, #208]
	mov	x28, x0
	mov	x0, x6
	mov	x19, x7
	mov	x20, x6
	mov	x21, x5
	mov	x27, x4
	stp	x8, x1, [sp, #32]               ; 16-byte Folded Spill
	mov	w1, #1
	mov	x24, x3
	mov	x22, x2
	blr	x25
	sub	x8, x24, #1
	madd	x23, x24, x19, x28
	mov	x0, x20
	madd	x1, x8, x19, x28
	mov	x2, x23
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB61_37
; %bb.1:                                ; %.lr.ph
	neg	x8, x19
	stp	x25, x22, [sp, #64]             ; 16-byte Folded Spill
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
LBB61_2:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB61_4 Depth 2
                                        ;     Child Loop BB61_30 Depth 2
                                        ;     Child Loop BB61_34 Depth 2
                                        ;     Child Loop BB61_14 Depth 2
	lsr	x8, x24, #1
	mov	x9, x28
	mov	x0, x20
	madd	x28, x27, x19, x23
	stp	x24, x8, [sp, #88]              ; 16-byte Folded Spill
	sub	x8, x24, x8
	str	x9, [sp, #80]                   ; 8-byte Folded Spill
	mul	x10, x8, x19
	str	x8, [sp, #104]                  ; 8-byte Folded Spill
	sub	x8, x27, #1
	clz	x8, x8
	add	x22, x9, x10
	mov	w9, #65
	sub	x1, x9, x8
	str	x10, [sp, #56]                  ; 8-byte Folded Spill
	blr	x25
	cmp	x27, #2
	b.lo	LBB61_5
; %bb.3:                                ; %.lr.ph.i.preheader
                                        ;   in Loop: Header=BB61_2 Depth=1
	mov	x26, x27
LBB61_4:                                ; %.lr.ph.i
                                        ;   Parent Loop BB61_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	lsr	x25, x26, #1
	mov	x0, x20
	mov	x1, x22
	msub	x24, x25, x19, x28
	mov	x2, x24
	blr	x21
	and	w8, w0, #0xff
	sub	x26, x26, x25
	cmp	w8, #1
	csel	x28, x28, x24, eq
	cmp	x26, #1
	b.hi	LBB61_4
LBB61_5:                                ; %sort.monobound_binary_first__anon_16702.exit
                                        ;   in Loop: Header=BB61_2 Depth=1
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	mov	x0, x20
	mov	x1, x22
	add	x24, x28, x8
	mov	x2, x24
	blr	x21
	and	w8, w0, #0xff
	ldr	x10, [sp, #104]                 ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x8, x28, x24, eq
	ldr	x28, [sp, #80]                  ; 8-byte Folded Reload
	sub	x8, x8, x23
	ldp	x25, x3, [sp, #64]              ; 16-byte Folded Reload
	udiv	x24, x8, x19
	cmp	x8, x19
	b.lo	LBB61_24
; %bb.6:                                ;   in Loop: Header=BB61_2 Depth=1
	add	x26, x24, x10
	mov	x25, x10
	cmp	x26, x3
	b.ls	LBB61_11
; %bb.7:                                ;   in Loop: Header=BB61_2 Depth=1
	mov	x0, x22
	ldr	x4, [sp, #96]                   ; 8-byte Folded Reload
	ldp	x22, x23, [sp, #32]             ; 16-byte Folded Reload
	mov	x5, x19
	add	x1, x24, x4
	mov	x6, x22
	mov	x2, x23
	bl	l_sort.trinity_rotation
	lsl	x8, x25, #1
	cmp	x25, x24, lsl #1
	mov	x3, x25
	ccmp	x8, x24, #0, ls
	ldp	x25, x9, [sp, #64]              ; 16-byte Folded Reload
	b.hs	LBB61_10
; %bb.8:                                ;   in Loop: Header=BB61_2 Depth=1
	cmp	x24, x9
	b.ls	LBB61_21
; %bb.9:                                ; %.critedge
                                        ;   in Loop: Header=BB61_2 Depth=1
	ldr	x23, [sp, #40]                  ; 8-byte Folded Reload
	cmp	x3, x9
	b.ls	LBB61_22
LBB61_10:                               ; %.critedge3
                                        ;   in Loop: Header=BB61_2 Depth=1
	mov	x0, x28
	mov	x1, x23
	mov	x2, x9
	mov	x4, x24
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	stp	x22, x25, [sp]
	bl	l_sort.rotate_merge_block__anon_16484
	b	LBB61_23
LBB61_11:                               ;   in Loop: Header=BB61_2 Depth=1
	str	x26, [sp, #24]                  ; 8-byte Folded Spill
	ldr	x22, [sp, #40]                  ; 8-byte Folded Reload
	ldr	x26, [sp, #56]                  ; 8-byte Folded Reload
	mov	x1, x28
	mov	x0, x22
	mov	x2, x26
	bl	_memcpy
	mul	x2, x24, x19
	add	x0, x22, x26
	mov	x1, x23
	bl	_memcpy
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	mov	x2, x25
	ldr	x7, [sp, #32]                   ; 8-byte Folded Reload
	ldr	x25, [sp, #64]                  ; 8-byte Folded Reload
	mul	x8, x8, x19
	cbz	x8, LBB61_15
; %bb.12:                               ; %iter.check
                                        ;   in Loop: Header=BB61_2 Depth=1
	ldr	x9, [sp, #24]                   ; 8-byte Folded Reload
	cmp	x8, #8
	madd	x9, x9, x19, x28
	b.hs	LBB61_16
LBB61_13:                               ; %.lr.ph.i103.preheader
                                        ;   in Loop: Header=BB61_2 Depth=1
	ldr	x10, [sp, #56]                  ; 8-byte Folded Reload
	add	x10, x28, x10
	sub	x10, x10, #1
LBB61_14:                               ; %.lr.ph.i103
                                        ;   Parent Loop BB61_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	subs	x11, x8, #1
	ldrb	w12, [x10, x8]
	mov	x8, x11
	strb	w12, [x9, x11]
	b.ne	LBB61_14
LBB61_15:                               ; %mem.copyBackwards__anon_9784.exit
                                        ;   in Loop: Header=BB61_2 Depth=1
	mov	x0, x28
	mov	x1, x22
	mov	x3, x24
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	str	x25, [sp]
	bl	l_sort.cross_merge__anon_14856
	ldr	x10, [sp, #104]                 ; 8-byte Folded Reload
	ldr	x3, [sp, #72]                   ; 8-byte Folded Reload
	b	LBB61_24
LBB61_16:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB61_2 Depth=1
	ldr	x14, [sp, #88]                  ; 8-byte Folded Reload
	sub	x10, x28, #1
	mov	w12, #1
	sub	x12, x12, x8
	add	x11, x14, x24
	madd	x11, x11, x19, x10
	add	x13, x11, x12
	cmp	x13, x11
	b.hi	LBB61_13
; %bb.17:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB61_2 Depth=1
	mul	x11, x14, x19
	add	x13, x10, x11
	add	x12, x13, x12
	cmp	x12, x13
	b.hi	LBB61_13
; %bb.18:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB61_2 Depth=1
	add	x12, x14, x24
	madd	x13, x14, x19, x10
	madd	x10, x12, x19, x10
	sub	x10, x13, x10
	cmp	x10, #32
	b.lo	LBB61_13
; %bb.19:                               ; %vector.main.loop.iter.check
                                        ;   in Loop: Header=BB61_2 Depth=1
	cmp	x8, #32
	b.hs	LBB61_29
; %bb.20:                               ;   in Loop: Header=BB61_2 Depth=1
	mov	x10, xzr
	b	LBB61_33
LBB61_21:                               ;   in Loop: Header=BB61_2 Depth=1
	mov	x0, x28
	mov	x1, x26
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	mov	x3, x9
	ldr	x4, [sp, #104]                  ; 8-byte Folded Reload
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	stp	x22, x25, [sp]
	bl	l_sort.partial_backwards_merge__anon_16483
	b	LBB61_23
LBB61_22:                               ;   in Loop: Header=BB61_2 Depth=1
	mov	x0, x28
	mov	x1, x26
	mov	x2, x23
	mov	x3, x9
	ldr	x4, [sp, #104]                  ; 8-byte Folded Reload
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	stp	x22, x25, [sp]
	bl	l_sort.partial_forward_merge__anon_16703
LBB61_23:                               ;   in Loop: Header=BB61_2 Depth=1
	ldr	x3, [sp, #72]                   ; 8-byte Folded Reload
	ldr	x10, [sp, #104]                 ; 8-byte Folded Reload
LBB61_24:                               ;   in Loop: Header=BB61_2 Depth=1
	ldr	x8, [sp, #88]                   ; 8-byte Folded Reload
	cmp	x27, x24
	b.eq	LBB61_37
; %bb.25:                               ;   in Loop: Header=BB61_2 Depth=1
	ldr	x22, [sp, #96]                  ; 8-byte Folded Reload
	sub	x27, x27, x24
	and	x8, x8, #0xfffffffffffffffe
	lsl	x9, x27, #1
	cmp	x8, x27
	ccmp	x22, x9, #2, hs
	add	x1, x27, x22
	cset	w8, hi
	cmp	x27, x3
	eor	w9, w8, #0x1
	csinc	w9, w9, wzr, ls
	cmp	w9, #1
	b.ne	LBB61_38
; %bb.26:                               ;   in Loop: Header=BB61_2 Depth=1
	cmp	x1, x3
	b.ls	LBB61_38
; %bb.27:                               ;   in Loop: Header=BB61_2 Depth=1
	add	x9, x24, x10
	cmp	x10, x3
	csel	w8, wzr, w8, hi
	madd	x28, x9, x19, x28
	cmp	w8, #1
	b.eq	LBB61_39
; %bb.28:                               ; %.critedge9
                                        ;   in Loop: Header=BB61_2 Depth=1
	mov	x0, x20
	mov	w1, #1
	blr	x25
	sub	x8, x22, #1
	madd	x23, x22, x19, x28
	mov	x0, x20
	madd	x1, x8, x19, x28
	mov	x2, x23
	blr	x21
	mov	x24, x22
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB61_2
	b	LBB61_37
LBB61_29:                               ; %vector.ph
                                        ;   in Loop: Header=BB61_2 Depth=1
	and	x10, x8, #0xffffffffffffffe0
	add	x13, x28, x11
	mov	x12, xzr
	sub	x13, x13, #16
	neg	x14, x10
LBB61_30:                               ; %vector.body
                                        ;   Parent Loop BB61_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x13, #-16]
	mvn	x15, x12
	add	x12, x12, #32
	add	x15, x8, x15
	sub	x13, x13, #32
	add	x15, x9, x15
	adds	x14, x14, #32
	stur	q0, [x15, #-15]
	stur	q1, [x15, #-31]
	b.ne	LBB61_30
; %bb.31:                               ; %middle.block
                                        ;   in Loop: Header=BB61_2 Depth=1
	cmp	x8, x10
	b.eq	LBB61_15
; %bb.32:                               ; %vec.epilog.iter.check
                                        ;   in Loop: Header=BB61_2 Depth=1
	tst	x8, #0x18
	b.eq	LBB61_36
LBB61_33:                               ; %vec.epilog.ph
                                        ;   in Loop: Header=BB61_2 Depth=1
	sub	x14, x11, x10
	and	x13, x8, #0xfffffffffffffff8
	add	x14, x28, x14
	and	x12, x8, #0x7
	sub	x11, x9, #7
	sub	x14, x14, #8
	sub	x15, x10, x13
LBB61_34:                               ; %vec.epilog.vector.body
                                        ;   Parent Loop BB61_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mvn	x16, x10
	add	x10, x10, #8
	add	x16, x8, x16
	adds	x15, x15, #8
	ldr	d0, [x14], #-8
	str	d0, [x11, x16]
	b.ne	LBB61_34
; %bb.35:                               ; %vec.epilog.middle.block
                                        ;   in Loop: Header=BB61_2 Depth=1
	cmp	x8, x13
	mov	x8, x12
	b.ne	LBB61_13
	b	LBB61_15
LBB61_36:                               ;   in Loop: Header=BB61_2 Depth=1
	and	x8, x8, #0x1f
	b	LBB61_13
LBB61_37:                               ; %common.ret1
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB61_38:                               ; %.critedge7
	.cfi_restore_state
	.cfi_remember_state
	add	x8, x24, x10
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	madd	x0, x8, x19, x28
	mov	x7, x19
	ldp	x8, x2, [sp, #32]               ; 16-byte Folded Reload
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	stp	x8, x25, [sp, #208]
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_backwards_merge__anon_16483
LBB61_39:
	.cfi_restore_state
	ldp	x8, x2, [sp, #32]               ; 16-byte Folded Reload
	mov	x0, x28
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	stp	x8, x25, [sp, #208]
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge__anon_16703
Lfunc_end61:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.parity_merge__anon_16486
l_sort.parity_merge__anon_16486:        ; @sort.parity_merge__anon_16486
Lfunc_begin62:
	.cfi_startproc
; %bb.0:                                ; %._crit_edge
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x28, x27, [sp, #48]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	madd	x27, x6, x2, x1
	sub	x28, x2, #1
	add	x8, x28, x3
	mov	x25, x1
	sub	x20, x27, x6
	mov	x24, x0
	madd	x21, x6, x3, x20
	mov	x19, x5
	madd	x22, x8, x6, x0
	mov	x26, x4
	cmp	x2, x3
	str	x7, [sp, #40]                   ; 8-byte Folded Spill
	str	x6, [sp, #24]                   ; 8-byte Folded Spill
	b.hs	LBB62_2
; %bb.1:                                ; %.cont16
	mov	x0, x19
	mov	x1, x25
	mov	x2, x27
	mov	x23, x6
	blr	x26
	and	w8, w0, #0xff
	mov	x0, x24
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x27, x25, eq
	add	x8, x1, x23
	csel	x27, x8, x27, eq
	csel	x25, x25, x8, eq
	blr	x2
	add	x23, x24, x23
	b	LBB62_3
LBB62_2:
	mov	x23, x24
LBB62_3:                                ; %.cont25
	mov	x0, x19
	mov	x1, x25
	mov	x2, x27
	str	x19, [sp, #8]                   ; 8-byte Folded Spill
	mov	x19, x26
	blr	x26
	and	w24, w0, #0xff
	mov	x0, x23
	cmp	w24, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x26, x27, x25, eq
	mov	x1, x26
	blr	x2
	str	x19, [sp, #32]                  ; 8-byte Folded Spill
	cbz	x28, LBB62_6
; %bb.4:                                ; %.cont.preheader
	ldr	x10, [sp, #24]                  ; 8-byte Folded Reload
	cmp	w24, #1
	ldr	x24, [sp, #24]                  ; 8-byte Folded Reload
	add	x8, x26, x10
	neg	x9, x10
	csel	x25, x25, x8, eq
	csel	x27, x8, x27, eq
	add	x26, x23, x10
	ldr	x23, [sp, #8]                   ; 8-byte Folded Reload
	str	x9, [sp, #16]                   ; 8-byte Folded Spill
LBB62_5:                                ; %.cont
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x23
	mov	x1, x25
	mov	x2, x27
	ldr	x19, [sp, #32]                  ; 8-byte Folded Reload
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x26
	cmp	w8, #1
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	csel	x1, x27, x25, eq
	add	x8, x1, x24
	csel	x27, x8, x27, eq
	csel	x25, x25, x8, eq
	blr	x2
	mov	x0, x23
	mov	x1, x20
	mov	x2, x21
	blr	x19
	and	w8, w0, #0xff
	ldr	x19, [sp, #16]                  ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x0, x22
	csel	x1, x20, x21, eq
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	add	x8, x1, x19
	csel	x21, x21, x8, eq
	csel	x20, x8, x20, eq
	blr	x2
	add	x22, x22, x19
	add	x26, x26, x24
	subs	x28, x28, #1
	b.ne	LBB62_5
	b	LBB62_7
LBB62_6:
	ldr	x23, [sp, #8]                   ; 8-byte Folded Reload
LBB62_7:                                ; %.cont50
	mov	x0, x23
	mov	x1, x20
	mov	x2, x21
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	blr	x8
	mov	w8, w0
	mov	x0, x22
	and	w8, w8, #0xff
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x1, x20, x21, eq
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	br	x2
Lfunc_end62:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_backwards_merge__anon_16492
l_sort.partial_backwards_merge__anon_16492: ; @sort.partial_backwards_merge__anon_16492
Lfunc_begin63:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #272
	.cfi_def_cfa_offset 272
	stp	x28, x27, [sp, #176]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #192]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #208]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #224]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #240]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #256]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	subs	x25, x1, x4
	b.eq	LBB63_44
; %bb.1:
	sub	x8, x4, #1
	mov	x22, x1
	mov	x26, x2
	mov	x23, x0
	mul	x8, x8, x7
	ldr	x21, [sp, #272]
	mov	x20, x7
	mov	x19, x6
	add	x27, x0, x8
	mov	x0, x6
	add	x2, x27, x7
	mov	x1, x27
	mov	x28, x4
	mov	x24, x5
	stp	x8, x3, [sp, #104]              ; 16-byte Folded Spill
	str	x27, [sp, #136]
	blr	x5
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	b.ne	LBB63_44
; %bb.2:
	mov	x3, x25
	cmp	x22, x8
	stp	x19, x24, [sp, #120]            ; 16-byte Folded Spill
	str	x23, [sp, #88]                  ; 8-byte Folded Spill
	b.hi	LBB63_5
; %bb.3:
	cmp	x3, #64
	b.lo	LBB63_5
; %bb.4:
	ldr	x19, [sp, #88]                  ; 8-byte Folded Reload
	mov	x0, x26
	ldp	x5, x4, [sp, #120]              ; 16-byte Folded Reload
	mov	x2, x28
	mov	x6, x20
	mov	x1, x19
	mov	x7, x21
	bl	l_sort.cross_merge__anon_14859
	mul	x2, x20, x22
	mov	x0, x19
	mov	x1, x26
	ldp	x29, x30, [sp, #256]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #240]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #208]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #192]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #176]            ; 16-byte Folded Reload
	add	sp, sp, #272
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_memcpy
LBB63_5:
	.cfi_restore_state
	ldr	x9, [sp, #88]                   ; 8-byte Folded Reload
	mul	x2, x3, x20
	mov	x0, x26
	sub	x8, x22, #1
	mov	x24, x26
	mov	x19, x3
	madd	x1, x20, x28, x9
	mov	x28, x9
	madd	x25, x8, x20, x9
	bl	_memcpy
	sub	x8, x19, #1
	ldr	x10, [sp, #104]                 ; 8-byte Folded Reload
	lsl	x9, x20, #4
	str	x20, [sp, #80]                  ; 8-byte Folded Spill
	mul	x8, x8, x20
	str	x24, [sp, #56]                  ; 8-byte Folded Spill
	cmp	x10, x9
	add	x26, x26, x8
	str	x26, [sp, #152]
	b.le	LBB63_27
; %bb.6:
	cmp	x8, x9
	b.le	LBB63_27
; %bb.7:                                ; %.preheader29.lr.ph
	add	x8, x28, x9
	neg	x11, x20, lsl #1
	sub	x10, x9, x20
	neg	x23, x20
	str	x9, [sp, #112]                  ; 8-byte Folded Spill
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
	add	x8, x24, x9
	stp	x10, x11, [sp, #96]             ; 16-byte Folded Spill
	str	x8, [sp, #72]                   ; 8-byte Folded Spill
	sub	x8, x20, x9
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
LBB63_8:                                ; %.preheader29
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB63_9 Depth 2
                                        ;     Child Loop BB63_12 Depth 2
                                        ;     Child Loop BB63_17 Depth 2
	mov	x24, xzr
	add	x19, x26, x8
LBB63_9:                                ;   Parent Loop BB63_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	x0, x8, [sp, #120]              ; 16-byte Folded Reload
	add	x22, x19, x24
	mov	x1, x27
	mov	x2, x22
	add	x28, x25, x24
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB63_11
; %bb.10:                               ;   in Loop: Header=BB63_9 Depth=2
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	mov	x0, x28
	add	x20, x22, x8
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x20, x20, x23
	add	x28, x28, x23
	mov	x0, x28
	mov	x1, x20
	blr	x21
	add	x0, x28, x23
	mov	x1, x22
	blr	x21
	ldp	x8, x9, [sp, #104]              ; 16-byte Folded Reload
	ldr	x10, [sp, #72]                  ; 8-byte Folded Reload
	add	x8, x20, x8
	sub	x24, x24, x9
	cmp	x8, x10
	b.hi	LBB63_9
	b	LBB63_23
LBB63_11:                               ; %.preheader27
                                        ;   in Loop: Header=BB63_8 Depth=1
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x22, xzr
	add	x9, x26, x24
	add	x8, x27, x8
	str	x9, [sp, #152]
	stp	x8, x9, [sp, #32]               ; 16-byte Folded Spill
LBB63_12:                               ;   Parent Loop BB63_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	x8, x2, [sp, #32]               ; 16-byte Folded Reload
	add	x19, x8, x22
	ldp	x0, x8, [sp, #120]              ; 16-byte Folded Reload
	mov	x1, x19
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB63_14
; %bb.13:                               ;   in Loop: Header=BB63_12 Depth=2
	ldr	x8, [sp, #96]                   ; 8-byte Folded Reload
	add	x20, x28, x22
	str	x19, [sp, #64]                  ; 8-byte Folded Spill
	mov	x0, x20
	add	x19, x19, x8
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x19, x19, x23
	add	x20, x20, x23
	mov	x0, x20
	mov	x1, x19
	blr	x21
	add	x0, x20, x23
	ldr	x1, [sp, #64]                   ; 8-byte Folded Reload
	blr	x21
	ldr	x8, [sp, #112]                  ; 8-byte Folded Reload
	ldr	x9, [sp, #48]                   ; 8-byte Folded Reload
	sub	x22, x22, x8
	ldr	x8, [sp, #104]                  ; 8-byte Folded Reload
	add	x8, x19, x8
	cmp	x8, x9
	b.hi	LBB63_12
	b	LBB63_24
LBB63_14:                               ; %.preheader26
                                        ;   in Loop: Header=BB63_8 Depth=1
	add	x9, x25, x24
	add	x8, x27, x22
	add	x25, x9, x22
	mov	x20, #-8
	str	x8, [sp, #136]
	b	LBB63_17
LBB63_15:                               ;   in Loop: Header=BB63_17 Depth=2
	mov	x0, x25
	mov	x1, x28
	blr	x21
	add	x19, x25, x23
	mov	x1, x22
	mov	x0, x19
	blr	x21
	add	x8, x22, x23
	add	x25, x19, x23
	str	x8, [sp, #152]
LBB63_16:                               ;   in Loop: Header=BB63_17 Depth=2
	cmn	x20, #1
	add	x20, x20, #1
	b.hs	LBB63_21
LBB63_17:                               ;   Parent Loop BB63_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	x24, x27, [sp, #128]            ; 8-byte Folded Reload
	ldr	x28, [sp, #152]
	ldr	x19, [sp, #120]                 ; 8-byte Folded Reload
	add	x22, x28, x23
	mov	x1, x27
	mov	x0, x19
	mov	x2, x22
	blr	x24
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB63_15
; %bb.18:                               ;   in Loop: Header=BB63_17 Depth=2
	add	x26, x27, x23
	mov	x0, x19
	mov	x1, x26
	mov	x2, x28
	blr	x24
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB63_20
; %bb.19:                               ;   in Loop: Header=BB63_17 Depth=2
	mov	x0, x25
	mov	x1, x27
	blr	x21
	add	x19, x25, x23
	mov	x1, x26
	mov	x0, x19
	blr	x21
	add	x8, x26, x23
	add	x25, x19, x23
	str	x8, [sp, #136]
	b	LBB63_16
LBB63_20:                               ; %select.end243
                                        ;   in Loop: Header=BB63_17 Depth=2
	mov	x0, x19
	mov	x1, x27
	mov	x2, x28
	blr	x24
	ldr	x9, [sp, #80]                   ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	add	x25, x25, x23
	mov	x1, x28
	csel	x8, xzr, x9, eq
	csel	x9, x9, xzr, eq
	add	x0, x25, x8
	str	x9, [sp, #64]                   ; 8-byte Folded Spill
	blr	x21
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	mov	x1, x27
	str	x22, [sp, #152]
	add	x0, x25, x8
	blr	x21
	mov	x0, x19
	mov	x1, x26
	mov	x2, x22
	add	x25, x25, x23
	str	x26, [sp, #136]
	blr	x24
	and	w8, w0, #0xff
	add	x9, sp, #136
	cmp	w8, #1
	add	x8, sp, #152
	csel	x22, x9, x8, eq
	mov	x0, x25
	ldr	x1, [x22]
	blr	x21
	ldr	x8, [x22]
	add	x25, x25, x23
	add	x8, x8, x23
	str	x8, [x22]
	b	LBB63_16
LBB63_21:                               ; %.loopexit
                                        ;   in Loop: Header=BB63_8 Depth=1
	ldr	x27, [sp, #136]
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	ldr	x26, [sp, #152]
	cmp	x27, x8
	b.ls	LBB63_26
; %bb.22:                               ; %.loopexit
                                        ;   in Loop: Header=BB63_8 Depth=1
	ldp	x8, x20, [sp, #72]              ; 16-byte Folded Reload
	ldr	x28, [sp, #88]                  ; 8-byte Folded Reload
	ldr	x24, [sp, #56]                  ; 8-byte Folded Reload
	cmp	x26, x8
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	b.hi	LBB63_8
	b	LBB63_27
LBB63_23:                               ; %.loopexit30
	add	x26, x26, x24
	add	x25, x25, x24
	str	x26, [sp, #152]
	b	LBB63_25
LBB63_24:                               ; %.loopexit28
	add	x27, x27, x22
	add	x8, x25, x24
	add	x25, x8, x22
	add	x26, x26, x24
	str	x27, [sp, #136]
LBB63_25:
	ldp	x20, x28, [sp, #80]             ; 16-byte Folded Reload
	str	x25, [sp, #144]
	ldr	x24, [sp, #56]                  ; 8-byte Folded Reload
	b	LBB63_28
LBB63_26:
	ldp	x20, x28, [sp, #80]             ; 16-byte Folded Reload
	ldr	x24, [sp, #56]                  ; 8-byte Folded Reload
LBB63_27:                               ; %.loopexit31
	str	x25, [sp, #144]
LBB63_28:
	add	x22, x24, x20
	cmp	x22, x26
	b.hs	LBB63_36
; %bb.29:
	add	x23, x28, x20
	cmp	x23, x27
	b.hs	LBB63_36
; %bb.30:                               ; %.lr.ph
	neg	x24, x20
	ldr	x28, [sp, #128]                 ; 8-byte Folded Reload
LBB63_31:                               ; =>This Inner Loop Header: Depth=1
	ldr	x25, [sp, #120]                 ; 8-byte Folded Reload
	add	x0, sp, #144
	ldr	x9, [sp, #88]                   ; 8-byte Folded Reload
	add	x1, sp, #160
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	add	x2, sp, #136
	add	x3, sp, #168
	add	x4, sp, #152
	mov	x5, x28
	mov	x6, x25
	mov	x7, x20
	stp	x9, x8, [sp, #160]
	str	x21, [sp]
	bl	l_sort.partial_forward_merge_right_tail_2__anon_16712
	ldr	x26, [sp, #152]
	tbnz	w0, #0, LBB63_34
; %bb.32:                               ; %select.end239
                                        ;   in Loop: Header=BB63_31 Depth=1
	ldr	x19, [sp, #136]
	mov	x0, x25
	mov	x2, x26
	mov	x1, x19
	blr	x28
	ldr	x8, [sp, #144]
	and	w9, w0, #0xff
	cmp	w9, #1
	mov	x28, x25
	csel	x9, xzr, x20, eq
	mov	x1, x26
	add	x25, x8, x24
	csel	x27, x20, xzr, eq
	add	x0, x25, x9
	blr	x21
	add	x20, x26, x24
	add	x0, x25, x27
	mov	x1, x19
	str	x20, [sp, #152]
	blr	x21
	add	x1, x19, x24
	mov	x0, x28
	ldr	x28, [sp, #128]                 ; 8-byte Folded Reload
	mov	x2, x20
	add	x19, x25, x24
	str	x1, [sp, #136]
	blr	x28
	and	w8, w0, #0xff
	add	x9, sp, #152
	cmp	w8, #1
	add	x8, sp, #136
	csel	x20, x8, x9, eq
	mov	x0, x19
	ldr	x1, [x20]
	blr	x21
	ldr	x8, [x20]
	add	x25, x19, x24
	add	x8, x8, x24
	str	x25, [sp, #144]
	str	x8, [x20]
	ldr	x20, [sp, #80]                  ; 8-byte Folded Reload
	ldr	x26, [sp, #152]
	ldr	x27, [sp, #136]
	cmp	x22, x26
	b.hs	LBB63_35
; %bb.33:                               ; %select.end239
                                        ;   in Loop: Header=BB63_31 Depth=1
	cmp	x23, x27
	b.lo	LBB63_31
	b	LBB63_35
LBB63_34:                               ; %.._crit_edge.loopexit_crit_edge
	ldp	x27, x25, [sp, #136]
LBB63_35:                               ; %._crit_edge.loopexit
	ldr	x24, [sp, #56]                  ; 8-byte Folded Reload
	ldr	x28, [sp, #88]                  ; 8-byte Folded Reload
LBB63_36:                               ; %._crit_edge
	cmp	x26, x24
	b.lo	LBB63_41
; %bb.37:                               ; %._crit_edge
	cmp	x27, x28
	b.lo	LBB63_41
; %bb.38:                               ; %.lr.ph55
	neg	x19, x20
	add	x20, sp, #152
	add	x22, sp, #136
LBB63_39:                               ; %select.end
                                        ; =>This Inner Loop Header: Depth=1
	ldp	x0, x8, [sp, #120]              ; 16-byte Folded Reload
	mov	x1, x27
	mov	x2, x26
	blr	x8
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x23, x22, x20, eq
	ldr	x1, [x23]
	blr	x21
	ldr	x8, [x23]
	add	x25, x25, x19
	add	x8, x8, x19
	str	x8, [x23]
	ldr	x26, [sp, #152]
	cmp	x26, x24
	b.lo	LBB63_41
; %bb.40:                               ; %select.end
                                        ;   in Loop: Header=BB63_39 Depth=1
	ldr	x27, [sp, #136]
	cmp	x27, x28
	b.hs	LBB63_39
LBB63_41:                               ; %.preheader
	ldr	x20, [sp, #80]                  ; 8-byte Folded Reload
	cmp	x26, x24
	b.lo	LBB63_44
; %bb.42:                               ; %.lr.ph62.preheader
	mov	x19, xzr
LBB63_43:                               ; %.lr.ph62
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x26, x19
	add	x0, x25, x19
	blr	x21
	sub	x19, x19, x20
	add	x8, x26, x19
	cmp	x8, x24
	b.hs	LBB63_43
LBB63_44:                               ; %common.ret1
	ldp	x29, x30, [sp, #256]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #240]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #208]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #192]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #176]            ; 16-byte Folded Reload
	add	sp, sp, #272
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end63:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.rotate_merge_block__anon_16493
l_sort.rotate_merge_block__anon_16493:  ; @sort.rotate_merge_block__anon_16493
Lfunc_begin64:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #192
	.cfi_def_cfa_offset 192
	stp	x28, x27, [sp, #96]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #176]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	sub	x8, x3, #1
	madd	x23, x3, x7, x0
	str	x1, [sp, #32]                   ; 8-byte Folded Spill
	mov	x26, x0
	madd	x1, x8, x7, x0
	mov	x22, x2
	ldr	x8, [sp, #192]
	mov	x0, x6
	mov	x2, x23
	mov	x19, x7
	mov	x20, x6
	mov	x24, x3
	mov	x21, x5
	mov	x27, x4
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	blr	x5
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB64_36
; %bb.1:                                ; %.lr.ph
	mov	x28, x24
	neg	x8, x19
	str	x22, [sp, #56]                  ; 8-byte Folded Spill
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
LBB64_2:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB64_4 Depth 2
                                        ;     Child Loop BB64_21 Depth 2
                                        ;     Child Loop BB64_25 Depth 2
                                        ;     Child Loop BB64_29 Depth 2
	lsr	x8, x28, #1
	cmp	x27, #2
	str	x26, [sp, #64]                  ; 8-byte Folded Spill
	stp	x28, x8, [sp, #72]              ; 16-byte Folded Spill
	sub	x8, x28, x8
	madd	x28, x27, x19, x23
	str	x8, [sp, #88]                   ; 8-byte Folded Spill
	mul	x8, x8, x19
	add	x22, x26, x8
	str	x8, [sp, #48]                   ; 8-byte Folded Spill
	b.lo	LBB64_5
; %bb.3:                                ; %.lr.ph.i.preheader
                                        ;   in Loop: Header=BB64_2 Depth=1
	mov	x26, x27
LBB64_4:                                ; %.lr.ph.i
                                        ;   Parent Loop BB64_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	lsr	x25, x26, #1
	mov	x0, x20
	mov	x1, x22
	msub	x24, x25, x19, x28
	mov	x2, x24
	blr	x21
	and	w8, w0, #0xff
	sub	x26, x26, x25
	cmp	w8, #1
	csel	x28, x28, x24, eq
	cmp	x26, #1
	b.hi	LBB64_4
LBB64_5:                                ; %sort.monobound_binary_first__anon_16713.exit
                                        ;   in Loop: Header=BB64_2 Depth=1
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	mov	x0, x20
	mov	x1, x22
	add	x24, x28, x8
	mov	x2, x24
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x28, x24, eq
	sub	x8, x8, x23
	ldp	x3, x26, [sp, #56]              ; 16-byte Folded Reload
	udiv	x24, x8, x19
	cmp	x8, x19
	ldp	x28, x25, [sp, #80]             ; 16-byte Folded Reload
	b.lo	LBB64_31
; %bb.6:                                ;   in Loop: Header=BB64_2 Depth=1
	add	x8, x24, x25
	cmp	x8, x3
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
	b.ls	LBB64_11
; %bb.7:                                ;   in Loop: Header=BB64_2 Depth=1
	mov	x0, x22
	add	x1, x24, x28
	ldp	x22, x23, [sp, #24]             ; 16-byte Folded Reload
	mov	x4, x28
	mov	x5, x19
	mov	x6, x22
	mov	x2, x23
	bl	l_sort.trinity_rotation
	lsl	x8, x25, #1
	cmp	x25, x24, lsl #1
	ldr	x9, [sp, #56]                   ; 8-byte Folded Reload
	ccmp	x8, x24, #0, ls
	b.hs	LBB64_10
; %bb.8:                                ;   in Loop: Header=BB64_2 Depth=1
	cmp	x24, x9
	b.ls	LBB64_17
; %bb.9:                                ; %.critedge
                                        ;   in Loop: Header=BB64_2 Depth=1
	ldr	x23, [sp, #32]                  ; 8-byte Folded Reload
	cmp	x25, x9
	b.ls	LBB64_18
LBB64_10:                               ; %.critedge3
                                        ;   in Loop: Header=BB64_2 Depth=1
	mov	x0, x26
	mov	x1, x23
	mov	x2, x9
	mov	x3, x25
	mov	x4, x24
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	str	x22, [sp]
	bl	l_sort.rotate_merge_block__anon_16493
	b	LBB64_19
LBB64_11:                               ;   in Loop: Header=BB64_2 Depth=1
	ldr	x22, [sp, #32]                  ; 8-byte Folded Reload
	mov	x1, x26
	ldr	x28, [sp, #48]                  ; 8-byte Folded Reload
	mov	x0, x22
	mov	x2, x28
	bl	_memcpy
	mul	x2, x24, x19
	add	x0, x22, x28
	mov	x1, x23
	ldr	x28, [sp, #80]                  ; 8-byte Folded Reload
	bl	_memcpy
	mul	x8, x28, x19
	ldr	x7, [sp, #24]                   ; 8-byte Folded Reload
	cbz	x8, LBB64_30
; %bb.12:                               ; %iter.check
                                        ;   in Loop: Header=BB64_2 Depth=1
	ldr	x9, [sp, #16]                   ; 8-byte Folded Reload
	cmp	x8, #8
	madd	x9, x9, x19, x26
	b.lo	LBB64_28
; %bb.13:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB64_2 Depth=1
	ldr	x16, [sp, #72]                  ; 8-byte Folded Reload
	sub	x12, x26, #1
	mov	w13, #1
	sub	x13, x13, x8
	add	x10, x16, x24
	mul	x11, x16, x19
	madd	x10, x10, x19, x12
	add	x15, x12, x11
	add	x14, x10, x13
	add	x13, x15, x13
	cmp	x14, x10
	ccmp	x13, x15, #2, ls
	b.hi	LBB64_28
; %bb.14:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB64_2 Depth=1
	madd	x12, x16, x19, x12
	sub	x10, x12, x10
	cmp	x10, #32
	b.lo	LBB64_28
; %bb.15:                               ; %vector.main.loop.iter.check
                                        ;   in Loop: Header=BB64_2 Depth=1
	cmp	x8, #32
	b.hs	LBB64_20
; %bb.16:                               ;   in Loop: Header=BB64_2 Depth=1
	mov	x10, xzr
	b	LBB64_24
LBB64_17:                               ;   in Loop: Header=BB64_2 Depth=1
	mov	x0, x26
	ldr	x1, [sp, #16]                   ; 8-byte Folded Reload
	ldr	x2, [sp, #32]                   ; 8-byte Folded Reload
	mov	x3, x9
	ldr	x4, [sp, #88]                   ; 8-byte Folded Reload
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	str	x22, [sp]
	bl	l_sort.partial_backwards_merge__anon_16492
	b	LBB64_19
LBB64_18:                               ;   in Loop: Header=BB64_2 Depth=1
	mov	x0, x26
	ldr	x1, [sp, #16]                   ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x9
	ldr	x4, [sp, #88]                   ; 8-byte Folded Reload
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	str	x22, [sp]
	bl	l_sort.partial_forward_merge__anon_16714
LBB64_19:                               ;   in Loop: Header=BB64_2 Depth=1
	ldr	x3, [sp, #56]                   ; 8-byte Folded Reload
	ldr	x25, [sp, #88]                  ; 8-byte Folded Reload
	b	LBB64_31
LBB64_20:                               ; %vector.ph
                                        ;   in Loop: Header=BB64_2 Depth=1
	and	x10, x8, #0xffffffffffffffe0
	add	x13, x26, x11
	mov	x12, xzr
	sub	x13, x13, #16
	neg	x14, x10
LBB64_21:                               ; %vector.body
                                        ;   Parent Loop BB64_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x13, #-16]
	mvn	x15, x12
	add	x12, x12, #32
	add	x15, x8, x15
	sub	x13, x13, #32
	add	x15, x9, x15
	adds	x14, x14, #32
	stur	q0, [x15, #-15]
	stur	q1, [x15, #-31]
	b.ne	LBB64_21
; %bb.22:                               ; %middle.block
                                        ;   in Loop: Header=BB64_2 Depth=1
	cmp	x8, x10
	b.eq	LBB64_30
; %bb.23:                               ; %vec.epilog.iter.check
                                        ;   in Loop: Header=BB64_2 Depth=1
	tst	x8, #0x18
	b.eq	LBB64_27
LBB64_24:                               ; %vec.epilog.ph
                                        ;   in Loop: Header=BB64_2 Depth=1
	sub	x14, x11, x10
	and	x13, x8, #0xfffffffffffffff8
	add	x14, x26, x14
	and	x12, x8, #0x7
	sub	x11, x9, #7
	sub	x14, x14, #8
	sub	x15, x10, x13
LBB64_25:                               ; %vec.epilog.vector.body
                                        ;   Parent Loop BB64_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mvn	x16, x10
	add	x10, x10, #8
	add	x16, x8, x16
	adds	x15, x15, #8
	ldr	d0, [x14], #-8
	str	d0, [x11, x16]
	b.ne	LBB64_25
; %bb.26:                               ; %vec.epilog.middle.block
                                        ;   in Loop: Header=BB64_2 Depth=1
	cmp	x8, x13
	mov	x8, x12
	b.ne	LBB64_28
	b	LBB64_30
LBB64_27:                               ;   in Loop: Header=BB64_2 Depth=1
	and	x8, x8, #0x1f
LBB64_28:                               ; %.lr.ph.i103.preheader
                                        ;   in Loop: Header=BB64_2 Depth=1
	ldr	x10, [sp, #48]                  ; 8-byte Folded Reload
	add	x10, x26, x10
	sub	x10, x10, #1
LBB64_29:                               ; %.lr.ph.i103
                                        ;   Parent Loop BB64_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	subs	x11, x8, #1
	ldrb	w12, [x10, x8]
	mov	x8, x11
	strb	w12, [x9, x11]
	b.ne	LBB64_29
LBB64_30:                               ; %mem.copyBackwards__anon_9784.exit
                                        ;   in Loop: Header=BB64_2 Depth=1
	mov	x0, x26
	mov	x1, x22
	mov	x2, x25
	mov	x3, x24
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.cross_merge__anon_14859
	ldr	x25, [sp, #88]                  ; 8-byte Folded Reload
	ldr	x3, [sp, #56]                   ; 8-byte Folded Reload
LBB64_31:                               ;   in Loop: Header=BB64_2 Depth=1
	ldr	x8, [sp, #72]                   ; 8-byte Folded Reload
	cmp	x27, x24
	b.eq	LBB64_36
; %bb.32:                               ;   in Loop: Header=BB64_2 Depth=1
	sub	x27, x27, x24
	and	x8, x8, #0xfffffffffffffffe
	lsl	x9, x27, #1
	cmp	x8, x27
	ccmp	x28, x9, #2, hs
	add	x1, x27, x28
	cset	w8, hi
	cmp	x27, x3
	eor	w9, w8, #0x1
	csinc	w9, w9, wzr, ls
	cmp	w9, #1
	b.ne	LBB64_37
; %bb.33:                               ;   in Loop: Header=BB64_2 Depth=1
	cmp	x1, x3
	b.ls	LBB64_37
; %bb.34:                               ;   in Loop: Header=BB64_2 Depth=1
	add	x9, x24, x25
	cmp	x25, x3
	csel	w8, wzr, w8, hi
	madd	x26, x9, x19, x26
	cmp	w8, #1
	b.eq	LBB64_38
; %bb.35:                               ; %.critedge9
                                        ;   in Loop: Header=BB64_2 Depth=1
	sub	x8, x28, #1
	madd	x23, x28, x19, x26
	mov	x0, x20
	madd	x1, x8, x19, x26
	mov	x2, x23
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB64_2
LBB64_36:                               ; %common.ret1
	ldp	x29, x30, [sp, #176]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #160]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             ; 16-byte Folded Reload
	add	sp, sp, #192
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB64_37:                               ; %.critedge7
	.cfi_restore_state
	.cfi_remember_state
	add	x8, x24, x25
	mov	x4, x28
	mov	x5, x21
	mov	x6, x20
	madd	x0, x8, x19, x26
	mov	x7, x19
	ldp	x8, x2, [sp, #24]               ; 16-byte Folded Reload
	ldp	x29, x30, [sp, #176]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #160]            ; 16-byte Folded Reload
	str	x8, [sp, #192]
	ldp	x22, x21, [sp, #144]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             ; 16-byte Folded Reload
	add	sp, sp, #192
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_backwards_merge__anon_16492
LBB64_38:
	.cfi_restore_state
	mov	x0, x26
	mov	x4, x28
	ldp	x8, x2, [sp, #24]               ; 16-byte Folded Reload
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #176]            ; 16-byte Folded Reload
	str	x8, [sp, #192]
	ldp	x20, x19, [sp, #160]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             ; 16-byte Folded Reload
	add	sp, sp, #192
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge__anon_16714
Lfunc_end64:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.parity_merge__anon_16495
l_sort.parity_merge__anon_16495:        ; @sort.parity_merge__anon_16495
Lfunc_begin65:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	add	x8, x3, x2
	add	x28, x1, x2, lsl #3
	sub	x26, x28, #8
	mov	x24, x6
	add	x8, x0, x8, lsl #3
	mov	x20, x5
	mov	x23, x2
	mov	x22, x1
	mov	x21, x0
	mov	x19, x4
	add	x27, x26, x3, lsl #3
	sub	x25, x8, #8
	cmp	x2, x3
	b.hs	LBB65_2
; %bb.1:                                ; %.cont16
	mov	x0, x20
	mov	w1, #1
	blr	x24
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x28]
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x28, x22, eq
	ldr	x9, [x8], #8
	csel	x28, x8, x28, eq
	csel	x22, x22, x8, eq
	str	x9, [x21], #8
LBB65_2:                                ; %.cont25
	lsl	x1, x23, #1
	mov	x0, x20
	blr	x24
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x28]
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x9, x28, x22, eq
	subs	x23, x23, #1
	ldr	x10, [x9]
	str	x10, [x21]
	b.eq	LBB65_5
; %bb.3:                                ; %.cont.preheader
	add	x9, x9, #8
	cmp	w8, #1
	csel	x22, x22, x9, eq
	csel	x24, x9, x28, eq
	add	x21, x21, #8
LBB65_4:                                ; %.cont
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x24]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x24, x22, eq
	ldr	x9, [x8], #8
	csel	x24, x8, x24, eq
	csel	x22, x22, x8, eq
	str	x9, [x21], #8
	ldr	x1, [x26]
	ldr	x2, [x27]
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x26, x27, eq
	ldr	x9, [x8], #-8
	csel	x27, x27, x8, eq
	csel	x26, x8, x26, eq
	subs	x23, x23, #1
	str	x9, [x25], #-8
	b.ne	LBB65_4
LBB65_5:                                ; %.cont50
	ldr	x1, [x26]
	mov	x0, x20
	ldr	x2, [x27]
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x26, x27, eq
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldr	x8, [x8]
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	str	x8, [x25]
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end65:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.quad_swap_merge__anon_16497
l_sort.quad_swap_merge__anon_16497:     ; @sort.quad_swap_merge__anon_16497
Lfunc_begin66:
	.cfi_startproc
; %bb.0:                                ; %.cont19
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x28, x27, [sp, #48]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	mov	x21, x0
	mov	x19, x2
	mov	x22, x0
	mov	x27, x1
	ldr	x1, [x0]
	mov	x0, x3
	ldr	x2, [x21, #16]!
	mov	x20, x3
	blr	x19
	and	w8, w0, #0xff
	mov	x10, x21
	cmp	w8, #1
	str	x21, [sp, #32]                  ; 8-byte Folded Spill
	cset	w8, eq
	csel	x9, x21, x22, eq
	ubfiz	x8, x8, #4, #32
	add	x9, x9, #8
	csel	x21, x22, x9, eq
	csel	x23, x9, x10, eq
	mov	x0, x20
	ldr	x8, [x22, x8]
	str	x8, [x27]
	ldr	x1, [x21]
	ldr	x2, [x23]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x23, x21, eq
	mov	x23, x22
	mov	x21, x22
	ldr	x8, [x8]
	str	x8, [x27, #8]
	ldr	x1, [x23, #8]!
	ldr	x2, [x21, #24]!
	blr	x19
	and	w8, w0, #0xff
	mov	w11, #24
	cmp	w8, #1
	mov	w9, #8
	csel	x10, x23, x21, eq
	cmp	w8, #1
	csel	x8, x9, x11, eq
	mov	x12, x21
	mov	x11, x27
	sub	x9, x10, #8
	str	x21, [sp, #24]                  ; 8-byte Folded Spill
	csel	x21, x9, x23, eq
	ldr	x8, [x22, x8]
	csel	x24, x12, x9, eq
	mov	x0, x20
	str	x8, [x11, #24]!
	ldr	x1, [x21]
	str	x11, [sp, #16]                  ; 8-byte Folded Spill
	ldr	x2, [x24]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x24, eq
	mov	x21, x22
	mov	x24, x22
	ldr	x8, [x8]
	str	x8, [x27, #16]
	ldr	x1, [x21, #32]!
	ldr	x2, [x24, #48]!
	blr	x19
	and	w9, w0, #0xff
	mov	w8, #32
	mov	w10, #48
	cmp	w9, #1
	csel	x8, x10, x8, eq
	csel	x9, x24, x21, eq
	mov	x10, x21
	str	x21, [sp, #40]                  ; 8-byte Folded Spill
	mov	x11, x24
	mov	x21, x27
	ldr	x8, [x22, x8]
	add	x9, x9, #8
	str	x24, [sp, #8]                   ; 8-byte Folded Spill
	csel	x24, x10, x9, eq
	csel	x25, x9, x11, eq
	mov	x0, x20
	str	x8, [x21, #32]!
	ldr	x1, [x24]
	ldr	x2, [x25]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x25, x24, eq
	mov	x25, x22
	mov	x24, x22
	ldr	x8, [x8]
	str	x8, [x27, #40]
	ldr	x1, [x25, #40]!
	ldr	x2, [x24, #56]!
	blr	x19
	and	w8, w0, #0xff
	mov	w11, #56
	cmp	w8, #1
	mov	w9, #40
	csel	x10, x25, x24, eq
	cmp	w8, #1
	csel	x8, x9, x11, eq
	mov	x26, x27
	sub	x9, x10, #8
	str	x25, [sp]                       ; 8-byte Folded Spill
	csel	x28, x9, x25, eq
	csel	x25, x24, x9, eq
	ldr	x8, [x22, x8]
	mov	x0, x20
	str	x8, [x26, #56]!
	ldr	x1, [x28]
	ldr	x2, [x25]
	blr	x19
	and	w8, w0, #0xff
	ldr	x1, [x27]
	cmp	w8, #1
	ldr	x2, [x21]
	csel	x8, x28, x25, eq
	mov	x0, x20
	ldr	x8, [x8]
	str	x8, [x27, #48]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	cset	w8, eq
	csel	x9, x21, x27, eq
	ubfiz	x8, x8, #5, #32
	add	x9, x9, #8
	csel	x25, x27, x9, eq
	csel	x21, x9, x21, eq
	ldr	x8, [x27, x8]
	str	x8, [x22]
	ldr	x1, [x25]
	ldr	x2, [x21]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x25, eq
	ldr	x9, [x8], #8
	csel	x22, x25, x8, eq
	csel	x21, x8, x21, eq
	str	x9, [x23]
	ldr	x1, [x22]
	ldr	x2, [x21]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x22, eq
	ldr	x9, [x8], #8
	csel	x22, x22, x8, eq
	csel	x21, x8, x21, eq
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	str	x9, [x8]
	ldr	x1, [x22]
	ldr	x2, [x21]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x22, eq
	ldp	x21, x9, [sp, #16]              ; 16-byte Folded Reload
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x1, [x21]
	ldr	x2, [x26]
	blr	x19
	and	w8, w0, #0xff
	mov	w10, #56
	cmp	w8, #1
	mov	x0, x20
	csel	x9, x21, x26, eq
	cmp	w8, #1
	mov	w8, #24
	sub	x9, x9, #8
	csel	x8, x8, x10, eq
	csel	x21, x9, x21, eq
	csel	x22, x26, x9, eq
	ldr	x8, [x27, x8]
	str	x8, [x24]
	ldr	x1, [x21]
	ldr	x2, [x22]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x22, eq
	ldr	x9, [x8], #-8
	csel	x21, x8, x21, eq
	csel	x22, x22, x8, eq
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	str	x9, [x8]
	ldr	x1, [x21]
	ldr	x2, [x22]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x21, x22, eq
	ldr	x9, [x8], #-8
	csel	x21, x8, x21, eq
	csel	x22, x22, x8, eq
	ldr	x8, [sp]                        ; 8-byte Folded Reload
	str	x9, [x8]
	ldr	x1, [x21]
	ldr	x2, [x22]
	blr	x19
	and	w8, w0, #0xff
	ldr	x9, [sp, #40]                   ; 8-byte Folded Reload
	cmp	w8, #1
	csel	x8, x21, x22, eq
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             ; 16-byte Folded Reload
	ldr	x8, [x8]
	str	x8, [x9]
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end66:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_backwards_merge__anon_16502
l_sort.partial_backwards_merge__anon_16502: ; @sort.partial_backwards_merge__anon_16502
Lfunc_begin67:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #208
	.cfi_def_cfa_offset 208
	stp	x28, x27, [sp, #112]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #128]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	subs	x26, x1, x4
	str	x5, [sp, #64]                   ; 8-byte Folded Spill
	b.eq	LBB67_39
; %bb.1:
	lsl	x8, x1, #3
	lsl	x22, x4, #3
	sub	x10, x22, #8
	mov	x27, x1
	mov	x25, x0
	add	x20, x0, x10
	stp	x8, x3, [sp, #24]               ; 16-byte Folded Spill
	add	x8, x8, x0
	sub	x19, x8, #8
	mov	x0, x6
	mov	w1, #1
	mov	x28, x6
	mov	x24, x4
	str	x10, [sp, #16]                  ; 8-byte Folded Spill
	stp	x20, x19, [sp, #72]
	mov	x23, x2
	mov	x21, x7
	blr	x7
	add	x22, x25, x22
	ldr	x1, [x20]
	mov	x0, x28
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	ldr	x2, [x22]
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	b.ne	LBB67_39
; %bb.2:
	cmp	x27, x8
	str	x28, [sp, #8]                   ; 8-byte Folded Spill
	stp	x25, x21, [sp, #48]             ; 16-byte Folded Spill
	str	x23, [sp, #40]                  ; 8-byte Folded Spill
	b.hi	LBB67_5
; %bb.3:
	cmp	x26, #64
	b.lo	LBB67_5
; %bb.4:
	ldp	x19, x20, [sp, #40]             ; 16-byte Folded Reload
	mov	x2, x24
	mov	x3, x26
	ldp	x6, x4, [sp, #56]               ; 16-byte Folded Reload
	mov	x0, x19
	ldr	x5, [sp, #8]                    ; 8-byte Folded Reload
	mov	x1, x20
	bl	l_sort.cross_merge__anon_14862
	mov	x0, x20
	mov	x1, x19
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            ; 16-byte Folded Reload
	ldr	x2, [sp, #24]                   ; 8-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_memcpy
LBB67_5:
	.cfi_restore_state
	ldr	x28, [sp, #40]                  ; 8-byte Folded Reload
	lsl	x24, x26, #3
	mov	x1, x22
	mov	x2, x24
	mov	x0, x28
	bl	_memcpy
	ldp	x21, x9, [sp, #8]               ; 16-byte Folded Reload
	sub	x8, x24, #8
	ldp	x26, x23, [sp, #48]             ; 16-byte Folded Reload
	add	x22, x28, x8
	ldr	x27, [sp, #64]                  ; 8-byte Folded Reload
	cmp	x9, #129
	str	x22, [sp, #88]
	b.lt	LBB67_24
; %bb.6:
	cmp	x8, #129
	b.lt	LBB67_24
; %bb.7:
	add	x8, x26, #128
	add	x25, x28, #128
	str	x8, [sp, #32]                   ; 8-byte Folded Spill
LBB67_8:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB67_11 Depth 2
                                        ;     Child Loop BB67_16 Depth 2
	mov	x0, x21
	mov	w1, #1
	blr	x23
	ldr	x1, [x20]
	mov	x0, x21
	ldur	x2, [x22, #-120]
	blr	x27
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB67_10
; %bb.9:                                ;   in Loop: Header=BB67_8 Depth=1
	ldr	x8, [x22]
	str	x8, [x19]
	ldur	x8, [x22, #-8]
	stur	x8, [x19, #-8]
	ldur	x8, [x22, #-16]
	stur	x8, [x19, #-16]
	ldur	x8, [x22, #-24]
	stur	x8, [x19, #-24]
	ldur	x8, [x22, #-32]
	stur	x8, [x19, #-32]
	ldur	x8, [x22, #-40]
	stur	x8, [x19, #-40]
	ldur	x8, [x22, #-48]
	stur	x8, [x19, #-48]
	ldur	x8, [x22, #-56]
	stur	x8, [x19, #-56]
	ldur	x8, [x22, #-64]
	stur	x8, [x19, #-64]
	ldur	x8, [x22, #-72]
	stur	x8, [x19, #-72]
	ldur	x8, [x22, #-80]
	stur	x8, [x19, #-80]
	ldur	x8, [x22, #-88]
	stur	x8, [x19, #-88]
	ldur	x8, [x22, #-96]
	stur	x8, [x19, #-96]
	ldur	x8, [x22, #-104]
	stur	x8, [x19, #-104]
	ldur	x8, [x22, #-112]
	stur	x8, [x19, #-112]
	ldur	x8, [x22, #-120]
	sub	x22, x22, #128
	cmp	x22, x25
	stur	x8, [x19, #-120]
	sub	x19, x19, #128
	b.hi	LBB67_8
	b	LBB67_22
LBB67_10:                               ; %.preheader2
                                        ;   in Loop: Header=BB67_8 Depth=1
	mov	x28, xzr
	ldr	x26, [sp, #72]
	ldr	x23, [sp, #32]                  ; 8-byte Folded Reload
	str	x22, [sp, #88]
LBB67_11:                               ;   Parent Loop BB67_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x21
	mov	w1, #1
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	add	x27, x26, x28
	blr	x8
	ldur	x1, [x27, #-120]
	mov	x0, x21
	ldr	x2, [x22]
	ldr	x8, [sp, #64]                   ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB67_13
; %bb.12:                               ;   in Loop: Header=BB67_11 Depth=2
	ldr	x8, [x27]
	add	x9, x19, x28
	sub	x28, x28, #128
	add	x20, x26, x28
	str	x8, [x9]
	cmp	x20, x23
	ldur	x8, [x27, #-8]
	stur	x8, [x9, #-8]
	ldur	x8, [x27, #-16]
	stur	x8, [x9, #-16]
	ldur	x8, [x27, #-24]
	stur	x8, [x9, #-24]
	ldur	x8, [x27, #-32]
	stur	x8, [x9, #-32]
	ldur	x8, [x27, #-40]
	stur	x8, [x9, #-40]
	ldur	x8, [x27, #-48]
	stur	x8, [x9, #-48]
	ldur	x8, [x27, #-56]
	stur	x8, [x9, #-56]
	ldur	x8, [x27, #-64]
	stur	x8, [x9, #-64]
	ldur	x8, [x27, #-72]
	stur	x8, [x9, #-72]
	ldur	x8, [x27, #-80]
	stur	x8, [x9, #-80]
	ldur	x8, [x27, #-88]
	stur	x8, [x9, #-88]
	ldur	x8, [x27, #-96]
	stur	x8, [x9, #-96]
	ldur	x8, [x27, #-104]
	stur	x8, [x9, #-104]
	ldur	x8, [x27, #-112]
	stur	x8, [x9, #-112]
	ldur	x8, [x27, #-120]
	stur	x8, [x9, #-120]
	b.hi	LBB67_11
	b	LBB67_23
LBB67_13:                               ; %.preheader1
                                        ;   in Loop: Header=BB67_8 Depth=1
	add	x19, x19, x28
	mov	x20, #-8
	stp	x27, x19, [sp, #72]
	ldp	x23, x27, [sp, #56]             ; 16-byte Folded Reload
	b	LBB67_16
LBB67_14:                               ;   in Loop: Header=BB67_16 Depth=2
	ldr	x8, [x28]
	sub	x9, x28, #16
	str	x8, [x19]
	ldur	x8, [x28, #-8]
	stur	x8, [x19, #-8]
	sub	x19, x19, #16
	str	x9, [sp, #88]
LBB67_15:                               ;   in Loop: Header=BB67_16 Depth=2
	cmn	x20, #1
	add	x20, x20, #1
	b.hs	LBB67_20
LBB67_16:                               ;   Parent Loop BB67_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	mov	x0, x21
	mov	w1, #1
	ldr	x22, [sp, #72]
	ldr	x28, [sp, #88]
	blr	x23
	mov	x26, x28
	ldr	x1, [x22]
	mov	x0, x21
	ldr	x2, [x26, #-8]!
	blr	x27
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB67_14
; %bb.17:                               ;   in Loop: Header=BB67_16 Depth=2
	mov	x0, x21
	mov	w1, #1
	blr	x23
	mov	x24, x27
	mov	x27, x22
	ldr	x2, [x28]
	mov	x0, x21
	ldr	x1, [x27, #-8]!
	blr	x24
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB67_19
; %bb.18:                               ;   in Loop: Header=BB67_16 Depth=2
	ldr	x8, [x22]
	sub	x9, x22, #16
	mov	x27, x24
	str	x8, [x19]
	ldur	x8, [x22, #-8]
	stur	x8, [x19, #-8]
	sub	x19, x19, #16
	str	x9, [sp, #72]
	b	LBB67_15
LBB67_19:                               ; %select.end133
                                        ;   in Loop: Header=BB67_16 Depth=2
	mov	x0, x21
	mov	w1, #2
	blr	x23
	ldr	x1, [x22]
	mov	x0, x21
	ldr	x2, [x28]
	blr	x24
	and	w8, w0, #0xff
	sub	x9, x19, #8
	cmp	w8, #1
	ldr	x10, [x28]
	cset	w8, ne
	cset	w11, eq
	mov	x0, x21
	str	x10, [x9, w8, uxtw #3]
	ldr	x8, [x22]
	str	x26, [sp, #88]
	str	x8, [x9, w11, uxtw #3]
	ldur	x1, [x22, #-8]
	str	x27, [sp, #72]
	ldur	x2, [x28, #-8]
	blr	x24
	and	w8, w0, #0xff
	add	x9, sp, #72
	cmp	w8, #1
	add	x8, sp, #88
	csel	x8, x9, x8, eq
	mov	x27, x24
	ldr	x9, [x8]
	ldr	x10, [x9], #-8
	stur	x10, [x19, #-16]
	sub	x19, x19, #24
	str	x9, [x8]
	b	LBB67_15
LBB67_20:                               ; %.loopexit
                                        ;   in Loop: Header=BB67_8 Depth=1
	ldp	x8, x28, [sp, #32]              ; 16-byte Folded Reload
	str	x19, [sp, #80]
	ldr	x20, [sp, #72]
	ldr	x22, [sp, #88]
	ldr	x26, [sp, #48]                  ; 8-byte Folded Reload
	cmp	x20, x8
	b.ls	LBB67_24
; %bb.21:                               ; %.loopexit
                                        ;   in Loop: Header=BB67_8 Depth=1
	cmp	x22, x25
	b.hi	LBB67_8
	b	LBB67_24
LBB67_22:                               ; %.loopexit5
	ldr	x20, [sp, #72]
	stp	x19, x22, [sp, #80]
	b	LBB67_24
LBB67_23:                               ; %.loopexit3
	add	x19, x19, x28
	ldr	x22, [sp, #88]
	ldp	x28, x26, [sp, #40]             ; 16-byte Folded Reload
	ldp	x23, x27, [sp, #56]             ; 16-byte Folded Reload
	stp	x20, x19, [sp, #72]
LBB67_24:                               ; %.loopexit6
	add	x24, x28, #8
	cmp	x24, x22
	b.hs	LBB67_32
; %bb.25:                               ; %.loopexit6
	add	x25, x26, #8
	cmp	x25, x20
	b.hs	LBB67_32
; %bb.26:
	ldp	x23, x27, [sp, #56]             ; 16-byte Folded Reload
	add	x26, sp, #88
LBB67_27:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	add	x0, sp, #80
	add	x1, sp, #96
	add	x2, sp, #72
	add	x3, sp, #104
	add	x4, sp, #88
	mov	x5, x27
	mov	x6, x21
	mov	x7, x23
	stp	x8, x28, [sp, #96]
	bl	l_sort.partial_forward_merge_right_tail_2__anon_16723
	tbnz	w0, #0, LBB67_31
; %bb.28:                               ; %select.end129
                                        ;   in Loop: Header=BB67_27 Depth=1
	mov	x0, x21
	mov	w1, #2
	blr	x23
	ldr	x19, [sp, #72]
	mov	x0, x21
	ldr	x20, [sp, #88]
	ldr	x1, [x19]
	ldr	x2, [x20]
	blr	x27
	ldr	x28, [sp, #80]
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x9, [x20]
	cset	w8, ne
	cset	w11, eq
	sub	x10, x28, #8
	mov	x0, x21
	str	x9, [x10, w8, uxtw #3]
	ldr	x8, [x19]
	str	x8, [x10, w11, uxtw #3]
	ldr	x2, [x20, #-8]!
	ldr	x1, [x19, #-8]!
	str	x20, [sp, #88]
	str	x19, [sp, #72]
	blr	x27
	and	w8, w0, #0xff
	sub	x19, x28, #24
	cmp	w8, #1
	add	x8, sp, #72
	csel	x8, x8, x26, eq
	str	x19, [sp, #80]
	ldr	x9, [x8]
	ldr	x10, [x9], #-8
	str	x9, [x8]
	ldr	x22, [sp, #88]
	ldr	x20, [sp, #72]
	stur	x10, [x28, #-16]
	ldr	x28, [sp, #40]                  ; 8-byte Folded Reload
	cmp	x24, x22
	b.hs	LBB67_30
; %bb.29:                               ; %select.end129
                                        ;   in Loop: Header=BB67_27 Depth=1
	cmp	x25, x20
	b.lo	LBB67_27
LBB67_30:                               ; %._crit_edge.loopexit
	ldp	x26, x23, [sp, #48]             ; 16-byte Folded Reload
	ldr	x27, [sp, #64]                  ; 8-byte Folded Reload
	b	LBB67_32
LBB67_31:                               ; %.lr.ph.._crit_edge.loopexit_crit_edge
	ldp	x19, x22, [sp, #80]
	ldr	x20, [sp, #72]
	ldr	x26, [sp, #48]                  ; 8-byte Folded Reload
LBB67_32:                               ; %._crit_edge
	cmp	x22, x28
	b.lo	LBB67_37
; %bb.33:                               ; %._crit_edge
	cmp	x20, x26
	b.lo	LBB67_37
; %bb.34:
	add	x24, sp, #88
	add	x25, sp, #72
LBB67_35:                               ; %.lr.ph25
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x21
	mov	w1, #1
	blr	x23
	ldr	x1, [x20]
	mov	x0, x21
	ldr	x2, [x22]
	blr	x27
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x25, x24, eq
	ldr	x9, [x8]
	ldr	x10, [x9], #-8
	str	x10, [x19], #-8
	str	x9, [x8]
	ldr	x22, [sp, #88]
	cmp	x22, x28
	b.lo	LBB67_37
; %bb.36:                               ; %.lr.ph25
                                        ;   in Loop: Header=BB67_35 Depth=1
	ldr	x20, [sp, #72]
	cmp	x20, x26
	b.hs	LBB67_35
LBB67_37:                               ; %.preheader
	cmp	x22, x28
	str	x19, [sp, #80]
	b.lo	LBB67_39
LBB67_38:                               ; %.lr.ph31
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [x22], #-8
	cmp	x22, x28
	str	x8, [x19], #-8
	b.hs	LBB67_38
LBB67_39:                               ; %common.ret1
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end67:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.rotate_merge_block__anon_16503
l_sort.rotate_merge_block__anon_16503:  ; @sort.rotate_merge_block__anon_16503
Lfunc_begin68:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #176
	.cfi_def_cfa_offset 176
	stp	x28, x27, [sp, #80]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #160]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	str	x1, [sp, #40]                   ; 8-byte Folded Spill
	mov	x24, x0
	mov	x0, x6
	mov	w1, #1
	mov	x25, x7
	mov	x20, x6
	mov	x21, x5
	mov	x26, x4
	mov	x27, x3
	mov	x22, x2
	blr	x7
	add	x19, x24, x27, lsl #3
	mov	x0, x20
	ldp	x1, x2, [x19, #-8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB68_37
; %bb.1:
	str	x25, [sp, #24]                  ; 8-byte Folded Spill
	str	x22, [sp, #48]                  ; 8-byte Folded Spill
LBB68_2:                                ; %.lr.ph
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB68_4 Depth 2
                                        ;     Child Loop BB68_31 Depth 2
                                        ;     Child Loop BB68_35 Depth 2
                                        ;     Child Loop BB68_22 Depth 2
	lsr	x22, x27, #1
	sub	x8, x26, #1
	sub	x9, x27, x22
	stp	x27, x24, [sp, #64]             ; 16-byte Folded Spill
	lsl	x27, x9, #3
	clz	x8, x8
	mov	x0, x20
	add	x28, x24, x27
	str	x9, [sp, #56]                   ; 8-byte Folded Spill
	mov	w9, #65
	sub	x1, x9, x8
	add	x23, x19, x26, lsl #3
	blr	x25
	cmp	x26, #2
	str	x27, [sp, #32]                  ; 8-byte Folded Spill
	b.lo	LBB68_5
; %bb.3:                                ; %.lr.ph.i.preheader
                                        ;   in Loop: Header=BB68_2 Depth=1
	mov	x24, x26
LBB68_4:                                ; %.lr.ph.i
                                        ;   Parent Loop BB68_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	lsr	x27, x24, #1
	ldr	x1, [x28]
	mov	x0, x20
	sub	x25, x23, x27, lsl #3
	ldr	x2, [x25]
	blr	x21
	and	w8, w0, #0xff
	sub	x24, x24, x27
	cmp	w8, #1
	csel	x23, x23, x25, eq
	cmp	x24, #1
	b.hi	LBB68_4
LBB68_5:                                ; %sort.monobound_binary_first__anon_16724.exit
                                        ;   in Loop: Header=BB68_2 Depth=1
	mov	x24, x23
	ldr	x1, [x28]
	mov	x0, x20
	ldr	x2, [x24, #-8]!
	blr	x21
	and	w8, w0, #0xff
	mov	x27, x22
	cmp	w8, #1
	ldr	x25, [sp, #24]                  ; 8-byte Folded Reload
	csel	x8, x23, x24, eq
	ldp	x3, x22, [sp, #48]              ; 16-byte Folded Reload
	sub	x24, x8, x19
	lsr	x23, x24, #3
	cmp	x24, #7
	b.ls	LBB68_25
; %bb.6:                                ;   in Loop: Header=BB68_2 Depth=1
	add	x8, x23, x22
	cmp	x8, x3
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
	b.ls	LBB68_10
; %bb.7:                                ;   in Loop: Header=BB68_2 Depth=1
	add	x1, x23, x27
	mov	x0, x28
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	mov	x4, x27
	mov	w5, #8
	mov	x19, x3
	bl	l_sort.trinity_rotation.9
	mov	x2, x19
	ldr	x0, [sp, #72]                   ; 8-byte Folded Reload
	cmp	x22, x23, lsl #1
	b.hi	LBB68_17
; %bb.8:                                ;   in Loop: Header=BB68_2 Depth=1
	lsl	x8, x22, #1
	cmp	x8, x23
	b.lo	LBB68_17
LBB68_9:                                ; %.critedge3
                                        ;   in Loop: Header=BB68_2 Depth=1
	ldr	x1, [sp, #40]                   ; 8-byte Folded Reload
	mov	x3, x22
	mov	x4, x23
	mov	x5, x21
	mov	x6, x20
	mov	x7, x25
	bl	l_sort.rotate_merge_block__anon_16503
	mov	x3, x19
	b	LBB68_25
LBB68_10:                               ;   in Loop: Header=BB68_2 Depth=1
	ldp	x22, x28, [sp, #32]             ; 16-byte Folded Reload
	str	x27, [sp, #8]                   ; 8-byte Folded Spill
	mov	x27, x25
	ldr	x25, [sp, #72]                  ; 8-byte Folded Reload
	mov	x2, x22
	mov	x0, x28
	mov	x1, x25
	bl	_memcpy
	add	x0, x28, x22
	and	x2, x24, #0xfffffffffffffff8
	mov	x1, x19
	mov	x24, x25
	mov	x25, x27
	ldr	x27, [sp, #8]                   ; 8-byte Folded Reload
	ldr	x22, [sp, #56]                  ; 8-byte Folded Reload
	bl	_memcpy
	ldr	x15, [sp, #64]                  ; 8-byte Folded Reload
	cmp	x15, #2
	b.lo	LBB68_23
; %bb.11:                               ; %iter.check
                                        ;   in Loop: Header=BB68_2 Depth=1
	lsl	x8, x27, #3
	cbz	x8, LBB68_20
; %bb.12:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB68_2 Depth=1
	add	x9, x15, x23
	sub	x11, x24, #1
	lsl	x9, x9, #3
	mov	w12, #1
	add	x10, x11, x9
	sub	x12, x12, x8
	add	x13, x10, x12
	cmp	x13, x10
	b.hi	LBB68_20
; %bb.13:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB68_2 Depth=1
	lsl	x10, x15, #3
	add	x13, x11, x10
	add	x12, x13, x12
	cmp	x12, x13
	b.hi	LBB68_20
; %bb.14:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB68_2 Depth=1
	add	x12, x15, x23
	add	x13, x11, x15, lsl #3
	add	x11, x11, x12, lsl #3
	sub	x12, x13, x11
	mov	x11, x8
	cmp	x12, #32
	b.lo	LBB68_21
; %bb.15:                               ; %vector.main.loop.iter.check
                                        ;   in Loop: Header=BB68_2 Depth=1
	cmp	x8, #32
	b.hs	LBB68_30
; %bb.16:                               ;   in Loop: Header=BB68_2 Depth=1
	mov	x11, xzr
	b	LBB68_34
LBB68_17:                               ;   in Loop: Header=BB68_2 Depth=1
	cmp	x23, x2
	b.ls	LBB68_24
; %bb.18:                               ; %.critedge
                                        ;   in Loop: Header=BB68_2 Depth=1
	cmp	x22, x2
	b.hi	LBB68_9
; %bb.19:                               ;   in Loop: Header=BB68_2 Depth=1
	ldr	x1, [sp, #16]                   ; 8-byte Folded Reload
	mov	x3, x19
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x25
	bl	l_sort.partial_forward_merge__anon_16725
	mov	x3, x19
	b	LBB68_25
LBB68_20:                               ;   in Loop: Header=BB68_2 Depth=1
	mov	x11, x8
LBB68_21:                               ; %.lr.ph.i103.preheader
                                        ;   in Loop: Header=BB68_2 Depth=1
	ldr	x9, [sp, #16]                   ; 8-byte Folded Reload
	add	x13, x11, x15, lsl #3
	sub	x12, x24, #1
	sub	x8, x13, x8
	add	x8, x12, x8
	lsl	x10, x9, #3
	neg	x9, x11
	add	x10, x11, x10
	add	x10, x12, x10
LBB68_22:                               ; %.lr.ph.i103
                                        ;   Parent Loop BB68_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldrb	w11, [x8], #-1
	cmn	x9, #1
	add	x9, x9, #1
	strb	w11, [x10], #-1
	b.lo	LBB68_22
LBB68_23:                               ; %mem.copyBackwards__anon_9784.exit
                                        ;   in Loop: Header=BB68_2 Depth=1
	mov	x0, x24
	ldr	x1, [sp, #40]                   ; 8-byte Folded Reload
	mov	x2, x22
	mov	x3, x23
	mov	x4, x21
	mov	x5, x20
	mov	x6, x25
	bl	l_sort.cross_merge__anon_14862
	ldr	x3, [sp, #48]                   ; 8-byte Folded Reload
	b	LBB68_25
LBB68_24:                               ;   in Loop: Header=BB68_2 Depth=1
	ldr	x1, [sp, #16]                   ; 8-byte Folded Reload
	mov	x3, x19
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x25
	bl	l_sort.partial_backwards_merge__anon_16502
	mov	x3, x19
LBB68_25:                               ;   in Loop: Header=BB68_2 Depth=1
	ldp	x8, x24, [sp, #64]              ; 16-byte Folded Reload
	cmp	x26, x23
	b.eq	LBB68_37
; %bb.26:                               ;   in Loop: Header=BB68_2 Depth=1
	sub	x26, x26, x23
	and	x8, x8, #0xfffffffffffffffe
	lsl	x9, x26, #1
	cmp	x8, x26
	ccmp	x27, x9, #2, hs
	add	x1, x26, x27
	cset	w8, hi
	cmp	x26, x3
	eor	w9, w8, #0x1
	csinc	w9, w9, wzr, ls
	cmp	w9, #1
	b.ne	LBB68_38
; %bb.27:                               ;   in Loop: Header=BB68_2 Depth=1
	cmp	x1, x3
	b.ls	LBB68_38
; %bb.28:                               ;   in Loop: Header=BB68_2 Depth=1
	add	x9, x23, x22
	cmp	x22, x3
	csel	w8, wzr, w8, hi
	add	x24, x24, x9, lsl #3
	cmp	w8, #1
	b.eq	LBB68_39
; %bb.29:                               ; %.critedge9
                                        ;   in Loop: Header=BB68_2 Depth=1
	mov	x0, x20
	mov	w1, #1
	blr	x25
	add	x19, x24, x27, lsl #3
	mov	x0, x20
	ldp	x1, x2, [x19, #-8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB68_2
	b	LBB68_37
LBB68_30:                               ; %vector.ph
                                        ;   in Loop: Header=BB68_2 Depth=1
	lsr	x14, x15, #3
	sub	x13, x24, #16
	and	x11, x8, #0xffffffffffffffe0
	add	x12, x13, x9
	add	x13, x13, x10
	neg	x14, x14, lsl #5
LBB68_31:                               ; %vector.body
                                        ;   Parent Loop BB68_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x13, #-16]
	sub	x13, x13, #32
	adds	x14, x14, #32
	stp	q1, q0, [x12, #-16]
	sub	x12, x12, #32
	b.ne	LBB68_31
; %bb.32:                               ; %middle.block
                                        ;   in Loop: Header=BB68_2 Depth=1
	cmp	x8, x11
	b.eq	LBB68_23
; %bb.33:                               ; %vec.epilog.iter.check
                                        ;   in Loop: Header=BB68_2 Depth=1
	tst	x15, #0x6
	b.eq	LBB68_36
LBB68_34:                               ; %vec.epilog.vector.body.preheader
                                        ;   in Loop: Header=BB68_2 Depth=1
	sub	x12, x24, #8
	sub	x9, x9, x11
	sub	x10, x10, x11
	add	x9, x12, x9
	add	x10, x12, x10
	sub	x8, x11, x8
LBB68_35:                               ; %vec.epilog.vector.body
                                        ;   Parent Loop BB68_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	d0, [x10], #-8
	adds	x8, x8, #8
	str	d0, [x9], #-8
	b.ne	LBB68_35
	b	LBB68_23
LBB68_36:                               ;   in Loop: Header=BB68_2 Depth=1
	and	x11, x8, #0x18
	b	LBB68_21
LBB68_37:                               ; %common.ret1
	ldp	x29, x30, [sp, #160]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #144]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #176
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB68_38:                               ; %.critedge7
	.cfi_restore_state
	.cfi_remember_state
	add	x8, x23, x22
	mov	x4, x27
	mov	x5, x21
	mov	x6, x20
	add	x0, x24, x8, lsl #3
	mov	x7, x25
	ldp	x29, x30, [sp, #160]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #144]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             ; 16-byte Folded Reload
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	add	sp, sp, #176
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_backwards_merge__anon_16502
LBB68_39:
	.cfi_restore_state
	mov	x0, x24
	mov	x4, x27
	mov	x5, x21
	mov	x6, x20
	mov	x7, x25
	ldr	x2, [sp, #40]                   ; 8-byte Folded Reload
	ldp	x29, x30, [sp, #160]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #144]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #176
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge__anon_16725
Lfunc_end68:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.parity_merge__anon_16505
l_sort.parity_merge__anon_16505:        ; @sort.parity_merge__anon_16505
Lfunc_begin69:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	add	x8, x3, x2
	add	x27, x1, x2, lsl #3
	sub	x25, x27, #8
	mov	x20, x5
	add	x8, x0, x8, lsl #3
	mov	x19, x4
	mov	x23, x2
	mov	x22, x1
	mov	x21, x0
	add	x26, x25, x3, lsl #3
	sub	x24, x8, #8
	cmp	x2, x3
	b.hs	LBB69_2
; %bb.1:                                ; %.cont16
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x27]
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x27, x22, eq
	ldr	x9, [x8], #8
	csel	x27, x8, x27, eq
	csel	x22, x22, x8, eq
	str	x9, [x21], #8
LBB69_2:                                ; %.cont25
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x27]
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x9, x27, x22, eq
	subs	x23, x23, #1
	ldr	x10, [x9]
	str	x10, [x21]
	b.eq	LBB69_5
; %bb.3:                                ; %.cont.preheader
	add	x9, x9, #8
	cmp	w8, #1
	csel	x22, x22, x9, eq
	csel	x27, x9, x27, eq
	add	x21, x21, #8
LBB69_4:                                ; %.cont
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x22]
	mov	x0, x20
	ldr	x2, [x27]
	blr	x19
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x27, x22, eq
	ldr	x9, [x8], #8
	csel	x27, x8, x27, eq
	csel	x22, x22, x8, eq
	str	x9, [x21], #8
	ldr	x1, [x25]
	ldr	x2, [x26]
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x25, x26, eq
	ldr	x9, [x8], #-8
	csel	x26, x26, x8, eq
	csel	x25, x8, x25, eq
	subs	x23, x23, #1
	str	x9, [x24], #-8
	b.ne	LBB69_4
LBB69_5:                                ; %.cont50
	ldr	x1, [x25]
	mov	x0, x20
	ldr	x2, [x26]
	blr	x19
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x25, x26, eq
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldr	x8, [x8]
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	str	x8, [x24]
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end69:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_backwards_merge__anon_16511
l_sort.partial_backwards_merge__anon_16511: ; @sort.partial_backwards_merge__anon_16511
Lfunc_begin70:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #192
	.cfi_def_cfa_offset 192
	stp	x28, x27, [sp, #96]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #176]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	subs	x28, x1, x4
	b.eq	LBB70_40
; %bb.1:
	lsl	x8, x4, #3
	mov	x26, x1
	sub	x10, x8, #8
	add	x11, x0, x8
	add	x19, x0, x10
	mov	x25, x2
	mov	x20, x0
	mov	x21, x6
	str	x10, [sp, #16]                  ; 8-byte Folded Spill
	lsl	x10, x1, #3
	add	x8, x10, x0
	ldr	x1, [x19]
	sub	x22, x8, #8
	ldr	x2, [x11]
	mov	x0, x6
	mov	x23, x5
	mov	x24, x4
	mov	x27, x3
	stp	x11, x10, [sp]                  ; 16-byte Folded Spill
	stp	x19, x22, [sp, #56]
	blr	x5
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB70_40
; %bb.2:
	cmp	x26, x27
	stp	x21, x23, [sp, #40]             ; 16-byte Folded Spill
	stp	x25, x20, [sp, #24]             ; 16-byte Folded Spill
	b.hi	LBB70_5
; %bb.3:
	cmp	x28, #64
	b.lo	LBB70_5
; %bb.4:
	ldp	x19, x20, [sp, #24]             ; 16-byte Folded Reload
	mov	x2, x24
	mov	x3, x28
	ldp	x5, x4, [sp, #40]               ; 16-byte Folded Reload
	mov	x0, x19
	mov	x1, x20
	bl	l_sort.cross_merge__anon_14865
	mov	x0, x20
	mov	x1, x19
	ldp	x29, x30, [sp, #176]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #160]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             ; 16-byte Folded Reload
	ldr	x2, [sp, #8]                    ; 8-byte Folded Reload
	add	sp, sp, #192
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_memcpy
LBB70_5:
	.cfi_restore_state
	lsl	x23, x28, #3
	ldr	x0, [sp, #24]                   ; 8-byte Folded Reload
	ldr	x1, [sp]                        ; 8-byte Folded Reload
	mov	x2, x23
	mov	x28, x0
	bl	_memcpy
	ldp	x26, x27, [sp, #32]             ; 16-byte Folded Reload
	sub	x8, x23, #8
	ldr	x9, [sp, #16]                   ; 8-byte Folded Reload
	add	x23, x28, x8
	cmp	x9, #129
	str	x23, [sp, #72]
	b.lt	LBB70_25
; %bb.6:
	ldr	x24, [sp, #48]                  ; 8-byte Folded Reload
	cmp	x8, #129
	b.lt	LBB70_25
; %bb.7:
	add	x25, x26, #128
	add	x20, x28, #128
LBB70_8:                                ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB70_11 Depth 2
                                        ;     Child Loop BB70_16 Depth 2
	ldr	x1, [x19]
	mov	x0, x27
	ldur	x2, [x23, #-120]
	blr	x24
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB70_10
; %bb.9:                                ;   in Loop: Header=BB70_8 Depth=1
	ldr	x8, [x23]
	str	x8, [x22]
	ldur	x8, [x23, #-8]
	stur	x8, [x22, #-8]
	ldur	x8, [x23, #-16]
	stur	x8, [x22, #-16]
	ldur	x8, [x23, #-24]
	stur	x8, [x22, #-24]
	ldur	x8, [x23, #-32]
	stur	x8, [x22, #-32]
	ldur	x8, [x23, #-40]
	stur	x8, [x22, #-40]
	ldur	x8, [x23, #-48]
	stur	x8, [x22, #-48]
	ldur	x8, [x23, #-56]
	stur	x8, [x22, #-56]
	ldur	x8, [x23, #-64]
	stur	x8, [x22, #-64]
	ldur	x8, [x23, #-72]
	stur	x8, [x22, #-72]
	ldur	x8, [x23, #-80]
	stur	x8, [x22, #-80]
	ldur	x8, [x23, #-88]
	stur	x8, [x22, #-88]
	ldur	x8, [x23, #-96]
	stur	x8, [x22, #-96]
	ldur	x8, [x23, #-104]
	stur	x8, [x22, #-104]
	ldur	x8, [x23, #-112]
	stur	x8, [x22, #-112]
	ldur	x8, [x23, #-120]
	sub	x23, x23, #128
	cmp	x23, x20
	stur	x8, [x22, #-120]
	sub	x22, x22, #128
	b.hi	LBB70_8
	b	LBB70_23
LBB70_10:                               ; %.preheader2
                                        ;   in Loop: Header=BB70_8 Depth=1
	mov	x28, xzr
	ldr	x26, [sp, #56]
	str	x23, [sp, #72]
LBB70_11:                               ;   Parent Loop BB70_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	add	x27, x26, x28
	ldr	x2, [x23]
	ldr	x0, [sp, #40]                   ; 8-byte Folded Reload
	ldur	x1, [x27, #-120]
	blr	x24
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB70_13
; %bb.12:                               ;   in Loop: Header=BB70_11 Depth=2
	ldr	x8, [x27]
	add	x9, x22, x28
	sub	x28, x28, #128
	add	x19, x26, x28
	str	x8, [x9]
	cmp	x19, x25
	ldur	x8, [x27, #-8]
	stur	x8, [x9, #-8]
	ldur	x8, [x27, #-16]
	stur	x8, [x9, #-16]
	ldur	x8, [x27, #-24]
	stur	x8, [x9, #-24]
	ldur	x8, [x27, #-32]
	stur	x8, [x9, #-32]
	ldur	x8, [x27, #-40]
	stur	x8, [x9, #-40]
	ldur	x8, [x27, #-48]
	stur	x8, [x9, #-48]
	ldur	x8, [x27, #-56]
	stur	x8, [x9, #-56]
	ldur	x8, [x27, #-64]
	stur	x8, [x9, #-64]
	ldur	x8, [x27, #-72]
	stur	x8, [x9, #-72]
	ldur	x8, [x27, #-80]
	stur	x8, [x9, #-80]
	ldur	x8, [x27, #-88]
	stur	x8, [x9, #-88]
	ldur	x8, [x27, #-96]
	stur	x8, [x9, #-96]
	ldur	x8, [x27, #-104]
	stur	x8, [x9, #-104]
	ldur	x8, [x27, #-112]
	stur	x8, [x9, #-112]
	ldur	x8, [x27, #-120]
	stur	x8, [x9, #-120]
	b.hi	LBB70_11
	b	LBB70_24
LBB70_13:                               ; %.preheader1
                                        ;   in Loop: Header=BB70_8 Depth=1
	add	x22, x22, x28
	mov	x19, #-8
	stp	x27, x22, [sp, #56]
	ldr	x27, [sp, #40]                  ; 8-byte Folded Reload
	b	LBB70_16
LBB70_14:                               ;   in Loop: Header=BB70_16 Depth=2
	ldr	x8, [x23]
	sub	x9, x23, #16
	str	x8, [x22]
	ldur	x8, [x23, #-8]
	stur	x8, [x22, #-8]
	sub	x22, x22, #16
	str	x9, [sp, #72]
LBB70_15:                               ;   in Loop: Header=BB70_16 Depth=2
	cmn	x19, #1
	add	x19, x19, #1
	b.hs	LBB70_21
LBB70_16:                               ;   Parent Loop BB70_8 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	x23, [sp, #72]
	mov	x0, x27
	ldr	x26, [sp, #56]
	mov	x28, x23
	ldr	x1, [x26]
	ldr	x2, [x28, #-8]!
	blr	x24
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB70_14
; %bb.17:                               ;   in Loop: Header=BB70_16 Depth=2
	mov	x21, x24
	mov	x24, x27
	mov	x27, x26
	ldr	x2, [x23]
	mov	x0, x24
	ldr	x1, [x27, #-8]!
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB70_19
; %bb.18:                               ;   in Loop: Header=BB70_16 Depth=2
	ldr	x8, [x26]
	sub	x9, x26, #16
	str	x8, [x22]
	ldur	x8, [x26, #-8]
	stur	x8, [x22, #-8]
	sub	x22, x22, #16
	str	x9, [sp, #56]
	b	LBB70_20
LBB70_19:                               ; %select.end136
                                        ;   in Loop: Header=BB70_16 Depth=2
	ldr	x1, [x26]
	mov	x0, x24
	ldr	x2, [x23]
	blr	x21
	and	w8, w0, #0xff
	sub	x9, x22, #8
	cmp	w8, #1
	ldr	x10, [x23]
	cset	w8, ne
	cset	w11, eq
	mov	x0, x24
	str	x10, [x9, w8, uxtw #3]
	ldr	x8, [x26]
	str	x28, [sp, #72]
	str	x8, [x9, w11, uxtw #3]
	ldur	x1, [x26, #-8]
	str	x27, [sp, #56]
	ldur	x2, [x23, #-8]
	blr	x21
	and	w8, w0, #0xff
	add	x9, sp, #56
	cmp	w8, #1
	add	x8, sp, #72
	csel	x8, x9, x8, eq
	ldr	x9, [x8]
	ldr	x10, [x9], #-8
	stur	x10, [x22, #-16]
	sub	x22, x22, #24
	str	x9, [x8]
LBB70_20:                               ;   in Loop: Header=BB70_16 Depth=2
	mov	x27, x24
	mov	x24, x21
	b	LBB70_15
LBB70_21:                               ; %.loopexit
                                        ;   in Loop: Header=BB70_8 Depth=1
	ldp	x28, x26, [sp, #24]             ; 16-byte Folded Reload
	str	x22, [sp, #64]
	ldr	x19, [sp, #56]
	ldr	x23, [sp, #72]
	cmp	x19, x25
	b.ls	LBB70_25
; %bb.22:                               ; %.loopexit
                                        ;   in Loop: Header=BB70_8 Depth=1
	cmp	x23, x20
	b.hi	LBB70_8
	b	LBB70_25
LBB70_23:                               ; %.loopexit5
	ldr	x19, [sp, #56]
	stp	x22, x23, [sp, #64]
	b	LBB70_25
LBB70_24:                               ; %.loopexit3
	add	x22, x22, x28
	ldr	x23, [sp, #72]
	ldp	x28, x26, [sp, #24]             ; 16-byte Folded Reload
	ldr	x27, [sp, #40]                  ; 8-byte Folded Reload
	stp	x19, x22, [sp, #56]
LBB70_25:                               ; %.loopexit6
	add	x24, x28, #8
	cmp	x24, x23
	b.hs	LBB70_33
; %bb.26:                               ; %.loopexit6
	add	x25, x26, #8
	cmp	x25, x19
	b.hs	LBB70_33
; %bb.27:
	add	x26, sp, #56
	add	x21, sp, #72
	ldr	x27, [sp, #40]                  ; 8-byte Folded Reload
LBB70_28:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x22, [sp, #48]                  ; 8-byte Folded Reload
	add	x0, sp, #64
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	add	x1, sp, #80
	add	x2, sp, #56
	add	x3, sp, #88
	add	x4, sp, #72
	mov	x5, x22
	mov	x6, x27
	stp	x8, x28, [sp, #80]
	bl	l_sort.partial_forward_merge_right_tail_2__anon_16734
	ldr	x23, [sp, #72]
	tbnz	w0, #0, LBB70_32
; %bb.29:                               ; %select.end132
                                        ;   in Loop: Header=BB70_28 Depth=1
	ldr	x19, [sp, #56]
	mov	x0, x27
	ldr	x2, [x23]
	ldr	x1, [x19]
	blr	x22
	ldr	x28, [sp, #64]
	and	w8, w0, #0xff
	cmp	w8, #1
	ldr	x9, [x23]
	cset	w8, ne
	cset	w11, eq
	sub	x10, x28, #8
	mov	x0, x27
	str	x9, [x10, w8, uxtw #3]
	ldr	x8, [x19]
	str	x8, [x10, w11, uxtw #3]
	ldr	x2, [x23, #-8]!
	ldr	x1, [x19, #-8]!
	str	x23, [sp, #72]
	str	x19, [sp, #56]
	blr	x22
	and	w8, w0, #0xff
	sub	x22, x28, #24
	cmp	w8, #1
	csel	x8, x26, x21, eq
	str	x22, [sp, #64]
	ldr	x9, [x8]
	ldr	x10, [x9], #-8
	str	x9, [x8]
	ldr	x23, [sp, #72]
	ldr	x19, [sp, #56]
	stur	x10, [x28, #-16]
	ldr	x28, [sp, #24]                  ; 8-byte Folded Reload
	cmp	x24, x23
	b.hs	LBB70_31
; %bb.30:                               ; %select.end132
                                        ;   in Loop: Header=BB70_28 Depth=1
	cmp	x25, x19
	b.lo	LBB70_28
LBB70_31:                               ; %._crit_edge.loopexit
	ldp	x26, x27, [sp, #32]             ; 16-byte Folded Reload
	b	LBB70_33
LBB70_32:                               ; %.lr.ph.._crit_edge.loopexit_crit_edge
	ldp	x19, x22, [sp, #56]
	ldr	x26, [sp, #32]                  ; 8-byte Folded Reload
LBB70_33:                               ; %._crit_edge
	cmp	x23, x28
	b.lo	LBB70_38
; %bb.34:                               ; %._crit_edge
	cmp	x19, x26
	b.lo	LBB70_38
; %bb.35:
	add	x24, sp, #72
	add	x25, sp, #56
LBB70_36:                               ; %.lr.ph25
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x19]
	mov	x0, x27
	ldr	x2, [x23]
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x25, x24, eq
	ldr	x9, [x8]
	ldr	x10, [x9], #-8
	str	x10, [x22], #-8
	str	x9, [x8]
	ldr	x23, [sp, #72]
	cmp	x23, x28
	b.lo	LBB70_38
; %bb.37:                               ; %.lr.ph25
                                        ;   in Loop: Header=BB70_36 Depth=1
	ldr	x19, [sp, #56]
	cmp	x19, x26
	b.hs	LBB70_36
LBB70_38:                               ; %.preheader
	cmp	x23, x28
	str	x22, [sp, #64]
	b.lo	LBB70_40
LBB70_39:                               ; %.lr.ph31
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [x23], #-8
	cmp	x23, x28
	str	x8, [x22], #-8
	b.hs	LBB70_39
LBB70_40:                               ; %common.ret1
	ldp	x29, x30, [sp, #176]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #160]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             ; 16-byte Folded Reload
	add	sp, sp, #192
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end70:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.rotate_merge_block__anon_16512
l_sort.rotate_merge_block__anon_16512:  ; @sort.rotate_merge_block__anon_16512
Lfunc_begin71:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #160
	.cfi_def_cfa_offset 160
	stp	x28, x27, [sp, #64]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #80]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #96]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #112]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #128]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	add	x22, x0, x3, lsl #3
	mov	x21, x2
	str	x1, [sp, #24]                   ; 8-byte Folded Spill
	mov	x26, x0
	mov	x0, x6
	mov	x19, x6
	ldp	x1, x2, [x22, #-8]
	mov	x20, x5
	mov	x23, x3
	mov	x25, x4
	blr	x5
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB71_37
; %bb.1:
	str	x21, [sp, #32]                  ; 8-byte Folded Spill
LBB71_2:                                ; %.lr.ph
                                        ; =>This Loop Header: Depth=1
                                        ;     Child Loop BB71_4 Depth 2
                                        ;     Child Loop BB71_31 Depth 2
                                        ;     Child Loop BB71_35 Depth 2
                                        ;     Child Loop BB71_22 Depth 2
	lsr	x8, x23, #1
	add	x28, x22, x25, lsl #3
	sub	x9, x23, x8
	mov	x21, x26
	cmp	x25, #2
	str	x23, [sp, #40]                  ; 8-byte Folded Spill
	stp	x8, x9, [sp, #48]               ; 16-byte Folded Spill
	lsl	x9, x9, #3
	add	x27, x26, x9
	str	x9, [sp, #16]                   ; 8-byte Folded Spill
	b.lo	LBB71_5
; %bb.3:                                ; %.lr.ph.i.preheader
                                        ;   in Loop: Header=BB71_2 Depth=1
	mov	x24, x25
LBB71_4:                                ; %.lr.ph.i
                                        ;   Parent Loop BB71_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	lsr	x26, x24, #1
	ldr	x1, [x27]
	mov	x0, x19
	sub	x23, x28, x26, lsl #3
	ldr	x2, [x23]
	blr	x20
	and	w8, w0, #0xff
	sub	x24, x24, x26
	cmp	w8, #1
	csel	x28, x28, x23, eq
	cmp	x24, #1
	b.hi	LBB71_4
LBB71_5:                                ; %sort.monobound_binary_first__anon_16735.exit
                                        ;   in Loop: Header=BB71_2 Depth=1
	mov	x23, x28
	ldr	x1, [x27]
	mov	x0, x19
	ldr	x2, [x23, #-8]!
	blr	x20
	and	w8, w0, #0xff
	ldr	x3, [sp, #32]                   ; 8-byte Folded Reload
	cmp	w8, #1
	mov	x26, x21
	csel	x8, x28, x23, eq
	ldr	x21, [sp, #48]                  ; 8-byte Folded Reload
	sub	x24, x8, x22
	lsr	x28, x24, #3
	cmp	x24, #7
	b.ls	LBB71_25
; %bb.6:                                ;   in Loop: Header=BB71_2 Depth=1
	ldr	x23, [sp, #56]                  ; 8-byte Folded Reload
	add	x8, x28, x23
	cmp	x8, x3
	str	x8, [sp, #8]                    ; 8-byte Folded Spill
	b.ls	LBB71_10
; %bb.7:                                ;   in Loop: Header=BB71_2 Depth=1
	add	x1, x28, x21
	mov	x0, x27
	ldr	x2, [sp, #24]                   ; 8-byte Folded Reload
	mov	x4, x21
	mov	w5, #8
	mov	x22, x3
	bl	l_sort.trinity_rotation.9
	mov	x2, x22
	cmp	x23, x28, lsl #1
	b.hi	LBB71_17
; %bb.8:                                ;   in Loop: Header=BB71_2 Depth=1
	lsl	x8, x23, #1
	cmp	x8, x28
	b.lo	LBB71_17
LBB71_9:                                ; %.critedge3
                                        ;   in Loop: Header=BB71_2 Depth=1
	mov	x0, x26
	ldr	x1, [sp, #24]                   ; 8-byte Folded Reload
	mov	x3, x23
	mov	x4, x28
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.rotate_merge_block__anon_16512
	mov	x3, x22
	b	LBB71_25
LBB71_10:                               ;   in Loop: Header=BB71_2 Depth=1
	mov	x27, x26
	ldp	x21, x26, [sp, #16]             ; 16-byte Folded Reload
	mov	x1, x27
	mov	x2, x21
	mov	x0, x26
	bl	_memcpy
	add	x0, x26, x21
	and	x2, x24, #0xfffffffffffffff8
	mov	x1, x22
	ldr	x21, [sp, #48]                  ; 8-byte Folded Reload
	mov	x26, x27
	bl	_memcpy
	ldr	x15, [sp, #40]                  ; 8-byte Folded Reload
	cmp	x15, #2
	b.lo	LBB71_23
; %bb.11:                               ; %iter.check
                                        ;   in Loop: Header=BB71_2 Depth=1
	lsl	x8, x21, #3
	cbz	x8, LBB71_20
; %bb.12:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB71_2 Depth=1
	add	x9, x15, x28
	sub	x11, x26, #1
	lsl	x9, x9, #3
	mov	w12, #1
	add	x10, x11, x9
	sub	x12, x12, x8
	add	x13, x10, x12
	cmp	x13, x10
	b.hi	LBB71_20
; %bb.13:                               ; %vector.scevcheck
                                        ;   in Loop: Header=BB71_2 Depth=1
	lsl	x10, x15, #3
	add	x13, x11, x10
	add	x12, x13, x12
	cmp	x12, x13
	b.hi	LBB71_20
; %bb.14:                               ; %vector.memcheck
                                        ;   in Loop: Header=BB71_2 Depth=1
	add	x12, x15, x28
	add	x13, x11, x15, lsl #3
	add	x11, x11, x12, lsl #3
	sub	x12, x13, x11
	mov	x11, x8
	cmp	x12, #32
	b.lo	LBB71_21
; %bb.15:                               ; %vector.main.loop.iter.check
                                        ;   in Loop: Header=BB71_2 Depth=1
	cmp	x8, #32
	b.hs	LBB71_30
; %bb.16:                               ;   in Loop: Header=BB71_2 Depth=1
	mov	x11, xzr
	b	LBB71_34
LBB71_17:                               ;   in Loop: Header=BB71_2 Depth=1
	cmp	x28, x2
	b.ls	LBB71_24
; %bb.18:                               ; %.critedge
                                        ;   in Loop: Header=BB71_2 Depth=1
	cmp	x23, x2
	b.hi	LBB71_9
; %bb.19:                               ;   in Loop: Header=BB71_2 Depth=1
	mov	x0, x26
	ldr	x1, [sp, #8]                    ; 8-byte Folded Reload
	ldr	x2, [sp, #24]                   ; 8-byte Folded Reload
	mov	x3, x22
	mov	x4, x23
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.partial_forward_merge__anon_16736
	mov	x3, x22
	b	LBB71_25
LBB71_20:                               ;   in Loop: Header=BB71_2 Depth=1
	mov	x11, x8
LBB71_21:                               ; %.lr.ph.i103.preheader
                                        ;   in Loop: Header=BB71_2 Depth=1
	ldr	x9, [sp, #8]                    ; 8-byte Folded Reload
	add	x13, x11, x15, lsl #3
	sub	x12, x26, #1
	sub	x8, x13, x8
	add	x8, x12, x8
	lsl	x10, x9, #3
	neg	x9, x11
	add	x10, x11, x10
	add	x10, x12, x10
LBB71_22:                               ; %.lr.ph.i103
                                        ;   Parent Loop BB71_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldrb	w11, [x8], #-1
	cmn	x9, #1
	add	x9, x9, #1
	strb	w11, [x10], #-1
	b.lo	LBB71_22
LBB71_23:                               ; %mem.copyBackwards__anon_9784.exit
                                        ;   in Loop: Header=BB71_2 Depth=1
	mov	x0, x26
	ldr	x1, [sp, #24]                   ; 8-byte Folded Reload
	mov	x2, x23
	mov	x3, x28
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.cross_merge__anon_14865
	ldr	x3, [sp, #32]                   ; 8-byte Folded Reload
	b	LBB71_25
LBB71_24:                               ;   in Loop: Header=BB71_2 Depth=1
	mov	x0, x26
	ldr	x1, [sp, #8]                    ; 8-byte Folded Reload
	ldr	x2, [sp, #24]                   ; 8-byte Folded Reload
	mov	x3, x22
	mov	x4, x23
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.partial_backwards_merge__anon_16511
	mov	x3, x22
LBB71_25:                               ;   in Loop: Header=BB71_2 Depth=1
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	cmp	x25, x28
	b.eq	LBB71_37
; %bb.26:                               ;   in Loop: Header=BB71_2 Depth=1
	sub	x25, x25, x28
	and	x8, x8, #0xfffffffffffffffe
	lsl	x9, x25, #1
	cmp	x8, x25
	ccmp	x21, x9, #2, hs
	add	x1, x25, x21
	cset	w8, hi
	cmp	x25, x3
	eor	w9, w8, #0x1
	csinc	w9, w9, wzr, ls
	cmp	w9, #1
	b.ne	LBB71_38
; %bb.27:                               ;   in Loop: Header=BB71_2 Depth=1
	cmp	x1, x3
	b.ls	LBB71_38
; %bb.28:                               ;   in Loop: Header=BB71_2 Depth=1
	ldr	x10, [sp, #56]                  ; 8-byte Folded Reload
	add	x9, x28, x10
	cmp	x10, x3
	csel	w8, wzr, w8, hi
	add	x26, x26, x9, lsl #3
	cmp	w8, #1
	b.eq	LBB71_39
; %bb.29:                               ; %.critedge9
                                        ;   in Loop: Header=BB71_2 Depth=1
	add	x22, x26, x21, lsl #3
	mov	x0, x19
	ldp	x1, x2, [x22, #-8]
	blr	x20
	mov	x23, x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB71_2
	b	LBB71_37
LBB71_30:                               ; %vector.ph
                                        ;   in Loop: Header=BB71_2 Depth=1
	lsr	x14, x15, #3
	sub	x13, x26, #16
	and	x11, x8, #0xffffffffffffffe0
	add	x12, x13, x9
	add	x13, x13, x10
	neg	x14, x14, lsl #5
LBB71_31:                               ; %vector.body
                                        ;   Parent Loop BB71_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldp	q1, q0, [x13, #-16]
	sub	x13, x13, #32
	adds	x14, x14, #32
	stp	q1, q0, [x12, #-16]
	sub	x12, x12, #32
	b.ne	LBB71_31
; %bb.32:                               ; %middle.block
                                        ;   in Loop: Header=BB71_2 Depth=1
	cmp	x8, x11
	b.eq	LBB71_23
; %bb.33:                               ; %vec.epilog.iter.check
                                        ;   in Loop: Header=BB71_2 Depth=1
	tst	x15, #0x6
	b.eq	LBB71_36
LBB71_34:                               ; %vec.epilog.vector.body.preheader
                                        ;   in Loop: Header=BB71_2 Depth=1
	sub	x12, x26, #8
	sub	x9, x9, x11
	sub	x10, x10, x11
	add	x9, x12, x9
	add	x10, x12, x10
	sub	x8, x11, x8
LBB71_35:                               ; %vec.epilog.vector.body
                                        ;   Parent Loop BB71_2 Depth=1
                                        ; =>  This Inner Loop Header: Depth=2
	ldr	d0, [x10], #-8
	adds	x8, x8, #8
	str	d0, [x9], #-8
	b.ne	LBB71_35
	b	LBB71_23
LBB71_36:                               ;   in Loop: Header=BB71_2 Depth=1
	and	x11, x8, #0x18
	b	LBB71_21
LBB71_37:                               ; %common.ret1
	ldp	x29, x30, [sp, #144]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #128]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             ; 16-byte Folded Reload
	add	sp, sp, #160
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB71_38:                               ; %.critedge7
	.cfi_restore_state
	.cfi_remember_state
	ldr	x8, [sp, #56]                   ; 8-byte Folded Reload
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	ldp	x29, x30, [sp, #144]            ; 16-byte Folded Reload
	add	x8, x28, x8
	ldp	x20, x19, [sp, #128]            ; 16-byte Folded Reload
	add	x0, x26, x8, lsl #3
	ldp	x22, x21, [sp, #112]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             ; 16-byte Folded Reload
	ldr	x2, [sp, #24]                   ; 8-byte Folded Reload
	add	sp, sp, #160
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_backwards_merge__anon_16511
LBB71_39:
	.cfi_restore_state
	mov	x0, x26
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	ldp	x29, x30, [sp, #144]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #128]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #112]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #96]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #80]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #64]             ; 16-byte Folded Reload
	ldr	x2, [sp, #24]                   ; 8-byte Folded Reload
	add	sp, sp, #160
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge__anon_16736
Lfunc_end71:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.median_of_nine__anon_16513
l_sort.median_of_nine__anon_16513:      ; @sort.median_of_nine__anon_16513
Lfunc_begin72:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #1248
	.cfi_def_cfa_offset 1344
	mov	x8, #58255
	mov	x20, x0
	movk	x8, #36408, lsl #16
	add	x0, sp, #96
	movk	x8, #14563, lsl #32
	stp	x7, x6, [sp, #64]               ; 16-byte Folded Spill
	movk	x8, #58254, lsl #48
	mov	x21, x4
	mov	x19, x5
	mov	x23, x3
	umulh	x8, x1, x8
	mov	x1, x20
	mov	x22, x2
	add	x24, sp, #96
	lsr	x8, x8, #3
	mul	x25, x8, x4
	blr	x5
	add	x20, x20, x25
	add	x0, x24, x21
	mov	x1, x20
	str	x0, [sp, #88]                   ; 8-byte Folded Spill
	blr	x19
	lsl	x27, x21, #1
	add	x20, x20, x25
	add	x26, x24, x27
	mov	x1, x20
	mov	x0, x26
	str	x27, [sp, #80]                  ; 8-byte Folded Spill
	blr	x19
	add	x8, x27, x21
	add	x20, x20, x25
	add	x0, x24, x8
	mov	x1, x20
	str	x0, [sp, #48]                   ; 8-byte Folded Spill
	blr	x19
	lsl	x27, x21, #2
	add	x20, x20, x25
	add	x28, x24, x27
	mov	x1, x20
	mov	x0, x28
	blr	x19
	add	x8, x27, x21
	add	x20, x20, x25
	add	x0, x24, x8
	mov	x1, x20
	str	x0, [sp, #40]                   ; 8-byte Folded Spill
	blr	x19
	mov	w8, #6
	add	x20, x20, x25
	mov	x1, x20
	madd	x0, x21, x8, x24
	str	x0, [sp, #56]                   ; 8-byte Folded Spill
	blr	x19
	lsl	x27, x21, #3
	add	x20, x20, x25
	sub	x8, x27, x21
	mov	x1, x20
	add	x0, x24, x8
	blr	x19
	add	x1, x20, x25
	add	x0, x24, x27
	str	x0, [sp, #32]                   ; 8-byte Folded Spill
	blr	x19
	mov	x0, x23
	mov	w1, #4
	ldr	x25, [sp, #72]                  ; 8-byte Folded Reload
	blr	x25
	ldr	x27, [sp, #88]                  ; 8-byte Folded Reload
	add	x1, sp, #96
	mov	x0, x23
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1152
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x24, x8
	blr	x19
	add	x1, x24, x20
	add	x0, sp, #96
	blr	x19
	add	x1, sp, #1152
	mov	x0, x27
	blr	x19
	add	x27, x26, x21
	mov	x0, x23
	mov	x1, x26
	mov	x2, x27
	str	x27, [sp, #16]                  ; 8-byte Folded Spill
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1152
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x26, x8
	blr	x19
	add	x1, x26, x20
	mov	x0, x26
	blr	x19
	add	x1, sp, #1152
	mov	x0, x27
	blr	x19
	add	x1, sp, #96
	mov	x0, x23
	mov	x2, x26
	blr	x22
	ldr	x27, [sp, #80]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x0, x26
	csel	x8, xzr, x27, eq
	add	x1, x24, x8
	blr	x19
	ldr	x20, [sp, #88]                  ; 8-byte Folded Reload
	mov	x0, x23
	add	x2, x20, x27
	mov	x1, x20
	str	x2, [sp, #24]                   ; 8-byte Folded Spill
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x27, xzr, eq
	add	x1, x20, x8
	blr	x19
	mov	x0, x23
	mov	w1, #4
	blr	x25
	add	x20, x28, x21
	mov	x0, x23
	mov	x1, x28
	mov	x2, x20
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1152
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x25, x21, xzr, eq
	add	x1, x28, x8
	blr	x19
	add	x1, x28, x25
	mov	x0, x28
	blr	x19
	add	x1, sp, #1152
	mov	x0, x20
	blr	x19
	add	x25, x28, x27
	mov	x0, x23
	add	x27, x25, x21
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1152
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x24, x21, xzr, eq
	add	x1, x25, x8
	blr	x19
	add	x1, x25, x24
	mov	x0, x25
	blr	x19
	add	x1, sp, #1152
	mov	x0, x27
	blr	x19
	mov	x0, x23
	mov	x1, x28
	mov	x2, x25
	blr	x22
	ldr	x27, [sp, #80]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x0, x25
	csel	x8, xzr, x27, eq
	add	x1, x28, x8
	blr	x19
	add	x2, x20, x27
	mov	x0, x23
	mov	x1, x20
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x20
	cmp	w8, #1
	csel	x8, x27, xzr, eq
	add	x1, x20, x8
	blr	x19
	add	x0, sp, #96
	ldr	x1, [sp, #40]                   ; 8-byte Folded Reload
	blr	x19
	ldr	x0, [sp, #48]                   ; 8-byte Folded Reload
	ldr	x1, [sp, #32]                   ; 8-byte Folded Reload
	blr	x19
	mov	x0, x23
	mov	w1, #4
	ldr	x28, [sp, #72]                  ; 8-byte Folded Reload
	blr	x28
	ldr	x25, [sp, #88]                  ; 8-byte Folded Reload
	add	x1, sp, #96
	mov	x0, x23
	mov	x2, x25
	blr	x22
	and	w8, w0, #0xff
	add	x24, sp, #96
	cmp	w8, #1
	add	x0, sp, #1152
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x24, x8
	blr	x19
	add	x1, x24, x20
	add	x0, sp, #96
	blr	x19
	add	x1, sp, #1152
	mov	x0, x25
	blr	x19
	ldr	x24, [sp, #16]                  ; 8-byte Folded Reload
	mov	x0, x23
	mov	x1, x26
	mov	x2, x24
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1152
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x26, x8
	blr	x19
	add	x1, x26, x20
	mov	x0, x26
	blr	x19
	add	x1, sp, #1152
	mov	x0, x24
	blr	x19
	add	x1, sp, #96
	mov	x0, x23
	mov	x2, x26
	blr	x22
	and	w8, w0, #0xff
	add	x9, sp, #96
	cmp	w8, #1
	mov	x0, x26
	csel	x8, xzr, x27, eq
	add	x1, x9, x8
	blr	x19
	mov	x0, x23
	mov	x1, x25
	ldr	x2, [sp, #24]                   ; 8-byte Folded Reload
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, x27, xzr, eq
	add	x1, x25, x8
	blr	x19
	add	x0, sp, #96
	ldr	x1, [sp, #56]                   ; 8-byte Folded Reload
	blr	x19
	mov	x0, x23
	mov	w1, #3
	blr	x28
	add	x1, sp, #96
	mov	x0, x23
	mov	x2, x25
	blr	x22
	and	w8, w0, #0xff
	add	x1, sp, #96
	mov	x0, x23
	mov	x2, x26
	cmp	w8, #1
	cset	w20, eq
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x23
	mov	x1, x25
	mov	x2, x26
	cmp	w8, #1
	cset	w24, ne
	blr	x22
	and	w9, w0, #0xff
	eor	w8, w20, w24
	cmp	w9, #1
	ldr	x0, [sp, #64]                   ; 8-byte Folded Reload
	cset	w9, eq
	eor	w9, w20, w9
	add	x8, x9, x8
	add	x9, sp, #96
	madd	x1, x8, x21, x9
	blr	x19
	add	sp, sp, #1248
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end72:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.flux_reverse_partition__anon_16515
l_sort.flux_reverse_partition__anon_16515: ; @sort.flux_reverse_partition__anon_16515
Lfunc_begin73:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x28, x27, [sp, #32]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	ldp	x22, x21, [sp, #128]
	mov	x24, x1
	mov	x25, x0
	mov	x0, x6
	mov	x1, x4
	mov	x19, x7
	mov	x20, x6
	mov	x23, x5
	mov	x27, x4
	mov	x26, x3
	mov	x28, x2
	blr	x21
	cmp	x27, #8
	stp	x21, x25, [sp, #8]              ; 16-byte Folded Spill
	str	x24, [sp, #24]                  ; 8-byte Folded Spill
	b.lo	LBB73_3
; %bb.1:                                ; %.cont81.preheader
	lsr	x21, x27, #3
LBB73_2:                                ; %.cont81
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x28, x28, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x28, x28, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x28, x28, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x28, x28, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x28, x28, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x28, x28, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x28, x28, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	add	x28, x28, x19
	subs	x21, x21, #1
	b.ne	LBB73_2
LBB73_3:                                ; %._crit_edge
	ands	x21, x27, #0x7
	b.eq	LBB73_11
; %bb.4:                                ; %.cont
	mov	x0, x20
	mov	x1, x26
	mov	x2, x28
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x28
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	cmp	x21, #1
	b.eq	LBB73_11
; %bb.5:                                ; %.cont.1
	add	x27, x28, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x27
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	cmp	x21, #2
	b.eq	LBB73_11
; %bb.6:                                ; %.cont.2
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x27
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	cmp	x21, #3
	b.eq	LBB73_11
; %bb.7:                                ; %.cont.3
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x27
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	cmp	x21, #4
	b.eq	LBB73_11
; %bb.8:                                ; %.cont.4
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x27
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	cmp	x21, #5
	b.eq	LBB73_11
; %bb.9:                                ; %.cont.5
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x27
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
	cmp	x21, #6
	b.eq	LBB73_11
; %bb.10:                               ; %.cont.6
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x26
	mov	x2, x27
	blr	x23
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x25, x24, eq
	add	x8, x0, x19
	csel	x24, x24, x8, eq
	csel	x25, x8, x25, eq
	blr	x22
LBB73_11:                               ; %._crit_edge149
	ldr	x9, [sp, #16]                   ; 8-byte Folded Reload
	sub	x8, x25, x9
	mov	x25, x9
	ldr	x9, [sp, #24]                   ; 8-byte Folded Reload
	udiv	x27, x8, x19
	sub	x8, x24, x9
	mov	x1, x9
	mov	x24, x9
	madd	x0, x27, x19, x25
	udiv	x21, x8, x19
	mul	x2, x21, x19
	bl	_memcpy
	cmp	x27, #97
	b.lo	LBB73_14
; %bb.12:                               ; %._crit_edge149
	lsr	x8, x27, #4
	cmp	x21, x8
	b.ls	LBB73_14
; %bb.13:
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x25
	mov	x1, x24
	mov	x2, x25
	mov	x3, x26
	mov	x4, x27
	mov	x5, x23
	mov	x6, x20
	mov	x7, x19
	stp	x22, x8, [sp, #128]
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.flux_partition__anon_14854
LBB73_14:
	.cfi_restore_state
	.cfi_remember_state
	cmp	x27, #95
	b.hi	LBB73_16
; %bb.15:
	mov	x0, x25
	mov	x1, x27
	mov	x2, x24
	mov	x3, x23
	mov	x4, x20
	mov	x5, x19
	mov	x6, x22
	ldr	x7, [sp, #8]                    ; 8-byte Folded Reload
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.tail_swap__anon_14832
LBB73_16:
	.cfi_restore_state
	.cfi_remember_state
	ldr	x21, [sp, #8]                   ; 8-byte Folded Reload
	mov	x0, x25
	mov	x1, x27
	mov	x2, x23
	mov	x3, x20
	mov	x4, x19
	mov	x5, x22
	mov	x6, x21
	bl	l_sort.quad_swap__anon_14834
	tbz	w0, #0, LBB73_18
; %bb.17:
	mov	x0, x25
	mov	x1, x27
	mov	x2, x24
	mov	x3, x27
	mov	x4, x23
	mov	x5, x20
	mov	x6, x19
	mov	x7, x22
	str	x21, [sp]
	bl	l_sort.quad_merge__anon_14835
	mov	x4, x0
	mov	x0, x25
	mov	x1, x27
	mov	x2, x24
	mov	x3, x27
	mov	x5, x23
	mov	x6, x20
	mov	x7, x19
	stp	x22, x21, [sp, #128]
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.rotate_merge__anon_14836
LBB73_18:                               ; %common.ret1
	.cfi_restore_state
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end73:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.median_of_nine__anon_16521
l_sort.median_of_nine__anon_16521:      ; @sort.median_of_nine__anon_16521
Lfunc_begin74:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	sub	sp, sp, #1232
	.cfi_def_cfa_offset 1328
	mov	x8, #58255
	mov	x20, x0
	movk	x8, #36408, lsl #16
	add	x0, sp, #80
	movk	x8, #14563, lsl #32
	str	x6, [sp, #56]                   ; 8-byte Folded Spill
	movk	x8, #58254, lsl #48
	mov	x19, x5
	mov	x21, x4
	mov	x23, x3
	umulh	x8, x1, x8
	mov	x1, x20
	mov	x22, x2
	add	x24, sp, #80
	lsr	x8, x8, #3
	mul	x27, x8, x4
	blr	x5
	add	x20, x20, x27
	add	x0, x24, x21
	mov	x1, x20
	str	x0, [sp, #64]                   ; 8-byte Folded Spill
	blr	x19
	lsl	x26, x21, #1
	add	x20, x20, x27
	add	x25, x24, x26
	mov	x1, x20
	mov	x0, x25
	str	x26, [sp, #72]                  ; 8-byte Folded Spill
	blr	x19
	add	x8, x26, x21
	add	x20, x20, x27
	add	x0, x24, x8
	mov	x1, x20
	str	x0, [sp, #40]                   ; 8-byte Folded Spill
	blr	x19
	lsl	x28, x21, #2
	add	x20, x20, x27
	add	x26, x24, x28
	mov	x1, x20
	mov	x0, x26
	blr	x19
	add	x8, x28, x21
	add	x20, x20, x27
	add	x0, x24, x8
	mov	x1, x20
	str	x0, [sp, #32]                   ; 8-byte Folded Spill
	blr	x19
	mov	w8, #6
	add	x20, x20, x27
	mov	x1, x20
	madd	x0, x21, x8, x24
	str	x0, [sp, #48]                   ; 8-byte Folded Spill
	blr	x19
	lsl	x28, x21, #3
	add	x20, x20, x27
	sub	x8, x28, x21
	mov	x1, x20
	add	x0, x24, x8
	blr	x19
	add	x1, x20, x27
	add	x0, x24, x28
	str	x0, [sp, #24]                   ; 8-byte Folded Spill
	blr	x19
	ldr	x27, [sp, #64]                  ; 8-byte Folded Reload
	add	x1, sp, #80
	mov	x0, x23
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1136
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x24, x8
	blr	x19
	add	x1, x24, x20
	add	x0, sp, #80
	blr	x19
	add	x1, sp, #1136
	mov	x0, x27
	mov	x28, x27
	blr	x19
	add	x27, x25, x21
	mov	x0, x23
	mov	x1, x25
	mov	x2, x27
	str	x27, [sp, #8]                   ; 8-byte Folded Spill
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1136
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x25, x8
	blr	x19
	add	x1, x25, x20
	mov	x0, x25
	blr	x19
	add	x1, sp, #1136
	mov	x0, x27
	blr	x19
	add	x1, sp, #80
	mov	x0, x23
	mov	x2, x25
	blr	x22
	ldr	x27, [sp, #72]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x0, x25
	csel	x8, xzr, x27, eq
	add	x1, x24, x8
	blr	x19
	add	x2, x28, x27
	mov	x0, x23
	mov	x1, x28
	str	x2, [sp, #16]                   ; 8-byte Folded Spill
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x28
	cmp	w8, #1
	mov	x24, x27
	csel	x8, x27, xzr, eq
	add	x1, x28, x8
	blr	x19
	add	x27, x26, x21
	mov	x0, x23
	mov	x1, x26
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1136
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x26, x8
	blr	x19
	add	x1, x26, x20
	mov	x0, x26
	blr	x19
	add	x1, sp, #1136
	mov	x0, x27
	blr	x19
	add	x20, x26, x24
	mov	x0, x23
	add	x28, x20, x21
	mov	x1, x20
	mov	x2, x28
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1136
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x24, x21, xzr, eq
	add	x1, x20, x8
	blr	x19
	add	x1, x20, x24
	mov	x0, x20
	blr	x19
	add	x1, sp, #1136
	mov	x0, x28
	blr	x19
	mov	x0, x23
	mov	x1, x26
	mov	x2, x20
	blr	x22
	ldr	x28, [sp, #72]                  ; 8-byte Folded Reload
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x0, x20
	csel	x8, xzr, x28, eq
	add	x1, x26, x8
	blr	x19
	add	x2, x27, x28
	mov	x0, x23
	mov	x1, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	csel	x8, x28, xzr, eq
	add	x1, x27, x8
	blr	x19
	add	x0, sp, #80
	ldr	x1, [sp, #32]                   ; 8-byte Folded Reload
	blr	x19
	ldr	x0, [sp, #40]                   ; 8-byte Folded Reload
	ldr	x1, [sp, #24]                   ; 8-byte Folded Reload
	blr	x19
	ldr	x27, [sp, #64]                  ; 8-byte Folded Reload
	add	x1, sp, #80
	mov	x0, x23
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	add	x24, sp, #80
	cmp	w8, #1
	add	x0, sp, #1136
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x24, x8
	blr	x19
	add	x1, x24, x20
	add	x0, sp, #80
	add	x26, sp, #80
	blr	x19
	add	x1, sp, #1136
	mov	x0, x27
	blr	x19
	ldr	x24, [sp, #8]                   ; 8-byte Folded Reload
	mov	x0, x23
	mov	x1, x25
	mov	x2, x24
	blr	x22
	and	w8, w0, #0xff
	add	x0, sp, #1136
	cmp	w8, #1
	csel	x8, xzr, x21, eq
	csel	x20, x21, xzr, eq
	add	x1, x25, x8
	blr	x19
	add	x1, x25, x20
	mov	x0, x25
	blr	x19
	add	x1, sp, #1136
	mov	x0, x24
	blr	x19
	add	x1, sp, #80
	mov	x0, x23
	mov	x2, x25
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x25
	cmp	w8, #1
	csel	x8, xzr, x28, eq
	add	x1, x26, x8
	blr	x19
	mov	x0, x23
	mov	x1, x27
	ldr	x2, [sp, #16]                   ; 8-byte Folded Reload
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x27
	cmp	w8, #1
	csel	x8, x28, xzr, eq
	add	x1, x27, x8
	blr	x19
	add	x0, sp, #80
	ldr	x1, [sp, #48]                   ; 8-byte Folded Reload
	blr	x19
	add	x1, sp, #80
	mov	x0, x23
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	add	x1, sp, #80
	mov	x0, x23
	mov	x2, x25
	cmp	w8, #1
	cset	w20, eq
	blr	x22
	and	w8, w0, #0xff
	mov	x0, x23
	mov	x1, x27
	mov	x2, x25
	cmp	w8, #1
	cset	w24, ne
	blr	x22
	and	w9, w0, #0xff
	eor	w8, w20, w24
	cmp	w9, #1
	ldr	x0, [sp, #56]                   ; 8-byte Folded Reload
	cset	w9, eq
	eor	w9, w20, w9
	add	x8, x9, x8
	madd	x1, x8, x21, x26
	blr	x19
	add	sp, sp, #1232
	.cfi_def_cfa_offset 96
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end74:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.flux_reverse_partition__anon_16523
l_sort.flux_reverse_partition__anon_16523: ; @sort.flux_reverse_partition__anon_16523
Lfunc_begin75:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x28, x27, [sp, #16]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x22, x5
	mov	x26, x4
	mov	x25, x3
	mov	x27, x2
	ldr	x21, [sp, #112]
	cmp	x4, #8
	stp	x0, x1, [sp]                    ; 16-byte Folded Spill
	b.hs	LBB75_2
; %bb.1:
	mov	x28, x1
	mov	x24, x0
	b	LBB75_4
LBB75_2:                                ; %.cont81.preheader
	lsr	x23, x26, #3
	mov	x24, x0
	mov	x28, x1
LBB75_3:                                ; %.cont81
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	add	x27, x27, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	add	x27, x27, x19
	subs	x23, x23, #1
	b.ne	LBB75_3
LBB75_4:                                ; %._crit_edge
	ands	x23, x26, #0x7
	b.eq	LBB75_7
; %bb.5:                                ; %.cont
	mov	x0, x20
	mov	x1, x25
	mov	x2, x27
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x27
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	cmp	x23, #1
	b.eq	LBB75_7
; %bb.6:                                ; %.cont.1
	add	x26, x27, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x26
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x26
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	cmp	x23, #2
	b.ne	LBB75_15
LBB75_7:
	ldr	x27, [sp]                       ; 8-byte Folded Reload
LBB75_8:                                ; %._crit_edge149
	sub	x8, x24, x27
	ldr	x24, [sp, #8]                   ; 8-byte Folded Reload
	udiv	x26, x8, x19
	sub	x8, x28, x24
	mov	x1, x24
	madd	x0, x26, x19, x27
	udiv	x23, x8, x19
	mul	x2, x23, x19
	bl	_memcpy
	cmp	x26, #97
	b.lo	LBB75_11
; %bb.9:                                ; %._crit_edge149
	lsr	x8, x26, #4
	cmp	x23, x8
	b.ls	LBB75_11
; %bb.10:
	mov	x0, x27
	mov	x1, x24
	mov	x2, x27
	mov	x3, x25
	mov	x4, x26
	mov	x5, x22
	mov	x6, x20
	mov	x7, x19
	str	x21, [sp, #112]
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.flux_partition__anon_14857
LBB75_11:
	.cfi_restore_state
	.cfi_remember_state
	cmp	x26, #95
	b.hi	LBB75_13
; %bb.12:
	mov	x0, x27
	mov	x1, x26
	mov	x2, x24
	mov	x3, x22
	mov	x4, x20
	mov	x5, x19
	mov	x6, x21
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.tail_swap__anon_14838
LBB75_13:
	.cfi_restore_state
	.cfi_remember_state
	mov	x0, x27
	mov	x1, x26
	mov	x2, x22
	mov	x3, x20
	mov	x4, x19
	mov	x5, x21
	bl	l_sort.quad_swap__anon_14839
	tbz	w0, #0, LBB75_20
; %bb.14:
	mov	x0, x27
	mov	x1, x26
	mov	x2, x24
	mov	x3, x26
	mov	x4, x22
	mov	x5, x20
	mov	x6, x19
	mov	x7, x21
	bl	l_sort.quad_merge__anon_14840
	mov	x4, x0
	mov	x0, x27
	mov	x1, x26
	mov	x2, x24
	mov	x3, x26
	mov	x5, x22
	mov	x6, x20
	mov	x7, x19
	str	x21, [sp, #112]
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.rotate_merge__anon_14841
LBB75_15:                               ; %.cont.2
	.cfi_restore_state
	add	x26, x26, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x26
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x26
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	ldr	x27, [sp]                       ; 8-byte Folded Reload
	cmp	x23, #3
	b.eq	LBB75_8
; %bb.16:                               ; %.cont.3
	add	x26, x26, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x26
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x26
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	cmp	x23, #4
	b.eq	LBB75_8
; %bb.17:                               ; %.cont.4
	add	x26, x26, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x26
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x26
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	cmp	x23, #5
	b.eq	LBB75_8
; %bb.18:                               ; %.cont.5
	add	x26, x26, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x26
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x26
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	cmp	x23, #6
	b.eq	LBB75_8
; %bb.19:                               ; %.cont.6
	add	x26, x26, x19
	mov	x0, x20
	mov	x1, x25
	mov	x2, x26
	blr	x22
	and	w8, w0, #0xff
	mov	x1, x26
	cmp	w8, #1
	csel	x0, x24, x28, eq
	add	x8, x0, x19
	csel	x28, x28, x8, eq
	csel	x24, x8, x24, eq
	blr	x21
	b	LBB75_8
LBB75_20:                               ; %common.ret1
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end75:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.flux_reverse_partition__anon_16531
l_sort.flux_reverse_partition__anon_16531: ; @sort.flux_reverse_partition__anon_16531
Lfunc_begin76:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x28, x27, [sp, #16]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x22, x1
	mov	x23, x0
	mov	x0, x6
	mov	x1, x4
	mov	x19, x7
	mov	x20, x6
	mov	x21, x5
	mov	x26, x4
	mov	x24, x3
	mov	x25, x2
	blr	x7
	cmp	x26, #8
	str	x19, [sp, #8]                   ; 8-byte Folded Spill
	b.hs	LBB76_2
; %bb.1:
	mov	x27, x22
	mov	x28, x23
	b	LBB76_4
LBB76_2:                                ; %.cont81.preheader
	lsr	x19, x26, #3
	mov	x28, x23
	mov	x27, x22
LBB76_3:                                ; %.cont81
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x24]
	mov	x0, x20
	ldr	x2, [x25]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	ldr	x1, [x24]
	csel	x27, x27, x9, eq
	ldr	x2, [x25, #8]
	csel	x28, x9, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #8]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	ldr	x1, [x24]
	csel	x27, x27, x9, eq
	ldr	x2, [x25, #16]
	csel	x28, x9, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #16]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	ldr	x1, [x24]
	csel	x27, x27, x9, eq
	ldr	x2, [x25, #24]
	csel	x28, x9, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #24]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	ldr	x1, [x24]
	csel	x27, x27, x9, eq
	ldr	x2, [x25, #32]
	csel	x28, x9, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #32]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	ldr	x1, [x24]
	csel	x27, x27, x9, eq
	ldr	x2, [x25, #40]
	csel	x28, x9, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #40]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	ldr	x1, [x24]
	csel	x27, x27, x9, eq
	ldr	x2, [x25, #48]
	csel	x28, x9, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #48]
	cmp	w9, #1
	mov	x0, x20
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	ldr	x1, [x24]
	csel	x27, x27, x9, eq
	ldr	x2, [x25, #56]
	csel	x28, x9, x28, eq
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #56]
	cmp	w9, #1
	add	x25, x25, #64
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	csel	x27, x27, x9, eq
	csel	x28, x9, x28, eq
	subs	x19, x19, #1
	b.ne	LBB76_3
LBB76_4:                                ; %._crit_edge
	ands	x19, x26, #0x7
	b.eq	LBB76_12
; %bb.5:                                ; %.cont
	ldr	x1, [x24]
	mov	x0, x20
	ldr	x2, [x25]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25]
	cmp	w9, #1
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	csel	x27, x27, x9, eq
	csel	x28, x9, x28, eq
	cmp	x19, #1
	b.eq	LBB76_12
; %bb.6:                                ; %.cont.1
	ldr	x1, [x24]
	mov	x0, x20
	ldr	x2, [x25, #8]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #8]
	cmp	w9, #1
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	csel	x27, x27, x9, eq
	csel	x28, x9, x28, eq
	cmp	x19, #2
	b.eq	LBB76_12
; %bb.7:                                ; %.cont.2
	ldr	x1, [x24]
	mov	x0, x20
	ldr	x2, [x25, #16]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #16]
	cmp	w9, #1
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	csel	x27, x27, x9, eq
	csel	x28, x9, x28, eq
	cmp	x19, #3
	b.eq	LBB76_12
; %bb.8:                                ; %.cont.3
	ldr	x1, [x24]
	mov	x0, x20
	ldr	x2, [x25, #24]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #24]
	cmp	w9, #1
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	csel	x27, x27, x9, eq
	csel	x28, x9, x28, eq
	cmp	x19, #4
	b.eq	LBB76_12
; %bb.9:                                ; %.cont.4
	ldr	x1, [x24]
	mov	x0, x20
	ldr	x2, [x25, #32]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #32]
	cmp	w9, #1
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	csel	x27, x27, x9, eq
	csel	x28, x9, x28, eq
	cmp	x19, #5
	b.eq	LBB76_12
; %bb.10:                               ; %.cont.5
	ldr	x1, [x24]
	mov	x0, x20
	ldr	x2, [x25, #40]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #40]
	cmp	w9, #1
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	csel	x27, x27, x9, eq
	csel	x28, x9, x28, eq
	cmp	x19, #6
	b.eq	LBB76_12
; %bb.11:                               ; %.cont.6
	ldr	x1, [x24]
	mov	x0, x20
	ldr	x2, [x25, #48]
	blr	x21
	and	w9, w0, #0xff
	ldr	x8, [x25, #48]
	cmp	w9, #1
	csel	x9, x28, x27, eq
	str	x8, [x9], #8
	csel	x27, x27, x9, eq
	csel	x28, x9, x28, eq
LBB76_12:                               ; %._crit_edge11
	sub	x19, x28, x23
	sub	x26, x27, x22
	and	x8, x19, #0xfffffffffffffff8
	and	x2, x26, #0xfffffffffffffff8
	add	x0, x23, x8
	mov	x1, x22
	lsr	x25, x19, #3
	bl	_memcpy
	cmp	x19, #776
	b.lo	LBB76_15
; %bb.13:                               ; %._crit_edge11
	lsr	x8, x26, #3
	lsr	x9, x19, #7
	cmp	x8, x9
	b.ls	LBB76_15
; %bb.14:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x23
	mov	x3, x24
	mov	x4, x25
	mov	x5, x21
	mov	x6, x20
	ldr	x7, [sp, #8]                    ; 8-byte Folded Reload
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.flux_partition__anon_14860
LBB76_15:
	.cfi_restore_state
	.cfi_remember_state
	cmp	x19, #767
	b.hi	LBB76_17
; %bb.16:
	mov	x0, x23
	mov	x1, x25
	mov	x2, x22
	mov	x3, x21
	mov	x4, x20
	ldr	x5, [sp, #8]                    ; 8-byte Folded Reload
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.tail_swap__anon_14843
LBB76_17:
	.cfi_restore_state
	.cfi_remember_state
	ldr	x19, [sp, #8]                   ; 8-byte Folded Reload
	mov	x0, x23
	mov	x1, x25
	mov	x2, x21
	mov	x3, x20
	mov	x4, x19
	bl	l_sort.quad_swap__anon_14844
	tbz	w0, #0, LBB76_19
; %bb.18:
	mov	x0, x23
	mov	x1, x25
	mov	x2, x22
	mov	x3, x25
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.quad_merge__anon_14845
	mov	x4, x0
	mov	x0, x23
	mov	x1, x25
	mov	x2, x22
	mov	x3, x25
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.rotate_merge__anon_14846
LBB76_19:                               ; %common.ret1
	.cfi_restore_state
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end76:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.flux_reverse_partition__anon_16539
l_sort.flux_reverse_partition__anon_16539: ; @sort.flux_reverse_partition__anon_16539
Lfunc_begin77:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x6
	mov	x20, x5
	mov	x25, x4
	mov	x23, x3
	mov	x24, x2
	mov	x21, x1
	mov	x22, x0
	cmp	x4, #8
	b.hs	LBB77_2
; %bb.1:
	mov	x26, x21
	mov	x27, x22
	b	LBB77_4
LBB77_2:                                ; %.cont81.preheader
	lsr	x28, x25, #3
	mov	x27, x22
	mov	x26, x21
LBB77_3:                                ; %.cont81
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x23]
	mov	x0, x19
	ldr	x2, [x24]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x23]
	csel	x26, x26, x9, eq
	ldr	x2, [x24, #8]
	csel	x27, x9, x27, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #8]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x23]
	csel	x26, x26, x9, eq
	ldr	x2, [x24, #16]
	csel	x27, x9, x27, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #16]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x23]
	csel	x26, x26, x9, eq
	ldr	x2, [x24, #24]
	csel	x27, x9, x27, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #24]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x23]
	csel	x26, x26, x9, eq
	ldr	x2, [x24, #32]
	csel	x27, x9, x27, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #32]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x23]
	csel	x26, x26, x9, eq
	ldr	x2, [x24, #40]
	csel	x27, x9, x27, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #40]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x23]
	csel	x26, x26, x9, eq
	ldr	x2, [x24, #48]
	csel	x27, x9, x27, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #48]
	cmp	w9, #1
	mov	x0, x19
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	ldr	x1, [x23]
	csel	x26, x26, x9, eq
	ldr	x2, [x24, #56]
	csel	x27, x9, x27, eq
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #56]
	cmp	w9, #1
	add	x24, x24, #64
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
	csel	x27, x9, x27, eq
	subs	x28, x28, #1
	b.ne	LBB77_3
LBB77_4:                                ; %._crit_edge
	ands	x25, x25, #0x7
	b.eq	LBB77_12
; %bb.5:                                ; %.cont
	ldr	x1, [x23]
	mov	x0, x19
	ldr	x2, [x24]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24]
	cmp	w9, #1
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
	csel	x27, x9, x27, eq
	cmp	x25, #1
	b.eq	LBB77_12
; %bb.6:                                ; %.cont.1
	ldr	x1, [x23]
	mov	x0, x19
	ldr	x2, [x24, #8]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #8]
	cmp	w9, #1
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
	csel	x27, x9, x27, eq
	cmp	x25, #2
	b.eq	LBB77_12
; %bb.7:                                ; %.cont.2
	ldr	x1, [x23]
	mov	x0, x19
	ldr	x2, [x24, #16]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #16]
	cmp	w9, #1
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
	csel	x27, x9, x27, eq
	cmp	x25, #3
	b.eq	LBB77_12
; %bb.8:                                ; %.cont.3
	ldr	x1, [x23]
	mov	x0, x19
	ldr	x2, [x24, #24]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #24]
	cmp	w9, #1
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
	csel	x27, x9, x27, eq
	cmp	x25, #4
	b.eq	LBB77_12
; %bb.9:                                ; %.cont.4
	ldr	x1, [x23]
	mov	x0, x19
	ldr	x2, [x24, #32]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #32]
	cmp	w9, #1
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
	csel	x27, x9, x27, eq
	cmp	x25, #5
	b.eq	LBB77_12
; %bb.10:                               ; %.cont.5
	ldr	x1, [x23]
	mov	x0, x19
	ldr	x2, [x24, #40]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #40]
	cmp	w9, #1
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
	csel	x27, x9, x27, eq
	cmp	x25, #6
	b.eq	LBB77_12
; %bb.11:                               ; %.cont.6
	ldr	x1, [x23]
	mov	x0, x19
	ldr	x2, [x24, #48]
	blr	x20
	and	w9, w0, #0xff
	ldr	x8, [x24, #48]
	cmp	w9, #1
	csel	x9, x27, x26, eq
	str	x8, [x9], #8
	csel	x26, x26, x9, eq
	csel	x27, x9, x27, eq
LBB77_12:                               ; %._crit_edge11
	sub	x25, x27, x22
	sub	x26, x26, x21
	and	x8, x25, #0xfffffffffffffff8
	and	x2, x26, #0xfffffffffffffff8
	add	x0, x22, x8
	mov	x1, x21
	lsr	x24, x25, #3
	bl	_memcpy
	cmp	x25, #776
	b.lo	LBB77_15
; %bb.13:                               ; %._crit_edge11
	lsr	x8, x26, #3
	lsr	x9, x25, #7
	cmp	x8, x9
	b.ls	LBB77_15
; %bb.14:
	mov	x0, x22
	mov	x1, x21
	mov	x2, x22
	mov	x3, x23
	mov	x4, x24
	mov	x5, x20
	mov	x6, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.flux_partition__anon_14863
LBB77_15:
	.cfi_restore_state
	.cfi_remember_state
	cmp	x25, #767
	b.hi	LBB77_17
; %bb.16:
	mov	x0, x22
	mov	x1, x24
	mov	x2, x21
	mov	x3, x20
	mov	x4, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.tail_swap__anon_14848
LBB77_17:
	.cfi_restore_state
	.cfi_remember_state
	mov	x0, x22
	mov	x1, x24
	mov	x2, x20
	mov	x3, x19
	bl	l_sort.quad_swap__anon_14849
	tbz	w0, #0, LBB77_19
; %bb.18:
	mov	x0, x22
	mov	x1, x24
	mov	x2, x21
	mov	x3, x24
	mov	x4, x20
	mov	x5, x19
	bl	l_sort.quad_merge__anon_14850
	mov	x4, x0
	mov	x0, x22
	mov	x1, x24
	mov	x2, x21
	mov	x3, x24
	mov	x5, x20
	mov	x6, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.rotate_merge__anon_14851
LBB77_19:                               ; %common.ret1
	.cfi_restore_state
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end77:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_right_tail_2__anon_16701
l_sort.partial_forward_merge_right_tail_2__anon_16701: ; @sort.partial_forward_merge_right_tail_2__anon_16701
Lfunc_begin78:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x28, x27, [sp, #32]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	ldp	x20, x9, [sp, #128]
	mov	x21, x7
	mov	x24, x6
	mov	x22, x4
	mov	x25, x5
	mov	x26, x0
	neg	x19, x7
	ldr	x8, [x4]
	stp	x1, x3, [sp]                    ; 16-byte Folded Spill
	stp	x6, x9, [sp, #16]               ; 16-byte Folded Spill
LBB78_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x24
	mov	w1, #1
	mov	x27, x25
	ldr	x25, [x2]
	mov	x23, x2
	add	x28, x8, x19
	blr	x9
	mov	x0, x24
	mov	x1, x25
	mov	x2, x28
	mov	x25, x27
	blr	x27
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB78_4
; %bb.2:                                ;   in Loop: Header=BB78_1 Depth=1
	ldr	x0, [x26]
	ldr	x1, [x22]
	blr	x20
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x22]
	add	x1, x8, x19
	str	x1, [x22]
	ldr	x0, [x26]
	blr	x20
	ldr	x8, [x26]
	mov	x2, x23
	ldp	x9, x24, [sp, #8]               ; 16-byte Folded Reload
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x22]
	add	x8, x8, x19
	str	x8, [x22]
	ldr	x9, [x9]
	add	x9, x9, x21
	cmp	x9, x8
	ldr	x9, [sp, #24]                   ; 8-byte Folded Reload
	b.lo	LBB78_1
LBB78_3:
	mov	w0, #1
	b	LBB78_8
LBB78_4:
	ldr	x8, [x23]
	mov	w1, #1
	ldr	x28, [x22]
	add	x25, x8, x19
	ldp	x24, x8, [sp, #16]              ; 16-byte Folded Reload
	mov	x0, x24
	blr	x8
	mov	x0, x24
	mov	x1, x25
	mov	x2, x28
	blr	x27
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB78_7
; %bb.5:
	ldr	x0, [x26]
	ldr	x1, [x23]
	blr	x20
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x23]
	add	x1, x8, x19
	str	x1, [x23]
	ldr	x0, [x26]
	blr	x20
	ldr	x8, [x26]
	ldr	x1, [sp]                        ; 8-byte Folded Reload
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x23]
	add	x8, x8, x19
	str	x8, [x23]
	ldr	x9, [x1]
	add	x9, x9, x21
	cmp	x9, x8
	b.hs	LBB78_3
; %bb.6:
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x0, x26
	mov	x2, x23
	mov	x4, x22
	ldp	x3, x6, [sp, #8]                ; 16-byte Folded Reload
	mov	x5, x27
	mov	x7, x21
	stp	x20, x8, [sp, #128]
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_left_tail_2__anon_16773
LBB78_7:
	.cfi_restore_state
	mov	w0, wzr
LBB78_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end78:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.trinity_rotation
l_sort.trinity_rotation:                ; @sort.trinity_rotation
Lfunc_begin79:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #208
	.cfi_def_cfa_offset 208
	stp	x28, x27, [sp, #112]            ; 16-byte Folded Spill
	stp	x26, x25, [sp, #128]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #144]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #160]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #176]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #192]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	sub	x19, x1, x4
	cmp	x3, #16, lsl #12                ; =65536
	mov	w8, #65536
	mov	x21, x6
	mov	x20, x5
	mov	x25, x4
	mov	x23, x1
	mov	x22, x2
	mov	x27, x0
	csel	x8, x3, x8, lo
	subs	x9, x19, x4
	b.ls	LBB79_7
; %bb.1:
	mul	x24, x20, x25
	cmp	x8, x25
	b.hs	LBB79_14
; %bb.2:
	add	x26, x27, x24
	cmp	x9, x8
	b.hi	LBB79_22
; %bb.3:
	cmp	x9, #4
	b.lo	LBB79_22
; %bb.4:                                ; %.lr.ph259.preheader
	mul	x24, x9, x20
	mov	x0, x22
	mov	x1, x26
	str	x22, [sp, #8]                   ; 8-byte Folded Spill
	mov	x2, x24
	bl	_memcpy
	sub	x9, x23, #1
	sub	x8, x25, #1
	sub	x10, x9, x25
	neg	x28, x20
	mul	x23, x20, x8
	mov	x19, x27
	mul	x26, x20, x10
	mul	x22, x20, x9
LBB79_5:                                ; %.lr.ph259
                                        ; =>This Inner Loop Header: Depth=1
	add	x20, x19, x22
	add	x0, x19, x26
	mov	x1, x20
	blr	x21
	add	x1, x19, x23
	mov	x0, x20
	blr	x21
	add	x19, x19, x28
	subs	x25, x25, #1
	b.ne	LBB79_5
; %bb.6:                                ; %._crit_edge260
	ldr	x1, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x27
	b	LBB79_52
LBB79_7:
	b.hs	LBB79_19
; %bb.8:
	cmp	x19, x8
	b.ls	LBB79_24
; %bb.9:
	mul	x26, x20, x25
	sub	x9, x25, x19
	mul	x28, x19, x20
	cmp	x9, x8
	b.hi	LBB79_29
; %bb.10:
	cmp	x9, #4
	b.lo	LBB79_29
; %bb.11:                               ; %.lr.ph227.preheader
	mul	x24, x9, x20
	add	x1, x27, x28
	mov	x0, x22
	add	x19, x1, x26
	mov	x2, x24
	bl	_memcpy
	sub	x25, x25, x23
LBB79_12:                               ; %.lr.ph227
                                        ; =>This Inner Loop Header: Depth=1
	add	x0, x27, x28
	mov	x1, x27
	add	x23, x27, x26
	blr	x21
	mov	x0, x27
	mov	x1, x23
	blr	x21
	add	x27, x27, x20
	adds	x25, x25, #1
	b.lo	LBB79_12
; %bb.13:                               ; %._crit_edge228
	sub	x0, x19, x24
	b	LBB79_51
LBB79_14:
	mov	x0, x22
	mov	x1, x27
	mov	x2, x24
	bl	_memcpy
	mul	x8, x19, x20
	cbz	x8, LBB79_50
; %bb.15:                               ; %iter.check341
	mov	x9, xzr
	cmp	x8, #8
	b.lo	LBB79_48
; %bb.16:                               ; %iter.check341
	add	x10, x24, #31
	cmp	x10, #32
	b.lo	LBB79_48
; %bb.17:                               ; %vector.main.loop.iter.check343
	cmp	x8, #32
	b.hs	LBB79_41
; %bb.18:
	mov	x9, xzr
	b	LBB79_45
LBB79_19:
	cbz	x25, LBB79_70
; %bb.20:                               ; %.lr.ph.preheader
	mul	x23, x20, x25
LBB79_21:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	add	x0, sp, #16
	mov	x1, x27
	add	x22, x27, x23
	blr	x21
	mov	x0, x27
	mov	x1, x22
	blr	x21
	add	x1, sp, #16
	mov	x0, x22
	add	x27, x27, x20
	blr	x21
	subs	x25, x25, #1
	b.ne	LBB79_21
	b	LBB79_70
LBB79_22:
	cmp	x25, #2
	b.hs	LBB79_31
; %bb.23:
	madd	x9, x19, x20, x26
	b	LBB79_34
LBB79_24:
	mul	x24, x20, x25
	mov	x0, x22
	mul	x21, x19, x20
	add	x1, x27, x24
	mov	x2, x21
	bl	_memcpy
	cbz	x24, LBB79_28
; %bb.25:                               ; %iter.check
	cmp	x24, #8
	b.hs	LBB79_54
LBB79_26:                               ; %.lr.ph.i194.preheader
	add	x8, x27, x21
LBB79_27:                               ; %.lr.ph.i194
                                        ; =>This Inner Loop Header: Depth=1
	add	x9, x27, x24
	subs	x10, x24, #1
	add	x11, x8, x24
	mov	x24, x10
	ldurb	w9, [x9, #-1]
	sturb	w9, [x11, #-1]
	b.ne	LBB79_27
LBB79_28:                               ; %mem.copyBackwards__anon_9784.exit
	mov	x0, x27
	mov	x1, x22
	mov	x2, x21
	b	LBB79_53
LBB79_29:
	cmp	x19, #2
	b.hs	LBB79_59
; %bb.30:
	add	x8, x27, x26
	add	x10, x8, x28
	b	LBB79_62
LBB79_31:                               ; %.lr.ph235
	sub	x8, x25, #1
	sub	x9, x23, #1
	lsr	x28, x25, #1
	neg	x19, x20
	mul	x8, x20, x8
	mov	x22, x27
	stp	x23, x8, [sp]                   ; 16-byte Folded Spill
	mul	x23, x20, x9
LBB79_32:                               ; =>This Inner Loop Header: Depth=1
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	add	x0, sp, #16
	add	x25, x22, x24
	add	x26, x27, x8
	mov	x1, x26
	blr	x21
	mov	x0, x26
	mov	x1, x22
	blr	x21
	mov	x0, x22
	mov	x1, x25
	blr	x21
	add	x26, x27, x23
	mov	x0, x25
	mov	x1, x26
	add	x22, x22, x20
	blr	x21
	add	x1, sp, #16
	mov	x0, x26
	blr	x21
	add	x27, x27, x19
	subs	x28, x28, #1
	b.ne	LBB79_32
; %bb.33:                               ; %._crit_edge236.loopexit
	ldr	x8, [sp]                        ; 8-byte Folded Reload
	add	x26, x22, x24
	madd	x9, x20, x8, x27
	mov	x27, x22
LBB79_34:                               ; %._crit_edge236
	sub	x8, x9, x26
	lsl	x10, x20, #1
	cmp	x10, x8
	b.hi	LBB79_38
; %bb.35:                               ; %.lr.ph245
	udiv	x8, x8, x10
	mov	x28, xzr
	neg	x19, x20
	sub	x22, x9, x20
	stp	x10, x9, [sp]                   ; 16-byte Folded Spill
	cmp	x8, #1
	csinc	x25, x8, xzr, hi
LBB79_36:                               ; =>This Inner Loop Header: Depth=1
	add	x24, x26, x28
	add	x0, sp, #16
	mov	x1, x24
	add	x23, x27, x28
	blr	x21
	mov	x0, x24
	mov	x1, x22
	blr	x21
	mov	x0, x22
	mov	x1, x23
	blr	x21
	add	x1, sp, #16
	mov	x0, x23
	blr	x21
	add	x28, x28, x20
	subs	x25, x25, #1
	add	x22, x22, x19
	b.ne	LBB79_36
; %bb.37:                               ; %._crit_edge246.loopexit
	ldp	x10, x9, [sp]                   ; 16-byte Folded Reload
	add	x27, x27, x28
	sub	x9, x9, x28
LBB79_38:                               ; %._crit_edge246
	sub	x8, x9, x27
	cmp	x10, x8
	b.hi	LBB79_70
; %bb.39:                               ; %.lr.ph253
	udiv	x8, x8, x10
	neg	x23, x20
	sub	x22, x9, x20
	cmp	x8, #1
	csinc	x24, x8, xzr, hi
LBB79_40:                               ; =>This Inner Loop Header: Depth=1
	add	x0, sp, #16
	mov	x1, x27
	blr	x21
	mov	x0, x27
	mov	x1, x22
	blr	x21
	add	x1, sp, #16
	mov	x0, x22
	add	x27, x27, x20
	blr	x21
	add	x22, x22, x23
	subs	x24, x24, #1
	b.ne	LBB79_40
	b	LBB79_70
LBB79_41:                               ; %vector.ph344
	and	x9, x8, #0xffffffffffffffe0
	mov	x11, x27
	neg	x10, x9
LBB79_42:                               ; %vector.body348
                                        ; =>This Inner Loop Header: Depth=1
	add	x12, x11, x24
	adds	x10, x10, #32
	ldp	q0, q1, [x12]
	stp	q0, q1, [x11], #32
	b.ne	LBB79_42
; %bb.43:                               ; %middle.block338
	cmp	x8, x9
	b.eq	LBB79_50
; %bb.44:                               ; %vec.epilog.iter.check355
	tst	x8, #0x18
	b.eq	LBB79_48
LBB79_45:                               ; %vec.epilog.ph356
	mov	x11, x9
	and	x9, x8, #0xfffffffffffffff8
	add	x10, x27, x11
	sub	x11, x11, x9
LBB79_46:                               ; %vec.epilog.vector.body364
                                        ; =>This Inner Loop Header: Depth=1
	ldr	d0, [x10, x24]
	adds	x11, x11, #8
	str	d0, [x10], #8
	b.ne	LBB79_46
; %bb.47:                               ; %vec.epilog.middle.block353
	cmp	x8, x9
	b.eq	LBB79_50
LBB79_48:                               ; %.lr.ph.i.preheader
	add	x10, x27, x9
	sub	x9, x9, x8
LBB79_49:                               ; %.lr.ph.i
                                        ; =>This Inner Loop Header: Depth=1
	ldrb	w11, [x10, x24]
	adds	x9, x9, #1
	strb	w11, [x10], #1
	b.lo	LBB79_49
LBB79_50:                               ; %mem.copyForwards__anon_9882.exit
	add	x0, x27, x8
LBB79_51:                               ; %mem.copyForwards__anon_9882.exit
	mov	x1, x22
LBB79_52:                               ; %mem.copyForwards__anon_9882.exit
	mov	x2, x24
LBB79_53:                               ; %mem.copyForwards__anon_9882.exit
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_memcpy
LBB79_54:                               ; %vector.scevcheck
	.cfi_restore_state
	.cfi_remember_state
	madd	x8, x20, x23, x27
	sub	x8, x8, #1
	sub	x9, x8, x24
	add	x9, x9, #1
	cmp	x9, x8
	b.hi	LBB79_26
; %bb.55:                               ; %vector.scevcheck
	add	x8, x24, x27
	sub	x8, x8, #1
	cmp	x8, x27
	b.lo	LBB79_26
; %bb.56:                               ; %vector.memcheck
	mul	x8, x20, x23
	add	x9, x24, x27
	add	x10, x8, x27
	sub	x9, x9, x10
	cmp	x9, #32
	b.lo	LBB79_26
; %bb.57:                               ; %vector.main.loop.iter.check
	cmp	x24, #32
	b.hs	LBB79_71
; %bb.58:
	mov	x9, xzr
	b	LBB79_75
LBB79_59:                               ; %.lr.ph205
	sub	x8, x23, #1
	sub	x9, x25, #1
	lsr	x19, x19, #1
	neg	x28, x20
	mul	x8, x20, x8
	mov	x22, x27
	stp	x23, x8, [sp]                   ; 16-byte Folded Spill
	mul	x23, x20, x9
LBB79_60:                               ; =>This Inner Loop Header: Depth=1
	add	x25, x27, x23
	add	x0, sp, #16
	mov	x1, x25
	add	x24, x22, x26
	blr	x21
	mov	x0, x25
	mov	x1, x22
	blr	x21
	mov	x0, x22
	mov	x1, x24
	blr	x21
	ldr	x8, [sp, #8]                    ; 8-byte Folded Reload
	mov	x0, x24
	add	x22, x22, x20
	add	x25, x27, x8
	mov	x1, x25
	blr	x21
	add	x1, sp, #16
	mov	x0, x25
	blr	x21
	subs	x19, x19, #1
	add	x27, x27, x28
	b.ne	LBB79_60
; %bb.61:                               ; %._crit_edge.loopexit
	ldr	x8, [sp]                        ; 8-byte Folded Reload
	madd	x10, x20, x8, x27
	add	x8, x27, x26
	mov	x27, x22
LBB79_62:                               ; %._crit_edge
	sub	x9, x8, x27
	lsl	x25, x20, #1
	cmp	x25, x9
	b.ls	LBB79_64
; %bb.63:
	mov	x22, x27
	b	LBB79_67
LBB79_64:                               ; %.lr.ph213
	udiv	x9, x9, x25
	mov	x26, xzr
	sub	x19, x10, x20
	sub	x24, x8, x20
	mov	x22, x27
	str	x10, [sp, #8]                   ; 8-byte Folded Spill
	cmp	x9, #1
	csinc	x28, x9, xzr, hi
LBB79_65:                               ; =>This Inner Loop Header: Depth=1
	add	x23, x24, x26
	add	x0, sp, #16
	mov	x1, x23
	blr	x21
	mov	x0, x23
	mov	x1, x22
	blr	x21
	add	x23, x19, x26
	mov	x0, x22
	mov	x1, x23
	blr	x21
	add	x1, sp, #16
	mov	x0, x23
	blr	x21
	sub	x28, x28, #1
	sub	x26, x26, x20
	add	x22, x22, x20
	cbnz	x28, LBB79_65
; %bb.66:                               ; %._crit_edge214.loopexit
	ldr	x10, [sp, #8]                   ; 8-byte Folded Reload
	sub	x27, x27, x26
	add	x10, x10, x26
LBB79_67:                               ; %._crit_edge214
	sub	x8, x10, x27
	cmp	x25, x8
	b.hi	LBB79_70
; %bb.68:                               ; %.lr.ph221
	udiv	x8, x8, x25
	neg	x23, x20
	sub	x19, x10, x20
	cmp	x8, #1
	csinc	x24, x8, xzr, hi
LBB79_69:                               ; =>This Inner Loop Header: Depth=1
	add	x0, sp, #16
	mov	x1, x22
	blr	x21
	mov	x0, x22
	mov	x1, x19
	blr	x21
	add	x1, sp, #16
	mov	x0, x19
	add	x22, x22, x20
	blr	x21
	subs	x24, x24, #1
	add	x19, x19, x23
	b.ne	LBB79_69
LBB79_70:                               ; %common.ret
	ldp	x29, x30, [sp, #192]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #176]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #160]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #144]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #128]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #208
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB79_71:                               ; %vector.ph
	.cfi_restore_state
	and	x9, x24, #0xffffffffffffffe0
	add	x10, x8, x27
	add	x11, x24, x27
	sub	x10, x10, #16
	sub	x11, x11, #16
	neg	x12, x9
LBB79_72:                               ; %vector.body
                                        ; =>This Inner Loop Header: Depth=1
	ldp	q1, q0, [x11, #-16]
	sub	x11, x11, #32
	adds	x12, x12, #32
	stp	q1, q0, [x10, #-16]
	sub	x10, x10, #32
	b.ne	LBB79_72
; %bb.73:                               ; %middle.block
	cmp	x24, x9
	b.eq	LBB79_28
; %bb.74:                               ; %vec.epilog.iter.check
	tst	x24, #0x18
	b.eq	LBB79_78
LBB79_75:                               ; %vec.epilog.ph
	sub	x8, x8, x9
	sub	x12, x24, x9
	and	x11, x24, #0xfffffffffffffff8
	add	x8, x8, x27
	add	x12, x12, x27
	and	x10, x24, #0x7
	sub	x8, x8, #8
	sub	x12, x12, #8
	sub	x9, x9, x11
LBB79_76:                               ; %vec.epilog.vector.body
                                        ; =>This Inner Loop Header: Depth=1
	ldr	d0, [x12], #-8
	adds	x9, x9, #8
	str	d0, [x8], #-8
	b.ne	LBB79_76
; %bb.77:                               ; %vec.epilog.middle.block
	cmp	x24, x11
	mov	x24, x10
	b.ne	LBB79_26
	b	LBB79_28
LBB79_78:
	and	x24, x24, #0x1f
	b	LBB79_26
Lfunc_end79:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge__anon_16703
l_sort.partial_forward_merge__anon_16703: ; @sort.partial_forward_merge__anon_16703
Lfunc_begin80:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #192
	.cfi_def_cfa_offset 192
	stp	x28, x27, [sp, #96]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #112]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #128]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #144]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #176]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	cmp	x1, x4
	b.eq	LBB80_17
; %bb.1:
	sub	x8, x1, #1
	mul	x26, x7, x4
	mov	x22, x0
	ldr	x28, [sp, #200]
	madd	x27, x8, x7, x0
	add	x24, x0, x26
	mov	x0, x6
	mov	w1, #1
	mov	x19, x7
	mov	x20, x6
	mov	x21, x5
	mov	x25, x4
	mov	x23, x2
	stp	x24, x27, [sp, #56]
	blr	x28
	sub	x1, x24, x19
	mov	x0, x20
	mov	x2, x24
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB80_17
; %bb.2:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x26
	str	x27, [sp, #48]                  ; 8-byte Folded Spill
	ldr	x27, [sp, #192]
	bl	_memcpy
	sub	x8, x25, #1
	str	x22, [sp, #88]
	madd	x25, x8, x19, x23
	sub	x8, x25, x19
	cmp	x8, x23
	stp	x23, x25, [sp, #72]
	str	x8, [sp, #40]                   ; 8-byte Folded Spill
	b.ls	LBB80_9
; %bb.3:
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	sub	x8, x8, x19
	cmp	x8, x24
	str	x8, [sp, #32]                   ; 8-byte Folded Spill
	b.ls	LBB80_9
; %bb.4:                                ; %.lr.ph
	lsl	x8, x19, #1
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
LBB80_5:                                ; =>This Inner Loop Header: Depth=1
	add	x0, sp, #88
	add	x1, sp, #72
	add	x2, sp, #80
	add	x3, sp, #56
	add	x4, sp, #64
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	stp	x27, x28, [sp]
	bl	l_sort.partial_forward_merge_right_head_2__anon_16774
	tbnz	w0, #0, LBB80_8
; %bb.6:                                ; %select.end54
                                        ;   in Loop: Header=BB80_5 Depth=1
	mov	x0, x20
	mov	w1, #2
	blr	x28
	ldr	x22, [sp, #72]
	mov	x0, x20
	ldr	x23, [sp, #56]
	mov	x1, x22
	mov	x2, x23
	blr	x21
	ldr	x24, [sp, #88]
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x1, x23
	csel	x8, xzr, x19, eq
	csel	x26, x19, xzr, eq
	add	x0, x24, x8
	blr	x27
	add	x23, x23, x19
	add	x0, x24, x26
	mov	x1, x22
	str	x23, [sp, #56]
	blr	x27
	add	x1, x22, x19
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	mov	x0, x20
	mov	x2, x23
	add	x22, x24, x8
	str	x1, [sp, #72]
	blr	x21
	and	w8, w0, #0xff
	add	x9, sp, #56
	cmp	w8, #1
	add	x8, sp, #72
	csel	x23, x9, x8, eq
	mov	x0, x22
	ldr	x1, [x23]
	blr	x27
	ldr	x8, [x23]
	add	x22, x22, x19
	add	x8, x8, x19
	str	x22, [sp, #88]
	str	x8, [x23]
	ldr	x8, [sp, #40]                   ; 8-byte Folded Reload
	ldr	x23, [sp, #72]
	ldr	x24, [sp, #56]
	cmp	x8, x23
	b.ls	LBB80_9
; %bb.7:                                ; %select.end54
                                        ;   in Loop: Header=BB80_5 Depth=1
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	cmp	x8, x24
	b.hi	LBB80_5
	b	LBB80_9
LBB80_8:                                ; %.._crit_edge.loopexit_crit_edge
	ldr	x22, [sp, #88]
	ldr	x23, [sp, #72]
	ldr	x24, [sp, #56]
LBB80_9:                                ; %._crit_edge
	cmp	x23, x25
	b.hi	LBB80_14
; %bb.10:                               ; %._crit_edge
	ldr	x8, [sp, #48]                   ; 8-byte Folded Reload
	cmp	x24, x8
	b.hi	LBB80_14
; %bb.11:
	add	x26, sp, #56
LBB80_12:                               ; %.lr.ph13
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	blr	x28
	mov	x0, x20
	mov	x1, x23
	mov	x2, x24
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x22
	cmp	w8, #1
	add	x8, sp, #72
	csel	x23, x26, x8, eq
	ldr	x1, [x23]
	blr	x27
	ldr	x8, [x23]
	add	x22, x22, x19
	add	x8, x8, x19
	str	x8, [x23]
	ldr	x23, [sp, #72]
	cmp	x23, x25
	b.hi	LBB80_14
; %bb.13:                               ; %.lr.ph13
                                        ;   in Loop: Header=BB80_12 Depth=1
	ldp	x8, x24, [sp, #48]              ; 8-byte Folded Reload
	cmp	x24, x8
	b.ls	LBB80_12
LBB80_14:                               ; %.preheader
	cmp	x23, x25
	b.hi	LBB80_17
; %bb.15:                               ; %.lr.ph19.preheader
	mov	x20, xzr
LBB80_16:                               ; %.lr.ph19
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x23, x20
	add	x0, x22, x20
	blr	x27
	add	x20, x20, x19
	add	x8, x23, x20
	cmp	x8, x25
	b.ls	LBB80_16
LBB80_17:                               ; %common.ret
	ldp	x29, x30, [sp, #176]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #160]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #128]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #112]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #96]             ; 16-byte Folded Reload
	add	sp, sp, #192
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end80:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_right_tail_2__anon_16712
l_sort.partial_forward_merge_right_tail_2__anon_16712: ; @sort.partial_forward_merge_right_tail_2__anon_16712
Lfunc_begin81:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x22, x4
	mov	x21, x5
	mov	x23, x3
	mov	x24, x2
	mov	x25, x1
	mov	x26, x0
	ldr	x27, [sp, #96]
	neg	x28, x7
	ldr	x8, [x4]
LBB81_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x24]
	add	x2, x8, x28
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB81_4
; %bb.2:                                ;   in Loop: Header=BB81_1 Depth=1
	ldr	x0, [x26]
	ldr	x1, [x22]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x28
	str	x8, [x26]
	ldr	x8, [x22]
	add	x1, x8, x28
	str	x1, [x22]
	ldr	x0, [x26]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x28
	str	x8, [x26]
	ldr	x8, [x22]
	add	x8, x8, x28
	str	x8, [x22]
	ldr	x9, [x23]
	add	x9, x9, x19
	cmp	x9, x8
	b.lo	LBB81_1
LBB81_3:
	mov	w0, #1
	b	LBB81_8
LBB81_4:
	ldr	x8, [x24]
	mov	x0, x20
	ldr	x2, [x22]
	add	x1, x8, x28
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB81_7
; %bb.5:
	ldr	x0, [x26]
	ldr	x1, [x24]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x28
	str	x8, [x26]
	ldr	x8, [x24]
	add	x1, x8, x28
	str	x1, [x24]
	ldr	x0, [x26]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x28
	str	x8, [x26]
	ldr	x8, [x24]
	add	x8, x8, x28
	str	x8, [x24]
	ldr	x9, [x25]
	add	x9, x9, x19
	cmp	x9, x8
	b.hs	LBB81_3
; %bb.6:
	mov	x0, x26
	mov	x1, x25
	mov	x2, x24
	mov	x3, x23
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	str	x27, [sp, #96]
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_left_tail_2__anon_16777
LBB81_7:
	.cfi_restore_state
	mov	w0, wzr
LBB81_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end81:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge__anon_16714
l_sort.partial_forward_merge__anon_16714: ; @sort.partial_forward_merge__anon_16714
Lfunc_begin82:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #176
	.cfi_def_cfa_offset 176
	stp	x28, x27, [sp, #80]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #96]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #112]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #128]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #160]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	cmp	x1, x4
	b.eq	LBB82_17
; %bb.1:
	mul	x26, x7, x4
	sub	x8, x1, #1
	mov	x23, x2
	mov	x22, x0
	add	x24, x0, x26
	madd	x27, x8, x7, x0
	sub	x1, x24, x7
	mov	x0, x6
	mov	x2, x24
	mov	x19, x7
	mov	x20, x6
	mov	x21, x5
	mov	x25, x4
	stp	x24, x27, [sp, #40]
	blr	x5
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB82_17
; %bb.2:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x26
	str	x27, [sp, #32]                  ; 8-byte Folded Spill
	ldr	x27, [sp, #176]
	bl	_memcpy
	sub	x8, x25, #1
	str	x22, [sp, #72]
	madd	x25, x8, x19, x23
	sub	x26, x25, x19
	cmp	x26, x23
	stp	x23, x25, [sp, #56]
	b.ls	LBB82_9
; %bb.3:
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	sub	x8, x8, x19
	cmp	x8, x24
	str	x8, [sp, #24]                   ; 8-byte Folded Spill
	b.ls	LBB82_9
; %bb.4:                                ; %.lr.ph
	lsl	x8, x19, #1
	str	x8, [sp, #16]                   ; 8-byte Folded Spill
LBB82_5:                                ; =>This Inner Loop Header: Depth=1
	add	x0, sp, #72
	add	x1, sp, #56
	add	x2, sp, #64
	add	x3, sp, #40
	add	x4, sp, #48
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	str	x27, [sp]
	bl	l_sort.partial_forward_merge_right_head_2__anon_16778
	tbnz	w0, #0, LBB82_8
; %bb.6:                                ; %select.end18
                                        ;   in Loop: Header=BB82_5 Depth=1
	ldr	x22, [sp, #56]
	mov	x0, x20
	ldr	x23, [sp, #40]
	mov	x1, x22
	mov	x2, x23
	blr	x21
	ldr	x24, [sp, #72]
	and	w8, w0, #0xff
	cmp	w8, #1
	mov	x1, x23
	csel	x8, xzr, x19, eq
	csel	x28, x19, xzr, eq
	add	x0, x24, x8
	blr	x27
	add	x23, x23, x19
	add	x0, x24, x28
	mov	x1, x22
	str	x23, [sp, #40]
	blr	x27
	add	x1, x22, x19
	ldr	x8, [sp, #16]                   ; 8-byte Folded Reload
	mov	x0, x20
	mov	x2, x23
	add	x22, x24, x8
	str	x1, [sp, #56]
	blr	x21
	and	w8, w0, #0xff
	add	x9, sp, #40
	cmp	w8, #1
	add	x8, sp, #56
	csel	x23, x9, x8, eq
	mov	x0, x22
	ldr	x1, [x23]
	blr	x27
	ldr	x8, [x23]
	add	x22, x22, x19
	add	x8, x8, x19
	str	x22, [sp, #72]
	str	x8, [x23]
	ldr	x23, [sp, #56]
	ldr	x24, [sp, #40]
	cmp	x26, x23
	b.ls	LBB82_9
; %bb.7:                                ; %select.end18
                                        ;   in Loop: Header=BB82_5 Depth=1
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	cmp	x8, x24
	b.hi	LBB82_5
	b	LBB82_9
LBB82_8:                                ; %.._crit_edge.loopexit_crit_edge
	ldr	x22, [sp, #72]
	ldr	x23, [sp, #56]
	ldr	x24, [sp, #40]
LBB82_9:                                ; %._crit_edge
	cmp	x23, x25
	b.hi	LBB82_14
; %bb.10:                               ; %._crit_edge
	ldr	x8, [sp, #32]                   ; 8-byte Folded Reload
	cmp	x24, x8
	b.hi	LBB82_14
; %bb.11:
	add	x26, sp, #56
	add	x28, sp, #40
LBB82_12:                               ; %.lr.ph13
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	x1, x23
	mov	x2, x24
	blr	x21
	and	w8, w0, #0xff
	mov	x0, x22
	cmp	w8, #1
	csel	x23, x28, x26, eq
	ldr	x1, [x23]
	blr	x27
	ldr	x8, [x23]
	add	x22, x22, x19
	add	x8, x8, x19
	str	x8, [x23]
	ldr	x23, [sp, #56]
	cmp	x23, x25
	b.hi	LBB82_14
; %bb.13:                               ; %.lr.ph13
                                        ;   in Loop: Header=BB82_12 Depth=1
	ldp	x8, x24, [sp, #32]              ; 8-byte Folded Reload
	cmp	x24, x8
	b.ls	LBB82_12
LBB82_14:                               ; %.preheader
	cmp	x23, x25
	b.hi	LBB82_17
; %bb.15:                               ; %.lr.ph19.preheader
	mov	x20, xzr
LBB82_16:                               ; %.lr.ph19
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x23, x20
	add	x0, x22, x20
	blr	x27
	add	x20, x20, x19
	add	x8, x23, x20
	cmp	x8, x25
	b.ls	LBB82_16
LBB82_17:                               ; %common.ret
	ldp	x29, x30, [sp, #160]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #144]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #112]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #96]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #176
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end82:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_right_tail_2__anon_16723
l_sort.partial_forward_merge_right_tail_2__anon_16723: ; @sort.partial_forward_merge_right_tail_2__anon_16723
Lfunc_begin83:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x22, x4
	mov	x21, x5
	mov	x23, x3
	mov	x24, x2
	mov	x25, x1
	mov	x26, x0
	ldr	x27, [x4]
LBB83_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	ldr	x28, [x24]
	blr	x19
	ldr	x1, [x28]
	mov	x0, x20
	ldur	x2, [x27, #-8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB83_4
; %bb.2:                                ;   in Loop: Header=BB83_1 Depth=1
	ldr	x8, [x22]
	ldr	x9, [x26]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x26]
	sub	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x22]
	sub	x9, x8, #8
	str	x9, [x22]
	ldr	x9, [x26]
	ldur	x8, [x8, #-8]
	str	x8, [x9]
	ldr	x8, [x26]
	sub	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x22]
	sub	x27, x8, #8
	str	x27, [x22]
	ldr	x8, [x23]
	add	x8, x8, #8
	cmp	x8, x27
	b.lo	LBB83_1
LBB83_3:
	mov	w0, #1
	b	LBB83_8
LBB83_4:
	mov	x0, x20
	mov	w1, #1
	ldr	x27, [x24]
	ldr	x28, [x22]
	blr	x19
	ldur	x1, [x27, #-8]
	mov	x0, x20
	ldr	x2, [x28]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB83_7
; %bb.5:
	ldr	x8, [x24]
	ldr	x9, [x26]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x26]
	sub	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x24]
	sub	x9, x8, #8
	str	x9, [x24]
	ldr	x9, [x26]
	ldur	x8, [x8, #-8]
	str	x8, [x9]
	ldr	x8, [x26]
	sub	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x24]
	sub	x8, x8, #8
	str	x8, [x24]
	ldr	x9, [x25]
	add	x9, x9, #8
	cmp	x9, x8
	b.hs	LBB83_3
; %bb.6:
	mov	x0, x26
	mov	x1, x25
	mov	x2, x24
	mov	x3, x23
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_left_tail_2__anon_16781
LBB83_7:
	.cfi_restore_state
	mov	w0, wzr
LBB83_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end83:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge__anon_16725
l_sort.partial_forward_merge__anon_16725: ; @sort.partial_forward_merge__anon_16725
Lfunc_begin84:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x28, x27, [sp, #48]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	cmp	x1, x4
	b.eq	LBB84_15
; %bb.1:
	lsl	x24, x4, #3
	add	x8, x0, x1, lsl #3
	mov	x22, x0
	add	x26, x0, x24
	sub	x25, x8, #8
	mov	x0, x6
	mov	w1, #1
	mov	x19, x7
	mov	x20, x6
	mov	x21, x5
	mov	x23, x2
	stp	x26, x25, [sp, #8]
	blr	x7
	ldp	x1, x2, [x26, #-8]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB84_15
; %bb.2:
	mov	x0, x23
	mov	x1, x22
	mov	x2, x24
	bl	_memcpy
	add	x8, x24, x23
	str	x22, [sp, #40]
	sub	x24, x8, #8
	sub	x27, x8, #16
	cmp	x27, x23
	stp	x23, x24, [sp, #24]
	b.ls	LBB84_7
; %bb.3:
	sub	x8, x25, #8
	str	x8, [sp]                        ; 8-byte Folded Spill
	cmp	x8, x26
	b.ls	LBB84_7
LBB84_4:                                ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	add	x0, sp, #40
	add	x1, sp, #24
	add	x2, sp, #32
	add	x3, sp, #8
	add	x4, sp, #16
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	bl	l_sort.partial_forward_merge_right_head_2__anon_16782
	tbnz	w0, #0, LBB84_8
; %bb.5:                                ; %select.end16
                                        ;   in Loop: Header=BB84_4 Depth=1
	mov	x0, x20
	mov	w1, #2
	blr	x19
	ldr	x22, [sp, #24]
	mov	x0, x20
	ldr	x23, [sp, #8]
	ldr	x1, [x22]
	ldr	x2, [x23]
	blr	x21
	and	w8, w0, #0xff
	ldr	x28, [sp, #40]
	cmp	w8, #1
	ldr	x9, [x23]
	cset	w8, ne
	cset	w10, eq
	mov	x0, x20
	str	x9, [x28, w8, uxtw #3]
	ldr	x8, [x22]
	str	x8, [x28, w10, uxtw #3]
	ldr	x2, [x23, #8]!
	ldr	x1, [x22, #8]!
	str	x23, [sp, #8]
	str	x22, [sp, #24]
	blr	x21
	and	w8, w0, #0xff
	add	x9, sp, #8
	cmp	w8, #1
	add	x8, sp, #24
	csel	x8, x9, x8, eq
	add	x22, x28, #24
	ldr	x9, [x8]
	str	x22, [sp, #40]
	ldr	x10, [x9], #8
	str	x9, [x8]
	ldr	x23, [sp, #24]
	ldr	x26, [sp, #8]
	str	x10, [x28, #16]
	cmp	x27, x23
	b.ls	LBB84_7
; %bb.6:                                ; %select.end16
                                        ;   in Loop: Header=BB84_4 Depth=1
	ldr	x8, [sp]                        ; 8-byte Folded Reload
	cmp	x8, x26
	b.hi	LBB84_4
LBB84_7:                                ; %._crit_edge
	cmp	x23, x24
	b.ls	LBB84_9
	b	LBB84_13
LBB84_8:                                ; %.lr.ph.._crit_edge.loopexit_crit_edge
	ldr	x22, [sp, #40]
	ldr	x23, [sp, #24]
	ldr	x26, [sp, #8]
	cmp	x23, x24
	b.hi	LBB84_13
LBB84_9:                                ; %._crit_edge
	cmp	x26, x25
	b.hi	LBB84_13
; %bb.10:
	add	x27, sp, #24
	add	x28, sp, #8
LBB84_11:                               ; %.lr.ph3
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	blr	x19
	ldr	x1, [x23]
	mov	x0, x20
	ldr	x2, [x26]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x28, x27, eq
	ldr	x9, [x8]
	ldr	x10, [x9], #8
	str	x9, [x8]
	ldr	x23, [sp, #24]
	str	x10, [x22], #8
	cmp	x23, x24
	b.hi	LBB84_13
; %bb.12:                               ; %.lr.ph3
                                        ;   in Loop: Header=BB84_11 Depth=1
	ldr	x26, [sp, #8]
	cmp	x26, x25
	b.ls	LBB84_11
LBB84_13:                               ; %.preheader
	cmp	x23, x24
	str	x22, [sp, #40]
	b.hi	LBB84_15
LBB84_14:                               ; %.lr.ph9
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [x23], #8
	cmp	x23, x24
	str	x8, [x22], #8
	b.ls	LBB84_14
LBB84_15:                               ; %common.ret
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end84:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_right_tail_2__anon_16734
l_sort.partial_forward_merge_right_tail_2__anon_16734: ; @sort.partial_forward_merge_right_tail_2__anon_16734
Lfunc_begin85:
	.cfi_startproc
; %bb.0:
	stp	x26, x25, [sp, #-80]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 80
	stp	x24, x23, [sp, #16]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_remember_state
	mov	x19, x6
	mov	x20, x5
	mov	x21, x4
	mov	x22, x3
	mov	x23, x2
	mov	x24, x1
	mov	x25, x0
	ldr	x8, [x4]
LBB85_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x23]
	mov	x0, x19
	ldur	x2, [x8, #-8]
	ldr	x1, [x9]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB85_4
; %bb.2:                                ;   in Loop: Header=BB85_1 Depth=1
	ldr	x8, [x21]
	ldr	x9, [x25]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x25]
	sub	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x21]
	sub	x9, x8, #8
	str	x9, [x21]
	ldr	x9, [x25]
	ldur	x8, [x8, #-8]
	str	x8, [x9]
	ldr	x8, [x25]
	sub	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x21]
	sub	x8, x8, #8
	str	x8, [x21]
	ldr	x9, [x22]
	add	x9, x9, #8
	cmp	x9, x8
	b.lo	LBB85_1
LBB85_3:
	mov	w0, #1
	b	LBB85_8
LBB85_4:
	ldr	x8, [x23]
	mov	x0, x19
	ldr	x9, [x21]
	ldur	x1, [x8, #-8]
	ldr	x2, [x9]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB85_7
; %bb.5:
	ldr	x8, [x23]
	ldr	x9, [x25]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x25]
	sub	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x23]
	sub	x9, x8, #8
	str	x9, [x23]
	ldr	x9, [x25]
	ldur	x8, [x8, #-8]
	str	x8, [x9]
	ldr	x8, [x25]
	sub	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x23]
	sub	x8, x8, #8
	str	x8, [x23]
	ldr	x9, [x24]
	add	x9, x9, #8
	cmp	x9, x8
	b.hs	LBB85_3
; %bb.6:
	mov	x1, x24
	mov	x2, x23
	mov	x3, x22
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	mov	x0, x25
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	b	l_sort.partial_forward_merge_left_tail_2__anon_16785
LBB85_7:
	.cfi_restore_state
	mov	w0, wzr
LBB85_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	ret
Lfunc_end85:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge__anon_16736
l_sort.partial_forward_merge__anon_16736: ; @sort.partial_forward_merge__anon_16736
Lfunc_begin86:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x28, x27, [sp, #48]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #64]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #80]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #96]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	cmp	x1, x4
	b.eq	LBB86_15
; %bb.1:
	lsl	x23, x4, #3
	mov	x22, x2
	add	x25, x0, x23
	add	x8, x0, x1, lsl #3
	mov	x21, x0
	sub	x24, x8, #8
	mov	x0, x6
	mov	x19, x6
	ldp	x1, x2, [x25, #-8]
	mov	x20, x5
	stp	x25, x24, [sp, #8]
	blr	x5
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB86_15
; %bb.2:
	mov	x0, x22
	mov	x1, x21
	mov	x2, x23
	bl	_memcpy
	add	x8, x23, x22
	str	x21, [sp, #40]
	sub	x23, x8, #8
	sub	x26, x8, #16
	cmp	x26, x22
	stp	x22, x23, [sp, #24]
	b.ls	LBB86_8
; %bb.3:
	sub	x27, x24, #8
LBB86_4:                                ; =>This Inner Loop Header: Depth=1
	cmp	x27, x25
	b.ls	LBB86_8
; %bb.5:                                ; %.lr.ph
                                        ;   in Loop: Header=BB86_4 Depth=1
	add	x0, sp, #40
	add	x1, sp, #24
	add	x2, sp, #32
	add	x3, sp, #8
	add	x4, sp, #16
	mov	x5, x20
	mov	x6, x19
	bl	l_sort.partial_forward_merge_right_head_2__anon_16786
	tbnz	w0, #0, LBB86_7
; %bb.6:                                ; %select.end16
                                        ;   in Loop: Header=BB86_4 Depth=1
	ldr	x21, [sp, #24]
	mov	x0, x19
	ldr	x22, [sp, #8]
	ldr	x1, [x21]
	ldr	x2, [x22]
	blr	x20
	and	w8, w0, #0xff
	ldr	x28, [sp, #40]
	cmp	w8, #1
	ldr	x9, [x22]
	cset	w8, ne
	cset	w10, eq
	mov	x0, x19
	str	x9, [x28, w8, uxtw #3]
	ldr	x8, [x21]
	str	x8, [x28, w10, uxtw #3]
	ldr	x2, [x22, #8]!
	ldr	x1, [x21, #8]!
	str	x22, [sp, #8]
	str	x21, [sp, #24]
	blr	x20
	and	w8, w0, #0xff
	add	x9, sp, #8
	cmp	w8, #1
	add	x8, sp, #24
	csel	x8, x9, x8, eq
	add	x21, x28, #24
	ldr	x9, [x8]
	str	x21, [sp, #40]
	ldr	x10, [x9], #8
	str	x9, [x8]
	ldr	x22, [sp, #24]
	ldr	x25, [sp, #8]
	str	x10, [x28, #16]
	cmp	x26, x22
	b.hi	LBB86_4
	b	LBB86_8
LBB86_7:                                ; %.lr.ph.._crit_edge.loopexit_crit_edge
	ldr	x21, [sp, #40]
	ldr	x22, [sp, #24]
	ldr	x25, [sp, #8]
LBB86_8:                                ; %._crit_edge
	cmp	x22, x23
	b.hi	LBB86_13
; %bb.9:                                ; %._crit_edge
	cmp	x25, x24
	b.hi	LBB86_13
; %bb.10:
	add	x26, sp, #24
	add	x27, sp, #8
LBB86_11:                               ; %.lr.ph3
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x22]
	mov	x0, x19
	ldr	x2, [x25]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	csel	x8, x27, x26, eq
	ldr	x9, [x8]
	ldr	x10, [x9], #8
	str	x9, [x8]
	ldr	x22, [sp, #24]
	str	x10, [x21], #8
	cmp	x22, x23
	b.hi	LBB86_13
; %bb.12:                               ; %.lr.ph3
                                        ;   in Loop: Header=BB86_11 Depth=1
	ldr	x25, [sp, #8]
	cmp	x25, x24
	b.ls	LBB86_11
LBB86_13:                               ; %.preheader
	cmp	x22, x23
	str	x21, [sp, #40]
	b.hi	LBB86_15
LBB86_14:                               ; %.lr.ph9
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x8, [x22], #8
	cmp	x22, x23
	str	x8, [x21], #8
	b.ls	LBB86_14
LBB86_15:                               ; %common.ret
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #96]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #80]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #64]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #144
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end86:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_left_tail_2__anon_16773
l_sort.partial_forward_merge_left_tail_2__anon_16773: ; @sort.partial_forward_merge_left_tail_2__anon_16773
Lfunc_begin87:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x28, x27, [sp, #32]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #48]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #64]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #80]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	ldp	x19, x24, [sp, #128]
	mov	x21, x7
	mov	x20, x6
	mov	x23, x2
	mov	x22, x4
	mov	x26, x0
	neg	x25, x7
	ldr	x8, [x2]
	stp	x1, x5, [sp, #16]               ; 16-byte Folded Spill
	str	x3, [sp, #8]                    ; 8-byte Folded Spill
LBB87_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	ldr	x28, [x22]
	add	x27, x8, x25
	blr	x24
	mov	x0, x20
	mov	x1, x27
	mov	x2, x28
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB87_3
; %bb.2:                                ;   in Loop: Header=BB87_1 Depth=1
	ldr	x0, [x26]
	ldr	x1, [x23]
	blr	x19
	ldr	x8, [x26]
	add	x8, x8, x25
	str	x8, [x26]
	ldr	x8, [x23]
	add	x1, x8, x25
	str	x1, [x23]
	ldr	x0, [x26]
	blr	x19
	ldr	x8, [x26]
	ldr	x9, [sp, #16]                   ; 8-byte Folded Reload
	add	x8, x8, x25
	str	x8, [x26]
	ldr	x8, [x23]
	add	x8, x8, x25
	str	x8, [x23]
	ldr	x9, [x9]
	add	x9, x9, x21
	cmp	x9, x8
	b.lo	LBB87_1
	b	LBB87_7
LBB87_3:
	ldr	x8, [x22]
	mov	x0, x20
	mov	w1, #1
	ldr	x27, [x23]
	add	x28, x8, x25
	blr	x24
	mov	x0, x20
	mov	x1, x27
	mov	x2, x28
	ldr	x8, [sp, #24]                   ; 8-byte Folded Reload
	blr	x8
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB87_5
; %bb.4:
	mov	w0, wzr
	b	LBB87_8
LBB87_5:
	ldr	x0, [x26]
	ldr	x1, [x22]
	blr	x19
	ldr	x8, [x26]
	add	x8, x8, x25
	str	x8, [x26]
	ldr	x8, [x22]
	add	x1, x8, x25
	str	x1, [x22]
	ldr	x0, [x26]
	blr	x19
	ldr	x8, [x26]
	ldr	x3, [sp, #8]                    ; 8-byte Folded Reload
	add	x8, x8, x25
	str	x8, [x26]
	ldr	x8, [x22]
	add	x8, x8, x25
	str	x8, [x22]
	ldr	x9, [x3]
	add	x9, x9, x21
	cmp	x9, x8
	b.hs	LBB87_7
; %bb.6:
	mov	x0, x26
	mov	x2, x23
	ldp	x1, x5, [sp, #16]               ; 16-byte Folded Reload
	mov	x4, x22
	mov	x6, x20
	mov	x7, x21
	stp	x19, x24, [sp, #128]
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_right_tail_2__anon_16701
LBB87_7:
	.cfi_restore_state
	mov	w0, #1
LBB87_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #64]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #48]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #128
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end87:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_right_head_2__anon_16774
l_sort.partial_forward_merge_right_head_2__anon_16774: ; @sort.partial_forward_merge_right_head_2__anon_16774
Lfunc_begin88:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x28, x27, [sp, #16]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	ldp	x23, x24, [sp, #112]
	mov	x19, x7
	mov	x20, x6
	mov	x22, x3
	mov	x21, x5
	mov	x25, x1
	mov	x26, x0
	ldr	x8, [x3]
	stp	x2, x4, [sp]                    ; 16-byte Folded Spill
LBB88_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	ldr	x27, [x25]
	add	x28, x8, x19
	blr	x24
	mov	x0, x20
	mov	x1, x27
	mov	x2, x28
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB88_3
; %bb.2:                                ;   in Loop: Header=BB88_1 Depth=1
	ldr	x0, [x26]
	ldr	x1, [x22]
	blr	x23
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x22]
	add	x1, x8, x19
	str	x1, [x22]
	ldr	x0, [x26]
	blr	x23
	ldr	x8, [x26]
	ldr	x9, [sp, #8]                    ; 8-byte Folded Reload
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x22]
	add	x8, x8, x19
	str	x8, [x22]
	ldr	x9, [x9]
	sub	x9, x9, x19
	cmp	x9, x8
	b.hi	LBB88_1
	b	LBB88_7
LBB88_3:
	ldr	x8, [x25]
	mov	x0, x20
	mov	w1, #1
	ldr	x28, [x22]
	add	x27, x8, x19
	blr	x24
	mov	x0, x20
	mov	x1, x27
	mov	x2, x28
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB88_5
; %bb.4:
	mov	w0, wzr
	b	LBB88_8
LBB88_5:
	ldr	x0, [x26]
	ldr	x1, [x25]
	blr	x23
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x25]
	add	x1, x8, x19
	str	x1, [x25]
	ldr	x0, [x26]
	blr	x23
	ldr	x8, [x26]
	ldr	x2, [sp]                        ; 8-byte Folded Reload
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x25]
	add	x8, x8, x19
	str	x8, [x25]
	ldr	x9, [x2]
	sub	x9, x9, x19
	cmp	x9, x8
	b.ls	LBB88_7
; %bb.6:
	mov	x0, x26
	mov	x1, x25
	mov	x3, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	stp	x23, x24, [sp, #112]
	ldr	x4, [sp, #8]                    ; 8-byte Folded Reload
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_left_head_2__anon_17221
LBB88_7:
	.cfi_restore_state
	mov	w0, #1
LBB88_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end88:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_left_tail_2__anon_16777
l_sort.partial_forward_merge_left_tail_2__anon_16777: ; @sort.partial_forward_merge_left_tail_2__anon_16777
Lfunc_begin89:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x23, x2
	mov	x21, x5
	mov	x22, x4
	mov	x24, x3
	mov	x25, x1
	mov	x26, x0
	ldr	x27, [sp, #96]
	neg	x28, x7
	ldr	x8, [x2]
LBB89_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x8, x28
	ldr	x2, [x22]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB89_3
; %bb.2:                                ;   in Loop: Header=BB89_1 Depth=1
	ldr	x0, [x26]
	ldr	x1, [x23]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x28
	str	x8, [x26]
	ldr	x8, [x23]
	add	x1, x8, x28
	str	x1, [x23]
	ldr	x0, [x26]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x28
	str	x8, [x26]
	ldr	x8, [x23]
	add	x8, x8, x28
	str	x8, [x23]
	ldr	x9, [x25]
	add	x9, x9, x19
	cmp	x9, x8
	b.lo	LBB89_1
	b	LBB89_7
LBB89_3:
	ldr	x8, [x22]
	mov	x0, x20
	ldr	x1, [x23]
	add	x2, x8, x28
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB89_5
; %bb.4:
	mov	w0, wzr
	b	LBB89_8
LBB89_5:
	ldr	x0, [x26]
	ldr	x1, [x22]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x28
	str	x8, [x26]
	ldr	x8, [x22]
	add	x1, x8, x28
	str	x1, [x22]
	ldr	x0, [x26]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x28
	str	x8, [x26]
	ldr	x8, [x22]
	add	x8, x8, x28
	str	x8, [x22]
	ldr	x9, [x24]
	add	x9, x9, x19
	cmp	x9, x8
	b.hs	LBB89_7
; %bb.6:
	mov	x0, x26
	mov	x1, x25
	mov	x2, x23
	mov	x3, x24
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	str	x27, [sp, #96]
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_right_tail_2__anon_16712
LBB89_7:
	.cfi_restore_state
	mov	w0, #1
LBB89_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end89:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_right_head_2__anon_16778
l_sort.partial_forward_merge_right_head_2__anon_16778: ; @sort.partial_forward_merge_right_head_2__anon_16778
Lfunc_begin90:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x22, x3
	mov	x21, x5
	mov	x23, x4
	mov	x24, x2
	mov	x25, x1
	mov	x26, x0
	ldr	x27, [sp, #96]
	ldr	x8, [x3]
LBB90_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x1, [x25]
	add	x2, x8, x19
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB90_3
; %bb.2:                                ;   in Loop: Header=BB90_1 Depth=1
	ldr	x0, [x26]
	ldr	x1, [x22]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x22]
	add	x1, x8, x19
	str	x1, [x22]
	ldr	x0, [x26]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x22]
	add	x8, x8, x19
	str	x8, [x22]
	ldr	x9, [x23]
	sub	x9, x9, x19
	cmp	x9, x8
	b.hi	LBB90_1
	b	LBB90_7
LBB90_3:
	ldr	x8, [x25]
	mov	x0, x20
	ldr	x2, [x22]
	add	x1, x8, x19
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB90_5
; %bb.4:
	mov	w0, wzr
	b	LBB90_8
LBB90_5:
	ldr	x0, [x26]
	ldr	x1, [x25]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x25]
	add	x1, x8, x19
	str	x1, [x25]
	ldr	x0, [x26]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x25]
	add	x8, x8, x19
	str	x8, [x25]
	ldr	x9, [x24]
	sub	x9, x9, x19
	cmp	x9, x8
	b.ls	LBB90_7
; %bb.6:
	mov	x0, x26
	mov	x1, x25
	mov	x2, x24
	mov	x3, x22
	mov	x4, x23
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	str	x27, [sp, #96]
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_left_head_2__anon_17226
LBB90_7:
	.cfi_restore_state
	mov	w0, #1
LBB90_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end90:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_left_tail_2__anon_16781
l_sort.partial_forward_merge_left_tail_2__anon_16781: ; @sort.partial_forward_merge_left_tail_2__anon_16781
Lfunc_begin91:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x23, x2
	mov	x21, x5
	mov	x22, x4
	mov	x24, x3
	mov	x25, x1
	mov	x26, x0
	ldr	x27, [x2]
LBB91_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	ldr	x28, [x22]
	blr	x19
	ldur	x1, [x27, #-8]
	mov	x0, x20
	ldr	x2, [x28]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB91_3
; %bb.2:                                ;   in Loop: Header=BB91_1 Depth=1
	ldr	x8, [x23]
	ldr	x9, [x26]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x26]
	sub	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x23]
	sub	x9, x8, #8
	str	x9, [x23]
	ldr	x9, [x26]
	ldur	x8, [x8, #-8]
	str	x8, [x9]
	ldr	x8, [x26]
	sub	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x23]
	sub	x27, x8, #8
	str	x27, [x23]
	ldr	x8, [x25]
	add	x8, x8, #8
	cmp	x8, x27
	b.lo	LBB91_1
	b	LBB91_7
LBB91_3:
	mov	x0, x20
	mov	w1, #1
	ldr	x27, [x23]
	ldr	x28, [x22]
	blr	x19
	ldr	x1, [x27]
	mov	x0, x20
	ldur	x2, [x28, #-8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB91_5
; %bb.4:
	mov	w0, wzr
	b	LBB91_8
LBB91_5:
	ldr	x8, [x22]
	ldr	x9, [x26]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x26]
	sub	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x22]
	sub	x9, x8, #8
	str	x9, [x22]
	ldr	x9, [x26]
	ldur	x8, [x8, #-8]
	str	x8, [x9]
	ldr	x8, [x26]
	sub	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x22]
	sub	x8, x8, #8
	str	x8, [x22]
	ldr	x9, [x24]
	add	x9, x9, #8
	cmp	x9, x8
	b.hs	LBB91_7
; %bb.6:
	mov	x0, x26
	mov	x1, x25
	mov	x2, x23
	mov	x3, x24
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_right_tail_2__anon_16723
LBB91_7:
	.cfi_restore_state
	mov	w0, #1
LBB91_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end91:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_right_head_2__anon_16782
l_sort.partial_forward_merge_right_head_2__anon_16782: ; @sort.partial_forward_merge_right_head_2__anon_16782
Lfunc_begin92:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x22, x3
	mov	x21, x5
	mov	x23, x4
	mov	x24, x2
	mov	x25, x1
	mov	x26, x0
	ldr	x27, [x3]
LBB92_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	ldr	x28, [x25]
	blr	x19
	ldr	x1, [x28]
	mov	x0, x20
	ldr	x2, [x27, #8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB92_3
; %bb.2:                                ;   in Loop: Header=BB92_1 Depth=1
	ldr	x8, [x22]
	ldr	x9, [x26]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x26]
	add	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x22]
	add	x9, x8, #8
	str	x9, [x22]
	ldr	x9, [x26]
	ldr	x8, [x8, #8]
	str	x8, [x9]
	ldr	x8, [x26]
	add	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x22]
	add	x27, x8, #8
	str	x27, [x22]
	ldr	x8, [x23]
	sub	x8, x8, #8
	cmp	x8, x27
	b.hi	LBB92_1
	b	LBB92_7
LBB92_3:
	mov	x0, x20
	mov	w1, #1
	ldr	x27, [x25]
	ldr	x28, [x22]
	blr	x19
	ldr	x1, [x27, #8]
	mov	x0, x20
	ldr	x2, [x28]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB92_5
; %bb.4:
	mov	w0, wzr
	b	LBB92_8
LBB92_5:
	ldr	x8, [x25]
	ldr	x9, [x26]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x26]
	add	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x25]
	add	x9, x8, #8
	str	x9, [x25]
	ldr	x9, [x26]
	ldr	x8, [x8, #8]
	str	x8, [x9]
	ldr	x8, [x26]
	add	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x9, [x24]
	sub	x9, x9, #8
	cmp	x9, x8
	b.ls	LBB92_7
; %bb.6:
	mov	x0, x26
	mov	x1, x25
	mov	x2, x24
	mov	x3, x22
	mov	x4, x23
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_left_head_2__anon_17231
LBB92_7:
	.cfi_restore_state
	mov	w0, #1
LBB92_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end92:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_left_tail_2__anon_16785
l_sort.partial_forward_merge_left_tail_2__anon_16785: ; @sort.partial_forward_merge_left_tail_2__anon_16785
Lfunc_begin93:
	.cfi_startproc
; %bb.0:
	stp	x26, x25, [sp, #-80]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 80
	stp	x24, x23, [sp, #16]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_remember_state
	mov	x19, x6
	mov	x20, x5
	mov	x22, x2
	mov	x21, x4
	mov	x23, x3
	mov	x24, x1
	mov	x25, x0
	ldr	x8, [x2]
LBB93_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x21]
	mov	x0, x19
	ldur	x1, [x8, #-8]
	ldr	x2, [x9]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB93_3
; %bb.2:                                ;   in Loop: Header=BB93_1 Depth=1
	ldr	x8, [x22]
	ldr	x9, [x25]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x25]
	sub	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x22]
	sub	x9, x8, #8
	str	x9, [x22]
	ldr	x9, [x25]
	ldur	x8, [x8, #-8]
	str	x8, [x9]
	ldr	x8, [x25]
	sub	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x22]
	sub	x8, x8, #8
	str	x8, [x22]
	ldr	x9, [x24]
	add	x9, x9, #8
	cmp	x9, x8
	b.lo	LBB93_1
	b	LBB93_7
LBB93_3:
	ldr	x8, [x22]
	mov	x0, x19
	ldr	x9, [x21]
	ldr	x1, [x8]
	ldur	x2, [x9, #-8]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB93_5
; %bb.4:
	mov	w0, wzr
	b	LBB93_8
LBB93_5:
	ldr	x8, [x21]
	ldr	x9, [x25]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x25]
	sub	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x21]
	sub	x9, x8, #8
	str	x9, [x21]
	ldr	x9, [x25]
	ldur	x8, [x8, #-8]
	str	x8, [x9]
	ldr	x8, [x25]
	sub	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x21]
	sub	x8, x8, #8
	str	x8, [x21]
	ldr	x9, [x23]
	add	x9, x9, #8
	cmp	x9, x8
	b.hs	LBB93_7
; %bb.6:
	mov	x1, x24
	mov	x2, x22
	mov	x3, x23
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	mov	x0, x25
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	b	l_sort.partial_forward_merge_right_tail_2__anon_16734
LBB93_7:
	.cfi_restore_state
	mov	w0, #1
LBB93_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	ret
Lfunc_end93:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_right_head_2__anon_16786
l_sort.partial_forward_merge_right_head_2__anon_16786: ; @sort.partial_forward_merge_right_head_2__anon_16786
Lfunc_begin94:
	.cfi_startproc
; %bb.0:
	stp	x26, x25, [sp, #-80]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 80
	stp	x24, x23, [sp, #16]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_remember_state
	mov	x19, x6
	mov	x20, x5
	mov	x22, x3
	mov	x21, x4
	mov	x23, x2
	mov	x24, x1
	mov	x25, x0
	ldr	x8, [x3]
LBB94_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x24]
	mov	x0, x19
	ldr	x2, [x8, #8]
	ldr	x1, [x9]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB94_3
; %bb.2:                                ;   in Loop: Header=BB94_1 Depth=1
	ldr	x8, [x22]
	ldr	x9, [x25]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x22]
	add	x9, x8, #8
	str	x9, [x22]
	ldr	x9, [x25]
	ldr	x8, [x8, #8]
	str	x8, [x9]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x22]
	add	x8, x8, #8
	str	x8, [x22]
	ldr	x9, [x21]
	sub	x9, x9, #8
	cmp	x9, x8
	b.hi	LBB94_1
	b	LBB94_7
LBB94_3:
	ldr	x8, [x24]
	mov	x0, x19
	ldr	x9, [x22]
	ldr	x1, [x8, #8]
	ldr	x2, [x9]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB94_5
; %bb.4:
	mov	w0, wzr
	b	LBB94_8
LBB94_5:
	ldr	x8, [x24]
	ldr	x9, [x25]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x24]
	add	x9, x8, #8
	str	x9, [x24]
	ldr	x9, [x25]
	ldr	x8, [x8, #8]
	str	x8, [x9]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x24]
	add	x8, x8, #8
	str	x8, [x24]
	ldr	x9, [x23]
	sub	x9, x9, #8
	cmp	x9, x8
	b.ls	LBB94_7
; %bb.6:
	mov	x1, x24
	mov	x2, x23
	mov	x3, x22
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	mov	x0, x25
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	b	l_sort.partial_forward_merge_left_head_2__anon_17236
LBB94_7:
	.cfi_restore_state
	mov	w0, #1
LBB94_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	ret
Lfunc_end94:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_left_head_2__anon_17221
l_sort.partial_forward_merge_left_head_2__anon_17221: ; @sort.partial_forward_merge_left_head_2__anon_17221
Lfunc_begin95:
	.cfi_startproc
; %bb.0:
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x28, x27, [sp, #16]             ; 16-byte Folded Spill
	stp	x26, x25, [sp, #32]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #48]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #64]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	ldp	x25, x22, [sp, #112]
	mov	x19, x7
	mov	x20, x6
	mov	x23, x1
	mov	x21, x5
	mov	x24, x3
	mov	x26, x0
	ldr	x8, [x1]
	stp	x4, x2, [sp]                    ; 16-byte Folded Spill
LBB95_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	ldr	x28, [x24]
	add	x27, x8, x19
	blr	x22
	mov	x0, x20
	mov	x1, x27
	mov	x2, x28
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB95_4
; %bb.2:                                ;   in Loop: Header=BB95_1 Depth=1
	ldr	x0, [x26]
	ldr	x1, [x23]
	blr	x25
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x23]
	add	x1, x8, x19
	str	x1, [x23]
	ldr	x0, [x26]
	blr	x25
	ldr	x8, [x26]
	ldr	x9, [sp, #8]                    ; 8-byte Folded Reload
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x23]
	add	x8, x8, x19
	str	x8, [x23]
	ldr	x9, [x9]
	sub	x9, x9, x19
	cmp	x9, x8
	b.hi	LBB95_1
LBB95_3:
	mov	w0, #1
	b	LBB95_8
LBB95_4:
	ldr	x8, [x24]
	mov	x0, x20
	mov	w1, #1
	ldr	x27, [x23]
	add	x28, x8, x19
	blr	x22
	mov	x0, x20
	mov	x1, x27
	mov	x2, x28
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB95_7
; %bb.5:
	ldr	x0, [x26]
	ldr	x1, [x24]
	blr	x25
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x24]
	add	x1, x8, x19
	str	x1, [x24]
	ldr	x0, [x26]
	blr	x25
	ldr	x8, [x26]
	ldr	x4, [sp]                        ; 8-byte Folded Reload
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x24]
	add	x8, x8, x19
	str	x8, [x24]
	ldr	x9, [x4]
	sub	x9, x9, x19
	cmp	x9, x8
	b.ls	LBB95_3
; %bb.6:
	mov	x0, x26
	mov	x1, x23
	mov	x3, x24
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	stp	x25, x22, [sp, #112]
	ldr	x2, [sp, #8]                    ; 8-byte Folded Reload
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_right_head_2__anon_16774
LBB95_7:
	.cfi_restore_state
	mov	w0, wzr
LBB95_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #48]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #32]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #112
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end95:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_left_head_2__anon_17226
l_sort.partial_forward_merge_left_head_2__anon_17226: ; @sort.partial_forward_merge_left_head_2__anon_17226
Lfunc_begin96:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x23, x1
	mov	x21, x5
	mov	x22, x4
	mov	x24, x3
	mov	x25, x2
	mov	x26, x0
	ldr	x27, [sp, #96]
	ldr	x8, [x1]
LBB96_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	add	x1, x8, x19
	ldr	x2, [x24]
	mov	x0, x20
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB96_4
; %bb.2:                                ;   in Loop: Header=BB96_1 Depth=1
	ldr	x0, [x26]
	ldr	x1, [x23]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x23]
	add	x1, x8, x19
	str	x1, [x23]
	ldr	x0, [x26]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x23]
	add	x8, x8, x19
	str	x8, [x23]
	ldr	x9, [x25]
	sub	x9, x9, x19
	cmp	x9, x8
	b.hi	LBB96_1
LBB96_3:
	mov	w0, #1
	b	LBB96_8
LBB96_4:
	ldr	x8, [x24]
	mov	x0, x20
	ldr	x1, [x23]
	add	x2, x8, x19
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB96_7
; %bb.5:
	ldr	x0, [x26]
	ldr	x1, [x24]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x24]
	add	x1, x8, x19
	str	x1, [x24]
	ldr	x0, [x26]
	blr	x27
	ldr	x8, [x26]
	add	x8, x8, x19
	str	x8, [x26]
	ldr	x8, [x24]
	add	x8, x8, x19
	str	x8, [x24]
	ldr	x9, [x22]
	sub	x9, x9, x19
	cmp	x9, x8
	b.ls	LBB96_3
; %bb.6:
	mov	x0, x26
	mov	x1, x23
	mov	x2, x25
	mov	x3, x24
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	str	x27, [sp, #96]
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_right_head_2__anon_16778
LBB96_7:
	.cfi_restore_state
	mov	w0, wzr
LBB96_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end96:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_left_head_2__anon_17231
l_sort.partial_forward_merge_left_head_2__anon_17231: ; @sort.partial_forward_merge_left_head_2__anon_17231
Lfunc_begin97:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	mov	x19, x7
	mov	x20, x6
	mov	x23, x1
	mov	x21, x5
	mov	x22, x4
	mov	x24, x3
	mov	x25, x2
	mov	x26, x0
	ldr	x27, [x1]
LBB97_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	mov	x0, x20
	mov	w1, #1
	ldr	x28, [x24]
	blr	x19
	ldr	x1, [x27, #8]
	mov	x0, x20
	ldr	x2, [x28]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB97_4
; %bb.2:                                ;   in Loop: Header=BB97_1 Depth=1
	ldr	x8, [x23]
	ldr	x9, [x26]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x26]
	add	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x23]
	add	x9, x8, #8
	str	x9, [x23]
	ldr	x9, [x26]
	ldr	x8, [x8, #8]
	str	x8, [x9]
	ldr	x8, [x26]
	add	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x23]
	add	x27, x8, #8
	str	x27, [x23]
	ldr	x8, [x25]
	sub	x8, x8, #8
	cmp	x8, x27
	b.hi	LBB97_1
LBB97_3:
	mov	w0, #1
	b	LBB97_8
LBB97_4:
	mov	x0, x20
	mov	w1, #1
	ldr	x27, [x23]
	ldr	x28, [x24]
	blr	x19
	ldr	x1, [x27]
	mov	x0, x20
	ldr	x2, [x28, #8]
	blr	x21
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB97_7
; %bb.5:
	ldr	x8, [x24]
	ldr	x9, [x26]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x26]
	add	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x24]
	add	x9, x8, #8
	str	x9, [x24]
	ldr	x9, [x26]
	ldr	x8, [x8, #8]
	str	x8, [x9]
	ldr	x8, [x26]
	add	x8, x8, #8
	str	x8, [x26]
	ldr	x8, [x24]
	add	x8, x8, #8
	str	x8, [x24]
	ldr	x9, [x22]
	sub	x9, x9, #8
	cmp	x9, x8
	b.ls	LBB97_3
; %bb.6:
	mov	x0, x26
	mov	x1, x23
	mov	x2, x25
	mov	x3, x24
	mov	x4, x22
	mov	x5, x21
	mov	x6, x20
	mov	x7, x19
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	l_sort.partial_forward_merge_right_head_2__anon_16782
LBB97_7:
	.cfi_restore_state
	mov	w0, wzr
LBB97_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
Lfunc_end97:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.partial_forward_merge_left_head_2__anon_17236
l_sort.partial_forward_merge_left_head_2__anon_17236: ; @sort.partial_forward_merge_left_head_2__anon_17236
Lfunc_begin98:
	.cfi_startproc
; %bb.0:
	stp	x26, x25, [sp, #-80]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 80
	stp	x24, x23, [sp, #16]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_remember_state
	mov	x19, x6
	mov	x20, x5
	mov	x23, x1
	mov	x21, x4
	mov	x22, x3
	mov	x24, x2
	mov	x25, x0
	ldr	x8, [x1]
LBB98_1:                                ; %tailrecurse
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x22]
	mov	x0, x19
	ldr	x1, [x8, #8]
	ldr	x2, [x9]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.eq	LBB98_4
; %bb.2:                                ;   in Loop: Header=BB98_1 Depth=1
	ldr	x8, [x23]
	ldr	x9, [x25]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x23]
	add	x9, x8, #8
	str	x9, [x23]
	ldr	x9, [x25]
	ldr	x8, [x8, #8]
	str	x8, [x9]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x23]
	add	x8, x8, #8
	str	x8, [x23]
	ldr	x9, [x24]
	sub	x9, x9, #8
	cmp	x9, x8
	b.hi	LBB98_1
LBB98_3:
	mov	w0, #1
	b	LBB98_8
LBB98_4:
	ldr	x8, [x23]
	mov	x0, x19
	ldr	x9, [x22]
	ldr	x1, [x8]
	ldr	x2, [x9, #8]
	blr	x20
	and	w8, w0, #0xff
	cmp	w8, #1
	b.ne	LBB98_7
; %bb.5:
	ldr	x8, [x22]
	ldr	x9, [x25]
	ldr	x8, [x8]
	str	x8, [x9]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x22]
	add	x9, x8, #8
	str	x9, [x22]
	ldr	x9, [x25]
	ldr	x8, [x8, #8]
	str	x8, [x9]
	ldr	x8, [x25]
	add	x8, x8, #8
	str	x8, [x25]
	ldr	x8, [x22]
	add	x8, x8, #8
	str	x8, [x22]
	ldr	x9, [x21]
	sub	x9, x9, #8
	cmp	x9, x8
	b.ls	LBB98_3
; %bb.6:
	mov	x1, x23
	mov	x2, x24
	mov	x3, x22
	mov	x4, x21
	mov	x5, x20
	mov	x6, x19
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	mov	x0, x25
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	b	l_sort.partial_forward_merge_right_head_2__anon_16786
LBB98_7:
	.cfi_restore_state
	mov	w0, wzr
LBB98_8:                                ; %common.ret1
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #16]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp], #80             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	ret
Lfunc_end98:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function sort.trinity_rotation.9
l_sort.trinity_rotation.9:              ; @sort.trinity_rotation.9
Lfunc_begin99:
	.cfi_startproc
; %bb.0:
	stp	x28, x27, [sp, #-96]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 96
	stp	x26, x25, [sp, #16]             ; 16-byte Folded Spill
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	.cfi_offset w27, -88
	.cfi_offset w28, -96
	.cfi_remember_state
	sub	x26, x1, x4
	cmp	x3, #16, lsl #12                ; =65536
	mov	w8, #65536
	mov	x20, x5
	mov	x24, x4
	mov	x22, x1
	mov	x21, x2
	mov	x19, x0
	csel	x8, x3, x8, lo
	subs	x9, x26, x4
	b.ls	LBB99_6
; %bb.1:
	mul	x23, x20, x24
	cmp	x8, x24
	b.hs	LBB99_13
; %bb.2:
	add	x1, x19, x23
	cmp	x9, x8
	b.hi	LBB99_21
; %bb.3:
	cmp	x9, #4
	b.lo	LBB99_21
; %bb.4:                                ; %.lr.ph71.preheader
	mul	x23, x9, x20
	mov	x0, x21
	mov	x2, x23
	bl	_memcpy
	sub	x10, x22, #1
	sub	x8, x24, #1
	sub	x9, x10, x24
	neg	x11, x20
	mul	x8, x20, x8
	mov	x12, x19
	mul	x9, x20, x9
	mul	x10, x20, x10
LBB99_5:                                ; %.lr.ph71
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12, x10]
	subs	x24, x24, #1
	str	x13, [x12, x9]
	ldr	x13, [x12, x8]
	str	x13, [x12, x10]
	add	x12, x12, x11
	b.ne	LBB99_5
	b	LBB99_27
LBB99_6:
	b.hs	LBB99_18
; %bb.7:
	cmp	x26, x8
	b.ls	LBB99_23
; %bb.8:
	mul	x25, x20, x24
	sub	x9, x24, x26
	mul	x27, x26, x20
	cmp	x9, x8
	b.hi	LBB99_28
; %bb.9:
	cmp	x9, #4
	b.lo	LBB99_28
; %bb.10:                               ; %.lr.ph39.preheader
	mul	x23, x9, x20
	add	x1, x19, x27
	mov	x0, x21
	add	x26, x1, x25
	mov	x2, x23
	bl	_memcpy
	sub	x8, x24, x22
LBB99_11:                               ; %.lr.ph39
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x19]
	adds	x8, x8, #1
	str	x9, [x19, x27]
	ldr	x9, [x19, x25]
	str	x9, [x19]
	add	x19, x19, x20
	b.lo	LBB99_11
; %bb.12:                               ; %._crit_edge40
	sub	x0, x26, x23
	b	LBB99_51
LBB99_13:
	mov	x0, x21
	mov	x1, x19
	mov	x2, x23
	bl	_memcpy
	mul	x8, x26, x20
	cbz	x8, LBB99_50
; %bb.14:                               ; %iter.check153
	mov	x9, xzr
	cmp	x8, #8
	b.lo	LBB99_48
; %bb.15:                               ; %iter.check153
	add	x10, x23, #31
	cmp	x10, #32
	b.lo	LBB99_48
; %bb.16:                               ; %vector.main.loop.iter.check155
	cmp	x8, #32
	b.hs	LBB99_41
; %bb.17:
	mov	x9, xzr
	b	LBB99_45
LBB99_18:
	cbz	x24, LBB99_67
; %bb.19:                               ; %.lr.ph.preheader
	mul	x8, x20, x24
LBB99_20:                               ; %.lr.ph
                                        ; =>This Inner Loop Header: Depth=1
	ldr	x9, [x19, x8]
	add	x11, x19, x20
	ldr	x10, [x19]
	subs	x24, x24, #1
	str	x9, [x19]
	str	x10, [x19, x8]
	mov	x19, x11
	b.ne	LBB99_20
	b	LBB99_67
LBB99_21:
	cmp	x24, #2
	b.hs	LBB99_30
; %bb.22:
	madd	x8, x26, x20, x1
	b	LBB99_33
LBB99_23:
	mul	x24, x20, x24
	mov	x0, x21
	mul	x23, x26, x20
	add	x1, x19, x24
	mov	x2, x23
	bl	_memcpy
	cbz	x24, LBB99_27
; %bb.24:                               ; %iter.check
	cmp	x24, #8
	b.hs	LBB99_52
LBB99_25:                               ; %.lr.ph.i3.preheader
	add	x8, x19, x23
LBB99_26:                               ; %.lr.ph.i3
                                        ; =>This Inner Loop Header: Depth=1
	add	x9, x19, x24
	subs	x10, x24, #1
	add	x11, x8, x24
	mov	x24, x10
	ldurb	w9, [x9, #-1]
	sturb	w9, [x11, #-1]
	b.ne	LBB99_26
LBB99_27:                               ; %._crit_edge72
	mov	x0, x19
	b	LBB99_51
LBB99_28:
	cmp	x26, #2
	b.hs	LBB99_57
; %bb.29:
	add	x10, x19, x25
	add	x8, x10, x27
	b	LBB99_60
LBB99_30:                               ; %.lr.ph47
	sub	x8, x24, #1
	sub	x10, x22, #1
	lsr	x9, x24, #1
	neg	x11, x20
	mul	x8, x20, x8
	mov	x12, x19
	mul	x10, x20, x10
LBB99_31:                               ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x19, x8]
	str	x13, [x19, x8]
	ldr	x13, [x12, x23]
	str	x13, [x12]
	ldr	x13, [x19, x10]
	str	x13, [x12, x23]
	add	x12, x12, x20
	str	x14, [x19, x10]
	add	x19, x19, x11
	b.ne	LBB99_31
; %bb.32:                               ; %._crit_edge48.loopexit
	madd	x8, x20, x22, x19
	add	x1, x12, x23
	mov	x19, x12
LBB99_33:                               ; %._crit_edge48
	sub	x10, x8, x1
	lsl	x9, x20, #1
	cmp	x9, x10
	b.ls	LBB99_35
; %bb.34:
	mov	x10, x8
	b	LBB99_38
LBB99_35:                               ; %.lr.ph57
	udiv	x10, x10, x9
	mov	x11, xzr
	neg	x12, x20
	cmp	x10, #1
	csinc	x13, x10, xzr, hi
	mov	x10, x8
LBB99_36:                               ; =>This Inner Loop Header: Depth=1
	add	x10, x10, x12
	ldr	x15, [x1, x11]
	subs	x13, x13, #1
	ldr	x14, [x10]
	str	x14, [x1, x11]
	ldr	x14, [x19, x11]
	str	x14, [x10]
	str	x15, [x19, x11]
	add	x11, x11, x20
	b.ne	LBB99_36
; %bb.37:                               ; %._crit_edge58.loopexit
	sub	x8, x8, x11
	add	x19, x19, x11
LBB99_38:                               ; %._crit_edge58
	sub	x8, x8, x19
	cmp	x9, x8
	b.hi	LBB99_67
; %bb.39:                               ; %.lr.ph65
	udiv	x9, x8, x9
	neg	x8, x20
	sub	x10, x10, x20
	cmp	x9, #1
	csinc	x9, x9, xzr, hi
LBB99_40:                               ; =>This Inner Loop Header: Depth=1
	ldr	x11, [x10]
	subs	x9, x9, #1
	ldr	x12, [x19]
	str	x11, [x19]
	add	x19, x19, x20
	str	x12, [x10]
	add	x10, x10, x8
	b.ne	LBB99_40
	b	LBB99_67
LBB99_41:                               ; %vector.ph156
	and	x9, x8, #0xffffffffffffffe0
	mov	x11, x19
	neg	x10, x9
LBB99_42:                               ; %vector.body160
                                        ; =>This Inner Loop Header: Depth=1
	add	x12, x11, x23
	adds	x10, x10, #32
	ldp	q0, q1, [x12]
	stp	q0, q1, [x11], #32
	b.ne	LBB99_42
; %bb.43:                               ; %middle.block150
	cmp	x8, x9
	b.eq	LBB99_50
; %bb.44:                               ; %vec.epilog.iter.check167
	tst	x8, #0x18
	b.eq	LBB99_48
LBB99_45:                               ; %vec.epilog.ph168
	mov	x11, x9
	and	x9, x8, #0xfffffffffffffff8
	add	x10, x19, x11
	sub	x11, x11, x9
LBB99_46:                               ; %vec.epilog.vector.body176
                                        ; =>This Inner Loop Header: Depth=1
	ldr	d0, [x10, x23]
	adds	x11, x11, #8
	str	d0, [x10], #8
	b.ne	LBB99_46
; %bb.47:                               ; %vec.epilog.middle.block165
	cmp	x8, x9
	b.eq	LBB99_50
LBB99_48:                               ; %.lr.ph.i.preheader
	add	x10, x19, x9
	sub	x9, x9, x8
LBB99_49:                               ; %.lr.ph.i
                                        ; =>This Inner Loop Header: Depth=1
	ldrb	w11, [x10, x23]
	adds	x9, x9, #1
	strb	w11, [x10], #1
	b.lo	LBB99_49
LBB99_50:                               ; %mem.copyForwards__anon_9882.exit
	add	x0, x19, x8
LBB99_51:                               ; %mem.copyForwards__anon_9882.exit
	mov	x1, x21
	mov	x2, x23
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	b	_memcpy
LBB99_52:                               ; %vector.scevcheck
	.cfi_restore_state
	.cfi_remember_state
	madd	x8, x20, x22, x19
	sub	x8, x8, #1
	sub	x9, x8, x24
	add	x9, x9, #1
	cmp	x9, x8
	b.hi	LBB99_25
; %bb.53:                               ; %vector.scevcheck
	add	x8, x24, x19
	sub	x8, x8, #1
	cmp	x8, x19
	b.lo	LBB99_25
; %bb.54:                               ; %vector.memcheck
	mul	x8, x20, x22
	add	x9, x24, x19
	add	x10, x8, x19
	sub	x9, x9, x10
	cmp	x9, #32
	b.lo	LBB99_25
; %bb.55:                               ; %vector.main.loop.iter.check
	cmp	x24, #32
	b.hs	LBB99_68
; %bb.56:
	mov	x9, xzr
	b	LBB99_72
LBB99_57:                               ; %.lr.ph17
	sub	x8, x22, #1
	sub	x10, x24, #1
	lsr	x9, x26, #1
	neg	x11, x20
	mul	x8, x20, x8
	mov	x12, x19
	mul	x10, x20, x10
LBB99_58:                               ; =>This Inner Loop Header: Depth=1
	ldr	x13, [x12]
	subs	x9, x9, #1
	ldr	x14, [x19, x10]
	str	x13, [x19, x10]
	ldr	x13, [x12, x25]
	str	x13, [x12]
	ldr	x13, [x19, x8]
	str	x13, [x12, x25]
	add	x12, x12, x20
	str	x14, [x19, x8]
	add	x19, x19, x11
	b.ne	LBB99_58
; %bb.59:                               ; %._crit_edge.loopexit
	madd	x8, x20, x22, x19
	add	x10, x19, x25
	mov	x19, x12
LBB99_60:                               ; %._crit_edge
	sub	x12, x10, x19
	lsl	x9, x20, #1
	cmp	x9, x12
	b.hi	LBB99_64
; %bb.61:                               ; %.lr.ph25
	udiv	x13, x12, x9
	mov	x11, xzr
	neg	x12, x20
	cmp	x13, #1
	csinc	x13, x13, xzr, hi
LBB99_62:                               ; =>This Inner Loop Header: Depth=1
	ldr	x14, [x19, x11]
	sub	x13, x13, #1
	ldr	x15, [x10, x12]
	str	x14, [x10, x12]
	ldr	x14, [x8, x12]
	str	x14, [x19, x11]
	add	x11, x11, x20
	str	x15, [x8, x12]
	sub	x12, x12, x20
	cbnz	x13, LBB99_62
; %bb.63:                               ; %._crit_edge26.loopexit
	add	x19, x19, x11
	sub	x8, x8, x11
LBB99_64:                               ; %._crit_edge26
	sub	x10, x8, x19
	cmp	x9, x10
	b.hi	LBB99_67
; %bb.65:                               ; %.lr.ph33
	udiv	x10, x10, x9
	neg	x9, x20
	sub	x8, x8, x20
	cmp	x10, #1
	csinc	x10, x10, xzr, hi
LBB99_66:                               ; =>This Inner Loop Header: Depth=1
	ldr	x11, [x8]
	subs	x10, x10, #1
	ldr	x12, [x19]
	str	x11, [x19]
	add	x19, x19, x20
	str	x12, [x8]
	add	x8, x8, x9
	b.ne	LBB99_66
LBB99_67:                               ; %common.ret
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #96             ; 16-byte Folded Reload
	.cfi_def_cfa_offset 0
	.cfi_restore w30
	.cfi_restore w29
	.cfi_restore w19
	.cfi_restore w20
	.cfi_restore w21
	.cfi_restore w22
	.cfi_restore w23
	.cfi_restore w24
	.cfi_restore w25
	.cfi_restore w26
	.cfi_restore w27
	.cfi_restore w28
	ret
LBB99_68:                               ; %vector.ph
	.cfi_restore_state
	and	x9, x24, #0xffffffffffffffe0
	add	x10, x8, x19
	add	x11, x24, x19
	sub	x10, x10, #16
	sub	x11, x11, #16
	neg	x12, x9
LBB99_69:                               ; %vector.body
                                        ; =>This Inner Loop Header: Depth=1
	ldp	q1, q0, [x11, #-16]
	sub	x11, x11, #32
	adds	x12, x12, #32
	stp	q1, q0, [x10, #-16]
	sub	x10, x10, #32
	b.ne	LBB99_69
; %bb.70:                               ; %middle.block
	cmp	x24, x9
	b.eq	LBB99_27
; %bb.71:                               ; %vec.epilog.iter.check
	tst	x24, #0x18
	b.eq	LBB99_75
LBB99_72:                               ; %vec.epilog.ph
	sub	x8, x8, x9
	sub	x12, x24, x9
	and	x11, x24, #0xfffffffffffffff8
	add	x8, x8, x19
	add	x12, x12, x19
	and	x10, x24, #0x7
	sub	x8, x8, #8
	sub	x12, x12, #8
	sub	x9, x9, x11
LBB99_73:                               ; %vec.epilog.vector.body
                                        ; =>This Inner Loop Header: Depth=1
	ldr	d0, [x12], #-8
	adds	x9, x9, #8
	str	d0, [x8], #-8
	b.ne	LBB99_73
; %bb.74:                               ; %vec.epilog.middle.block
	cmp	x24, x11
	mov	x24, x10
	b.ne	LBB99_25
	b	LBB99_27
LBB99_75:
	and	x24, x24, #0x1f
	b	LBB99_25
Lfunc_end99:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function roc_builtins.str.number_of_bytes
_roc_builtins.str.number_of_bytes:      ; @roc_builtins.str.number_of_bytes
Lfunc_begin100:
	.cfi_startproc
; %bb.0:
	b	_roc_builtins.str.count_utf8_bytes
Lfunc_end100:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_inspect_e4f9cf3a6c4e3d6be9d05048391b2e3975855fa3e34f66d41fe2c9a84e5c7b
_Inspect_inspect_e4f9cf3a6c4e3d6be9d05048391b2e3975855fa3e34f66d41fe2c9a84e5c7b: ; @Inspect_inspect_e4f9cf3a6c4e3d6be9d05048391b2e3975855fa3e34f66d41fe2c9a84e5c7b
Lfunc_begin101:
	.file	1 "." "roc_app"
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp16:
	add	x1, sp, #8
	bl	"_#Derived_toInspector_[Exit 2,StdoutErr 1]_ec2bd03bf86b935fa34d71ad7ebb49f1f10f87d343e521511d8f9e6625620cd"
	add	x0, sp, #48
	bl	_Inspect_dbgInit_3bbacd33228bca14fe5573efe7278cde33c78fe9028ba98810cff368dece
	add	x0, sp, #48
	add	x1, sp, #8
	add	x2, sp, #72
	bl	"_#Derived_custom2_c610e85212d0697cb161d4ba431ba63f273feee7dcb7927c9ff5d74ae6cbfa3"
	ldur	q0, [sp, #72]
	ldr	x8, [sp, #88]
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	add	sp, sp, #128
	ret
Ltmp17:
Lfunc_end101:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_dbgI32_da6b85ec7e1e6f2f01e92f35cc48f7475ea87261d357876fef3f23dc338e
_Inspect_dbgI32_da6b85ec7e1e6f2f01e92f35cc48f7475ea87261d357876fef3f23dc338e: ; @Inspect_dbgI32_da6b85ec7e1e6f2f01e92f35cc48f7475ea87261d357876fef3f23dc338e
Lfunc_begin102:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
	mov	w8, #2
Ltmp18:
	str	w0, [sp]
	mov	x0, sp
	add	x1, sp, #40
	strb	w8, [sp, #32]
	bl	_Inspect_custom_1149386876d826e56f26fd066413b9c565aa3dea67161e512a9ba24db887d5
	ldur	q0, [sp, #40]
	ldur	q1, [sp, #56]
	ldr	x8, [sp, #72]
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	stp	q0, q1, [x19]
	str	x8, [x19, #32]
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #112
	ret
Ltmp19:
Lfunc_end102:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_204_50a9b514f5bf5c5ff0dff77dffab9b9f2c8b7084581b52c249d53019289d446b
_Inspect_204_50a9b514f5bf5c5ff0dff77dffab9b9f2c8b7084581b52c249d53019289d446b: ; @Inspect_204_50a9b514f5bf5c5ff0dff77dffab9b9f2c8b7084581b52c249d53019289d446b
Lfunc_begin103:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
Ltmp20:
	ldr	q0, [x1]
	ldr	x8, [x1, #16]
	mov	x1, sp
	add	x2, sp, #24
	str	q0, [sp]
	str	x8, [sp, #16]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	mov	x0, sp
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #24]
	ldr	x8, [sp, #40]
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp21:
Lfunc_end103:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_custom_653de62d66328bd02e166b818cc28fc7f76ad909358c5f3f340dd1c827546c9
_Inspect_custom_653de62d66328bd02e166b818cc28fc7f76ad909358c5f3f340dd1c827546c9: ; @Inspect_custom_653de62d66328bd02e166b818cc28fc7f76ad909358c5f3f340dd1c827546c9
Lfunc_begin104:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldp	q1, q0, [x0]
	ldr	x8, [x0, #32]
	stp	q1, q0, [x1]
	str	x8, [x1, #32]
	ret
Ltmp22:
Lfunc_end104:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_206_11922f5e717257e3c76632973ee406cbf106889cd4e80e37d14c1d9c194671
_Inspect_206_11922f5e717257e3c76632973ee406cbf106889cd4e80e37d14c1d9c194671: ; @Inspect_206_11922f5e717257e3c76632973ee406cbf106889cd4e80e37d14c1d9c194671
Lfunc_begin105:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #240
	.cfi_def_cfa_offset 240
	stp	x24, x23, [sp, #176]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #192]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #224]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
Ltmp23:
	ldp	x9, x20, [x1, #16]
	mov	x19, x2
	mov	w8, #40
	ldp	x21, x22, [x1, #32]
	mov	x23, #-9151314442816847872
	add	x2, sp, #56
	ldr	q0, [x1]
	add	x1, sp, #32
	stp	x8, xzr, [sp, #32]
	str	x9, [sp, #16]
	str	q0, [sp]
	str	x23, [sp, #48]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #32
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #56
	mov	x1, sp
	add	x2, sp, #80
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	mov	x0, sp
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #80
	add	x4, sp, #104
	mov	x1, x20
	mov	x2, x21
	mov	x3, x22
	bl	_Inspect_208_36ded37b63679dfb9096703c22eba74b3449a854bc97ac179ba6ffbbbaa21
	mov	x0, x20
	mov	x1, x21
	mov	x2, x22
	bl	"l_#Attr_#dec_2"
	mov	w8, #41
	add	x0, sp, #104
	add	x1, sp, #128
	add	x2, sp, #152
	str	x23, [sp, #144]
	stp	x8, xzr, [sp, #128]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #128
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #152]
	ldr	x8, [sp, #168]
	ldp	x29, x30, [sp, #224]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #208]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #176]            ; 16-byte Folded Reload
	add	sp, sp, #240
	ret
Ltmp24:
Lfunc_end105:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_walk_52459ae5e05017996bb4298dd9ac3944ffe997fa2e2ad98ba6fd7348395f63
_List_walk_52459ae5e05017996bb4298dd9ac3944ffe997fa2e2ad98ba6fd7348395f63: ; @List_walk_52459ae5e05017996bb4298dd9ac3944ffe997fa2e2ad98ba6fd7348395f63
Lfunc_begin106:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #96
	.cfi_def_cfa_offset 96
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	mov	x19, x4
	mov	x20, x3
	mov	x21, x2
	mov	x22, x1
	mov	x23, x0
Ltmp25:
	bl	_List_len_35bfe7dc6dba25ddadede12999f2a34775468912610779bf675f9c2d81ecac
	mov	x5, x0
	add	x6, sp, #8
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x20
	mov	x4, xzr
	bl	_List_walkHelp_53eef38977ca9e3af29e8b6fc9f50f557be9bbd173abd2118eb5488f19fb2
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #96
	ret
Ltmp26:
Lfunc_end106:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_walkHelp_53eef38977ca9e3af29e8b6fc9f50f557be9bbd173abd2118eb5488f19fb2
_List_walkHelp_53eef38977ca9e3af29e8b6fc9f50f557be9bbd173abd2118eb5488f19fb2: ; @List_walkHelp_53eef38977ca9e3af29e8b6fc9f50f557be9bbd173abd2118eb5488f19fb2
Lfunc_begin107:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #224
	.cfi_def_cfa_offset 224
	stp	x26, x25, [sp, #144]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #160]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #176]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #192]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #208]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	mov	x25, x3
Ltmp27:
	mov	w3, #1
	mov	x19, x6
	mov	x21, x5
	mov	x24, x4
	mov	x20, x2
	mov	x22, x1
	mov	x23, x0
	bl	"l_#Attr_#inc_2"
	ldr	q0, [x25]
	add	x8, sp, #32
	ldr	x9, [x25, #16]
	str	q0, [sp, #32]
	str	x9, [sp, #48]
LBB107_1:                               ; %joinpointcont
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x8]
	mov	x0, x24
	ldr	x8, [x8, #16]
	mov	x1, x21
	str	q0, [sp]
	str	x8, [sp, #16]
	bl	_Num_isLt_669c1355a3e727bb53dd458f2e96e48571aa45dfabcfb4b7de1689484f11
	tbz	w0, #0, LBB107_3
; %bb.2:                                ; %then_block
                                        ;   in Loop: Header=BB107_1 Depth=1
	add	x4, sp, #64
	mov	x0, x23
	mov	x1, x22
	mov	x2, x20
	mov	x3, x24
	bl	_List_getUnsafe_2cc6e6d3c5a48a76ea218c439d44b6318e7bd267419a22dcb25b258a2c06a
	add	x0, sp, #64
	mov	w1, #1
	bl	"l_#Attr_#inc_1"
	mov	x0, sp
	add	x1, sp, #64
	add	x2, sp, #88
	bl	_Inspect_210_139c9542137b10e977a775e441e04012cc6d2c98579f3cdeb5fb42ef98df6d6
	add	x0, sp, #64
	bl	"l_#Attr_#dec_1"
	mov	x0, x24
	mov	w1, #1
	bl	_Num_addWrap_e84248fb50d0833361d0417df114b0b3b3448fff97c39cdde963b09a9aebb8
	ldur	q0, [sp, #88]
	mov	x24, x0
	ldr	x9, [sp, #104]
	add	x8, sp, #112
	str	q0, [sp, #112]
	str	x9, [sp, #128]
	b	LBB107_1
LBB107_3:                               ; %else_block
	mov	x0, x23
	mov	x1, x22
	mov	x2, x20
	bl	"l_#Attr_#dec_2"
	ldr	q0, [sp]
	ldr	x8, [sp, #16]
	ldp	x29, x30, [sp, #208]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #192]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #176]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #160]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #144]            ; 16-byte Folded Reload
	add	sp, sp, #224
	ret
Ltmp28:
Lfunc_end107:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_apply_676ec9e417566a851359c2c6d5d5332f7d40742f8274a8672f3cad244846
_Inspect_apply_676ec9e417566a851359c2c6d5d5332f7d40742f8274a8672f3cad244846: ; @Inspect_apply_676ec9e417566a851359c2c6d5d5332f7d40742f8274a8672f3cad244846
Lfunc_begin108:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x8, x0
	mov	x19, x2
Ltmp29:
	add	x2, sp, #8
	mov	x0, x1
	mov	x1, x8
	bl	_Inspect_250_6bc1e748a2edd5eacd7f49eb7476d47387e76d8e94fcfcf34a1d5a6fa86e
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp30:
Lfunc_end108:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Derived_custom3_beb22fad19423347b2aa99b33212e862ded3f83df5d6238acb1a6a9ade3e
"_#Derived_custom3_beb22fad19423347b2aa99b33212e862ded3f83df5d6238acb1a6a9ade3e": ; @"#Derived_custom3_beb22fad19423347b2aa99b33212e862ded3f83df5d6238acb1a6a9ade3e"
Lfunc_begin109:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x28, x27, [sp, #-64]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 64
	stp	x22, x21, [sp, #16]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w27, -56
	.cfi_offset w28, -64
	sub	sp, sp, #1168
	.cfi_def_cfa_offset 1232
Ltmp31:
	ldp	q1, q0, [x1]
	mov	x19, x2
	mov	x20, x0
	add	x22, sp, #120
	stp	q1, q0, [sp]
	ldrb	w8, [sp, #24]
	cmp	w8, #5
	b.hi	LBB109_3
; %bb.1:                                ; %entry
Lloh63:
	adrp	x9, LJTI109_0@PAGE
Lloh64:
	add	x9, x9, LJTI109_0@PAGEOFF
	adr	x10, LBB109_2
	ldrb	w11, [x9, x8]
	add	x10, x10, x11, lsl #2
	br	x10
LBB109_2:                               ; %branch0
	mov	x0, sp
	bl	"l_#Attr_#dec_3"
	mov	x8, #29250
	mov	w9, #25968
	movk	x8, #27503, lsl #16
	mov	x10, #-8502796096475496448
	movk	x8, #28261, lsl #32
	add	x0, sp, #96
	movk	x8, #26960, lsl #48
	add	x4, sp, #120
	mov	x1, xzr
	mov	x2, xzr
	mov	x3, xzr
	str	x10, [sp, #112]
	stp	x8, x9, [sp, #96]
	bl	_Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
	add	x0, sp, #96
	bl	"l_#Attr_#dec_1"
	mov	x0, xzr
	mov	x1, xzr
	mov	x2, xzr
	bl	"l_#Attr_#dec_2"
	ldp	q1, q2, [x22, #16]
	add	x8, sp, #176
	ldur	q0, [sp, #120]
	str	q2, [sp, #208]
	ldr	x9, [sp, #168]
	stp	q0, q1, [sp, #176]
	str	x9, [sp, #224]
	b	LBB109_9
LBB109_3:                               ; %default
	mov	x0, sp
	bl	"l_#Attr_#dec_3"
	mov	x8, #29271
	mov	w9, #111
	movk	x8, #29801, lsl #16
	mov	x10, #-8574853690513424384
	movk	x8, #23141, lsl #32
	add	x0, sp, #1008
	movk	x8, #29285, lsl #48
	add	x4, sp, #1032
	mov	x1, xzr
	mov	x2, xzr
	mov	x3, xzr
	str	x9, [sp, #1016]
	str	x8, [sp, #1008]
	str	x10, [sp, #1024]
	bl	_Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
	add	x0, sp, #1008
	bl	"l_#Attr_#dec_1"
	mov	x0, xzr
	mov	x1, xzr
	mov	x2, xzr
	bl	"l_#Attr_#dec_2"
	ldp	q0, q1, [x22, #912]
	add	x8, sp, #1088
	str	q0, [sp, #1088]
	ldr	q2, [x22, #944]
	str	q1, [sp, #1104]
	ldr	x9, [sp, #1080]
	str	q2, [sp, #1120]
	str	x9, [sp, #1136]
	b	LBB109_9
LBB109_4:                               ; %branch1
	mov	x0, sp
	bl	"l_#Attr_#dec_3"
	mov	x8, #28233
	mov	w9, #25972
	movk	x8, #25972, lsl #16
	movk	w9, #100, lsl #16
	movk	x8, #29298, lsl #32
	mov	x10, #-8430738502437568512
	movk	x8, #28789, lsl #48
	add	x0, sp, #240
	add	x4, sp, #264
	mov	x1, xzr
	mov	x2, xzr
	mov	x3, xzr
	stp	x8, x9, [sp, #240]
	str	x10, [sp, #256]
	bl	_Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
	mov	x0, xzr
	mov	x1, xzr
	mov	x2, xzr
	bl	"l_#Attr_#dec_2"
	add	x0, sp, #240
	bl	"l_#Attr_#dec_1"
	ldp	q0, q1, [x22, #144]
	add	x8, sp, #320
	ldr	q2, [x22, #176]
	stp	q0, q1, [sp, #320]
	ldr	x9, [sp, #312]
	str	q2, [sp, #352]
	str	x9, [sp, #368]
	b	LBB109_9
LBB109_5:                               ; %branch2
	mov	x9, #29775
	ldr	q0, [sp]
	movk	x9, #25960, lsl #16
	ldr	x8, [sp, #16]
	movk	x9, #114, lsl #32
	mov	x10, #-8863084066665136128
	add	x0, sp, #384
	add	x1, sp, #432
	str	q0, [sp, #384]
	stp	x8, x9, [sp, #400]
	stp	xzr, x10, [sp, #416]
	bl	_Inspect_dbgStr_d394208415ac8fe0ce8aa0ddf6a845c7cc74d818698e3d25c85705ce311f5ec
	mov	w0, #24
	mov	w1, #8
	mov	w2, #1
	bl	_roc_builtins.utils.allocate_with_refcount
	ldr	q0, [sp, #432]
	mov	x21, x0
	ldr	x8, [sp, #448]
	add	x4, sp, #456
	mov	x1, x21
	mov	w2, #1
	str	q0, [x0]
	mov	w3, #1
	str	x8, [x0, #16]
	add	x0, sp, #408
	bl	_Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
	add	x0, sp, #408
	bl	"l_#Attr_#dec_1"
	mov	x0, x21
	mov	w1, #1
	mov	w2, #1
	bl	"l_#Attr_#dec_2"
	ldp	q0, q1, [x22, #336]
	add	x8, sp, #512
	ldr	q2, [x22, #368]
	stp	q0, q1, [sp, #512]
	ldr	x9, [sp, #504]
	str	q2, [sp, #544]
	str	x9, [sp, #560]
	b	LBB109_9
LBB109_6:                               ; %branch3
	mov	x0, sp
	bl	"l_#Attr_#dec_3"
	mov	x8, #30031
	mov	w9, #29295
	movk	x8, #20340, lsl #16
	movk	w9, #121, lsl #16
	movk	x8, #19814, lsl #32
	mov	x10, #-8430738502437568512
	movk	x8, #28005, lsl #48
	add	x0, sp, #576
	add	x4, sp, #600
	mov	x1, xzr
	mov	x2, xzr
	mov	x3, xzr
	str	x8, [sp, #576]
	str	x9, [sp, #584]
	str	x10, [sp, #592]
	bl	_Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
	add	x0, sp, #576
	bl	"l_#Attr_#dec_1"
	mov	x0, xzr
	mov	x1, xzr
	mov	x2, xzr
	bl	"l_#Attr_#dec_2"
	ldp	q0, q1, [x22, #480]
	add	x8, sp, #656
	ldr	q2, [x22, #512]
	stp	q0, q1, [sp, #656]
	ldr	x9, [sp, #648]
	str	q2, [sp, #688]
	str	x9, [sp, #704]
	b	LBB109_9
LBB109_7:                               ; %branch4
	mov	x0, sp
	bl	"l_#Attr_#dec_3"
	mov	x8, #28245
	mov	w9, #25972
	movk	x8, #30067, lsl #16
	movk	w9, #100, lsl #16
	movk	x8, #28784, lsl #32
	mov	x10, #-8430738502437568512
	movk	x8, #29295, lsl #48
	add	x0, sp, #720
	add	x4, sp, #744
	mov	x1, xzr
	mov	x2, xzr
	mov	x3, xzr
	str	x8, [sp, #720]
	str	x9, [sp, #728]
	str	x10, [sp, #736]
	bl	_Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
	add	x0, sp, #720
	bl	"l_#Attr_#dec_1"
	mov	x0, xzr
	mov	x1, xzr
	mov	x2, xzr
	bl	"l_#Attr_#dec_2"
	ldp	q0, q1, [x22, #624]
	add	x8, sp, #800
	ldr	q2, [x22, #656]
	stp	q0, q1, [sp, #800]
	ldr	x9, [sp, #792]
	str	q2, [sp, #832]
	str	x9, [sp, #848]
	b	LBB109_9
LBB109_8:                               ; %branch5
	mov	x0, sp
	bl	"l_#Attr_#dec_3"
	mov	x8, #28503
	mov	w9, #27491
	movk	x8, #27765, lsl #16
	mov	x10, #-8502796096475496448
	movk	x8, #16996, lsl #32
	add	x0, sp, #864
	movk	x8, #28524, lsl #48
	add	x4, sp, #888
	mov	x1, xzr
	mov	x2, xzr
	mov	x3, xzr
	str	x9, [sp, #872]
	str	x8, [sp, #864]
	str	x10, [sp, #880]
	bl	_Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
	mov	x0, xzr
	mov	x1, xzr
	mov	x2, xzr
	bl	"l_#Attr_#dec_2"
	add	x0, sp, #864
	bl	"l_#Attr_#dec_1"
	ldp	q0, q1, [x22, #768]
	add	x8, sp, #944
	ldr	q2, [x22, #800]
	stp	q0, q1, [sp, #944]
	ldr	x9, [sp, #936]
	str	q2, [sp, #976]
	str	x9, [sp, #992]
LBB109_9:                               ; %joinpointcont
	ldp	q0, q1, [x8]
	add	x0, sp, #32
	add	x2, sp, #1144
	mov	x1, x20
	ldr	q2, [x8, #32]
	stp	q0, q1, [sp, #32]
	ldr	x8, [x8, #48]
	str	q2, [sp, #64]
	str	x8, [sp, #80]
	bl	_Inspect_apply_8acb95ddb9a746c2bf4dc0f4f96ce3b3e1f1e4f2559e7641b193db1f161d1c41
	ldr	q0, [x22, #1024]
	ldr	x8, [sp, #1160]
	str	q0, [x19]
	str	x8, [x19, #16]
	add	sp, sp, #1168
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #64             ; 16-byte Folded Reload
	ret
Ltmp32:
	.loh AdrpAdd	Lloh63, Lloh64
Lfunc_end109:
	.cfi_endproc
	.section	__TEXT,__const
LJTI109_0:
	.byte	(LBB109_2-LBB109_2)>>2
	.byte	(LBB109_4-LBB109_2)>>2
	.byte	(LBB109_5-LBB109_2)>>2
	.byte	(LBB109_6-LBB109_2)>>2
	.byte	(LBB109_7-LBB109_2)>>2
	.byte	(LBB109_8-LBB109_2)>>2
                                        ; -- End function
	.section	__TEXT,__text,regular,pure_instructions
	.p2align	2                               ; -- Begin function PlatformTasks_task_closure_stderrLine_df662f4854c7c5a297d6c339e28fd51ddc944983db9bc7f012ab2c1c69a52db6
_PlatformTasks_task_closure_stderrLine_df662f4854c7c5a297d6c339e28fd51ddc944983db9bc7f012ab2c1c69a52db6: ; @PlatformTasks_task_closure_stderrLine_df662f4854c7c5a297d6c339e28fd51ddc944983db9bc7f012ab2c1c69a52db6
Lfunc_begin110:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp33:
	mov	x1, sp
	mov	x20, x0
	bl	_roc_fx_stderrLine_fastcc_wrapper
	mov	x0, x20
	bl	"l_#Attr_#dec_1"
	ldp	q0, q1, [sp]
	stp	q0, q1, [x19]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp34:
Lfunc_end110:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_38_464ad9696114b8eea8bc3daaaa648b1d3685be4c8d824dbb0c93c169d61
_Task_38_464ad9696114b8eea8bc3daaaa648b1d3685be4c8d824dbb0c93c169d61: ; @Task_38_464ad9696114b8eea8bc3daaaa648b1d3685be4c8d824dbb0c93c169d61
Lfunc_begin111:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #16
	.cfi_def_cfa_offset 16
Ltmp35:
	strb	wzr, [sp, #12]
	str	w0, [sp, #8]
	ldr	x8, [sp, #8]
	str	x8, [x1]
	add	sp, sp, #16
	ret
Ltmp36:
Lfunc_end111:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e: ; @Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
Lfunc_begin112:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
Ltmp37:
	add	x2, sp, #8
	bl	_Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp38:
Lfunc_end112:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_dbgStr_d394208415ac8fe0ce8aa0ddf6a845c7cc74d818698e3d25c85705ce311f5ec
_Inspect_dbgStr_d394208415ac8fe0ce8aa0ddf6a845c7cc74d818698e3d25c85705ce311f5ec: ; @Inspect_dbgStr_d394208415ac8fe0ce8aa0ddf6a845c7cc74d818698e3d25c85705ce311f5ec
Lfunc_begin113:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp39:
	add	x1, sp, #8
	bl	_Inspect_custom_f0adb8f180253d489b50ac5199522556362f583929ee5e65c919bd9ed2bc82f
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp40:
Lfunc_end113:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Derived_custom2_c610e85212d0697cb161d4ba431ba63f273feee7dcb7927c9ff5d74ae6cbfa3
"_#Derived_custom2_c610e85212d0697cb161d4ba431ba63f273feee7dcb7927c9ff5d74ae6cbfa3": ; @"#Derived_custom2_c610e85212d0697cb161d4ba431ba63f273feee7dcb7927c9ff5d74ae6cbfa3"
Lfunc_begin114:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x28, x27, [sp, #-64]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 64
	stp	x22, x21, [sp, #16]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w27, -56
	.cfi_offset w28, -64
	sub	sp, sp, #560
	.cfi_def_cfa_offset 624
	mov	x19, x2
	mov	x20, x0
Ltmp41:
	ldrb	w8, [x1, #32]
	add	x22, sp, #120
	cbz	w8, LBB114_2
; %bb.1:                                ; %else_block
	ldp	q0, q1, [x1]
	mov	x8, #29779
	mov	w9, #114
	movk	x8, #28516, lsl #16
	mov	x10, #-8574853690513424384
	movk	x8, #29813, lsl #32
	add	x0, sp, #320
	movk	x8, #29253, lsl #48
	add	x1, sp, #384
	str	x10, [sp, #376]
	stp	q0, q1, [sp, #320]
	stp	x8, x9, [sp, #360]
	bl	"_#Derived_toInspector_[BrokenPipe 0,Interrupted 0,Other 1,OutOfMemory 0,Unsupported 0,WouldBlock 0,WriteZero 0]_f03bf86f79d121cbfd774dec4a65912e99f5f17c33852bbc45e81916e62b53b"
	mov	w0, #40
	mov	w1, #8
	mov	w2, #1
	bl	_roc_builtins.utils.allocate_with_refcount
	ldp	q0, q1, [sp, #384]
	mov	x21, x0
	add	x4, sp, #424
	mov	x1, x21
	mov	w2, #1
	mov	w3, #1
	ldr	x8, [sp, #416]
	stp	q0, q1, [x0]
	str	x8, [x0, #32]
	add	x0, sp, #360
	bl	_Inspect_dbgTag_d1a1e4356bd9fe6c31754def4c60a14042ade1c6c101618179cfd5d1c73189
	mov	x0, x21
	mov	w1, #1
	mov	w2, #1
	bl	"l_#Attr_#dec_4"
	add	x0, sp, #360
	bl	"l_#Attr_#dec_1"
	ldp	q0, q1, [x22, #304]
	add	x8, sp, #480
	ldr	q2, [x22, #336]
	stp	q0, q1, [sp, #480]
	ldr	x9, [sp, #472]
	str	q2, [sp, #512]
	str	x9, [sp, #528]
	b	LBB114_3
LBB114_2:                               ; %then_block
	mov	w9, #30789
	ldr	q0, [x1]
	ldr	x8, [x1, #16]
	movk	w9, #29801, lsl #16
	mov	x10, #-8935141660703064064
	ldr	w0, [x1, #24]
	add	x1, sp, #120
	str	q0, [sp, #64]
	str	x8, [sp, #80]
	stp	x9, xzr, [sp, #96]
	str	x10, [sp, #112]
	bl	_Inspect_dbgI32_da6b85ec7e1e6f2f01e92f35cc48f7475ea87261d357876fef3f23dc338e
	add	x0, sp, #64
	add	x1, sp, #160
	bl	_Inspect_dbgStr_e3211b24ebda6e959f98c8dfabbb8bde232b75ae94930caa03d2bdb8e7b5674
	add	x0, sp, #64
	bl	"l_#Attr_#dec_1"
	mov	w0, #80
	mov	w1, #8
	mov	w2, #1
	bl	_roc_builtins.utils.allocate_with_refcount
	ldur	q0, [sp, #120]
	mov	x21, x0
	ldr	q1, [x22, #16]
	add	x4, sp, #200
	ldr	x8, [sp, #152]
	mov	x1, x21
	mov	w2, #2
	mov	w3, #2
	stp	q0, q1, [x0]
	str	x8, [x0, #32]
	ldp	q0, q1, [sp, #160]
	stur	q0, [x0, #40]
	ldr	x8, [sp, #192]
	stur	q1, [x0, #56]
	str	x8, [x0, #72]
	add	x0, sp, #96
	bl	_Inspect_dbgTag_d1a1e4356bd9fe6c31754def4c60a14042ade1c6c101618179cfd5d1c73189
	mov	x0, x21
	mov	w1, #2
	mov	w2, #2
	bl	"l_#Attr_#dec_4"
	add	x0, sp, #96
	bl	"l_#Attr_#dec_1"
	ldp	q0, q1, [x22, #80]
	add	x8, sp, #256
	ldr	q2, [x22, #112]
	stp	q0, q1, [sp, #256]
	ldr	x9, [sp, #248]
	str	q2, [sp, #288]
	str	x9, [sp, #304]
LBB114_3:                               ; %joinpointcont
	ldp	q0, q1, [x8]
	mov	x0, sp
	add	x2, sp, #536
	mov	x1, x20
	ldr	q2, [x8, #32]
	stp	q0, q1, [sp]
	ldr	x8, [x8, #48]
	str	q2, [sp, #32]
	str	x8, [sp, #48]
	bl	_Inspect_apply_4afec3b1b615e34b46f852dc4576722a03d82d96cc27deb38d7b350ecaf31
	ldr	q0, [x22, #416]
	ldr	x8, [sp, #552]
	str	q0, [x19]
	str	x8, [x19, #16]
	add	sp, sp, #560
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #64             ; 16-byte Folded Reload
	ret
Ltmp42:
Lfunc_end114:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_206_f784f33513051f4f09b2b103edd2f576ced88ace36b12d3f4e2a3dbe51fcfeb
_Inspect_206_f784f33513051f4f09b2b103edd2f576ced88ace36b12d3f4e2a3dbe51fcfeb: ; @Inspect_206_f784f33513051f4f09b2b103edd2f576ced88ace36b12d3f4e2a3dbe51fcfeb
Lfunc_begin115:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #240
	.cfi_def_cfa_offset 240
	stp	x24, x23, [sp, #176]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #192]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #224]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
Ltmp43:
	ldp	x9, x20, [x1, #16]
	mov	x19, x2
	mov	w8, #40
	ldp	x21, x22, [x1, #32]
	mov	x23, #-9151314442816847872
	add	x2, sp, #56
	ldr	q0, [x1]
	add	x1, sp, #32
	stp	x8, xzr, [sp, #32]
	str	x9, [sp, #16]
	str	q0, [sp]
	str	x23, [sp, #48]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #32
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #56
	mov	x1, sp
	add	x2, sp, #80
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	mov	x0, sp
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #80
	add	x4, sp, #104
	mov	x1, x20
	mov	x2, x21
	mov	x3, x22
	bl	_Inspect_208_af2554e3880a1c7af81a4c13c1df135146f6cac58d2d046bda16fbd7c23db3
	mov	x0, x20
	mov	x1, x21
	mov	x2, x22
	bl	"l_#Attr_#dec_4"
	mov	w8, #41
	add	x0, sp, #104
	add	x1, sp, #128
	add	x2, sp, #152
	str	x23, [sp, #144]
	stp	x8, xzr, [sp, #128]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #128
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #152]
	ldr	x8, [sp, #168]
	ldp	x29, x30, [sp, #224]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #208]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #176]            ; 16-byte Folded Reload
	add	sp, sp, #240
	ret
Ltmp44:
Lfunc_end115:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198
_Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198: ; @Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198
Lfunc_begin116:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp45:
	add	x8, sp, #8
	mov	x19, x2
	bl	_roc_builtins.str.concat
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp46:
Lfunc_end116:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_walk_078eba49b7090dbd2c6fb82297218e6d2eb88883fa33ff213b919f6e68cc
_List_walk_078eba49b7090dbd2c6fb82297218e6d2eb88883fa33ff213b919f6e68cc: ; @List_walk_078eba49b7090dbd2c6fb82297218e6d2eb88883fa33ff213b919f6e68cc
Lfunc_begin117:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #96
	.cfi_def_cfa_offset 96
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	mov	x19, x4
	mov	x20, x3
	mov	x21, x2
	mov	x22, x1
	mov	x23, x0
Ltmp47:
	bl	_List_len_68697e959be5e5da06cc73b6f998e193cbf2d9b22efd0355a3d37129951b
	mov	x5, x0
	add	x6, sp, #8
	mov	x0, x23
	mov	x1, x22
	mov	x2, x21
	mov	x3, x20
	mov	x4, xzr
	bl	_List_walkHelp_99aa979e4a9cadd6dbe48ea878ec84acb7696eb93470c375f6893f1da46c3772
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #96
	ret
Ltmp48:
Lfunc_end117:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function _7_52aff1341cf42f5e6559a2cf028663f7bbbc7576ac1948fc58784a0613b79
__7_52aff1341cf42f5e6559a2cf028663f7bbbc7576ac1948fc58784a0613b79: ; @_7_52aff1341cf42f5e6559a2cf028663f7bbbc7576ac1948fc58784a0613b79
Lfunc_begin118:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp49:
	bl	"l_#Attr_#dec_3"
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	ldr	w0, [x19]
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	b	_Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565
Ltmp50:
Lfunc_end118:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #UserApp_main_bae7cba17581e9e24ed8c02e992f1bda9aeff2d299cc1289ddd0dbdf373061
"_#UserApp_main_bae7cba17581e9e24ed8c02e992f1bda9aeff2d299cc1289ddd0dbdf373061": ; @"#UserApp_main_bae7cba17581e9e24ed8c02e992f1bda9aeff2d299cc1289ddd0dbdf373061"
Lfunc_begin119:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #96
	.cfi_def_cfa_offset 96
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp51:
	bl	_Test_calculateMiddleTotal_b5dcd15815911a96b9d7e883b1723ec1e9f2a35835ca79db2284140ebd0aa83
	mov	w8, #26984
	mov	x9, #-9007199254740992000
	movk	w8, #32, lsl #16
	add	x1, sp, #32
	str	x9, [sp, #24]
	stp	x8, xzr, [sp, #8]
	bl	_Num_toStr_7f7e162ee4345c12acb2c8dddfd129c8c9ef562ecb31841cfff13d4789ffc2
	add	x0, sp, #8
	add	x1, sp, #32
	add	x2, sp, #56
	bl	_Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198
	add	x0, sp, #32
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #56
	bl	_Stdout_line_c852b6d75d2364d70d094699f8a9cda9129d5310ed82ea45564f47a9
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #96
	ret
Ltmp52:
Lfunc_end119:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_ok_7f8c4a473141d41efa7657e3f378539f18179e0b2dff0f626f6dce25d295f
_Task_ok_7f8c4a473141d41efa7657e3f378539f18179e0b2dff0f626f6dce25d295f: ; @Task_ok_7f8c4a473141d41efa7657e3f378539f18179e0b2dff0f626f6dce25d295f
Lfunc_begin120:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldp	q0, q1, [sp, #-48]!
	.cfi_def_cfa_offset 48
	strb	wzr, [sp, #40]
	ldr	q2, [sp, #32]
	stp	q0, q1, [x0]
	str	q2, [x0, #32]
	add	sp, sp, #48
	ret
Ltmp53:
Lfunc_end120:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Stdout_handleErr_539d94cac9151288c18279a5f1573e8d65d66aeb5922fa6ed8cbc577893894
_Stdout_handleErr_539d94cac9151288c18279a5f1573e8d65d66aeb5922fa6ed8cbc577893894: ; @Stdout_handleErr_539d94cac9151288c18279a5f1573e8d65d66aeb5922fa6ed8cbc577893894
Lfunc_begin121:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x24, x23, [sp, #-64]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 64
	stp	x22, x21, [sp, #16]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	sub	sp, sp, #656
	.cfi_def_cfa_offset 720
	mov	x23, #29253
	mov	x8, #14948
	mov	x9, #20590
	movk	x23, #28530, lsl #16
	movk	x8, #16954, lsl #16
	movk	x9, #28777, lsl #16
	movk	x23, #19314, lsl #32
	movk	x8, #28530, lsl #32
	movk	x9, #101, lsl #32
	mov	x19, x1
	movk	x23, #28265, lsl #48
	movk	x8, #25963, lsl #48
	movk	x9, #38144, lsl #48
Ltmp54:
	add	x1, sp, #8
	mov	x20, x0
	stp	x23, x8, [sp, #8]
	str	x9, [sp, #24]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #8
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB121_2
; %bb.1:                                ; %then_block
	ldr	q0, [sp, #32]
	strb	wzr, [sp, #56]
	ldr	x9, [sp, #48]
	add	x8, sp, #64
	strb	wzr, [sp, #88]
	str	q0, [sp, #64]
	str	x9, [sp, #80]
	b	LBB121_13
LBB121_2:                               ; %else_block
	mov	x8, #14948
	mov	x9, #27714
	movk	x8, #22330, lsl #16
	movk	x9, #25455, lsl #16
	movk	x8, #30063, lsl #32
	movk	x9, #107, lsl #32
	movk	x8, #25708, lsl #48
	movk	x9, #38144, lsl #48
	add	x1, sp, #104
	mov	x0, x20
	add	x22, sp, #160
	stp	x23, x8, [sp, #104]
	str	x9, [sp, #120]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #104
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB121_4
; %bb.3:                                ; %then_block9
	mov	w9, #5
	ldr	q0, [sp, #128]
	ldr	x10, [sp, #144]
	add	x8, sp, #160
	strb	w9, [sp, #152]
	str	q0, [x22]
	str	x10, [sp, #176]
	strb	w9, [sp, #184]
	b	LBB121_13
LBB121_4:                               ; %else_block10
	mov	x8, #14948
	mov	x9, #25946
	movk	x8, #22330, lsl #16
	movk	x9, #28530, lsl #16
	movk	x8, #26994, lsl #32
	movk	x9, #37888, lsl #48
	movk	x8, #25972, lsl #48
	add	x1, sp, #200
	mov	x0, x20
	str	x9, [sp, #216]
	stp	x23, x8, [sp, #200]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #200
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB121_6
; %bb.5:                                ; %then_block24
	mov	w9, #6
	ldr	q0, [x22, #64]
	ldr	x10, [sp, #240]
	add	x8, sp, #256
	strb	w9, [sp, #248]
	str	q0, [x22, #96]
	str	x10, [sp, #272]
	strb	w9, [sp, #280]
	b	LBB121_13
LBB121_6:                               ; %else_block25
	mov	x8, #14948
	mov	x9, #28528
	movk	x8, #21818, lsl #16
	movk	x9, #29810, lsl #16
	movk	x8, #29550, lsl #32
	movk	x9, #25701, lsl #32
	movk	x8, #28789, lsl #48
	movk	x9, #38400, lsl #48
	add	x1, sp, #296
	mov	x0, x20
	stp	x23, x8, [sp, #296]
	str	x9, [sp, #312]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #296
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB121_8
; %bb.7:                                ; %then_block39
	mov	w9, #4
	ldr	q0, [x22, #160]
	ldr	x10, [sp, #336]
	add	x8, sp, #352
	strb	w9, [sp, #344]
	str	q0, [x22, #192]
	str	x10, [sp, #368]
	strb	w9, [sp, #376]
	b	LBB121_13
LBB121_8:                               ; %else_block40
	mov	x8, #14948
	mov	x9, #30066
	movk	x8, #18746, lsl #16
	movk	x9, #29808, lsl #16
	movk	x8, #29806, lsl #32
	movk	x9, #25701, lsl #32
	movk	x8, #29285, lsl #48
	movk	x9, #38400, lsl #48
	add	x1, sp, #392
	mov	x0, x20
	stp	x23, x8, [sp, #392]
	str	x9, [sp, #408]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #392
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB121_10
; %bb.9:                                ; %then_block54
	mov	w9, #1
	ldr	q0, [x22, #256]
	ldr	x10, [sp, #432]
	add	x8, sp, #448
	strb	w9, [sp, #440]
	str	q0, [x22, #288]
	str	x10, [sp, #464]
	strb	w9, [sp, #472]
	b	LBB121_13
LBB121_10:                              ; %else_block55
	mov	x8, #14948
	mov	x9, #25933
	movk	x8, #20282, lsl #16
	movk	x9, #28525, lsl #16
	movk	x8, #29813, lsl #32
	movk	x9, #31090, lsl #32
	movk	x8, #26191, lsl #48
	movk	x9, #38400, lsl #48
	add	x1, sp, #488
	mov	x0, x20
	stp	x23, x8, [sp, #488]
	str	x9, [sp, #504]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #488
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB121_12
; %bb.11:                               ; %then_block69
	mov	w9, #3
	ldr	q0, [x22, #352]
	ldr	x10, [sp, #528]
	add	x8, sp, #544
	strb	w9, [sp, #536]
	str	q0, [x22, #384]
	str	x10, [sp, #560]
	strb	w9, [sp, #568]
	b	LBB121_13
LBB121_12:                              ; %else_block70
	mov	x0, x20
	mov	w1, #1
	bl	"l_#Attr_#inc_1"
	ldp	x8, x9, [x20]
	mov	w11, #2
	ldr	x10, [x20, #16]
	str	x8, [sp, #584]
	add	x8, sp, #329
	str	x9, [sp, #592]
	add	x9, sp, #361
	str	x10, [sp, #600]
	ldur	q0, [x8, #255]
	add	x8, sp, #616
	strb	w11, [sp, #608]
	strb	w11, [sp, #640]
	str	x10, [sp, #632]
	stur	q0, [x9, #255]
LBB121_13:                              ; %common.ret
	mov	w9, #1
	ldp	q0, q1, [x8]
	strb	w9, [x8, #32]
	ldr	x8, [x8, #32]
	stp	q0, q1, [x19]
	str	x8, [x19, #32]
	add	sp, sp, #656
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #16]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp], #64             ; 16-byte Folded Reload
	ret
Ltmp55:
Lfunc_end121:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_toStr_7cfa03e91e0ec9327f388a68dbd26ae2735e7e95165f9e519543e02299bee9
_Inspect_toStr_7cfa03e91e0ec9327f388a68dbd26ae2735e7e95165f9e519543e02299bee9: ; @Inspect_toStr_7cfa03e91e0ec9327f388a68dbd26ae2735e7e95165f9e519543e02299bee9
Lfunc_begin122:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp56:
	mov	x1, sp
	bl	_Inspect_inspect_e4f9cf3a6c4e3d6be9d05048391b2e3975855fa3e34f66d41fe2c9a84e5c7b
	mov	x0, sp
	add	x1, sp, #24
	bl	_Inspect_toDbgStr_9d7544bbc8507265e131f9b42f567d6c54e799c62356103470ba3daf5673a8
	ldur	q0, [sp, #24]
	ldr	x8, [sp, #40]
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp57:
Lfunc_end122:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_210_3d7aff37b23cd9f9e6beb177d8bf818babb9d186ea278cc981a34be43b8cf34
_Inspect_210_3d7aff37b23cd9f9e6beb177d8bf818babb9d186ea278cc981a34be43b8cf34: ; @Inspect_210_3d7aff37b23cd9f9e6beb177d8bf818babb9d186ea278cc981a34be43b8cf34
Lfunc_begin123:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
	mov	x20, x1
	mov	w8, #32
	mov	x9, #-9151314442816847872
Ltmp58:
	add	x1, sp, #8
	add	x2, sp, #32
	stp	x8, xzr, [sp, #8]
	str	x9, [sp, #24]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #8
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #32
	add	x2, sp, #56
	mov	x1, x20
	bl	_Inspect_213_24ce363245042dce6c6647d3662b4b2c84c622d118936f8265c24f93e9d3a2c
	ldur	q0, [sp, #56]
	ldr	x8, [sp, #72]
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #112
	ret
Ltmp59:
Lfunc_end123:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_42_dee69d62f6dd2acac17218e148d3d8138e18cca99859936284942954b14b32
_Task_42_dee69d62f6dd2acac17218e148d3d8138e18cca99859936284942954b14b32: ; @Task_42_dee69d62f6dd2acac17218e148d3d8138e18cca99859936284942954b14b32
Lfunc_begin124:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #160
	.cfi_def_cfa_offset 160
	stp	x20, x19, [sp, #128]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #144]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x3
Ltmp60:
	add	x3, sp, #8
	bl	_Task_67_fea4b522fb116c2bf818212d595291e57cec745699352eecbb7184315f386ce8
	add	x0, sp, #8
	add	x1, sp, #56
	bl	__3_12f97a97f61aca488b75d4cbbdb83020191eefe4f33d263875d76e4b447613
	ldrb	w8, [sp, #96]
	cbz	w8, LBB124_3
; %bb.1:                                ; %entry
	add	x0, sp, #56
	cmp	w8, #1
	b.ne	LBB124_4
; %bb.2:                                ; %branch1
	add	x1, sp, #112
	bl	_Task_38_837964ef27185f97a31536069e8f60f59d43cf26aef4e69eeafaab204a51f2
	ldr	x8, [sp, #112]
	b	LBB124_5
LBB124_3:                               ; %branch0
	add	x0, sp, #56
	add	x1, sp, #104
	bl	_Task_35_3899d549ca6f5b7757a69b861e0c9a44bfbbd717ac2039f8ca1abc46d7d32e
	ldr	x8, [sp, #104]
	b	LBB124_5
LBB124_4:                               ; %default
	add	x1, sp, #120
	bl	_Task_46_56b1edb1daf8df7ae4fb1a2df75794dcef5a427f85ac1fa18ff4bea1e8e00
	ldr	x8, [sp, #120]
LBB124_5:                               ; %common.ret
	str	x8, [x19]
	ldp	x29, x30, [sp, #144]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #128]            ; 16-byte Folded Reload
	add	sp, sp, #160
	ret
Ltmp61:
Lfunc_end124:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Stderr_handleErr_1c44a9ca60e694ea5bce656141adb8728c249dc46543e7c34883c1136ab140
_Stderr_handleErr_1c44a9ca60e694ea5bce656141adb8728c249dc46543e7c34883c1136ab140: ; @Stderr_handleErr_1c44a9ca60e694ea5bce656141adb8728c249dc46543e7c34883c1136ab140
Lfunc_begin125:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #432
	.cfi_def_cfa_offset 432
	stp	x28, x27, [sp, #368]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #384]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #400]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #416]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w27, -56
	.cfi_offset w28, -64
	mov	x22, #29253
	mov	x8, #14948
	mov	x9, #20590
	movk	x22, #28530, lsl #16
	movk	x8, #16954, lsl #16
	movk	x9, #28777, lsl #16
	movk	x22, #19314, lsl #32
	movk	x8, #28530, lsl #32
	movk	x9, #101, lsl #32
	mov	x19, x1
	movk	x22, #28265, lsl #48
	movk	x8, #25963, lsl #48
	movk	x9, #38144, lsl #48
Ltmp62:
	mov	x1, sp
	mov	x20, x0
	stp	x22, x8, [sp]
	str	x9, [sp, #16]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	mov	x0, sp
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB125_2
; %bb.1:
	mov	w8, wzr
	add	x9, sp, #24
	b	LBB125_13
LBB125_2:                               ; %else_block
	mov	x8, #14948
	mov	x9, #27714
	movk	x8, #22330, lsl #16
	movk	x9, #25455, lsl #16
	movk	x8, #30063, lsl #32
	movk	x9, #107, lsl #32
	movk	x8, #25708, lsl #48
	movk	x9, #38144, lsl #48
	add	x1, sp, #56
	mov	x0, x20
	stp	x22, x8, [sp, #56]
	str	x9, [sp, #72]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #56
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB125_4
; %bb.3:
	mov	w8, #5
	add	x9, sp, #80
	b	LBB125_13
LBB125_4:                               ; %else_block7
	mov	x8, #14948
	mov	x9, #25946
	movk	x8, #22330, lsl #16
	movk	x9, #28530, lsl #16
	movk	x8, #26994, lsl #32
	movk	x9, #37888, lsl #48
	movk	x8, #25972, lsl #48
	add	x1, sp, #112
	mov	x0, x20
	str	x9, [sp, #128]
	stp	x22, x8, [sp, #112]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #112
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB125_6
; %bb.5:
	mov	w8, #6
	add	x9, sp, #136
	b	LBB125_13
LBB125_6:                               ; %else_block17
	mov	x8, #14948
	mov	x9, #28528
	movk	x8, #21818, lsl #16
	movk	x9, #29810, lsl #16
	movk	x8, #29550, lsl #32
	movk	x9, #25701, lsl #32
	movk	x8, #28789, lsl #48
	movk	x9, #38400, lsl #48
	add	x1, sp, #168
	mov	x0, x20
	stp	x22, x8, [sp, #168]
	str	x9, [sp, #184]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #168
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB125_8
; %bb.7:
	mov	w8, #4
	add	x9, sp, #192
	b	LBB125_13
LBB125_8:                               ; %else_block27
	mov	x8, #14948
	mov	x9, #30066
	movk	x8, #18746, lsl #16
	movk	x9, #29808, lsl #16
	movk	x8, #29806, lsl #32
	movk	x9, #25701, lsl #32
	movk	x8, #29285, lsl #48
	movk	x9, #38400, lsl #48
	add	x1, sp, #224
	mov	x0, x20
	stp	x22, x8, [sp, #224]
	str	x9, [sp, #240]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #224
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB125_10
; %bb.9:
	mov	w8, #1
	add	x9, sp, #248
	b	LBB125_13
LBB125_10:                              ; %else_block37
	mov	x8, #14948
	mov	x9, #25933
	movk	x8, #20282, lsl #16
	movk	x9, #28525, lsl #16
	movk	x8, #29813, lsl #32
	movk	x9, #31090, lsl #32
	movk	x8, #26191, lsl #48
	movk	x9, #38400, lsl #48
	add	x1, sp, #280
	mov	x0, x20
	stp	x22, x8, [sp, #280]
	str	x9, [sp, #296]
	bl	_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	mov	w21, w0
	add	x0, sp, #280
	bl	"l_#Attr_#dec_1"
	tbz	w21, #0, LBB125_12
; %bb.11:
	mov	w8, #3
	add	x9, sp, #304
	b	LBB125_13
LBB125_12:                              ; %else_block47
	mov	x0, x20
	mov	w1, #1
	bl	"l_#Attr_#inc_1"
	ldr	q0, [x20]
	mov	w8, #2
	ldr	x10, [x20, #16]
	add	x9, sp, #336
	str	q0, [sp, #336]
	str	x10, [sp, #352]
LBB125_13:                              ; %common.ret
	strb	w8, [x9, #24]
	ldp	q0, q1, [x9]
	stp	q0, q1, [x19]
	ldp	x29, x30, [sp, #416]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #400]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #384]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #368]            ; 16-byte Folded Reload
	add	sp, sp, #432
	ret
Ltmp63:
Lfunc_end125:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_35_3899d549ca6f5b7757a69b861e0c9a44bfbbd717ac2039f8ca1abc46d7d32e
_Task_35_3899d549ca6f5b7757a69b861e0c9a44bfbbd717ac2039f8ca1abc46d7d32e: ; @Task_35_3899d549ca6f5b7757a69b861e0c9a44bfbbd717ac2039f8ca1abc46d7d32e
Lfunc_begin126:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #16
	.cfi_def_cfa_offset 16
	mov	w8, #1
Ltmp64:
	strb	w8, [sp, #12]
	ldr	x8, [sp, #8]
	str	x8, [x1]
	add	sp, sp, #16
	ret
Ltmp65:
Lfunc_end126:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_67_fea4b522fb116c2bf818212d595291e57cec745699352eecbb7184315f386ce8
_Task_67_fea4b522fb116c2bf818212d595291e57cec745699352eecbb7184315f386ce8: ; @Task_67_fea4b522fb116c2bf818212d595291e57cec745699352eecbb7184315f386ce8
Lfunc_begin127:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #320
	.cfi_def_cfa_offset 320
	stp	x28, x27, [sp, #272]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #288]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #304]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w27, -40
	.cfi_offset w28, -48
Ltmp66:
	stp	x1, x2, [sp, #16]
	add	x1, sp, #32
	str	x0, [sp, #8]
	add	x0, sp, #8
	mov	x19, x3
	bl	_PlatformTasks_task_closure_stdoutLine_e8e3cb4c459a1e25c7bed4d87759a21ad8b1f9ce7dd1dd4beba947ebadfffae4
	ldrb	w8, [sp, #56]
	cmp	w8, #1
	b.ne	LBB127_2
; %bb.1:
	add	x9, sp, #64
	b	LBB127_3
LBB127_2:                               ; %else_block
	ldr	q0, [sp, #32]
	add	x0, sp, #112
	ldr	x8, [sp, #48]
	add	x1, sp, #136
	add	x20, sp, #176
	str	q0, [sp, #112]
	str	x8, [sp, #128]
	bl	_Stdout_handleErr_539d94cac9151288c18279a5f1573e8d65d66aeb5922fa6ed8cbc577893894
	add	x0, sp, #112
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #136]
	mov	w8, wzr
	ldur	q1, [sp, #152]
	add	x9, sp, #224
	ldr	x10, [sp, #168]
	stp	q0, q1, [x20]
	str	x10, [sp, #208]
	stp	q0, q1, [x20, #48]
	str	x10, [sp, #256]
LBB127_3:                               ; %common.ret
	ldp	q0, q1, [x9]
	strb	w8, [x9, #40]
	ldr	q2, [x9, #32]
	stp	q0, q1, [x19]
	ldp	x29, x30, [sp, #304]            ; 16-byte Folded Reload
	str	q2, [x19, #32]
	ldp	x20, x19, [sp, #288]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #272]            ; 16-byte Folded Reload
	add	sp, sp, #320
	ret
Ltmp67:
Lfunc_end127:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function PlatformTasks_stdoutLine_4dcdd9fc1c563c9592918682f5bb9bfbff249c75cdcf934a994231c5c3a018
_PlatformTasks_stdoutLine_4dcdd9fc1c563c9592918682f5bb9bfbff249c75cdcf934a994231c5c3a018: ; @PlatformTasks_stdoutLine_4dcdd9fc1c563c9592918682f5bb9bfbff249c75cdcf934a994231c5c3a018
Lfunc_begin128:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldr	x8, [x0, #16]
	ldr	q0, [x0]
	str	x8, [x1, #16]
	str	q0, [x1]
	ret
Ltmp68:
Lfunc_end128:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function _8_8b8e749a7d5dc4035aed2d09b8b4ad59fac5ad694339521a2df23bf1ac35c3
__8_8b8e749a7d5dc4035aed2d09b8b4ad59fac5ad694339521a2df23bf1ac35c3: ; @_8_8b8e749a7d5dc4035aed2d09b8b4ad59fac5ad694339521a2df23bf1ac35c3
Lfunc_begin129:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldr	w0, [x0]
	b	_Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565
Ltmp69:
Lfunc_end129:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_onErr_5fea3a382f6b6c4a2af77ea4365b5abbdda8b93d1f0b9b895dc2a48489fb2
_Task_onErr_5fea3a382f6b6c4a2af77ea4365b5abbdda8b93d1f0b9b895dc2a48489fb2: ; @Task_onErr_5fea3a382f6b6c4a2af77ea4365b5abbdda8b93d1f0b9b895dc2a48489fb2
Lfunc_begin130:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldr	w8, [x3]
	ldrb	w4, [x3, #4]
	mov	w3, w8
	ret
Ltmp70:
Lfunc_end130:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function PlatformTasks_task_closure_stdoutLine_e8e3cb4c459a1e25c7bed4d87759a21ad8b1f9ce7dd1dd4beba947ebadfffae4
_PlatformTasks_task_closure_stdoutLine_e8e3cb4c459a1e25c7bed4d87759a21ad8b1f9ce7dd1dd4beba947ebadfffae4: ; @PlatformTasks_task_closure_stdoutLine_e8e3cb4c459a1e25c7bed4d87759a21ad8b1f9ce7dd1dd4beba947ebadfffae4
Lfunc_begin131:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp71:
	mov	x1, sp
	mov	x20, x0
	bl	_roc_fx_stdoutLine_fastcc_wrapper
	mov	x0, x20
	bl	"l_#Attr_#dec_1"
	ldp	q0, q1, [sp]
	stp	q0, q1, [x19]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp72:
Lfunc_end131:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_dbgInit_3bbacd33228bca14fe5573efe7278cde33c78fe9028ba98810cff368dece
_Inspect_dbgInit_3bbacd33228bca14fe5573efe7278cde33c78fe9028ba98810cff368dece: ; @Inspect_dbgInit_3bbacd33228bca14fe5573efe7278cde33c78fe9028ba98810cff368dece
Lfunc_begin132:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #32
	.cfi_def_cfa_offset 32
Ltmp73:
	stp	xzr, xzr, [sp, #8]
	mov	x8, #-9223372036854775808
	ldur	q0, [sp, #8]
	str	x8, [sp, #24]
	str	x8, [x0, #16]
	str	q0, [x0]
	add	sp, sp, #32
	ret
Ltmp74:
Lfunc_end132:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_mapErr_78fff63b9d7571652dd558be04af7c0e5b15b7f19efda5bd78185837663f63
_Task_mapErr_78fff63b9d7571652dd558be04af7c0e5b15b7f19efda5bd78185837663f63: ; @Task_mapErr_78fff63b9d7571652dd558be04af7c0e5b15b7f19efda5bd78185837663f63
Lfunc_begin133:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp75:
	mov	w1, #1
	mov	x19, x0
	bl	"l_#Attr_#inc_1"
	ldp	x0, x1, [x19]
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	ldr	x2, [x19, #16]
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	ret
Ltmp76:
Lfunc_end133:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Str_isEmpty_cb411178cb7686889a4ee0e4b4c57e63975186dc9f1448b79e94c2721a21a2
_Str_isEmpty_cb411178cb7686889a4ee0e4b4c57e63975186dc9f1448b79e94c2721a21a2: ; @Str_isEmpty_cb411178cb7686889a4ee0e4b4c57e63975186dc9f1448b79e94c2721a21a2
Lfunc_begin134:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp77:
	bl	_roc_builtins.str.number_of_bytes
	cmp	x0, #0
	cset	w0, eq
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp78:
Lfunc_end134:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_getUnsafe_4a74cf314ac9371a5ea518de15e620d82137397f51a1fa6eff156547f363
_List_getUnsafe_4a74cf314ac9371a5ea518de15e620d82137397f51a1fa6eff156547f363: ; @List_getUnsafe_4a74cf314ac9371a5ea518de15e620d82137397f51a1fa6eff156547f363
Lfunc_begin135:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	mov	w8, #40
Ltmp79:
	madd	x8, x3, x8, x0
	ldp	q1, q0, [x8]
	ldr	x9, [x8, #32]
	stp	q1, q0, [sp]
	stp	q1, q0, [x4]
	str	x9, [sp, #32]
	str	x9, [x4, #32]
	add	sp, sp, #48
	ret
Ltmp80:
Lfunc_end135:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_213_24ce363245042dce6c6647d3662b4b2c84c622d118936f8265c24f93e9d3a2c
_Inspect_213_24ce363245042dce6c6647d3662b4b2c84c622d118936f8265c24f93e9d3a2c: ; @Inspect_213_24ce363245042dce6c6647d3662b4b2c84c622d118936f8265c24f93e9d3a2c
Lfunc_begin136:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x8, x0
	mov	x19, x2
Ltmp81:
	add	x2, sp, #8
	mov	x0, x1
	mov	x1, x8
	bl	_Inspect_apply_95dbc324453309f26dee9436b39568cc8bcbe17ef409e9273c4edb58653fd
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp82:
Lfunc_end136:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
_Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6: ; @Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
Lfunc_begin137:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	b	_roc_builtins.str.equal
Ltmp83:
Lfunc_end137:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_208_af2554e3880a1c7af81a4c13c1df135146f6cac58d2d046bda16fbd7c23db3
_Inspect_208_af2554e3880a1c7af81a4c13c1df135146f6cac58d2d046bda16fbd7c23db3: ; @Inspect_208_af2554e3880a1c7af81a4c13c1df135146f6cac58d2d046bda16fbd7c23db3
Lfunc_begin138:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x8, x0
	mov	x19, x4
Ltmp84:
	add	x4, sp, #8
	mov	x0, x1
	mov	x1, x2
	mov	x2, x3
	mov	x3, x8
	bl	_List_walk_078eba49b7090dbd2c6fb82297218e6d2eb88883fa33ff213b919f6e68cc
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp85:
Lfunc_end138:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function _10_8c3fdd6849785e1b32106ad9c6ae59845e2314f0a6799376d4e3e3b9be62d181
__10_8c3fdd6849785e1b32106ad9c6ae59845e2314f0a6799376d4e3e3b9be62d181: ; @_10_8c3fdd6849785e1b32106ad9c6ae59845e2314f0a6799376d4e3e3b9be62d181
Lfunc_begin139:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp86:
	bl	"l_#Attr_#dec_3"
	mov	w0, #1
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	b	_Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565
Ltmp87:
Lfunc_end139:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function _73_c919149ababf2a569c5e2b164c2465c785dc3bc7f566b8dcef7ec4ae86e8d57
__73_c919149ababf2a569c5e2b164c2465c785dc3bc7f566b8dcef7ec4ae86e8d57: ; @_73_c919149ababf2a569c5e2b164c2465c785dc3bc7f566b8dcef7ec4ae86e8d57
Lfunc_begin140:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	stp	x20, x19, [sp, #16]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x3
Ltmp88:
	add	x3, sp, #8
	bl	_Task_42_dee69d62f6dd2acac17218e148d3d8138e18cca99859936284942954b14b32
	ldr	x8, [sp, #8]
	ldp	x29, x30, [sp, #32]             ; 16-byte Folded Reload
	str	x8, [x19]
	ldp	x20, x19, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #48
	ret
Ltmp89:
Lfunc_end140:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Num_addWrap_e84248fb50d0833361d0417df114b0b3b3448fff97c39cdde963b09a9aebb8
_Num_addWrap_e84248fb50d0833361d0417df114b0b3b3448fff97c39cdde963b09a9aebb8: ; @Num_addWrap_e84248fb50d0833361d0417df114b0b3b3448fff97c39cdde963b09a9aebb8
Lfunc_begin141:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	add	x0, x0, x1
	ret
Ltmp90:
Lfunc_end141:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_attempt_1fbc6d79b671ab88e8a9425cd46a77344c0f7ee34ea43fdcaf5a014c6759d
_Task_attempt_1fbc6d79b671ab88e8a9425cd46a77344c0f7ee34ea43fdcaf5a014c6759d: ; @Task_attempt_1fbc6d79b671ab88e8a9425cd46a77344c0f7ee34ea43fdcaf5a014c6759d
Lfunc_begin142:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ret
Ltmp91:
Lfunc_end142:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_67_ca8af06be175497c1986028dec9ff9bde775267ac5c92d6992ca796b5e797c
_Task_67_ca8af06be175497c1986028dec9ff9bde775267ac5c92d6992ca796b5e797c: ; @Task_67_ca8af06be175497c1986028dec9ff9bde775267ac5c92d6992ca796b5e797c
Lfunc_begin143:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #224
	.cfi_def_cfa_offset 224
	stp	x20, x19, [sp, #192]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #208]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp92:
	stp	x1, x2, [sp, #8]
	add	x1, sp, #24
	str	x0, [sp]
	mov	x0, sp
	mov	x19, x3
	bl	_PlatformTasks_task_closure_stderrLine_df662f4854c7c5a297d6c339e28fd51ddc944983db9bc7f012ab2c1c69a52db6
	ldrb	w8, [sp, #48]
	cmp	w8, #1
	b.ne	LBB143_2
; %bb.1:
	add	x9, sp, #56
	b	LBB143_3
LBB143_2:                               ; %else_block
	ldur	q0, [sp, #24]
	add	x0, sp, #96
	ldr	x8, [sp, #40]
	add	x1, sp, #120
	str	q0, [sp, #96]
	str	x8, [sp, #112]
	bl	_Stderr_handleErr_1c44a9ca60e694ea5bce656141adb8728c249dc46543e7c34883c1136ab140
	add	x0, sp, #96
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #120]
	mov	w8, wzr
	ldr	x10, [sp, #136]
	add	x9, sp, #152
	ldrb	w11, [sp, #144]
	stur	q0, [sp, #152]
	str	x10, [sp, #168]
	strb	w11, [sp, #176]
LBB143_3:                               ; %common.ret
	ldp	q0, q1, [x9]
	strb	w8, [x9, #32]
	ldr	x8, [x9, #32]
	stp	q0, q1, [x19]
	ldp	x29, x30, [sp, #208]            ; 16-byte Folded Reload
	str	x8, [x19, #32]
	ldp	x20, x19, [sp, #192]            ; 16-byte Folded Reload
	add	sp, sp, #224
	ret
Ltmp93:
Lfunc_end143:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_204_b7c59c3aec44645db91b229c81990d288c86aeb49f116d1eae85e2b9a39999f
_Inspect_204_b7c59c3aec44645db91b229c81990d288c86aeb49f116d1eae85e2b9a39999f: ; @Inspect_204_b7c59c3aec44645db91b229c81990d288c86aeb49f116d1eae85e2b9a39999f
Lfunc_begin144:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
Ltmp94:
	ldr	q0, [x1]
	ldr	x8, [x1, #16]
	mov	x1, sp
	add	x2, sp, #24
	str	q0, [sp]
	str	x8, [sp, #16]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	mov	x0, sp
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #24]
	ldr	x8, [sp, #40]
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp95:
Lfunc_end144:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_210_139c9542137b10e977a775e441e04012cc6d2c98579f3cdeb5fb42ef98df6d6
_Inspect_210_139c9542137b10e977a775e441e04012cc6d2c98579f3cdeb5fb42ef98df6d6: ; @Inspect_210_139c9542137b10e977a775e441e04012cc6d2c98579f3cdeb5fb42ef98df6d6
Lfunc_begin145:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
	mov	x20, x1
	mov	w8, #32
	mov	x9, #-9151314442816847872
Ltmp96:
	add	x1, sp, #8
	add	x2, sp, #32
	stp	x8, xzr, [sp, #8]
	str	x9, [sp, #24]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #8
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #32
	add	x2, sp, #56
	mov	x1, x20
	bl	_Inspect_213_bd5db9a62133a57f3c3971868413d37dfa646aa8a2764e7763fd4ba5b0b0d4
	ldur	q0, [sp, #56]
	ldr	x8, [sp, #72]
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #112
	ret
Ltmp97:
Lfunc_end145:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function _mainForHost_9d949d48d48bd9629a662ead3e2fc9728ebe6544f0834563102ca492bac0
__mainForHost_9d949d48d48bd9629a662ead3e2fc9728ebe6544f0834563102ca492bac0: ; @_mainForHost_9d949d48d48bd9629a662ead3e2fc9728ebe6544f0834563102ca492bac0
Lfunc_begin146:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp98:
	bl	"_#UserApp_main_bae7cba17581e9e24ed8c02e992f1bda9aeff2d299cc1289ddd0dbdf373061"
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	b	_Task_attempt_1fbc6d79b671ab88e8a9425cd46a77344c0f7ee34ea43fdcaf5a014c6759d
Ltmp99:
Lfunc_end146:
	.cfi_endproc
                                        ; -- End function
	.globl	_roc__mainForHost_1_exposed_generic ; -- Begin function roc__mainForHost_1_exposed_generic
	.p2align	2
_roc__mainForHost_1_exposed_generic:    ; @roc__mainForHost_1_exposed_generic
Lfunc_begin147:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x0
Ltmp100:
	bl	__mainForHost_9d949d48d48bd9629a662ead3e2fc9728ebe6544f0834563102ca492bac0
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	stp	x0, x1, [x19]
	str	x2, [x19, #16]
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	ret
Ltmp101:
Lfunc_end147:
	.cfi_endproc
                                        ; -- End function
	.globl	_roc__mainForHost_1_exposed     ; -- Begin function roc__mainForHost_1_exposed
	.p2align	2
_roc__mainForHost_1_exposed:            ; @roc__mainForHost_1_exposed
Lfunc_begin148:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x8
Ltmp102:
	bl	__mainForHost_9d949d48d48bd9629a662ead3e2fc9728ebe6544f0834563102ca492bac0
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	stp	x0, x1, [x19]
	str	x2, [x19, #16]
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	ret
Ltmp103:
Lfunc_end148:
	.cfi_endproc
                                        ; -- End function
	.globl	_roc__mainForHost_1_exposed_size ; -- Begin function roc__mainForHost_1_exposed_size
	.p2align	2
_roc__mainForHost_1_exposed_size:       ; @roc__mainForHost_1_exposed_size
Lfunc_begin149:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	w0, #24
	ret
Ltmp104:
Lfunc_end149:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_250_6bc1e748a2edd5eacd7f49eb7476d47387e76d8e94fcfcf34a1d5a6fa86e
_Inspect_250_6bc1e748a2edd5eacd7f49eb7476d47387e76d8e94fcfcf34a1d5a6fa86e: ; @Inspect_250_6bc1e748a2edd5eacd7f49eb7476d47387e76d8e94fcfcf34a1d5a6fa86e
Lfunc_begin150:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #176
	.cfi_def_cfa_offset 176
	stp	x22, x21, [sp, #128]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #144]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #160]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	mov	x19, x2
	mov	x20, x1
	mov	w21, #34
	mov	x22, #-9151314442816847872
Ltmp105:
	add	x1, sp, #8
	add	x2, sp, #32
	stp	x21, xzr, [sp, #8]
	str	x22, [sp, #24]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #8
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #32
	add	x2, sp, #56
	mov	x1, x20
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #56
	add	x1, sp, #80
	add	x2, sp, #104
	stp	x21, xzr, [sp, #80]
	str	x22, [sp, #96]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #80
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #104]
	ldr	x8, [sp, #120]
	ldp	x29, x30, [sp, #160]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #144]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #128]            ; 16-byte Folded Reload
	add	sp, sp, #176
	ret
Ltmp106:
Lfunc_end150:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function PlatformTasks_stderrLine_aad9a2f5f9418b386cce489a0bac8cb5bba34171864909e4dfec1ea4e26bfb7
_PlatformTasks_stderrLine_aad9a2f5f9418b386cce489a0bac8cb5bba34171864909e4dfec1ea4e26bfb7: ; @PlatformTasks_stderrLine_aad9a2f5f9418b386cce489a0bac8cb5bba34171864909e4dfec1ea4e26bfb7
Lfunc_begin151:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldr	x8, [x0, #16]
	ldr	q0, [x0]
	str	x8, [x1, #16]
	str	q0, [x1]
	ret
Ltmp107:
Lfunc_end151:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_err_72f11ea62bc2627ca7ca9959232e519a82934c5e521930f57f3646c32591
_Task_err_72f11ea62bc2627ca7ca9959232e519a82934c5e521930f57f3646c32591: ; @Task_err_72f11ea62bc2627ca7ca9959232e519a82934c5e521930f57f3646c32591
Lfunc_begin152:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	w8, #1
Ltmp108:
	str	w0, [sp, #-48]!
	.cfi_def_cfa_offset 48
	ldp	q1, q0, [sp]
	strb	w8, [sp, #40]
	ldr	q2, [sp, #32]
	stp	q1, q0, [x1]
	str	q2, [x1, #32]
	add	sp, sp, #48
	ret
Ltmp109:
Lfunc_end152:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_custom_bfa1d47a221bdaf089999196bed323c433d1a6b8c78ec612e6fa7b3e3d811
_Inspect_custom_bfa1d47a221bdaf089999196bed323c433d1a6b8c78ec612e6fa7b3e3d811: ; @Inspect_custom_bfa1d47a221bdaf089999196bed323c433d1a6b8c78ec612e6fa7b3e3d811
Lfunc_begin153:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldp	q1, q0, [x0, #16]
	ldr	x8, [x0, #48]
	ldr	q2, [x0]
	stp	q1, q0, [x1, #16]
	str	x8, [x1, #48]
	str	q2, [x1]
	ret
Ltmp110:
Lfunc_end153:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_apply_95dbc324453309f26dee9436b39568cc8bcbe17ef409e9273c4edb58653fd
_Inspect_apply_95dbc324453309f26dee9436b39568cc8bcbe17ef409e9273c4edb58653fd: ; @Inspect_apply_95dbc324453309f26dee9436b39568cc8bcbe17ef409e9273c4edb58653fd
Lfunc_begin154:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
	mov	x8, x0
Ltmp111:
	ldrb	w9, [x0, #32]
	mov	x0, x1
	cbz	w9, LBB154_3
; %bb.1:                                ; %entry
	cmp	w9, #1
	b.ne	LBB154_4
; %bb.2:                                ; %branch1
	add	x2, sp, #32
	mov	x1, x8
	add	x20, sp, #32
	bl	_Inspect_250_92df2e9c67226884f739cd53c0493c2aabaabd406877a3b72a3e676dc54e081
	b	LBB154_5
LBB154_3:                               ; %branch0
	add	x2, sp, #8
	mov	x1, x8
	add	x20, sp, #8
	bl	"_#Derived_custom3_beb22fad19423347b2aa99b33212e862ded3f83df5d6238acb1a6a9ade3e"
	b	LBB154_5
LBB154_4:                               ; %default
	add	x2, sp, #56
	mov	x1, x8
	add	x20, sp, #56
	bl	_Inspect_272_4fe2c0cee861629d2ef04c3f725dba5813b563598f88e6fe57cefd4dd1a133
LBB154_5:                               ; %common.ret
	ldr	q0, [x20]
	ldr	x8, [x20, #16]
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #112
	ret
Ltmp112:
Lfunc_end154:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_len_35bfe7dc6dba25ddadede12999f2a34775468912610779bf675f9c2d81ecac
_List_len_35bfe7dc6dba25ddadede12999f2a34775468912610779bf675f9c2d81ecac: ; @List_len_35bfe7dc6dba25ddadede12999f2a34775468912610779bf675f9c2d81ecac
Lfunc_begin155:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	x0, x1
Ltmp113:
	ret
Ltmp114:
Lfunc_end155:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Stdout_line_c852b6d75d2364d70d094699f8a9cda9129d5310ed82ea45564f47a9
_Stdout_line_c852b6d75d2364d70d094699f8a9cda9129d5310ed82ea45564f47a9: ; @Stdout_line_c852b6d75d2364d70d094699f8a9cda9129d5310ed82ea45564f47a9
Lfunc_begin156:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
Ltmp115:
	add	x1, sp, #8
	bl	_PlatformTasks_stdoutLine_4dcdd9fc1c563c9592918682f5bb9bfbff249c75cdcf934a994231c5c3a018
	add	x0, sp, #8
	bl	_Task_mapErr_78fff63b9d7571652dd558be04af7c0e5b15b7f19efda5bd78185837663f63
	mov	x19, x0
	add	x0, sp, #8
	mov	x20, x1
	mov	x21, x2
	bl	"l_#Attr_#dec_1"
	mov	x0, x19
	mov	x1, x20
	mov	x2, x21
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp116:
Lfunc_end156:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_208_36ded37b63679dfb9096703c22eba74b3449a854bc97ac179ba6ffbbbaa21
_Inspect_208_36ded37b63679dfb9096703c22eba74b3449a854bc97ac179ba6ffbbbaa21: ; @Inspect_208_36ded37b63679dfb9096703c22eba74b3449a854bc97ac179ba6ffbbbaa21
Lfunc_begin157:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x8, x0
	mov	x19, x4
Ltmp117:
	add	x4, sp, #8
	mov	x0, x1
	mov	x1, x2
	mov	x2, x3
	mov	x3, x8
	bl	_List_walk_52459ae5e05017996bb4298dd9ac3944ffe997fa2e2ad98ba6fd7348395f63
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp118:
Lfunc_end157:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Stderr_line_1484a21b4257566f7c1b3505e4f6c430eb1121cbfb946b32fb115b90b1ef50
_Stderr_line_1484a21b4257566f7c1b3505e4f6c430eb1121cbfb946b32fb115b90b1ef50: ; @Stderr_line_1484a21b4257566f7c1b3505e4f6c430eb1121cbfb946b32fb115b90b1ef50
Lfunc_begin158:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x22, x21, [sp, #32]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
Ltmp119:
	add	x1, sp, #8
	bl	_PlatformTasks_stderrLine_aad9a2f5f9418b386cce489a0bac8cb5bba34171864909e4dfec1ea4e26bfb7
	add	x0, sp, #8
	bl	_Task_mapErr_b7a3f2a8f8a550a8b7d9f583e11fe2d9be1c46afd270ccbd14dc29ab1919b1
	mov	x19, x0
	add	x0, sp, #8
	mov	x20, x1
	mov	x21, x2
	bl	"l_#Attr_#dec_1"
	mov	x0, x19
	mov	x1, x20
	mov	x2, x21
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp120:
Lfunc_end158:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Dict_defaultMaxLoadFactor_7a93171d29c34145ace0bed7f158bc6f747d259f21a8119f90767f874eb48b94
_Dict_defaultMaxLoadFactor_7a93171d29c34145ace0bed7f158bc6f747d259f21a8119f90767f874eb48b94: ; @Dict_defaultMaxLoadFactor_7a93171d29c34145ace0bed7f158bc6f747d259f21a8119f90767f874eb48b94
Lfunc_begin159:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	w8, #52429
	movk	w8, #16204, lsl #16
	fmov	s0, w8
Ltmp121:
	ret
Ltmp122:
Lfunc_end159:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565
_Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565: ; @Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565
Lfunc_begin160:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ret
Ltmp123:
Lfunc_end160:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_toDbgStr_9d7544bbc8507265e131f9b42f567d6c54e799c62356103470ba3daf5673a8
_Inspect_toDbgStr_9d7544bbc8507265e131f9b42f567d6c54e799c62356103470ba3daf5673a8: ; @Inspect_toDbgStr_9d7544bbc8507265e131f9b42f567d6c54e799c62356103470ba3daf5673a8
Lfunc_begin161:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldr	x8, [x0, #16]
	ldr	q0, [x0]
	str	x8, [x1, #16]
	str	q0, [x1]
	ret
Ltmp124:
Lfunc_end161:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_len_4e123451c288c52798d3df0fc84811d2d957f324242982575c70dfd6d338df
_List_len_4e123451c288c52798d3df0fc84811d2d957f324242982575c70dfd6d338df: ; @List_len_4e123451c288c52798d3df0fc84811d2d957f324242982575c70dfd6d338df
Lfunc_begin162:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	x0, x1
Ltmp125:
	ret
Ltmp126:
Lfunc_end162:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_isEmpty_99e2ebbd98e8a2a4c7ed9bd71d205d9f7b5d7e7a9ddb68dab65f2ad1c2198b
_List_isEmpty_99e2ebbd98e8a2a4c7ed9bd71d205d9f7b5d7e7a9ddb68dab65f2ad1c2198b: ; @List_isEmpty_99e2ebbd98e8a2a4c7ed9bd71d205d9f7b5d7e7a9ddb68dab65f2ad1c2198b
Lfunc_begin163:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp127:
	bl	_List_len_dc3f621de1221c7c53a19e877c377561ede91cdd88b1a687d310a39785a
	mov	x1, xzr
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	b	_Bool_structuralEq_cabb163ea8b383114bab450f2ea4bdf6f97d5dc22e57b593db81e3bce47
Ltmp128:
Lfunc_end163:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Num_subWrap_edaf1bd3d1c2ffcc44df55829c02f262426de2ffbea9be2cdf075ec12c528d
_Num_subWrap_edaf1bd3d1c2ffcc44df55829c02f262426de2ffbea9be2cdf075ec12c528d: ; @Num_subWrap_edaf1bd3d1c2ffcc44df55829c02f262426de2ffbea9be2cdf075ec12c528d
Lfunc_begin164:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	w0, w0, w1
	ret
Ltmp129:
Lfunc_end164:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Bool_structuralEq_cabb163ea8b383114bab450f2ea4bdf6f97d5dc22e57b593db81e3bce47
_Bool_structuralEq_cabb163ea8b383114bab450f2ea4bdf6f97d5dc22e57b593db81e3bce47: ; @Bool_structuralEq_cabb163ea8b383114bab450f2ea4bdf6f97d5dc22e57b593db81e3bce47
Lfunc_begin165:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	cmp	x0, x1
	cset	w0, eq
	ret
Ltmp130:
Lfunc_end165:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_272_4fe2c0cee861629d2ef04c3f725dba5813b563598f88e6fe57cefd4dd1a133
_Inspect_272_4fe2c0cee861629d2ef04c3f725dba5813b563598f88e6fe57cefd4dd1a133: ; @Inspect_272_4fe2c0cee861629d2ef04c3f725dba5813b563598f88e6fe57cefd4dd1a133
Lfunc_begin166:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x20, x0
Ltmp131:
	ldr	w0, [x1]
	mov	x1, sp
	mov	x19, x2
	bl	_Num_toStr_f273102d33b910ab8b1eda6e483bb587ec34372c3562cd9bfb68bcf889ba9cd
	mov	x1, sp
	add	x2, sp, #24
	mov	x0, x20
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	mov	x0, sp
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #24]
	ldr	x8, [sp, #40]
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp132:
Lfunc_end166:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_custom_1149386876d826e56f26fd066413b9c565aa3dea67161e512a9ba24db887d5
_Inspect_custom_1149386876d826e56f26fd066413b9c565aa3dea67161e512a9ba24db887d5: ; @Inspect_custom_1149386876d826e56f26fd066413b9c565aa3dea67161e512a9ba24db887d5
Lfunc_begin167:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldp	q1, q0, [x0]
	ldr	x8, [x0, #32]
	stp	q1, q0, [x1]
	str	x8, [x1, #32]
	ret
Ltmp133:
Lfunc_end167:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_custom_926c4e1deae44cb32fa91b0fc2f966fdf98af98ee562517f2d5df6cc1b8bf0
_Inspect_custom_926c4e1deae44cb32fa91b0fc2f966fdf98af98ee562517f2d5df6cc1b8bf0: ; @Inspect_custom_926c4e1deae44cb32fa91b0fc2f966fdf98af98ee562517f2d5df6cc1b8bf0
Lfunc_begin168:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldp	q1, q0, [x0, #16]
	ldr	x8, [x0, #48]
	ldr	q2, [x0]
	stp	q1, q0, [x1, #16]
	str	x8, [x1, #48]
	str	q2, [x1]
	ret
Ltmp134:
Lfunc_end168:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_walkHelp_99aa979e4a9cadd6dbe48ea878ec84acb7696eb93470c375f6893f1da46c3772
_List_walkHelp_99aa979e4a9cadd6dbe48ea878ec84acb7696eb93470c375f6893f1da46c3772: ; @List_walkHelp_99aa979e4a9cadd6dbe48ea878ec84acb7696eb93470c375f6893f1da46c3772
Lfunc_begin169:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #240
	.cfi_def_cfa_offset 240
	stp	x26, x25, [sp, #160]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #176]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #192]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #208]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #224]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w25, -72
	.cfi_offset w26, -80
	mov	x25, x3
Ltmp135:
	mov	w3, #1
	mov	x19, x6
	mov	x21, x5
	mov	x24, x4
	mov	x20, x2
	mov	x22, x1
	mov	x23, x0
	bl	"l_#Attr_#inc_4"
	ldr	q0, [x25]
	add	x8, sp, #32
	ldr	x9, [x25, #16]
	str	q0, [sp, #32]
	str	x9, [sp, #48]
LBB169_1:                               ; %joinpointcont
                                        ; =>This Inner Loop Header: Depth=1
	ldr	q0, [x8]
	mov	x0, x24
	ldr	x8, [x8, #16]
	mov	x1, x21
	str	q0, [sp]
	str	x8, [sp, #16]
	bl	_Num_isLt_669c1355a3e727bb53dd458f2e96e48571aa45dfabcfb4b7de1689484f11
	tbz	w0, #0, LBB169_3
; %bb.2:                                ; %then_block
                                        ;   in Loop: Header=BB169_1 Depth=1
	add	x4, sp, #64
	mov	x0, x23
	mov	x1, x22
	mov	x2, x20
	mov	x3, x24
	bl	_List_getUnsafe_4a74cf314ac9371a5ea518de15e620d82137397f51a1fa6eff156547f363
	add	x0, sp, #64
	mov	w1, #1
	bl	"l_#Attr_#inc_5"
	mov	x0, sp
	add	x1, sp, #64
	add	x2, sp, #104
	bl	_Inspect_210_3d7aff37b23cd9f9e6beb177d8bf818babb9d186ea278cc981a34be43b8cf34
	mov	x0, x24
	mov	w1, #1
	bl	_Num_addWrap_e84248fb50d0833361d0417df114b0b3b3448fff97c39cdde963b09a9aebb8
	ldur	q0, [sp, #104]
	mov	x24, x0
	ldr	x9, [sp, #120]
	add	x8, sp, #128
	str	q0, [sp, #128]
	str	x9, [sp, #144]
	b	LBB169_1
LBB169_3:                               ; %else_block
	mov	x0, x23
	mov	x1, x22
	mov	x2, x20
	bl	"l_#Attr_#dec_4"
	ldr	q0, [sp]
	ldr	x8, [sp, #16]
	ldp	x29, x30, [sp, #224]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #208]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #192]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #176]            ; 16-byte Folded Reload
	ldp	x26, x25, [sp, #160]            ; 16-byte Folded Reload
	add	sp, sp, #240
	ret
Ltmp136:
Lfunc_end169:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_mapErr_b7a3f2a8f8a550a8b7d9f583e11fe2d9be1c46afd270ccbd14dc29ab1919b1
_Task_mapErr_b7a3f2a8f8a550a8b7d9f583e11fe2d9be1c46afd270ccbd14dc29ab1919b1: ; @Task_mapErr_b7a3f2a8f8a550a8b7d9f583e11fe2d9be1c46afd270ccbd14dc29ab1919b1
Lfunc_begin170:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp137:
	mov	w1, #1
	mov	x19, x0
	bl	"l_#Attr_#inc_1"
	ldp	x0, x1, [x19]
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	ldr	x2, [x19, #16]
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	ret
Ltmp138:
Lfunc_end170:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Derived_toInspector_[BrokenPipe 0,Interrupted 0,Other 1,OutOfMemory 0,Unsupported 0,WouldBlock 0,WriteZero 0]_f03bf86f79d121cbfd774dec4a65912e99f5f17c33852bbc45e81916e62b53b
"_#Derived_toInspector_[BrokenPipe 0,Interrupted 0,Other 1,OutOfMemory 0,Unsupported 0,WouldBlock 0,WriteZero 0]_f03bf86f79d121cbfd774dec4a65912e99f5f17c33852bbc45e81916e62b53b": ; @"#Derived_toInspector_[BrokenPipe 0,Interrupted 0,Other 1,OutOfMemory 0,Unsupported 0,WouldBlock 0,WriteZero 0]_f03bf86f79d121cbfd774dec4a65912e99f5f17c33852bbc45e81916e62b53b"
Lfunc_begin171:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp139:
	ldr	q0, [x0]
	ldr	x8, [x0, #16]
	add	x1, sp, #40
	ldrb	w9, [x0, #24]
	mov	x0, sp
	strb	wzr, [sp, #32]
	str	q0, [sp]
	str	x8, [sp, #16]
	strb	w9, [sp, #24]
	bl	_Inspect_custom_1149386876d826e56f26fd066413b9c565aa3dea67161e512a9ba24db887d5
	ldur	q0, [sp, #40]
	ldur	q1, [sp, #56]
	ldr	x8, [sp, #72]
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	stp	q0, q1, [x19]
	str	x8, [x19, #32]
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #112
	ret
Ltmp140:
Lfunc_end171:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_custom_f0adb8f180253d489b50ac5199522556362f583929ee5e65c919bd9ed2bc82f
_Inspect_custom_f0adb8f180253d489b50ac5199522556362f583929ee5e65c919bd9ed2bc82f: ; @Inspect_custom_f0adb8f180253d489b50ac5199522556362f583929ee5e65c919bd9ed2bc82f
Lfunc_begin172:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ldr	x8, [x0, #16]
	ldr	q0, [x0]
	str	x8, [x1, #16]
	str	q0, [x1]
	ret
Ltmp141:
Lfunc_end172:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_isEmpty_76e6e4fef22a778f22804a4a55d5f106b42fb9eadb9eb1f662982e2379174e
_List_isEmpty_76e6e4fef22a778f22804a4a55d5f106b42fb9eadb9eb1f662982e2379174e: ; @List_isEmpty_76e6e4fef22a778f22804a4a55d5f106b42fb9eadb9eb1f662982e2379174e
Lfunc_begin173:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp142:
	bl	_List_len_35bfe7dc6dba25ddadede12999f2a34775468912610779bf675f9c2d81ecac
	mov	x1, xzr
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	b	_Bool_structuralEq_cabb163ea8b383114bab450f2ea4bdf6f97d5dc22e57b593db81e3bce47
Ltmp143:
Lfunc_end173:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Num_toStr_7f7e162ee4345c12acb2c8dddfd129c8c9ef562ecb31841cfff13d4789ffc2
_Num_toStr_7f7e162ee4345c12acb2c8dddfd129c8c9ef562ecb31841cfff13d4789ffc2: ; @Num_toStr_7f7e162ee4345c12acb2c8dddfd129c8c9ef562ecb31841cfff13d4789ffc2
Lfunc_begin174:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp144:
	add	x8, sp, #8
	mov	x19, x1
	bl	_roc_builtins.str.from_int.u64
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp145:
Lfunc_end174:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Test_calculateMiddleTotal_b5dcd15815911a96b9d7e883b1723ec1e9f2a35835ca79db2284140ebd0aa83
_Test_calculateMiddleTotal_b5dcd15815911a96b9d7e883b1723ec1e9f2a35835ca79db2284140ebd0aa83: ; @Test_calculateMiddleTotal_b5dcd15815911a96b9d7e883b1723ec1e9f2a35835ca79db2284140ebd0aa83
Lfunc_begin175:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	x22, x21, [sp, #64]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
Ltmp146:
	mov	x0, sp
	bl	_Set_empty_4c26d916fc42dd8d2a9bd5abfc2993ea3741d5b5db9aa72687bec6b6e3098
	mov	x3, sp
	mov	x0, xzr
	mov	x1, xzr
	mov	x2, xzr
	bl	_List_sortWith_91183c4be76c8c6e9a1aca423ca6b7bdfddc155d7aac337b8db73395e0e64d
	mov	x19, x0
	mov	x20, x1
	mov	x21, x2
	bl	_List_len_4e123451c288c52798d3df0fc84811d2d957f324242982575c70dfd6d338df
	mov	x22, x0
	mov	x0, x19
	mov	x1, x20
	mov	x2, x21
	bl	"l_#Attr_#dec_10"
	mov	x0, x22
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #64]             ; 16-byte Folded Reload
	add	sp, sp, #112
	ret
Ltmp147:
Lfunc_end175:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function _11_2c7d993eadf275d994a1f98b824972fece3cfca6b6ac52dd7bb717e1f5753
__11_2c7d993eadf275d994a1f98b824972fece3cfca6b6ac52dd7bb717e1f5753: ; @_11_2c7d993eadf275d994a1f98b824972fece3cfca6b6ac52dd7bb717e1f5753
Lfunc_begin176:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	w0, #1
	b	_Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565
Ltmp148:
Lfunc_end176:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_dbgStr_e3211b24ebda6e959f98c8dfabbb8bde232b75ae94930caa03d2bdb8e7b5674
_Inspect_dbgStr_e3211b24ebda6e959f98c8dfabbb8bde232b75ae94930caa03d2bdb8e7b5674: ; @Inspect_dbgStr_e3211b24ebda6e959f98c8dfabbb8bde232b75ae94930caa03d2bdb8e7b5674
Lfunc_begin177:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #128
	.cfi_def_cfa_offset 128
	stp	x22, x21, [sp, #80]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #96]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #112]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	mov	x19, x1
Ltmp149:
	mov	w1, #1
	mov	x20, x0
	mov	w21, #1
	bl	"l_#Attr_#inc_1"
	ldr	q0, [x20]
	mov	x0, sp
	ldr	x8, [x20, #16]
	add	x1, sp, #40
	strb	w21, [sp, #32]
	str	q0, [sp]
	str	x8, [sp, #16]
	bl	_Inspect_custom_1149386876d826e56f26fd066413b9c565aa3dea67161e512a9ba24db887d5
	ldur	q0, [sp, #40]
	ldur	q1, [sp, #56]
	ldr	x8, [sp, #72]
	ldp	x29, x30, [sp, #112]            ; 16-byte Folded Reload
	stp	q0, q1, [x19]
	str	x8, [x19, #32]
	ldp	x20, x19, [sp, #96]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #80]             ; 16-byte Folded Reload
	add	sp, sp, #128
	ret
Ltmp150:
Lfunc_end177:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
_Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d: ; @Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
Lfunc_begin178:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #352
	.cfi_def_cfa_offset 352
	stp	x28, x27, [sp, #272]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #288]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #304]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #320]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #336]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	mov	x23, x2
	mov	x21, x1
	mov	x20, x0
Ltmp151:
	mov	x0, x1
	mov	x1, x2
	mov	x2, x3
	mov	x19, x4
	mov	x22, x3
	bl	_List_isEmpty_76e6e4fef22a778f22804a4a55d5f106b42fb9eadb9eb1f662982e2379174e
	tbz	w0, #0, LBB178_2
; %bb.1:                                ; %then_block
	mov	x0, x20
	mov	w1, #1
	bl	"l_#Attr_#inc_1"
	ldr	q0, [x20]
	strb	wzr, [sp, #48]
	ldr	x8, [x20, #16]
	mov	x0, sp
	add	x1, sp, #56
	add	x20, sp, #56
	str	q0, [sp]
	str	x8, [sp, #16]
	b	LBB178_3
LBB178_2:                               ; %else_block
	mov	x0, x21
	mov	x1, x23
	mov	x2, x22
	mov	w3, #1
	mov	w24, #1
	bl	"l_#Attr_#inc_2"
	mov	x0, x20
	mov	w1, #1
	bl	"l_#Attr_#inc_1"
	ldr	x8, [x20, #16]
	stp	x23, x22, [sp, #144]
	ldr	q0, [x20]
	add	x0, sp, #160
	add	x1, sp, #216
	add	x20, sp, #216
	stp	x8, x21, [sp, #128]
	ldp	q2, q1, [sp, #128]
	str	q0, [sp, #112]
	str	q0, [sp, #160]
	strb	w24, [sp, #208]
	stp	q2, q1, [sp, #176]
LBB178_3:                               ; %common.ret
	bl	_Inspect_custom_bfa1d47a221bdaf089999196bed323c433d1a6b8c78ec612e6fa7b3e3d811
	ldp	q0, q1, [x20]
	ldr	q2, [x20, #32]
	stp	q0, q1, [x19]
	ldr	x8, [x20, #48]
	ldp	x29, x30, [sp, #336]            ; 16-byte Folded Reload
	str	q2, [x19, #32]
	str	x8, [x19, #48]
	ldp	x20, x19, [sp, #320]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #272]            ; 16-byte Folded Reload
	add	sp, sp, #352
	ret
Ltmp152:
Lfunc_end178:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_getUnsafe_2cc6e6d3c5a48a76ea218c439d44b6318e7bd267419a22dcb25b258a2c06a
_List_getUnsafe_2cc6e6d3c5a48a76ea218c439d44b6318e7bd267419a22dcb25b258a2c06a: ; @List_getUnsafe_2cc6e6d3c5a48a76ea218c439d44b6318e7bd267419a22dcb25b258a2c06a
Lfunc_begin179:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #32
	.cfi_def_cfa_offset 32
	mov	w8, #24
Ltmp153:
	madd	x8, x3, x8, x0
	ldr	x9, [x8, #16]
	ldr	q0, [x8]
	str	x9, [sp, #16]
	str	q0, [sp]
	str	q0, [x4]
	str	x9, [x4, #16]
	add	sp, sp, #32
	ret
Ltmp154:
Lfunc_end179:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_250_92df2e9c67226884f739cd53c0493c2aabaabd406877a3b72a3e676dc54e081
_Inspect_250_92df2e9c67226884f739cd53c0493c2aabaabd406877a3b72a3e676dc54e081: ; @Inspect_250_92df2e9c67226884f739cd53c0493c2aabaabd406877a3b72a3e676dc54e081
Lfunc_begin180:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #192
	.cfi_def_cfa_offset 192
	stp	x22, x21, [sp, #144]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #160]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #176]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	mov	x19, x2
	mov	w20, #34
Ltmp155:
	ldr	q0, [x1]
	mov	x21, #-9151314442816847872
	ldr	x8, [x1, #16]
	add	x1, sp, #24
	add	x2, sp, #48
	stp	x20, xzr, [sp, #24]
	str	q0, [sp]
	str	x8, [sp, #16]
	str	x21, [sp, #40]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #24
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #48
	mov	x1, sp
	add	x2, sp, #72
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	mov	x0, sp
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #72
	add	x1, sp, #96
	add	x2, sp, #120
	stp	x20, xzr, [sp, #96]
	str	x21, [sp, #112]
	bl	_Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	add	x0, sp, #96
	bl	"l_#Attr_#dec_1"
	ldur	q0, [sp, #120]
	ldr	x8, [sp, #136]
	ldp	x29, x30, [sp, #176]            ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #160]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #144]            ; 16-byte Folded Reload
	add	sp, sp, #192
	ret
Ltmp156:
Lfunc_end180:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_53_1dc6f9836252db90e110ad1b5e28c952e1292787deeab71a2a18c14f1d18ec0
_Task_53_1dc6f9836252db90e110ad1b5e28c952e1292787deeab71a2a18c14f1d18ec0: ; @Task_53_1dc6f9836252db90e110ad1b5e28c952e1292787deeab71a2a18c14f1d18ec0
Lfunc_begin181:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #144
	.cfi_def_cfa_offset 144
	stp	x20, x19, [sp, #112]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #128]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp157:
	str	w3, [sp, #8]
	add	x3, sp, #16
	mov	x19, x5
	strb	w4, [sp, #12]
	bl	_Task_67_ca8af06be175497c1986028dec9ff9bde775267ac5c92d6992ca796b5e797c
	ldrb	w8, [sp, #48]
	cmp	w8, #1
	b.ne	LBB181_2
; %bb.1:                                ; %then_block
	strb	w8, [sp, #60]
	ldr	x8, [sp, #56]
	b	LBB181_6
LBB181_2:                               ; %else_block
	ldp	q0, q1, [sp, #16]
	add	x0, sp, #64
	ldrb	w8, [sp, #12]
	stp	q0, q1, [sp, #64]
	cbz	w8, LBB181_4
; %bb.3:                                ; %default
	bl	__10_8c3fdd6849785e1b32106ad9c6ae59845e2314f0a6799376d4e3e3b9be62d181
	b	LBB181_5
LBB181_4:                               ; %branch0
	add	x1, sp, #8
	bl	__7_52aff1341cf42f5e6559a2cf028663f7bbbc7576ac1948fc58784a0613b79
LBB181_5:                               ; %joinpointcont
	add	x1, sp, #104
	bl	_Task_38_464ad9696114b8eea8bc3daaaa648b1d3685be4c8d824dbb0c93c169d61
	ldr	x8, [sp, #104]
LBB181_6:                               ; %common.ret
	str	x8, [x19]
	ldp	x29, x30, [sp, #128]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #112]            ; 16-byte Folded Reload
	add	sp, sp, #144
	ret
Ltmp158:
Lfunc_end181:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Set_isEmpty_127cb22736133e34b265d61ea1d591a8834a13a1d4a2cb161a40b74f7c37b3
_Set_isEmpty_127cb22736133e34b265d61ea1d591a8834a13a1d4a2cb161a40b74f7c37b3: ; @Set_isEmpty_127cb22736133e34b265d61ea1d591a8834a13a1d4a2cb161a40b74f7c37b3
Lfunc_begin182:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	b	_Dict_isEmpty_eabc27640eff330d625cb2f6435f5dccaec45dd590ad64015fdca105b70
Ltmp159:
Lfunc_end182:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function _3_12f97a97f61aca488b75d4cbbdb83020191eefe4f33d263875d76e4b447613
__3_12f97a97f61aca488b75d4cbbdb83020191eefe4f33d263875d76e4b447613: ; @_3_12f97a97f61aca488b75d4cbbdb83020191eefe4f33d263875d76e4b447613
Lfunc_begin183:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x28, x27, [sp, #-48]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 48
	stp	x20, x19, [sp, #16]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w27, -40
	.cfi_offset w28, -48
	sub	sp, sp, #512
	.cfi_def_cfa_offset 560
Ltmp160:
	ldrb	w8, [x0, #40]
	mov	x19, x1
	cmp	w8, #1
	b.ne	LBB183_2
; %bb.1:                                ; %then_block
	bl	"l_#Attr_#dec_11"
	mov	x0, sp
	mov	x20, sp
	bl	_Task_ok_7f8c4a473141d41efa7657e3f378539f18179e0b2dff0f626f6dce25d295f
	b	LBB183_8
LBB183_2:                               ; %else_block
	ldp	q0, q1, [x0]
	ldr	x8, [x0, #32]
	stp	q0, q1, [sp, #48]
	tst	w8, #0xff
	str	x8, [sp, #80]
	b.eq	LBB183_4
; %bb.3:                                ; %else_block7
	ldp	q0, q1, [x0]
	mov	w9, #31
Lloh65:
	adrp	x8, l__str_literal_3867905241449124926@PAGE+8
Lloh66:
	add	x8, x8, l__str_literal_3867905241449124926@PAGEOFF+8
	add	x1, sp, #352
	stp	x9, x9, [sp, #336]
	ldr	x10, [x0, #32]
	add	x0, sp, #288
	stp	q0, q1, [sp, #288]
	stp	x10, x8, [sp, #320]
	bl	_Inspect_toStr_7cfa03e91e0ec9327f388a68dbd26ae2735e7e95165f9e519543e02299bee9
	mov	w8, #169
Lloh67:
	adrp	x9, l__str_literal_3894810976106795109@PAGE+8
Lloh68:
	add	x9, x9, l__str_literal_3894810976106795109@PAGEOFF+8
	add	x0, sp, #352
	add	x1, sp, #376
	add	x2, sp, #400
	str	x8, [sp, #392]
	stp	x9, x8, [sp, #376]
	bl	_Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198
	add	x0, sp, #376
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #328
	add	x1, sp, #400
	add	x2, sp, #424
	bl	_Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198
	add	x0, sp, #400
	bl	"l_#Attr_#dec_1"
	add	x0, sp, #424
	bl	_Stderr_line_1484a21b4257566f7c1b3505e4f6c430eb1121cbfb946b32fb115b90b1ef50
	mov	w20, #1
	add	x3, sp, #448
	strb	w20, [sp, #452]
	bl	_Task_onErr_5fea3a382f6b6c4a2af77ea4365b5abbdda8b93d1f0b9b895dc2a48489fb2
	strb	w20, [sp, #460]
	add	x5, sp, #456
	add	x6, sp, #464
	add	x20, sp, #464
	b	LBB183_7
LBB183_4:                               ; %then_block6
	ldp	q1, q0, [x0]
	str	q1, [sp, #144]
	stp	q1, q0, [sp, #96]
	ldr	x8, [x0, #32]
	ldr	x9, [sp, #112]
	add	x0, sp, #144
	ldr	w20, [sp, #120]
	str	x8, [sp, #128]
	str	x9, [sp, #160]
	bl	_Str_isEmpty_cb411178cb7686889a4ee0e4b4c57e63975186dc9f1448b79e94c2721a21a2
	tbz	w0, #0, LBB183_6
; %bb.5:                                ; %then_block18
	add	x0, sp, #144
	bl	"l_#Attr_#dec_1"
	add	x1, sp, #176
	mov	w0, w20
	add	x20, sp, #176
	bl	_Task_err_72f11ea62bc2627ca7ca9959232e519a82934c5e521930f57f3646c32591
	b	LBB183_8
LBB183_6:                               ; %else_block19
	add	x0, sp, #144
	bl	_Stderr_line_1484a21b4257566f7c1b3505e4f6c430eb1121cbfb946b32fb115b90b1ef50
	add	x3, sp, #224
	str	w20, [sp, #224]
	strb	wzr, [sp, #228]
	bl	_Task_onErr_5fea3a382f6b6c4a2af77ea4365b5abbdda8b93d1f0b9b895dc2a48489fb2
	str	w20, [sp, #232]
	add	x5, sp, #232
	strb	wzr, [sp, #236]
	add	x6, sp, #240
	add	x20, sp, #240
LBB183_7:                               ; %common.ret
	bl	_Task_await_9ddbc9a5a6ab79818cf720ec32ba1aeb5838e37cd919c2ff6b897d7d866d5c7
LBB183_8:                               ; %common.ret
	ldp	q0, q1, [x20]
	ldr	q2, [x20, #32]
	stp	q0, q1, [x19]
	str	q2, [x19, #32]
	add	sp, sp, #512
	ldp	x29, x30, [sp, #32]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #16]             ; 16-byte Folded Reload
	ldp	x28, x27, [sp], #48             ; 16-byte Folded Reload
	ret
Ltmp161:
	.loh AdrpAdd	Lloh67, Lloh68
	.loh AdrpAdd	Lloh65, Lloh66
Lfunc_end183:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Set_empty_4c26d916fc42dd8d2a9bd5abfc2993ea3741d5b5db9aa72687bec6b6e3098
_Set_empty_4c26d916fc42dd8d2a9bd5abfc2993ea3741d5b5db9aa72687bec6b6e3098: ; @Set_empty_4c26d916fc42dd8d2a9bd5abfc2993ea3741d5b5db9aa72687bec6b6e3098
Lfunc_begin184:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #96
	.cfi_def_cfa_offset 96
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x0
Ltmp162:
	mov	x0, sp
	bl	_Dict_empty_392aebc0773ca1163ead8eb210e2c2aabca4fe4ded9f2b122a7dab30d082d98b
	ldp	q0, q1, [sp]
	ldp	q2, q3, [sp, #32]
	stp	q0, q1, [x19]
	stp	q2, q3, [x19, #32]
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	add	sp, sp, #96
	ret
Ltmp163:
Lfunc_end184:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Dict_isEmpty_eabc27640eff330d625cb2f6435f5dccaec45dd590ad64015fdca105b70
_Dict_isEmpty_eabc27640eff330d625cb2f6435f5dccaec45dd590ad64015fdca105b70: ; @Dict_isEmpty_eabc27640eff330d625cb2f6435f5dccaec45dd590ad64015fdca105b70
Lfunc_begin185:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x22, x21, [sp, #-48]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 48
	stp	x20, x19, [sp, #16]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
Ltmp164:
	ldp	x8, x1, [x0]
	ldp	x19, x20, [x0, #32]
	ldp	x2, x21, [x0, #16]
	mov	x0, x8
	bl	"l_#Attr_#dec_13"
	mov	x0, x21
	mov	x1, x19
	mov	x2, x20
	bl	_List_isEmpty_99e2ebbd98e8a2a4c7ed9bd71d205d9f7b5d7e7a9ddb68dab65f2ad1c2198b
	mov	w22, w0
	mov	x0, x21
	mov	x1, x19
	mov	x2, x20
	bl	"l_#Attr_#dec_15"
	ldp	x29, x30, [sp, #32]             ; 16-byte Folded Reload
	and	w0, w22, #0x1
	ldp	x20, x19, [sp, #16]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp], #48             ; 16-byte Folded Reload
	ret
Ltmp165:
Lfunc_end185:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_await_9ddbc9a5a6ab79818cf720ec32ba1aeb5838e37cd919c2ff6b897d7d866d5c7
_Task_await_9ddbc9a5a6ab79818cf720ec32ba1aeb5838e37cd919c2ff6b897d7d866d5c7: ; @Task_await_9ddbc9a5a6ab79818cf720ec32ba1aeb5838e37cd919c2ff6b897d7d866d5c7
Lfunc_begin186:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #96
	.cfi_def_cfa_offset 96
Ltmp166:
	ldr	x8, [x5]
	mov	w9, #2
	str	w3, [sp, #32]
	stp	x0, x1, [sp, #8]
	str	x2, [sp, #24]
	ldur	q0, [sp, #8]
	strb	w4, [sp, #36]
	str	x8, [sp, #80]
	ldur	q1, [sp, #24]
	strb	w9, [sp, #88]
	ldr	q2, [sp, #80]
	str	x8, [sp, #40]
	stp	q0, q1, [sp, #48]
	stp	q0, q1, [x6]
	str	q2, [x6, #32]
	add	sp, sp, #96
	ret
Ltmp167:
Lfunc_end186:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_dbgTag_d1a1e4356bd9fe6c31754def4c60a14042ade1c6c101618179cfd5d1c73189
_Inspect_dbgTag_d1a1e4356bd9fe6c31754def4c60a14042ade1c6c101618179cfd5d1c73189: ; @Inspect_dbgTag_d1a1e4356bd9fe6c31754def4c60a14042ade1c6c101618179cfd5d1c73189
Lfunc_begin187:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #352
	.cfi_def_cfa_offset 352
	stp	x28, x27, [sp, #272]            ; 16-byte Folded Spill
	stp	x24, x23, [sp, #288]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #304]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #320]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #336]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
	.cfi_offset w27, -72
	.cfi_offset w28, -80
	mov	x23, x2
	mov	x21, x1
	mov	x20, x0
Ltmp168:
	mov	x0, x1
	mov	x1, x2
	mov	x2, x3
	mov	x19, x4
	mov	x22, x3
	bl	_List_isEmpty_54b3c6d264e7c557f2fe74ef29431163e9a30a2e4aca38b681d4b9ee62de031
	tbz	w0, #0, LBB187_2
; %bb.1:                                ; %then_block
	mov	x0, x20
	mov	w1, #1
	bl	"l_#Attr_#inc_1"
	ldr	q0, [x20]
	strb	wzr, [sp, #48]
	ldr	x8, [x20, #16]
	mov	x0, sp
	add	x1, sp, #56
	add	x20, sp, #56
	str	q0, [sp]
	str	x8, [sp, #16]
	b	LBB187_3
LBB187_2:                               ; %else_block
	mov	x0, x21
	mov	x1, x23
	mov	x2, x22
	mov	w3, #1
	mov	w24, #1
	bl	"l_#Attr_#inc_4"
	mov	x0, x20
	mov	w1, #1
	bl	"l_#Attr_#inc_1"
	ldr	x8, [x20, #16]
	stp	x23, x22, [sp, #144]
	ldr	q0, [x20]
	add	x0, sp, #160
	add	x1, sp, #216
	add	x20, sp, #216
	stp	x8, x21, [sp, #128]
	ldp	q2, q1, [sp, #128]
	str	q0, [sp, #112]
	str	q0, [sp, #160]
	strb	w24, [sp, #208]
	stp	q2, q1, [sp, #176]
LBB187_3:                               ; %common.ret
	bl	_Inspect_custom_926c4e1deae44cb32fa91b0fc2f966fdf98af98ee562517f2d5df6cc1b8bf0
	ldp	q0, q1, [x20]
	ldr	q2, [x20, #32]
	stp	q0, q1, [x19]
	ldr	x8, [x20, #48]
	ldp	x29, x30, [sp, #336]            ; 16-byte Folded Reload
	str	q2, [x19, #32]
	str	x8, [x19, #48]
	ldp	x20, x19, [sp, #320]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #304]            ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #288]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #272]            ; 16-byte Folded Reload
	add	sp, sp, #352
	ret
Ltmp169:
Lfunc_end187:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_apply_4afec3b1b615e34b46f852dc4576722a03d82d96cc27deb38d7b350ecaf31
_Inspect_apply_4afec3b1b615e34b46f852dc4576722a03d82d96cc27deb38d7b350ecaf31: ; @Inspect_apply_4afec3b1b615e34b46f852dc4576722a03d82d96cc27deb38d7b350ecaf31
Lfunc_begin188:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
	mov	x8, x0
Ltmp170:
	ldrb	w9, [x0, #48]
	mov	x0, x1
	cbz	w9, LBB188_2
; %bb.1:                                ; %default
	add	x2, sp, #24
	mov	x1, x8
	add	x20, sp, #24
	bl	_Inspect_206_f784f33513051f4f09b2b103edd2f576ced88ace36b12d3f4e2a3dbe51fcfeb
	b	LBB188_3
LBB188_2:                               ; %branch0
	mov	x2, sp
	mov	x1, x8
	mov	x20, sp
	bl	_Inspect_204_50a9b514f5bf5c5ff0dff77dffab9b9f2c8b7084581b52c249d53019289d446b
LBB188_3:                               ; %common.ret
	ldr	q0, [x20]
	ldr	x8, [x20, #16]
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp171:
Lfunc_end188:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Num_toStr_f273102d33b910ab8b1eda6e483bb587ec34372c3562cd9bfb68bcf889ba9cd
_Num_toStr_f273102d33b910ab8b1eda6e483bb587ec34372c3562cd9bfb68bcf889ba9cd: ; @Num_toStr_f273102d33b910ab8b1eda6e483bb587ec34372c3562cd9bfb68bcf889ba9cd
Lfunc_begin189:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp172:
	add	x8, sp, #8
	mov	x19, x1
	bl	_roc_builtins.str.from_int.i32
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp173:
Lfunc_end189:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Num_isLt_669c1355a3e727bb53dd458f2e96e48571aa45dfabcfb4b7de1689484f11
_Num_isLt_669c1355a3e727bb53dd458f2e96e48571aa45dfabcfb4b7de1689484f11: ; @Num_isLt_669c1355a3e727bb53dd458f2e96e48571aa45dfabcfb4b7de1689484f11
Lfunc_begin190:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	cmp	x0, x1
	cset	w0, lo
	ret
Ltmp174:
Lfunc_end190:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_apply_8acb95ddb9a746c2bf4dc0f4f96ce3b3e1f1e4f2559e7641b193db1f161d1c41
_Inspect_apply_8acb95ddb9a746c2bf4dc0f4f96ce3b3e1f1e4f2559e7641b193db1f161d1c41: ; @Inspect_apply_8acb95ddb9a746c2bf4dc0f4f96ce3b3e1f1e4f2559e7641b193db1f161d1c41
Lfunc_begin191:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
	mov	x8, x0
Ltmp175:
	ldrb	w9, [x0, #48]
	mov	x0, x1
	cbz	w9, LBB191_2
; %bb.1:                                ; %default
	add	x2, sp, #24
	mov	x1, x8
	add	x20, sp, #24
	bl	_Inspect_206_11922f5e717257e3c76632973ee406cbf106889cd4e80e37d14c1d9c194671
	b	LBB191_3
LBB191_2:                               ; %branch0
	mov	x2, sp
	mov	x1, x8
	mov	x20, sp
	bl	_Inspect_204_b7c59c3aec44645db91b229c81990d288c86aeb49f116d1eae85e2b9a39999f
LBB191_3:                               ; %common.ret
	ldr	q0, [x20]
	ldr	x8, [x20, #16]
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp176:
Lfunc_end191:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_38_837964ef27185f97a31536069e8f60f59d43cf26aef4e69eeafaab204a51f2
_Task_38_837964ef27185f97a31536069e8f60f59d43cf26aef4e69eeafaab204a51f2: ; @Task_38_837964ef27185f97a31536069e8f60f59d43cf26aef4e69eeafaab204a51f2
Lfunc_begin192:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #16
	.cfi_def_cfa_offset 16
Ltmp177:
	ldr	w8, [x0]
	strb	wzr, [sp, #12]
	str	w8, [sp, #8]
	ldr	x8, [sp, #8]
	str	x8, [x1]
	add	sp, sp, #16
	ret
Ltmp178:
Lfunc_end192:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_len_dc3f621de1221c7c53a19e877c377561ede91cdd88b1a687d310a39785a
_List_len_dc3f621de1221c7c53a19e877c377561ede91cdd88b1a687d310a39785a: ; @List_len_dc3f621de1221c7c53a19e877c377561ede91cdd88b1a687d310a39785a
Lfunc_begin193:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	x0, x1
Ltmp179:
	ret
Ltmp180:
Lfunc_end193:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_sortWith_91183c4be76c8c6e9a1aca423ca6b7bdfddc155d7aac337b8db73395e0e64d
_List_sortWith_91183c4be76c8c6e9a1aca423ca6b7bdfddc155d7aac337b8db73395e0e64d: ; @List_sortWith_91183c4be76c8c6e9a1aca423ca6b7bdfddc155d7aac337b8db73395e0e64d
Lfunc_begin194:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #272
	.cfi_def_cfa_offset 272
	stp	x28, x27, [sp, #208]            ; 16-byte Folded Spill
	stp	x22, x21, [sp, #224]            ; 16-byte Folded Spill
	stp	x20, x19, [sp, #240]            ; 16-byte Folded Spill
	stp	x29, x30, [sp, #256]            ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w27, -56
	.cfi_offset w28, -64
Ltmp181:
	ldp	q0, q1, [x3]
	mov	x19, x3
	cmp	x1, #1
	stp	x0, x1, [sp, #120]
	str	x2, [sp, #136]
	ldp	q2, q3, [x3, #32]
	stp	q0, q1, [sp, #32]
	stp	q2, q3, [sp, #64]
	b.hi	LBB194_2
; %bb.1:
	ldur	q0, [sp, #120]
	ldr	x8, [sp, #136]
	str	q0, [sp, #96]
	str	x8, [sp, #112]
	b	LBB194_9
LBB194_2:
	ldur	q0, [sp, #120]
	ldr	x8, [sp, #136]
	str	q0, [sp, #144]
	ldr	x21, [sp, #152]
	cmp	x8, #0
	csel	x9, x8, xzr, gt
	str	x8, [sp, #160]
	and	x10, x21, x8, asr #63
	orr	x9, x10, x9
	cbnz	x9, LBB194_4
; %bb.3:
	tbz	x8, #63, LBB194_5
LBB194_4:                               ; %list.RocList.isUnique.exit.i.i
	ldr	x9, [sp, #144]
	lsl	x10, x8, #1
	cmp	x8, #0
	mov	x11, #-9223372036854775808
	csel	x9, x10, x9, lt
	ldur	x10, [x9, #-8]
	cmp	x10, x11
	b.ne	LBB194_10
LBB194_5:                               ; %list.RocList.isUnique.exit.thread.i.i
	ldr	q0, [sp, #144]
	ldr	x8, [sp, #160]
	str	q0, [sp, #176]
	str	x8, [sp, #192]
LBB194_6:                               ; %list.RocList.makeUnique.exit.i
	ldr	x20, [sp, #176]
	ldur	q0, [sp, #184]
	cbz	x20, LBB194_8
; %bb.7:
	fmov	x1, d0
Lloh69:
	adrp	x2, l_Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2_compare_wrapper@PAGE
Lloh70:
	add	x2, x2, l_Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2_compare_wrapper@PAGEOFF
Lloh71:
	adrp	x5, "l_#Attr_#generic_rc_by_ref_6_inc_n"@PAGE
Lloh72:
	add	x5, x5, "l_#Attr_#generic_rc_by_ref_6_inc_n"@PAGEOFF
	add	x3, sp, #32
	mov	x0, x20
	mov	w4, #1
	mov	x6, xzr
	mov	w7, #1
Lloh73:
	adrp	x8, "l_#Attr_#generic_copy_by_ref_1"@PAGE
Lloh74:
	add	x8, x8, "l_#Attr_#generic_copy_by_ref_1"@PAGEOFF
	str	q0, [sp, #16]                   ; 16-byte Folded Spill
	str	x8, [sp]
	bl	l_sort.fluxsort
	ldr	q0, [sp, #16]                   ; 16-byte Folded Reload
LBB194_8:                               ; %common.ret.i
	str	x20, [sp, #96]
	stur	q0, [sp, #104]
LBB194_9:                               ; %roc_builtins.list.sort_with.exit
	ldp	x20, x21, [sp, #96]
	mov	x0, x19
	ldr	x22, [sp, #112]
	bl	"l_#Attr_#dec_17"
	mov	x0, x20
	mov	x1, x21
	mov	x2, x22
	ldp	x29, x30, [sp, #256]            ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #240]            ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #224]            ; 16-byte Folded Reload
	ldp	x28, x27, [sp, #208]            ; 16-byte Folded Reload
	add	sp, sp, #272
	ret
LBB194_10:
	cbz	x21, LBB194_17
; %bb.11:
	mov	w0, #8
	mov	w1, #8
	bl	_roc_alloc
	ldr	x8, [sp, #160]
	mov	x20, x0
	ldr	x9, [sp, #144]
	mov	x10, #-9223372036854775808
	lsl	x11, x8, #1
	cmp	x8, #0
	csel	x0, x11, x9, lt
	str	x10, [x20], #8
	cbz	x8, LBB194_16
; %bb.12:
	cbz	x0, LBB194_16
; %bb.13:
	ldr	x8, [x0, #-8]!
	cbz	x8, LBB194_16
; %bb.14:
	sub	x9, x8, #1
	cmp	x8, x10
	str	x9, [x0]
	b.ne	LBB194_16
; %bb.15:
	mov	w1, #8
	bl	_roc_dealloc
LBB194_16:                              ; %list.RocList.decref.exit41.i.i
	stp	x20, x21, [sp, #176]
	str	x21, [sp, #192]
	b	LBB194_6
LBB194_17:                              ; %.critedge.i.i.i
	cbz	x8, LBB194_21
; %bb.18:                               ; %.critedge.i.i.i
	cbz	x9, LBB194_21
; %bb.19:                               ; %.critedge.i.i.i
	cbz	x10, LBB194_21
; %bb.20:
	sub	x8, x10, #1
	stur	x8, [x9, #-8]
LBB194_21:                              ; %list.RocList.decref.exit.i.i
	stp	xzr, xzr, [sp, #176]
	str	xzr, [sp, #192]
	b	LBB194_6
Ltmp182:
	.loh AdrpAdd	Lloh73, Lloh74
	.loh AdrpAdd	Lloh71, Lloh72
	.loh AdrpAdd	Lloh69, Lloh70
Lfunc_end194:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_len_68697e959be5e5da06cc73b6f998e193cbf2d9b22efd0355a3d37129951b
_List_len_68697e959be5e5da06cc73b6f998e193cbf2d9b22efd0355a3d37129951b: ; @List_len_68697e959be5e5da06cc73b6f998e193cbf2d9b22efd0355a3d37129951b
Lfunc_begin195:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	x0, x1
Ltmp183:
	ret
Ltmp184:
Lfunc_end195:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Task_46_56b1edb1daf8df7ae4fb1a2df75794dcef5a427f85ac1fa18ff4bea1e8e00
_Task_46_56b1edb1daf8df7ae4fb1a2df75794dcef5a427f85ac1fa18ff4bea1e8e00: ; @Task_46_56b1edb1daf8df7ae4fb1a2df75794dcef5a427f85ac1fa18ff4bea1e8e00
Lfunc_begin196:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp185:
	ldr	x9, [x0, #32]
	ldp	x8, x1, [x0]
	add	x5, sp, #8
	ldr	x2, [x0, #16]
	str	x9, [sp]
	ldr	w3, [x0, #24]
	ldrb	w4, [x0, #28]
	mov	x0, x8
	bl	_Task_53_1dc6f9836252db90e110ad1b5e28c952e1292787deeab71a2a18c14f1d18ec0
	ldrb	w8, [sp, #12]
	cmp	w8, #1
	b.ne	LBB196_3
; %bb.1:                                ; %then_block
	ldrb	w8, [sp, #4]
	cbz	w8, LBB196_4
; %bb.2:                                ; %default
	bl	__11_2c7d993eadf275d994a1f98b824972fece3cfca6b6ac52dd7bb717e1f5753
	b	LBB196_5
LBB196_3:                               ; %else_block
	ldr	w8, [sp, #8]
	strb	wzr, [sp, #28]
	str	w8, [sp, #24]
	ldr	x8, [sp, #24]
	b	LBB196_6
LBB196_4:                               ; %branch0
	mov	x0, sp
	bl	__8_8b8e749a7d5dc4035aed2d09b8b4ad59fac5ad694339521a2df23bf1ac35c3
LBB196_5:                               ; %joinpointcont
	add	x1, sp, #16
	bl	_Task_38_464ad9696114b8eea8bc3daaaa648b1d3685be4c8d824dbb0c93c169d61
	ldr	x8, [sp, #16]
LBB196_6:                               ; %common.ret
	str	x8, [x19]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp186:
Lfunc_end196:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Dict_empty_392aebc0773ca1163ead8eb210e2c2aabca4fe4ded9f2b122a7dab30d082d98b
_Dict_empty_392aebc0773ca1163ead8eb210e2c2aabca4fe4ded9f2b122a7dab30d082d98b: ; @Dict_empty_392aebc0773ca1163ead8eb210e2c2aabca4fe4ded9f2b122a7dab30d082d98b
Lfunc_begin197:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #112
	.cfi_def_cfa_offset 112
	stp	d9, d8, [sp, #64]               ; 16-byte Folded Spill
	stp	x20, x19, [sp, #80]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #96]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset b8, -40
	.cfi_offset b9, -48
	mov	x19, x0
Ltmp187:
	bl	_Dict_defaultMaxLoadFactor_7a93171d29c34145ace0bed7f158bc6f747d259f21a8119f90767f874eb48b94
	fmov	s8, s0
	bl	_Dict_initialShifts_839d816e30d259b7a113479095a2bf4a37efc9c09ed13ea6ca0fa9b9a5ff9
	stp	xzr, xzr, [sp]
	stp	xzr, xzr, [sp, #16]
	stp	xzr, xzr, [sp, #32]
	str	xzr, [sp, #48]
	str	s8, [sp, #56]
	strb	w0, [sp, #60]
	ldp	q0, q1, [sp]
	ldp	q2, q3, [sp, #32]
	stp	q0, q1, [x19]
	stp	q2, q3, [x19, #32]
	ldp	x29, x30, [sp, #96]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #80]             ; 16-byte Folded Reload
	ldp	d9, d8, [sp, #64]               ; 16-byte Folded Reload
	add	sp, sp, #112
	ret
Ltmp188:
Lfunc_end197:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function List_isEmpty_54b3c6d264e7c557f2fe74ef29431163e9a30a2e4aca38b681d4b9ee62de031
_List_isEmpty_54b3c6d264e7c557f2fe74ef29431163e9a30a2e4aca38b681d4b9ee62de031: ; @List_isEmpty_54b3c6d264e7c557f2fe74ef29431163e9a30a2e4aca38b681d4b9ee62de031
Lfunc_begin198:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp189:
	bl	_List_len_68697e959be5e5da06cc73b6f998e193cbf2d9b22efd0355a3d37129951b
	mov	x1, xzr
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	b	_Bool_structuralEq_cabb163ea8b383114bab450f2ea4bdf6f97d5dc22e57b593db81e3bce47
Ltmp190:
Lfunc_end198:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Inspect_213_bd5db9a62133a57f3c3971868413d37dfa646aa8a2764e7763fd4ba5b0b0d4
_Inspect_213_bd5db9a62133a57f3c3971868413d37dfa646aa8a2764e7763fd4ba5b0b0d4: ; @Inspect_213_bd5db9a62133a57f3c3971868413d37dfa646aa8a2764e7763fd4ba5b0b0d4
Lfunc_begin199:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #64
	.cfi_def_cfa_offset 64
	stp	x20, x19, [sp, #32]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #48]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x8, x0
	mov	x19, x2
Ltmp191:
	add	x2, sp, #8
	mov	x0, x1
	mov	x1, x8
	bl	_Inspect_apply_676ec9e417566a851359c2c6d5d5332f7d40742f8274a8672f3cad244846
	ldur	q0, [sp, #8]
	ldr	x8, [sp, #24]
	ldp	x29, x30, [sp, #48]             ; 16-byte Folded Reload
	str	q0, [x19]
	str	x8, [x19, #16]
	ldp	x20, x19, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #64
	ret
Ltmp192:
Lfunc_end199:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2
_Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2: ; @Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2
Lfunc_begin200:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	mov	x0, x2
Ltmp193:
	bl	_Set_isEmpty_127cb22736133e34b265d61ea1d591a8834a13a1d4a2cb161a40b74f7c37b3
	mov	w8, #1
	tst	w0, #0x1
	cinc	w0, w8, eq
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp194:
Lfunc_end200:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Derived_toInspector_[Exit 2,StdoutErr 1]_ec2bd03bf86b935fa34d71ad7ebb49f1f10f87d343e521511d8f9e6625620cd
"_#Derived_toInspector_[Exit 2,StdoutErr 1]_ec2bd03bf86b935fa34d71ad7ebb49f1f10f87d343e521511d8f9e6625620cd": ; @"#Derived_toInspector_[Exit 2,StdoutErr 1]_ec2bd03bf86b935fa34d71ad7ebb49f1f10f87d343e521511d8f9e6625620cd"
Lfunc_begin201:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #80
	.cfi_def_cfa_offset 80
	stp	x20, x19, [sp, #48]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #64]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
Ltmp195:
	add	x1, sp, #8
	bl	_Inspect_custom_653de62d66328bd02e166b818cc28fc7f76ad909358c5f3f340dd1c827546c9
	ldur	q0, [sp, #8]
	ldur	q1, [sp, #24]
	ldr	x8, [sp, #40]
	ldp	x29, x30, [sp, #64]             ; 16-byte Folded Reload
	stp	q0, q1, [x19]
	str	x8, [x19, #32]
	ldp	x20, x19, [sp, #48]             ; 16-byte Folded Reload
	add	sp, sp, #80
	ret
Ltmp196:
Lfunc_end201:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Dict_initialShifts_839d816e30d259b7a113479095a2bf4a37efc9c09ed13ea6ca0fa9b9a5ff9
_Dict_initialShifts_839d816e30d259b7a113479095a2bf4a37efc9c09ed13ea6ca0fa9b9a5ff9: ; @Dict_initialShifts_839d816e30d259b7a113479095a2bf4a37efc9c09ed13ea6ca0fa9b9a5ff9
Lfunc_begin202:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	w0, #64
	mov	w1, #3
	b	_Num_subWrap_edaf1bd3d1c2ffcc44df55829c02f262426de2ffbea9be2cdf075ec12c528d
Ltmp197:
Lfunc_end202:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_1
"l_#Attr_#dec_1":                       ; @"#Attr_#dec_1"
Lfunc_begin203:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp198:
	ldr	x8, [x0, #16]
	cmp	x8, #0
	b.le	LBB203_2
; %bb.1:                                ; %modify_rc
	bl	_roc_builtins.str.allocation_ptr
	sub	x0, x0, #8
	bl	_decrement_refcounted_ptr_8
LBB203_2:                               ; %modify_rc_str_cont
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp199:
Lfunc_end203:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function decrement_refcounted_ptr_8
_decrement_refcounted_ptr_8:            ; @decrement_refcounted_ptr_8
Lfunc_begin204:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp200:
	ldr	x8, [x0]
	cbz	x8, LBB204_3
; %bb.1:
	sub	x9, x8, #1
	mov	x10, #-9223372036854775808
	cmp	x8, x10
	str	x9, [x0]
	b.ne	LBB204_3
; %bb.2:
	mov	w1, #8
	bl	_roc_dealloc
LBB204_3:                               ; %roc_builtins.utils.decref_rc_ptr.exit
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp201:
Lfunc_end204:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_2
"l_#Attr_#dec_2":                       ; @"#Attr_#dec_2"
Lfunc_begin205:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #96
	.cfi_def_cfa_offset 96
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
Ltmp202:
	cmp	x2, #0
	and	x9, x1, x2, asr #63
	csel	x8, x2, xzr, gt
	mov	x19, x2
	mov	x21, x1
	mov	x20, x0
	orr	x8, x9, x8
	lsl	x23, x2, #1
	stp	x1, x2, [sp, #16]
	str	x0, [sp, #8]
	cbnz	x8, LBB205_3
; %bb.1:                                ; %entry
	tbnz	x19, #63, LBB205_3
; %bb.2:
	mov	x22, x20
	b	LBB205_4
LBB205_3:                               ; %list.RocList.isUnique.exit.i.i
	cmp	x19, #0
	mov	x9, #-9223372036854775808
	csel	x22, x23, x20, lt
	ldur	x8, [x22, #-8]
	cmp	x8, x9
	b.ne	LBB205_9
LBB205_4:                               ; %list.RocList.isUnique.exit.thread.i.i
	cbz	x22, LBB205_9
; %bb.5:
	tbz	x19, #63, LBB205_7
; %bb.6:
	ldur	x21, [x23, #-16]
LBB205_7:                               ; %list.RocList.getAllocationElementCount.exit.i.i
	cbz	x21, LBB205_9
LBB205_8:                               ; %.lr.ph.i.i
                                        ; =>This Inner Loop Header: Depth=1
Ltmp203:
	mov	x0, x22
	bl	"l_#Attr_#dec_1"
Ltmp204:
	subs	x21, x21, #1
	add	x22, x22, #24
	b.ne	LBB205_8
LBB205_9:                               ; %.critedge.i.i
	cmp	x19, #0
	csel	x8, x23, x20, lt
	cbz	x19, LBB205_14
; %bb.10:                               ; %.critedge.i.i
	cbz	x8, LBB205_14
; %bb.11:
	ldr	x9, [x8, #-8]!
	cbz	x9, LBB205_14
; %bb.12:
	sub	x10, x9, #1
	mov	x11, #-9223372036854775808
	cmp	x9, x11
	str	x10, [x8]
	b.ne	LBB205_14
; %bb.13:
	sub	x0, x8, #8
	mov	w1, #8
	bl	_roc_dealloc
LBB205_14:                              ; %roc_builtins.list.decref.exit
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #96
	ret
Ltmp205:
Lfunc_end205:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#inc_2
"l_#Attr_#inc_2":                       ; @"#Attr_#inc_2"
Lfunc_begin206:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #32
	.cfi_def_cfa_offset 32
Ltmp206:
	cmp	x2, #0
	and	x9, x1, x2, asr #63
	csel	x8, x2, xzr, gt
	stp	x1, x2, [sp, #16]
	orr	x9, x9, x8
	lsl	x8, x2, #1
	str	x0, [sp, #8]
	cbnz	x9, LBB206_2
; %bb.1:                                ; %entry
	tbz	x2, #63, LBB206_4
LBB206_2:                               ; %list.RocList.isUnique.exit.i.i
	cmp	x2, #0
	mov	x10, #-9223372036854775808
	csel	x9, x8, x0, lt
	ldur	x9, [x9, #-8]
	cmp	x9, x10
	b.ne	LBB206_6
; %bb.3:                                ; %list.RocList.isUnique.exit.i.i
	tbnz	x2, #63, LBB206_6
LBB206_4:                               ; %list.RocList.isUnique.exit.i.i
	cbz	x0, LBB206_6
; %bb.5:
	stur	x1, [x0, #-16]
LBB206_6:                               ; %.critedge.i.i
	cmp	x2, #0
	csel	x8, x8, x0, lt
	cbz	x8, LBB206_9
; %bb.7:
	and	x8, x8, #0xfffffffffffffff8
	ldur	x9, [x8, #-8]
	cbz	x9, LBB206_9
; %bb.8:
	add	x9, x9, x3
	stur	x9, [x8, #-8]
LBB206_9:                               ; %roc_builtins.list.incref.exit
	add	sp, sp, #32
	ret
Ltmp207:
Lfunc_end206:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#inc_1
"l_#Attr_#inc_1":                       ; @"#Attr_#inc_1"
Lfunc_begin207:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp208:
	ldr	x8, [x0, #16]
	cmp	x8, #0
	b.le	LBB207_3
; %bb.1:                                ; %modify_rc
	mov	x19, x1
	bl	_roc_builtins.str.allocation_ptr
	ldur	x8, [x0, #-8]
	cbz	x8, LBB207_3
; %bb.2:
	add	x8, x8, x19
	stur	x8, [x0, #-8]
LBB207_3:                               ; %modify_rc_str_cont
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	ret
Ltmp209:
Lfunc_end207:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_3
"l_#Attr_#dec_3":                       ; @"#Attr_#dec_3"
Lfunc_begin208:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp210:
	ldrb	w8, [x0, #24]
	cmp	w8, #2
	b.ne	LBB208_2
; %bb.1:                                ; %tag_id_modify
	bl	"l_#Attr_#dec_1"
LBB208_2:                               ; %modify_rc_union_merge
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp211:
Lfunc_end208:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function roc_fx_stderrLine_fastcc_wrapper
_roc_fx_stderrLine_fastcc_wrapper:      ; @roc_fx_stderrLine_fastcc_wrapper
Lfunc_begin209:
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	mov	x8, x1
	bl	_roc_fx_stderrLine
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Lfunc_end209:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_4
"l_#Attr_#dec_4":                       ; @"#Attr_#dec_4"
Lfunc_begin210:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #96
	.cfi_def_cfa_offset 96
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
Ltmp212:
	cmp	x2, #0
	and	x9, x1, x2, asr #63
	csel	x8, x2, xzr, gt
	mov	x19, x2
	mov	x21, x1
	mov	x20, x0
	orr	x8, x9, x8
	lsl	x23, x2, #1
	stp	x1, x2, [sp, #16]
	str	x0, [sp, #8]
	cbnz	x8, LBB210_3
; %bb.1:                                ; %entry
	tbnz	x19, #63, LBB210_3
; %bb.2:
	mov	x22, x20
	b	LBB210_4
LBB210_3:                               ; %list.RocList.isUnique.exit.i.i
	cmp	x19, #0
	mov	x9, #-9223372036854775808
	csel	x22, x23, x20, lt
	ldur	x8, [x22, #-8]
	cmp	x8, x9
	b.ne	LBB210_9
LBB210_4:                               ; %list.RocList.isUnique.exit.thread.i.i
	cbz	x22, LBB210_9
; %bb.5:
	tbz	x19, #63, LBB210_7
; %bb.6:
	ldur	x21, [x23, #-16]
LBB210_7:                               ; %list.RocList.getAllocationElementCount.exit.i.i
	cbz	x21, LBB210_9
LBB210_8:                               ; %.lr.ph.i.i
                                        ; =>This Inner Loop Header: Depth=1
Ltmp213:
	mov	x0, x22
	bl	"l_#Attr_#dec_5"
Ltmp214:
	subs	x21, x21, #1
	add	x22, x22, #40
	b.ne	LBB210_8
LBB210_9:                               ; %.critedge.i.i
	cmp	x19, #0
	csel	x8, x23, x20, lt
	cbz	x19, LBB210_14
; %bb.10:                               ; %.critedge.i.i
	cbz	x8, LBB210_14
; %bb.11:
	ldr	x9, [x8, #-8]!
	cbz	x9, LBB210_14
; %bb.12:
	sub	x10, x9, #1
	mov	x11, #-9223372036854775808
	cmp	x9, x11
	str	x10, [x8]
	b.ne	LBB210_14
; %bb.13:
	sub	x0, x8, #8
	mov	w1, #8
	bl	_roc_dealloc
LBB210_14:                              ; %roc_builtins.list.decref.exit
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #96
	ret
Ltmp215:
Lfunc_end210:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_5
"l_#Attr_#dec_5":                       ; @"#Attr_#dec_5"
Lfunc_begin211:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp216:
	ldrb	w8, [x0, #32]
	cbz	w8, LBB211_3
; %bb.1:                                ; %entry
	cmp	w8, #1
	b.ne	LBB211_4
; %bb.2:                                ; %tag_id_modify1
	bl	"l_#Attr_#dec_1"
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
LBB211_3:                               ; %tag_id_modify
	bl	"l_#Attr_#dec_3"
LBB211_4:                               ; %modify_rc_union_merge
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp217:
Lfunc_end211:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function roc_fx_stdoutLine_fastcc_wrapper
_roc_fx_stdoutLine_fastcc_wrapper:      ; @roc_fx_stdoutLine_fastcc_wrapper
Lfunc_begin212:
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	mov	x8, x1
	bl	_roc_fx_stdoutLine
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Lfunc_end212:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#inc_4
"l_#Attr_#inc_4":                       ; @"#Attr_#inc_4"
Lfunc_begin213:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #32
	.cfi_def_cfa_offset 32
Ltmp218:
	cmp	x2, #0
	and	x9, x1, x2, asr #63
	csel	x8, x2, xzr, gt
	stp	x1, x2, [sp, #16]
	orr	x9, x9, x8
	lsl	x8, x2, #1
	str	x0, [sp, #8]
	cbnz	x9, LBB213_2
; %bb.1:                                ; %entry
	tbz	x2, #63, LBB213_4
LBB213_2:                               ; %list.RocList.isUnique.exit.i.i
	cmp	x2, #0
	mov	x10, #-9223372036854775808
	csel	x9, x8, x0, lt
	ldur	x9, [x9, #-8]
	cmp	x9, x10
	b.ne	LBB213_6
; %bb.3:                                ; %list.RocList.isUnique.exit.i.i
	tbnz	x2, #63, LBB213_6
LBB213_4:                               ; %list.RocList.isUnique.exit.i.i
	cbz	x0, LBB213_6
; %bb.5:
	stur	x1, [x0, #-16]
LBB213_6:                               ; %.critedge.i.i
	cmp	x2, #0
	csel	x8, x8, x0, lt
	cbz	x8, LBB213_9
; %bb.7:
	and	x8, x8, #0xfffffffffffffff8
	ldur	x9, [x8, #-8]
	cbz	x9, LBB213_9
; %bb.8:
	add	x9, x9, x3
	stur	x9, [x8, #-8]
LBB213_9:                               ; %roc_builtins.list.incref.exit
	add	sp, sp, #32
	ret
Ltmp219:
Lfunc_end213:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#inc_5
"l_#Attr_#inc_5":                       ; @"#Attr_#inc_5"
Lfunc_begin214:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp220:
	ldrb	w8, [x0, #32]
	cbz	w8, LBB214_3
; %bb.1:                                ; %entry
	cmp	w8, #1
	b.ne	LBB214_4
; %bb.2:                                ; %tag_id_modify1
	bl	"l_#Attr_#inc_1"
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
LBB214_3:                               ; %tag_id_modify
	bl	"l_#Attr_#inc_3"
LBB214_4:                               ; %modify_rc_union_merge
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp221:
Lfunc_end214:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#inc_3
"l_#Attr_#inc_3":                       ; @"#Attr_#inc_3"
Lfunc_begin215:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp222:
	ldrb	w8, [x0, #24]
	cmp	w8, #2
	b.ne	LBB215_2
; %bb.1:                                ; %tag_id_modify
	bl	"l_#Attr_#inc_1"
LBB215_2:                               ; %modify_rc_union_merge
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp223:
Lfunc_end215:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_10
"l_#Attr_#dec_10":                      ; @"#Attr_#dec_10"
Lfunc_begin216:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp224:
	lsl	x9, x2, #1
	cmp	x2, #0
	mov	x8, x0
	csel	x0, x9, x0, lt
	stp	x1, x2, [sp, #16]
	str	x8, [sp, #8]
	cbz	x2, LBB216_5
; %bb.1:                                ; %entry
	cbz	x0, LBB216_5
; %bb.2:
	ldr	x8, [x0, #-8]!
	cbz	x8, LBB216_5
; %bb.3:
	sub	x9, x8, #1
	mov	x10, #-9223372036854775808
	cmp	x8, x10
	str	x9, [x0]
	b.ne	LBB216_5
; %bb.4:
	mov	w1, #8
	bl	_roc_dealloc
LBB216_5:                               ; %roc_builtins.list.decref.exit
	ldp	x29, x30, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #48
	ret
Ltmp225:
Lfunc_end216:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_11
"l_#Attr_#dec_11":                      ; @"#Attr_#dec_11"
Lfunc_begin217:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp226:
	ldrb	w8, [x0, #40]
	cbz	w8, LBB217_2
; %bb.1:                                ; %modify_rc_union_merge
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
LBB217_2:                               ; %tag_id_modify
	bl	"l_#Attr_#dec_12"
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp227:
Lfunc_end217:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_12
"l_#Attr_#dec_12":                      ; @"#Attr_#dec_12"
Lfunc_begin218:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp228:
	ldrb	w8, [x0, #32]
	cbz	w8, LBB218_3
; %bb.1:                                ; %entry
	cmp	w8, #1
	b.ne	LBB218_4
; %bb.2:                                ; %tag_id_modify1
	bl	"l_#Attr_#dec_3"
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
LBB218_3:                               ; %tag_id_modify
	bl	"l_#Attr_#dec_1"
LBB218_4:                               ; %modify_rc_union_merge
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp229:
Lfunc_end218:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_13
"l_#Attr_#dec_13":                      ; @"#Attr_#dec_13"
Lfunc_begin219:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp230:
	lsl	x9, x2, #1
	cmp	x2, #0
	mov	x8, x0
	csel	x0, x9, x0, lt
	stp	x1, x2, [sp, #16]
	str	x8, [sp, #8]
	cbz	x2, LBB219_5
; %bb.1:                                ; %entry
	cbz	x0, LBB219_5
; %bb.2:
	ldr	x8, [x0, #-8]!
	cbz	x8, LBB219_5
; %bb.3:
	sub	x9, x8, #1
	mov	x10, #-9223372036854775808
	cmp	x8, x10
	str	x9, [x0]
	b.ne	LBB219_5
; %bb.4:
	mov	w1, #8
	bl	_roc_dealloc
LBB219_5:                               ; %roc_builtins.list.decref.exit
	ldp	x29, x30, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #48
	ret
Ltmp231:
Lfunc_end219:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_14
"l_#Attr_#dec_14":                      ; @"#Attr_#dec_14"
Lfunc_begin220:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ret
Ltmp232:
Lfunc_end220:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_15
"l_#Attr_#dec_15":                      ; @"#Attr_#dec_15"
Lfunc_begin221:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #96
	.cfi_def_cfa_offset 96
	stp	x24, x23, [sp, #32]             ; 16-byte Folded Spill
	stp	x22, x21, [sp, #48]             ; 16-byte Folded Spill
	stp	x20, x19, [sp, #64]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #80]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	.cfi_offset w21, -40
	.cfi_offset w22, -48
	.cfi_offset w23, -56
	.cfi_offset w24, -64
Ltmp233:
	cmp	x2, #0
	and	x9, x1, x2, asr #63
	csel	x8, x2, xzr, gt
	mov	x19, x2
	mov	x21, x1
	mov	x20, x0
	orr	x8, x9, x8
	lsl	x22, x2, #1
	stp	x1, x2, [sp, #16]
	str	x0, [sp, #8]
	cbnz	x8, LBB221_3
; %bb.1:                                ; %entry
	tbnz	x19, #63, LBB221_3
; %bb.2:
	mov	x23, x20
	b	LBB221_4
LBB221_3:                               ; %list.RocList.isUnique.exit.i.i
	cmp	x19, #0
	mov	x9, #-9223372036854775808
	csel	x23, x22, x20, lt
	ldur	x8, [x23, #-8]
	cmp	x8, x9
	b.ne	LBB221_9
LBB221_4:                               ; %list.RocList.isUnique.exit.thread.i.i
	cbz	x23, LBB221_9
; %bb.5:
	tbz	x19, #63, LBB221_7
; %bb.6:
	ldur	x21, [x22, #-16]
LBB221_7:                               ; %list.RocList.getAllocationElementCount.exit.i.i
	cbz	x21, LBB221_9
LBB221_8:                               ; %.lr.ph.i.i
                                        ; =>This Inner Loop Header: Depth=1
Ltmp234:
	ldp	x1, x2, [x23, #8]
	ldr	x0, [x23], #24
	bl	"l_#Attr_#dec_16"
Ltmp235:
	subs	x21, x21, #1
	b.ne	LBB221_8
LBB221_9:                               ; %.critedge.i.i
	cmp	x19, #0
	csel	x8, x22, x20, lt
	cbz	x19, LBB221_14
; %bb.10:                               ; %.critedge.i.i
	cbz	x8, LBB221_14
; %bb.11:
	ldr	x9, [x8, #-8]!
	cbz	x9, LBB221_14
; %bb.12:
	sub	x10, x9, #1
	mov	x11, #-9223372036854775808
	cmp	x9, x11
	str	x10, [x8]
	b.ne	LBB221_14
; %bb.13:
	sub	x0, x8, #8
	mov	w1, #8
	bl	_roc_dealloc
LBB221_14:                              ; %roc_builtins.list.decref.exit
	ldp	x29, x30, [sp, #80]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp, #64]             ; 16-byte Folded Reload
	ldp	x22, x21, [sp, #48]             ; 16-byte Folded Reload
	ldp	x24, x23, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #96
	ret
Ltmp236:
Lfunc_end221:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_16
"l_#Attr_#dec_16":                      ; @"#Attr_#dec_16"
Lfunc_begin222:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp237:
	str	x0, [sp, #8]
	add	x0, sp, #8
	stp	x1, x2, [sp, #16]
	bl	"l_#Attr_#dec_1"
	ldp	x29, x30, [sp, #32]             ; 16-byte Folded Reload
	add	sp, sp, #48
	ret
Ltmp238:
Lfunc_end222:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2_compare_wrapper
l_Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2_compare_wrapper: ; @Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2_compare_wrapper
Lfunc_begin223:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #32
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	mov	x2, x0
Ltmp239:
	mov	x0, sp
	add	x1, sp, #8
	bl	_Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #32
	ret
Ltmp240:
Lfunc_end223:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#generic_rc_by_ref_6_inc_n
"l_#Attr_#generic_rc_by_ref_6_inc_n":   ; @"#Attr_#generic_rc_by_ref_6_inc_n"
Lfunc_begin224:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x29, x30, [sp, #-16]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 16
	.cfi_offset w30, -8
	.cfi_offset w29, -16
Ltmp241:
	bl	"l_#Attr_#inc_17"
	ldp	x29, x30, [sp], #16             ; 16-byte Folded Reload
	ret
Ltmp242:
Lfunc_end224:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#inc_17
"l_#Attr_#inc_17":                      ; @"#Attr_#inc_17"
Lfunc_begin225:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x1
	mov	x20, x0
Ltmp243:
	ldp	x1, x2, [x0, #8]
	mov	x3, x19
	ldr	x0, [x0]
	bl	"l_#Attr_#inc_13"
	ldp	x1, x2, [x20, #32]
	mov	x3, x19
	ldr	x0, [x20, #24]
	bl	"l_#Attr_#inc_15"
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	ret
Ltmp244:
Lfunc_end225:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#inc_13
"l_#Attr_#inc_13":                      ; @"#Attr_#inc_13"
Lfunc_begin226:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #32
	.cfi_def_cfa_offset 32
Ltmp245:
	lsl	x8, x2, #1
	cmp	x2, #0
	csel	x8, x8, x0, lt
	stp	x1, x2, [sp, #16]
	str	x0, [sp, #8]
	cbz	x8, LBB226_3
; %bb.1:
	and	x8, x8, #0xfffffffffffffff8
	ldur	x9, [x8, #-8]
	cbz	x9, LBB226_3
; %bb.2:
	add	x9, x9, x3
	stur	x9, [x8, #-8]
LBB226_3:                               ; %roc_builtins.list.incref.exit
	add	sp, sp, #32
	ret
Ltmp246:
Lfunc_end226:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#inc_15
"l_#Attr_#inc_15":                      ; @"#Attr_#inc_15"
Lfunc_begin227:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #32
	.cfi_def_cfa_offset 32
Ltmp247:
	cmp	x2, #0
	and	x9, x1, x2, asr #63
	csel	x8, x2, xzr, gt
	stp	x1, x2, [sp, #16]
	orr	x9, x9, x8
	lsl	x8, x2, #1
	str	x0, [sp, #8]
	cbnz	x9, LBB227_2
; %bb.1:                                ; %entry
	tbz	x2, #63, LBB227_4
LBB227_2:                               ; %list.RocList.isUnique.exit.i.i
	cmp	x2, #0
	mov	x10, #-9223372036854775808
	csel	x9, x8, x0, lt
	ldur	x9, [x9, #-8]
	cmp	x9, x10
	b.ne	LBB227_6
; %bb.3:                                ; %list.RocList.isUnique.exit.i.i
	tbnz	x2, #63, LBB227_6
LBB227_4:                               ; %list.RocList.isUnique.exit.i.i
	cbz	x0, LBB227_6
; %bb.5:
	stur	x1, [x0, #-16]
LBB227_6:                               ; %.critedge.i.i
	cmp	x2, #0
	csel	x8, x8, x0, lt
	cbz	x8, LBB227_9
; %bb.7:
	and	x8, x8, #0xfffffffffffffff8
	ldur	x9, [x8, #-8]
	cbz	x9, LBB227_9
; %bb.8:
	add	x9, x9, x3
	stur	x9, [x8, #-8]
LBB227_9:                               ; %roc_builtins.list.incref.exit
	add	sp, sp, #32
	ret
Ltmp248:
Lfunc_end227:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#generic_copy_by_ref_1
"l_#Attr_#generic_copy_by_ref_1":       ; @"#Attr_#generic_copy_by_ref_1"
Lfunc_begin228:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	ret
Ltmp249:
Lfunc_end228:
	.cfi_endproc
                                        ; -- End function
	.p2align	2                               ; -- Begin function #Attr_#dec_17
"l_#Attr_#dec_17":                      ; @"#Attr_#dec_17"
Lfunc_begin229:
	.loc	1 0 0                           ; roc_app:0:0
	.cfi_startproc
; %bb.0:                                ; %entry
	stp	x20, x19, [sp, #-32]!           ; 16-byte Folded Spill
	.cfi_def_cfa_offset 32
	stp	x29, x30, [sp, #16]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
Ltmp250:
	ldp	x1, x2, [x0, #8]
	mov	x19, x0
	ldr	x0, [x0]
	bl	"l_#Attr_#dec_13"
	ldp	x1, x2, [x19, #32]
	ldr	x0, [x19, #24]
	bl	"l_#Attr_#dec_15"
	ldp	x29, x30, [sp, #16]             ; 16-byte Folded Reload
	ldp	x20, x19, [sp], #32             ; 16-byte Folded Reload
	ret
Ltmp251:
Lfunc_end229:
	.cfi_endproc
                                        ; -- End function
	.globl	_roc__mainForHost_0_caller      ; -- Begin function roc__mainForHost_0_caller
	.p2align	2
_roc__mainForHost_0_caller:             ; @roc__mainForHost_0_caller
Lfunc_begin230:
	.cfi_startproc
; %bb.0:                                ; %entry
	sub	sp, sp, #48
	.cfi_def_cfa_offset 48
	stp	x20, x19, [sp, #16]             ; 16-byte Folded Spill
	stp	x29, x30, [sp, #32]             ; 16-byte Folded Spill
	.cfi_offset w30, -8
	.cfi_offset w29, -16
	.cfi_offset w19, -24
	.cfi_offset w20, -32
	mov	x19, x2
	ldr	x0, [x1]
	ldp	x8, x2, [x1, #8]
	add	x3, sp, #8
	mov	x1, x8
	bl	__73_c919149ababf2a569c5e2b164c2465c785dc3bc7f566b8dcef7ec4ae86e8d57
	ldr	x8, [sp, #8]
	ldp	x29, x30, [sp, #32]             ; 16-byte Folded Reload
	str	x8, [x19]
	ldp	x20, x19, [sp, #16]             ; 16-byte Folded Reload
	add	sp, sp, #48
	ret
Lfunc_end230:
	.cfi_endproc
                                        ; -- End function
	.globl	_roc__mainForHost_0_result_size ; -- Begin function roc__mainForHost_0_result_size
	.p2align	2
_roc__mainForHost_0_result_size:        ; @roc__mainForHost_0_result_size
Lfunc_begin231:
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	w0, #8
	ret
Lfunc_end231:
	.cfi_endproc
                                        ; -- End function
	.globl	_roc__mainForHost_0_size        ; -- Begin function roc__mainForHost_0_size
	.p2align	2
_roc__mainForHost_0_size:               ; @roc__mainForHost_0_size
Lfunc_begin232:
	.cfi_startproc
; %bb.0:                                ; %entry
	mov	w0, #24
	ret
Lfunc_end232:
	.cfi_endproc
                                        ; -- End function
	.section	__TEXT,__literal4,4byte_literals
	.p2align	2, 0x0                          ; @0
l___unnamed_2:
	.short	0                               ; 0x0
	.byte	4                               ; 0x4
	.space	1

	.section	__TEXT,__literal16,16byte_literals
	.p2align	3, 0x0                          ; @1
l___unnamed_6:
	.space	8
	.short	21                              ; 0x15
	.space	6

	.section	__TEXT,__cstring,cstring_literals
_sort.fluxsort__anon_13352:             ; @sort.fluxsort__anon_13352
	.asciz	"Out of memory while trying to allocate for sorting"

	.section	__TEXT,__literal4,4byte_literals
	.p2align	2, 0x0                          ; @2
l___unnamed_5:
	.short	0                               ; 0x0
	.byte	1                               ; 0x1
	.space	1

	.p2align	2, 0x0                          ; @3
l___unnamed_4:
	.short	0                               ; 0x0
	.byte	2                               ; 0x2
	.space	1

	.p2align	2, 0x0                          ; @4
l___unnamed_3:
	.short	0                               ; 0x0
	.byte	3                               ; 0x3
	.space	1

	.section	__TEXT,__cstring,cstring_literals
_fmt.digits2__anon_14339:               ; @fmt.digits2__anon_14339
	.asciz	"00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899"

	.section	__TEXT,__const
	.p2align	3, 0x0                          ; @5
l___unnamed_7:
	.quad	0
	.quad	0                               ; 0x0
	.quad	-9223372036854775808            ; 0x8000000000000000

	.section	__DATA,__data
	.globl	__mh_execute_header             ; @_mh_execute_header
	.weak_definition	__mh_execute_header
	.p2align	2, 0x0
__mh_execute_header:
	.space	32

	.section	__TEXT,__const
	.p2align	3, 0x0                          ; @6
l___unnamed_1:
	.space	8
	.byte	0                               ; 0x0
	.space	7
	.space	8
	.byte	0                               ; 0x0
	.space	7
	.byte	2                               ; 0x2
	.byte	32                              ; 0x20
	.space	6

	.p2align	3, 0x0                          ; @_str_literal_3867905241449124926
l__str_literal_3867905241449124926:
	.ascii	"\000\000\000\000\000\000\000\000Program exited with error:\n    "

	.p2align	3, 0x0                          ; @_str_literal_3894810976106795109
l__str_literal_3894810976106795109:
	.ascii	"\000\000\000\000\000\000\000\000\n\nTip: If you do not want to exit on this error, use `Task.mapErr` to handle the error.\nDocs for `Task.mapErr`: <https://www.roc-lang.org/packages/basic-cli/Task#mapErr>"

	.section	__DWARF,__debug_abbrev,regular,debug
Lsection_abbrev:
	.byte	1                               ; Abbreviation Code
	.byte	17                              ; DW_TAG_compile_unit
	.byte	1                               ; DW_CHILDREN_yes
	.byte	37                              ; DW_AT_producer
	.byte	14                              ; DW_FORM_strp
	.byte	19                              ; DW_AT_language
	.byte	5                               ; DW_FORM_data2
	.byte	3                               ; DW_AT_name
	.byte	14                              ; DW_FORM_strp
	.byte	16                              ; DW_AT_stmt_list
	.byte	23                              ; DW_FORM_sec_offset
	.byte	27                              ; DW_AT_comp_dir
	.byte	14                              ; DW_FORM_strp
	.byte	17                              ; DW_AT_low_pc
	.byte	1                               ; DW_FORM_addr
	.byte	85                              ; DW_AT_ranges
	.byte	23                              ; DW_FORM_sec_offset
	.byte	0                               ; EOM(1)
	.byte	0                               ; EOM(2)
	.byte	2                               ; Abbreviation Code
	.byte	46                              ; DW_TAG_subprogram
	.byte	0                               ; DW_CHILDREN_no
	.byte	17                              ; DW_AT_low_pc
	.byte	1                               ; DW_FORM_addr
	.byte	18                              ; DW_AT_high_pc
	.byte	6                               ; DW_FORM_data4
	.ascii	"\347\177"                      ; DW_AT_APPLE_omit_frame_ptr
	.byte	25                              ; DW_FORM_flag_present
	.byte	64                              ; DW_AT_frame_base
	.byte	24                              ; DW_FORM_exprloc
	.byte	110                             ; DW_AT_linkage_name
	.byte	14                              ; DW_FORM_strp
	.byte	3                               ; DW_AT_name
	.byte	14                              ; DW_FORM_strp
	.byte	73                              ; DW_AT_type
	.byte	19                              ; DW_FORM_ref4
	.byte	50                              ; DW_AT_accessibility
	.byte	11                              ; DW_FORM_data1
	.byte	0                               ; EOM(1)
	.byte	0                               ; EOM(2)
	.byte	3                               ; Abbreviation Code
	.byte	46                              ; DW_TAG_subprogram
	.byte	0                               ; DW_CHILDREN_no
	.byte	110                             ; DW_AT_linkage_name
	.byte	14                              ; DW_FORM_strp
	.byte	3                               ; DW_AT_name
	.byte	14                              ; DW_FORM_strp
	.byte	73                              ; DW_AT_type
	.byte	19                              ; DW_FORM_ref4
	.byte	50                              ; DW_AT_accessibility
	.byte	11                              ; DW_FORM_data1
	.byte	32                              ; DW_AT_inline
	.byte	11                              ; DW_FORM_data1
	.byte	0                               ; EOM(1)
	.byte	0                               ; EOM(2)
	.byte	4                               ; Abbreviation Code
	.byte	36                              ; DW_TAG_base_type
	.byte	0                               ; DW_CHILDREN_no
	.byte	3                               ; DW_AT_name
	.byte	14                              ; DW_FORM_strp
	.byte	62                              ; DW_AT_encoding
	.byte	11                              ; DW_FORM_data1
	.byte	11                              ; DW_AT_byte_size
	.byte	11                              ; DW_FORM_data1
	.byte	0                               ; EOM(1)
	.byte	0                               ; EOM(2)
	.byte	5                               ; Abbreviation Code
	.byte	46                              ; DW_TAG_subprogram
	.byte	1                               ; DW_CHILDREN_yes
	.byte	17                              ; DW_AT_low_pc
	.byte	1                               ; DW_FORM_addr
	.byte	18                              ; DW_AT_high_pc
	.byte	6                               ; DW_FORM_data4
	.ascii	"\347\177"                      ; DW_AT_APPLE_omit_frame_ptr
	.byte	25                              ; DW_FORM_flag_present
	.byte	64                              ; DW_AT_frame_base
	.byte	24                              ; DW_FORM_exprloc
	.byte	110                             ; DW_AT_linkage_name
	.byte	14                              ; DW_FORM_strp
	.byte	3                               ; DW_AT_name
	.byte	14                              ; DW_FORM_strp
	.byte	73                              ; DW_AT_type
	.byte	19                              ; DW_FORM_ref4
	.byte	50                              ; DW_AT_accessibility
	.byte	11                              ; DW_FORM_data1
	.byte	0                               ; EOM(1)
	.byte	0                               ; EOM(2)
	.byte	6                               ; Abbreviation Code
	.byte	29                              ; DW_TAG_inlined_subroutine
	.byte	0                               ; DW_CHILDREN_no
	.byte	49                              ; DW_AT_abstract_origin
	.byte	19                              ; DW_FORM_ref4
	.byte	17                              ; DW_AT_low_pc
	.byte	1                               ; DW_FORM_addr
	.byte	18                              ; DW_AT_high_pc
	.byte	6                               ; DW_FORM_data4
	.byte	88                              ; DW_AT_call_file
	.byte	11                              ; DW_FORM_data1
	.byte	89                              ; DW_AT_call_line
	.byte	11                              ; DW_FORM_data1
	.byte	0                               ; EOM(1)
	.byte	0                               ; EOM(2)
	.byte	0                               ; EOM(3)
	.section	__DWARF,__debug_info,regular,debug
Lsection_info:
Lcu_begin0:
.set Lset0, Ldebug_info_end0-Ldebug_info_start0 ; Length of Unit
	.long	Lset0
Ldebug_info_start0:
	.short	4                               ; DWARF version number
.set Lset1, Lsection_abbrev-Lsection_abbrev ; Offset Into Abbrev. Section
	.long	Lset1
	.byte	8                               ; Address Size (in bytes)
	.byte	1                               ; Abbrev [1] 0xb:0xe74 DW_TAG_compile_unit
	.long	0                               ; DW_AT_producer
	.short	2                               ; DW_AT_language
	.long	26                              ; DW_AT_name
.set Lset2, Lline_table_start0-Lsection_line ; DW_AT_stmt_list
	.long	Lset2
	.long	34                              ; DW_AT_comp_dir
	.quad	0                               ; DW_AT_low_pc
.set Lset3, Ldebug_ranges0-Ldebug_range ; DW_AT_ranges
	.long	Lset3
	.byte	2                               ; Abbrev [2] 0x2a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin101                  ; DW_AT_low_pc
.set Lset4, Lfunc_end101-Lfunc_begin101 ; DW_AT_high_pc
	.long	Lset4
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	36                              ; DW_AT_linkage_name
	.long	36                              ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x46:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin102                  ; DW_AT_low_pc
.set Lset5, Lfunc_end102-Lfunc_begin102 ; DW_AT_high_pc
	.long	Lset5
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	115                             ; DW_AT_linkage_name
	.long	115                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x62:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin103                  ; DW_AT_low_pc
.set Lset6, Lfunc_end103-Lfunc_begin103 ; DW_AT_high_pc
	.long	Lset6
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	191                             ; DW_AT_linkage_name
	.long	191                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x7e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin104                  ; DW_AT_low_pc
.set Lset7, Lfunc_end104-Lfunc_begin104 ; DW_AT_high_pc
	.long	Lset7
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	268                             ; DW_AT_linkage_name
	.long	268                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x9a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin105                  ; DW_AT_low_pc
.set Lset8, Lfunc_end105-Lfunc_begin105 ; DW_AT_high_pc
	.long	Lset8
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	347                             ; DW_AT_linkage_name
	.long	347                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xb6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin106                  ; DW_AT_low_pc
.set Lset9, Lfunc_end106-Lfunc_begin106 ; DW_AT_high_pc
	.long	Lset9
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	422                             ; DW_AT_linkage_name
	.long	422                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xd2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin107                  ; DW_AT_low_pc
.set Lset10, Lfunc_end107-Lfunc_begin107 ; DW_AT_high_pc
	.long	Lset10
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	495                             ; DW_AT_linkage_name
	.long	495                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xee:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin108                  ; DW_AT_low_pc
.set Lset11, Lfunc_end108-Lfunc_begin108 ; DW_AT_high_pc
	.long	Lset11
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	571                             ; DW_AT_linkage_name
	.long	571                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x10a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin109                  ; DW_AT_low_pc
.set Lset12, Lfunc_end109-Lfunc_begin109 ; DW_AT_high_pc
	.long	Lset12
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	646                             ; DW_AT_linkage_name
	.long	646                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x126:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin110                  ; DW_AT_low_pc
.set Lset13, Lfunc_end110-Lfunc_begin110 ; DW_AT_high_pc
	.long	Lset13
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	724                             ; DW_AT_linkage_name
	.long	724                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x142:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin111                  ; DW_AT_low_pc
.set Lset14, Lfunc_end111-Lfunc_begin111 ; DW_AT_high_pc
	.long	Lset14
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	827                             ; DW_AT_linkage_name
	.long	827                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x15e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin112                  ; DW_AT_low_pc
.set Lset15, Lfunc_end112-Lfunc_begin112 ; DW_AT_high_pc
	.long	Lset15
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	895                             ; DW_AT_linkage_name
	.long	895                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x17a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin113                  ; DW_AT_low_pc
.set Lset16, Lfunc_end113-Lfunc_begin113 ; DW_AT_high_pc
	.long	Lset16
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	973                             ; DW_AT_linkage_name
	.long	973                             ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x196:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin114                  ; DW_AT_low_pc
.set Lset17, Lfunc_end114-Lfunc_begin114 ; DW_AT_high_pc
	.long	Lset17
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1052                            ; DW_AT_linkage_name
	.long	1052                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x1b2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin115                  ; DW_AT_low_pc
.set Lset18, Lfunc_end115-Lfunc_begin115 ; DW_AT_high_pc
	.long	Lset18
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1133                            ; DW_AT_linkage_name
	.long	1133                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x1ce:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin116                  ; DW_AT_low_pc
.set Lset19, Lfunc_end116-Lfunc_begin116 ; DW_AT_high_pc
	.long	Lset19
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1209                            ; DW_AT_linkage_name
	.long	1209                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x1ea:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin117                  ; DW_AT_low_pc
.set Lset20, Lfunc_end117-Lfunc_begin117 ; DW_AT_high_pc
	.long	Lset20
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1283                            ; DW_AT_linkage_name
	.long	1283                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x206:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin118                  ; DW_AT_low_pc
.set Lset21, Lfunc_end118-Lfunc_begin118 ; DW_AT_high_pc
	.long	Lset21
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1354                            ; DW_AT_linkage_name
	.long	1354                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x222:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin119                  ; DW_AT_low_pc
.set Lset22, Lfunc_end119-Lfunc_begin119 ; DW_AT_high_pc
	.long	Lset22
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1419                            ; DW_AT_linkage_name
	.long	1419                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x23e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin120                  ; DW_AT_low_pc
.set Lset23, Lfunc_end120-Lfunc_begin120 ; DW_AT_high_pc
	.long	Lset23
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1496                            ; DW_AT_linkage_name
	.long	1496                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x25a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin121                  ; DW_AT_low_pc
.set Lset24, Lfunc_end121-Lfunc_begin121 ; DW_AT_high_pc
	.long	Lset24
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1566                            ; DW_AT_linkage_name
	.long	1566                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x276:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin122                  ; DW_AT_low_pc
.set Lset25, Lfunc_end122-Lfunc_begin122 ; DW_AT_high_pc
	.long	Lset25
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1646                            ; DW_AT_linkage_name
	.long	1646                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x292:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin123                  ; DW_AT_low_pc
.set Lset26, Lfunc_end123-Lfunc_begin123 ; DW_AT_high_pc
	.long	Lset26
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1723                            ; DW_AT_linkage_name
	.long	1723                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x2ae:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin124                  ; DW_AT_low_pc
.set Lset27, Lfunc_end124-Lfunc_begin124 ; DW_AT_high_pc
	.long	Lset27
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1799                            ; DW_AT_linkage_name
	.long	1799                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x2ca:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin125                  ; DW_AT_low_pc
.set Lset28, Lfunc_end125-Lfunc_begin125 ; DW_AT_high_pc
	.long	Lset28
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1870                            ; DW_AT_linkage_name
	.long	1870                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x2e6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin126                  ; DW_AT_low_pc
.set Lset29, Lfunc_end126-Lfunc_begin126 ; DW_AT_high_pc
	.long	Lset29
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	1950                            ; DW_AT_linkage_name
	.long	1950                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x302:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin127                  ; DW_AT_low_pc
.set Lset30, Lfunc_end127-Lfunc_begin127 ; DW_AT_high_pc
	.long	Lset30
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2021                            ; DW_AT_linkage_name
	.long	2021                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x31e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin128                  ; DW_AT_low_pc
.set Lset31, Lfunc_end128-Lfunc_begin128 ; DW_AT_high_pc
	.long	Lset31
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2094                            ; DW_AT_linkage_name
	.long	2094                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x33a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin129                  ; DW_AT_low_pc
.set Lset32, Lfunc_end129-Lfunc_begin129 ; DW_AT_high_pc
	.long	Lset32
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2182                            ; DW_AT_linkage_name
	.long	2182                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x356:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin130                  ; DW_AT_low_pc
.set Lset33, Lfunc_end130-Lfunc_begin130 ; DW_AT_high_pc
	.long	Lset33
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2248                            ; DW_AT_linkage_name
	.long	2248                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x372:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin131                  ; DW_AT_low_pc
.set Lset34, Lfunc_end131-Lfunc_begin131 ; DW_AT_high_pc
	.long	Lset34
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2321                            ; DW_AT_linkage_name
	.long	2321                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x38e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin132                  ; DW_AT_low_pc
.set Lset35, Lfunc_end132-Lfunc_begin132 ; DW_AT_high_pc
	.long	Lset35
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2424                            ; DW_AT_linkage_name
	.long	2424                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x3aa:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin133                  ; DW_AT_low_pc
.set Lset36, Lfunc_end133-Lfunc_begin133 ; DW_AT_high_pc
	.long	Lset36
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2501                            ; DW_AT_linkage_name
	.long	2501                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x3c6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin134                  ; DW_AT_low_pc
.set Lset37, Lfunc_end134-Lfunc_begin134 ; DW_AT_high_pc
	.long	Lset37
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2576                            ; DW_AT_linkage_name
	.long	2576                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x3e2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin135                  ; DW_AT_low_pc
.set Lset38, Lfunc_end135-Lfunc_begin135 ; DW_AT_high_pc
	.long	Lset38
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2651                            ; DW_AT_linkage_name
	.long	2651                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x3fe:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin136                  ; DW_AT_low_pc
.set Lset39, Lfunc_end136-Lfunc_begin136 ; DW_AT_high_pc
	.long	Lset39
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2727                            ; DW_AT_linkage_name
	.long	2727                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x41a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin137                  ; DW_AT_low_pc
.set Lset40, Lfunc_end137-Lfunc_begin137 ; DW_AT_high_pc
	.long	Lset40
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2803                            ; DW_AT_linkage_name
	.long	2803                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x436:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin138                  ; DW_AT_low_pc
.set Lset41, Lfunc_end138-Lfunc_begin138 ; DW_AT_high_pc
	.long	Lset41
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2883                            ; DW_AT_linkage_name
	.long	2883                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x452:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin139                  ; DW_AT_low_pc
.set Lset42, Lfunc_end139-Lfunc_begin139 ; DW_AT_high_pc
	.long	Lset42
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	2958                            ; DW_AT_linkage_name
	.long	2958                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x46e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin140                  ; DW_AT_low_pc
.set Lset43, Lfunc_end140-Lfunc_begin140 ; DW_AT_high_pc
	.long	Lset43
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3027                            ; DW_AT_linkage_name
	.long	3027                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x48a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin141                  ; DW_AT_low_pc
.set Lset44, Lfunc_end141-Lfunc_begin141 ; DW_AT_high_pc
	.long	Lset44
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3095                            ; DW_AT_linkage_name
	.long	3095                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x4a6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin142                  ; DW_AT_low_pc
.set Lset45, Lfunc_end142-Lfunc_begin142 ; DW_AT_high_pc
	.long	Lset45
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3170                            ; DW_AT_linkage_name
	.long	3170                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x4c2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin143                  ; DW_AT_low_pc
.set Lset46, Lfunc_end143-Lfunc_begin143 ; DW_AT_high_pc
	.long	Lset46
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3245                            ; DW_AT_linkage_name
	.long	3245                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x4de:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin144                  ; DW_AT_low_pc
.set Lset47, Lfunc_end144-Lfunc_begin144 ; DW_AT_high_pc
	.long	Lset47
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3316                            ; DW_AT_linkage_name
	.long	3316                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x4fa:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin145                  ; DW_AT_low_pc
.set Lset48, Lfunc_end145-Lfunc_begin145 ; DW_AT_high_pc
	.long	Lset48
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3392                            ; DW_AT_linkage_name
	.long	3392                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x516:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin146                  ; DW_AT_low_pc
.set Lset49, Lfunc_end146-Lfunc_begin146 ; DW_AT_high_pc
	.long	Lset49
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3468                            ; DW_AT_linkage_name
	.long	3468                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x532:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin147                  ; DW_AT_low_pc
.set Lset50, Lfunc_end147-Lfunc_begin147 ; DW_AT_high_pc
	.long	Lset50
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3542                            ; DW_AT_linkage_name
	.long	3542                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x54e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin148                  ; DW_AT_low_pc
.set Lset51, Lfunc_end148-Lfunc_begin148 ; DW_AT_high_pc
	.long	Lset51
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3577                            ; DW_AT_linkage_name
	.long	3577                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x56a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin149                  ; DW_AT_low_pc
.set Lset52, Lfunc_end149-Lfunc_begin149 ; DW_AT_high_pc
	.long	Lset52
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3604                            ; DW_AT_linkage_name
	.long	3604                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x586:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin150                  ; DW_AT_low_pc
.set Lset53, Lfunc_end150-Lfunc_begin150 ; DW_AT_high_pc
	.long	Lset53
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3636                            ; DW_AT_linkage_name
	.long	3636                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x5a2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin151                  ; DW_AT_low_pc
.set Lset54, Lfunc_end151-Lfunc_begin151 ; DW_AT_high_pc
	.long	Lset54
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3709                            ; DW_AT_linkage_name
	.long	3709                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x5be:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin152                  ; DW_AT_low_pc
.set Lset55, Lfunc_end152-Lfunc_begin152 ; DW_AT_high_pc
	.long	Lset55
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3798                            ; DW_AT_linkage_name
	.long	3798                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x5da:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin153                  ; DW_AT_low_pc
.set Lset56, Lfunc_end153-Lfunc_begin153 ; DW_AT_high_pc
	.long	Lset56
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3868                            ; DW_AT_linkage_name
	.long	3868                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x5f6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin154                  ; DW_AT_low_pc
.set Lset57, Lfunc_end154-Lfunc_begin154 ; DW_AT_high_pc
	.long	Lset57
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	3945                            ; DW_AT_linkage_name
	.long	3945                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x612:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin155                  ; DW_AT_low_pc
.set Lset58, Lfunc_end155-Lfunc_begin155 ; DW_AT_high_pc
	.long	Lset58
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4021                            ; DW_AT_linkage_name
	.long	4021                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x62e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin156                  ; DW_AT_low_pc
.set Lset59, Lfunc_end156-Lfunc_begin156 ; DW_AT_high_pc
	.long	Lset59
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4093                            ; DW_AT_linkage_name
	.long	4093                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x64a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin157                  ; DW_AT_low_pc
.set Lset60, Lfunc_end157-Lfunc_begin157 ; DW_AT_high_pc
	.long	Lset60
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4162                            ; DW_AT_linkage_name
	.long	4162                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x666:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin158                  ; DW_AT_low_pc
.set Lset61, Lfunc_end158-Lfunc_begin158 ; DW_AT_high_pc
	.long	Lset61
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4236                            ; DW_AT_linkage_name
	.long	4236                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x682:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin159                  ; DW_AT_low_pc
.set Lset62, Lfunc_end159-Lfunc_begin159 ; DW_AT_high_pc
	.long	Lset62
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4311                            ; DW_AT_linkage_name
	.long	4311                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x69e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin160                  ; DW_AT_low_pc
.set Lset63, Lfunc_end160-Lfunc_begin160 ; DW_AT_high_pc
	.long	Lset63
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4402                            ; DW_AT_linkage_name
	.long	4402                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x6ba:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin161                  ; DW_AT_low_pc
.set Lset64, Lfunc_end161-Lfunc_begin161 ; DW_AT_high_pc
	.long	Lset64
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4471                            ; DW_AT_linkage_name
	.long	4471                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x6d6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin162                  ; DW_AT_low_pc
.set Lset65, Lfunc_end162-Lfunc_begin162 ; DW_AT_high_pc
	.long	Lset65
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4551                            ; DW_AT_linkage_name
	.long	4551                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x6f2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin163                  ; DW_AT_low_pc
.set Lset66, Lfunc_end163-Lfunc_begin163 ; DW_AT_high_pc
	.long	Lset66
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4623                            ; DW_AT_linkage_name
	.long	4623                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x70e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin164                  ; DW_AT_low_pc
.set Lset67, Lfunc_end164-Lfunc_begin164 ; DW_AT_high_pc
	.long	Lset67
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4699                            ; DW_AT_linkage_name
	.long	4699                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x72a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin165                  ; DW_AT_low_pc
.set Lset68, Lfunc_end165-Lfunc_begin165 ; DW_AT_high_pc
	.long	Lset68
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4774                            ; DW_AT_linkage_name
	.long	4774                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x746:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin166                  ; DW_AT_low_pc
.set Lset69, Lfunc_end166-Lfunc_begin166 ; DW_AT_high_pc
	.long	Lset69
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4852                            ; DW_AT_linkage_name
	.long	4852                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x762:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin167                  ; DW_AT_low_pc
.set Lset70, Lfunc_end167-Lfunc_begin167 ; DW_AT_high_pc
	.long	Lset70
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	4927                            ; DW_AT_linkage_name
	.long	4927                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x77e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin168                  ; DW_AT_low_pc
.set Lset71, Lfunc_end168-Lfunc_begin168 ; DW_AT_high_pc
	.long	Lset71
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5005                            ; DW_AT_linkage_name
	.long	5005                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x79a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin169                  ; DW_AT_low_pc
.set Lset72, Lfunc_end169-Lfunc_begin169 ; DW_AT_high_pc
	.long	Lset72
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5083                            ; DW_AT_linkage_name
	.long	5083                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x7b6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin170                  ; DW_AT_low_pc
.set Lset73, Lfunc_end170-Lfunc_begin170 ; DW_AT_high_pc
	.long	Lset73
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5162                            ; DW_AT_linkage_name
	.long	5162                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x7d2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin171                  ; DW_AT_low_pc
.set Lset74, Lfunc_end171-Lfunc_begin171 ; DW_AT_high_pc
	.long	Lset74
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5237                            ; DW_AT_linkage_name
	.long	5237                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x7ee:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin172                  ; DW_AT_low_pc
.set Lset75, Lfunc_end172-Lfunc_begin172 ; DW_AT_high_pc
	.long	Lset75
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5412                            ; DW_AT_linkage_name
	.long	5412                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x80a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin173                  ; DW_AT_low_pc
.set Lset76, Lfunc_end173-Lfunc_begin173 ; DW_AT_high_pc
	.long	Lset76
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5491                            ; DW_AT_linkage_name
	.long	5491                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x826:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin174                  ; DW_AT_low_pc
.set Lset77, Lfunc_end174-Lfunc_begin174 ; DW_AT_high_pc
	.long	Lset77
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5567                            ; DW_AT_linkage_name
	.long	5567                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x842:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin175                  ; DW_AT_low_pc
.set Lset78, Lfunc_end175-Lfunc_begin175 ; DW_AT_high_pc
	.long	Lset78
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5640                            ; DW_AT_linkage_name
	.long	5640                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x85e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin176                  ; DW_AT_low_pc
.set Lset79, Lfunc_end176-Lfunc_begin176 ; DW_AT_high_pc
	.long	Lset79
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5730                            ; DW_AT_linkage_name
	.long	5730                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x87a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin177                  ; DW_AT_low_pc
.set Lset80, Lfunc_end177-Lfunc_begin177 ; DW_AT_high_pc
	.long	Lset80
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5796                            ; DW_AT_linkage_name
	.long	5796                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x896:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin178                  ; DW_AT_low_pc
.set Lset81, Lfunc_end178-Lfunc_begin178 ; DW_AT_high_pc
	.long	Lset81
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5875                            ; DW_AT_linkage_name
	.long	5875                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x8b2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin179                  ; DW_AT_low_pc
.set Lset82, Lfunc_end179-Lfunc_begin179 ; DW_AT_high_pc
	.long	Lset82
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	5954                            ; DW_AT_linkage_name
	.long	5954                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x8ce:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin180                  ; DW_AT_low_pc
.set Lset83, Lfunc_end180-Lfunc_begin180 ; DW_AT_high_pc
	.long	Lset83
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6031                            ; DW_AT_linkage_name
	.long	6031                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x8ea:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin181                  ; DW_AT_low_pc
.set Lset84, Lfunc_end181-Lfunc_begin181 ; DW_AT_high_pc
	.long	Lset84
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6107                            ; DW_AT_linkage_name
	.long	6107                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x906:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin182                  ; DW_AT_low_pc
.set Lset85, Lfunc_end182-Lfunc_begin182 ; DW_AT_high_pc
	.long	Lset85
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6179                            ; DW_AT_linkage_name
	.long	6179                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x922:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin183                  ; DW_AT_low_pc
.set Lset86, Lfunc_end183-Lfunc_begin183 ; DW_AT_high_pc
	.long	Lset86
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6254                            ; DW_AT_linkage_name
	.long	6254                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x93e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin184                  ; DW_AT_low_pc
.set Lset87, Lfunc_end184-Lfunc_begin184 ; DW_AT_high_pc
	.long	Lset87
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6320                            ; DW_AT_linkage_name
	.long	6320                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x95a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin185                  ; DW_AT_low_pc
.set Lset88, Lfunc_end185-Lfunc_begin185 ; DW_AT_high_pc
	.long	Lset88
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6392                            ; DW_AT_linkage_name
	.long	6392                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x976:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin186                  ; DW_AT_low_pc
.set Lset89, Lfunc_end186-Lfunc_begin186 ; DW_AT_high_pc
	.long	Lset89
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6465                            ; DW_AT_linkage_name
	.long	6465                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x992:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin187                  ; DW_AT_low_pc
.set Lset90, Lfunc_end187-Lfunc_begin187 ; DW_AT_high_pc
	.long	Lset90
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6540                            ; DW_AT_linkage_name
	.long	6540                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x9ae:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin188                  ; DW_AT_low_pc
.set Lset91, Lfunc_end188-Lfunc_begin188 ; DW_AT_high_pc
	.long	Lset91
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6618                            ; DW_AT_linkage_name
	.long	6618                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x9ca:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin189                  ; DW_AT_low_pc
.set Lset92, Lfunc_end189-Lfunc_begin189 ; DW_AT_high_pc
	.long	Lset92
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6694                            ; DW_AT_linkage_name
	.long	6694                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0x9e6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin190                  ; DW_AT_low_pc
.set Lset93, Lfunc_end190-Lfunc_begin190 ; DW_AT_high_pc
	.long	Lset93
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6768                            ; DW_AT_linkage_name
	.long	6768                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xa02:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin191                  ; DW_AT_low_pc
.set Lset94, Lfunc_end191-Lfunc_begin191 ; DW_AT_high_pc
	.long	Lset94
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6838                            ; DW_AT_linkage_name
	.long	6838                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xa1e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin192                  ; DW_AT_low_pc
.set Lset95, Lfunc_end192-Lfunc_begin192 ; DW_AT_high_pc
	.long	Lset95
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6917                            ; DW_AT_linkage_name
	.long	6917                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xa3a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin193                  ; DW_AT_low_pc
.set Lset96, Lfunc_end193-Lfunc_begin193 ; DW_AT_high_pc
	.long	Lset96
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	6988                            ; DW_AT_linkage_name
	.long	6988                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xa56:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin194                  ; DW_AT_low_pc
.set Lset97, Lfunc_end194-Lfunc_begin194 ; DW_AT_high_pc
	.long	Lset97
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7057                            ; DW_AT_linkage_name
	.long	7057                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xa72:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin195                  ; DW_AT_low_pc
.set Lset98, Lfunc_end195-Lfunc_begin195 ; DW_AT_high_pc
	.long	Lset98
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7134                            ; DW_AT_linkage_name
	.long	7134                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xa8e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin196                  ; DW_AT_low_pc
.set Lset99, Lfunc_end196-Lfunc_begin196 ; DW_AT_high_pc
	.long	Lset99
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7204                            ; DW_AT_linkage_name
	.long	7204                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xaaa:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin197                  ; DW_AT_low_pc
.set Lset100, Lfunc_end197-Lfunc_begin197 ; DW_AT_high_pc
	.long	Lset100
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7274                            ; DW_AT_linkage_name
	.long	7274                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xac6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin198                  ; DW_AT_low_pc
.set Lset101, Lfunc_end198-Lfunc_begin198 ; DW_AT_high_pc
	.long	Lset101
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7350                            ; DW_AT_linkage_name
	.long	7350                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xae2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin199                  ; DW_AT_low_pc
.set Lset102, Lfunc_end199-Lfunc_begin199 ; DW_AT_high_pc
	.long	Lset102
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7427                            ; DW_AT_linkage_name
	.long	7427                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xafe:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin200                  ; DW_AT_low_pc
.set Lset103, Lfunc_end200-Lfunc_begin200 ; DW_AT_high_pc
	.long	Lset103
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7502                            ; DW_AT_linkage_name
	.long	7502                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xb1a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin201                  ; DW_AT_low_pc
.set Lset104, Lfunc_end201-Lfunc_begin201 ; DW_AT_high_pc
	.long	Lset104
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7579                            ; DW_AT_linkage_name
	.long	7579                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xb36:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin202                  ; DW_AT_low_pc
.set Lset105, Lfunc_end202-Lfunc_begin202 ; DW_AT_high_pc
	.long	Lset105
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7685                            ; DW_AT_linkage_name
	.long	7685                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xb52:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin203                  ; DW_AT_low_pc
.set Lset106, Lfunc_end203-Lfunc_begin203 ; DW_AT_high_pc
	.long	Lset106
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7766                            ; DW_AT_linkage_name
	.long	7766                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xb6e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin204                  ; DW_AT_low_pc
.set Lset107, Lfunc_end204-Lfunc_begin204 ; DW_AT_high_pc
	.long	Lset107
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7779                            ; DW_AT_linkage_name
	.long	7779                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	3                               ; Abbrev [3] 0xb8a:0xf DW_TAG_subprogram
	.long	7806                            ; DW_AT_linkage_name
	.long	7806                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	1                               ; DW_AT_inline
	.byte	4                               ; Abbrev [4] 0xb99:0x7 DW_TAG_base_type
	.long	7837                            ; DW_AT_name
	.byte	0                               ; DW_AT_encoding
	.byte	0                               ; DW_AT_byte_size
	.byte	5                               ; Abbrev [5] 0xba0:0x30 DW_TAG_subprogram
	.quad	Lfunc_begin205                  ; DW_AT_low_pc
.set Lset108, Lfunc_end205-Lfunc_begin205 ; DW_AT_high_pc
	.long	Lset108
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7847                            ; DW_AT_linkage_name
	.long	7847                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	6                               ; Abbrev [6] 0xbbc:0x13 DW_TAG_inlined_subroutine
	.long	2954                            ; DW_AT_abstract_origin
	.quad	Ltmp203                         ; DW_AT_low_pc
.set Lset109, Ltmp204-Ltmp203           ; DW_AT_high_pc
	.long	Lset109
	.byte	1                               ; DW_AT_call_file
	.byte	0                               ; DW_AT_call_line
	.byte	0                               ; End Of Children Mark
	.byte	2                               ; Abbrev [2] 0xbd0:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin206                  ; DW_AT_low_pc
.set Lset110, Lfunc_end206-Lfunc_begin206 ; DW_AT_high_pc
	.long	Lset110
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7860                            ; DW_AT_linkage_name
	.long	7860                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xbec:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin207                  ; DW_AT_low_pc
.set Lset111, Lfunc_end207-Lfunc_begin207 ; DW_AT_high_pc
	.long	Lset111
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7873                            ; DW_AT_linkage_name
	.long	7873                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xc08:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin208                  ; DW_AT_low_pc
.set Lset112, Lfunc_end208-Lfunc_begin208 ; DW_AT_high_pc
	.long	Lset112
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7886                            ; DW_AT_linkage_name
	.long	7886                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	3                               ; Abbrev [3] 0xc24:0xf DW_TAG_subprogram
	.long	7899                            ; DW_AT_linkage_name
	.long	7899                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	1                               ; DW_AT_inline
	.byte	5                               ; Abbrev [5] 0xc33:0x30 DW_TAG_subprogram
	.quad	Lfunc_begin210                  ; DW_AT_low_pc
.set Lset113, Lfunc_end210-Lfunc_begin210 ; DW_AT_high_pc
	.long	Lset113
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7930                            ; DW_AT_linkage_name
	.long	7930                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	6                               ; Abbrev [6] 0xc4f:0x13 DW_TAG_inlined_subroutine
	.long	3108                            ; DW_AT_abstract_origin
	.quad	Ltmp213                         ; DW_AT_low_pc
.set Lset114, Ltmp214-Ltmp213           ; DW_AT_high_pc
	.long	Lset114
	.byte	1                               ; DW_AT_call_file
	.byte	0                               ; DW_AT_call_line
	.byte	0                               ; End Of Children Mark
	.byte	2                               ; Abbrev [2] 0xc63:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin211                  ; DW_AT_low_pc
.set Lset115, Lfunc_end211-Lfunc_begin211 ; DW_AT_high_pc
	.long	Lset115
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7943                            ; DW_AT_linkage_name
	.long	7943                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xc7f:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin213                  ; DW_AT_low_pc
.set Lset116, Lfunc_end213-Lfunc_begin213 ; DW_AT_high_pc
	.long	Lset116
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7956                            ; DW_AT_linkage_name
	.long	7956                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xc9b:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin214                  ; DW_AT_low_pc
.set Lset117, Lfunc_end214-Lfunc_begin214 ; DW_AT_high_pc
	.long	Lset117
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7969                            ; DW_AT_linkage_name
	.long	7969                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xcb7:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin215                  ; DW_AT_low_pc
.set Lset118, Lfunc_end215-Lfunc_begin215 ; DW_AT_high_pc
	.long	Lset118
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7982                            ; DW_AT_linkage_name
	.long	7982                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xcd3:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin216                  ; DW_AT_low_pc
.set Lset119, Lfunc_end216-Lfunc_begin216 ; DW_AT_high_pc
	.long	Lset119
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	7995                            ; DW_AT_linkage_name
	.long	7995                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xcef:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin217                  ; DW_AT_low_pc
.set Lset120, Lfunc_end217-Lfunc_begin217 ; DW_AT_high_pc
	.long	Lset120
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8009                            ; DW_AT_linkage_name
	.long	8009                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xd0b:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin218                  ; DW_AT_low_pc
.set Lset121, Lfunc_end218-Lfunc_begin218 ; DW_AT_high_pc
	.long	Lset121
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8023                            ; DW_AT_linkage_name
	.long	8023                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xd27:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin219                  ; DW_AT_low_pc
.set Lset122, Lfunc_end219-Lfunc_begin219 ; DW_AT_high_pc
	.long	Lset122
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8037                            ; DW_AT_linkage_name
	.long	8037                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xd43:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin220                  ; DW_AT_low_pc
.set Lset123, Lfunc_end220-Lfunc_begin220 ; DW_AT_high_pc
	.long	Lset123
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8051                            ; DW_AT_linkage_name
	.long	8051                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	3                               ; Abbrev [3] 0xd5f:0xf DW_TAG_subprogram
	.long	8065                            ; DW_AT_linkage_name
	.long	8065                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	1                               ; DW_AT_inline
	.byte	5                               ; Abbrev [5] 0xd6e:0x30 DW_TAG_subprogram
	.quad	Lfunc_begin221                  ; DW_AT_low_pc
.set Lset124, Lfunc_end221-Lfunc_begin221 ; DW_AT_high_pc
	.long	Lset124
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8096                            ; DW_AT_linkage_name
	.long	8096                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	6                               ; Abbrev [6] 0xd8a:0x13 DW_TAG_inlined_subroutine
	.long	3423                            ; DW_AT_abstract_origin
	.quad	Ltmp234                         ; DW_AT_low_pc
.set Lset125, Ltmp235-Ltmp234           ; DW_AT_high_pc
	.long	Lset125
	.byte	1                               ; DW_AT_call_file
	.byte	0                               ; DW_AT_call_line
	.byte	0                               ; End Of Children Mark
	.byte	2                               ; Abbrev [2] 0xd9e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin222                  ; DW_AT_low_pc
.set Lset126, Lfunc_end222-Lfunc_begin222 ; DW_AT_high_pc
	.long	Lset126
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8110                            ; DW_AT_linkage_name
	.long	8110                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xdba:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin223                  ; DW_AT_low_pc
.set Lset127, Lfunc_end223-Lfunc_begin223 ; DW_AT_high_pc
	.long	Lset127
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8124                            ; DW_AT_linkage_name
	.long	8124                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xdd6:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin224                  ; DW_AT_low_pc
.set Lset128, Lfunc_end224-Lfunc_begin224 ; DW_AT_high_pc
	.long	Lset128
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8217                            ; DW_AT_linkage_name
	.long	8217                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xdf2:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin225                  ; DW_AT_low_pc
.set Lset129, Lfunc_end225-Lfunc_begin225 ; DW_AT_high_pc
	.long	Lset129
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8250                            ; DW_AT_linkage_name
	.long	8250                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xe0e:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin226                  ; DW_AT_low_pc
.set Lset130, Lfunc_end226-Lfunc_begin226 ; DW_AT_high_pc
	.long	Lset130
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8264                            ; DW_AT_linkage_name
	.long	8264                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xe2a:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin227                  ; DW_AT_low_pc
.set Lset131, Lfunc_end227-Lfunc_begin227 ; DW_AT_high_pc
	.long	Lset131
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8278                            ; DW_AT_linkage_name
	.long	8278                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xe46:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin228                  ; DW_AT_low_pc
.set Lset132, Lfunc_end228-Lfunc_begin228 ; DW_AT_high_pc
	.long	Lset132
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8292                            ; DW_AT_linkage_name
	.long	8292                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	2                               ; Abbrev [2] 0xe62:0x1c DW_TAG_subprogram
	.quad	Lfunc_begin229                  ; DW_AT_low_pc
.set Lset133, Lfunc_end229-Lfunc_begin229 ; DW_AT_high_pc
	.long	Lset133
                                        ; DW_AT_APPLE_omit_frame_ptr
	.byte	1                               ; DW_AT_frame_base
	.byte	111
	.long	8321                            ; DW_AT_linkage_name
	.long	8321                            ; DW_AT_name
	.long	2969                            ; DW_AT_type
	.byte	1                               ; DW_AT_accessibility
                                        ; DW_ACCESS_public
	.byte	0                               ; End Of Children Mark
Ldebug_info_end0:
	.section	__DWARF,__debug_ranges,regular,debug
Ldebug_range:
Ldebug_ranges0:
	.quad	Lfunc_begin101
	.quad	Lfunc_end208
	.quad	Lfunc_begin210
	.quad	Lfunc_end211
	.quad	Lfunc_begin213
	.quad	Lfunc_end229
	.quad	0
	.quad	0
	.section	__DWARF,__debug_str,regular,debug
Linfo_string:
	.asciz	"my llvm compiler frontend"     ; string offset=0
	.asciz	"roc_app"                       ; string offset=26
	.asciz	"."                             ; string offset=34
	.asciz	"Inspect_inspect_e4f9cf3a6c4e3d6be9d05048391b2e3975855fa3e34f66d41fe2c9a84e5c7b" ; string offset=36
	.asciz	"Inspect_dbgI32_da6b85ec7e1e6f2f01e92f35cc48f7475ea87261d357876fef3f23dc338e" ; string offset=115
	.asciz	"Inspect_204_50a9b514f5bf5c5ff0dff77dffab9b9f2c8b7084581b52c249d53019289d446b" ; string offset=191
	.asciz	"Inspect_custom_653de62d66328bd02e166b818cc28fc7f76ad909358c5f3f340dd1c827546c9" ; string offset=268
	.asciz	"Inspect_206_11922f5e717257e3c76632973ee406cbf106889cd4e80e37d14c1d9c194671" ; string offset=347
	.asciz	"List_walk_52459ae5e05017996bb4298dd9ac3944ffe997fa2e2ad98ba6fd7348395f63" ; string offset=422
	.asciz	"List_walkHelp_53eef38977ca9e3af29e8b6fc9f50f557be9bbd173abd2118eb5488f19fb2" ; string offset=495
	.asciz	"Inspect_apply_676ec9e417566a851359c2c6d5d5332f7d40742f8274a8672f3cad244846" ; string offset=571
	.asciz	"#Derived_custom3_beb22fad19423347b2aa99b33212e862ded3f83df5d6238acb1a6a9ade3e" ; string offset=646
	.asciz	"PlatformTasks_task_closure_stderrLine_df662f4854c7c5a297d6c339e28fd51ddc944983db9bc7f012ab2c1c69a52db6" ; string offset=724
	.asciz	"Task_38_464ad9696114b8eea8bc3daaaa648b1d3685be4c8d824dbb0c93c169d61" ; string offset=827
	.asciz	"Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e" ; string offset=895
	.asciz	"Inspect_dbgStr_d394208415ac8fe0ce8aa0ddf6a845c7cc74d818698e3d25c85705ce311f5ec" ; string offset=973
	.asciz	"#Derived_custom2_c610e85212d0697cb161d4ba431ba63f273feee7dcb7927c9ff5d74ae6cbfa3" ; string offset=1052
	.asciz	"Inspect_206_f784f33513051f4f09b2b103edd2f576ced88ace36b12d3f4e2a3dbe51fcfeb" ; string offset=1133
	.asciz	"Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198" ; string offset=1209
	.asciz	"List_walk_078eba49b7090dbd2c6fb82297218e6d2eb88883fa33ff213b919f6e68cc" ; string offset=1283
	.asciz	"_7_52aff1341cf42f5e6559a2cf028663f7bbbc7576ac1948fc58784a0613b79" ; string offset=1354
	.asciz	"#UserApp_main_bae7cba17581e9e24ed8c02e992f1bda9aeff2d299cc1289ddd0dbdf373061" ; string offset=1419
	.asciz	"Task_ok_7f8c4a473141d41efa7657e3f378539f18179e0b2dff0f626f6dce25d295f" ; string offset=1496
	.asciz	"Stdout_handleErr_539d94cac9151288c18279a5f1573e8d65d66aeb5922fa6ed8cbc577893894" ; string offset=1566
	.asciz	"Inspect_toStr_7cfa03e91e0ec9327f388a68dbd26ae2735e7e95165f9e519543e02299bee9" ; string offset=1646
	.asciz	"Inspect_210_3d7aff37b23cd9f9e6beb177d8bf818babb9d186ea278cc981a34be43b8cf34" ; string offset=1723
	.asciz	"Task_42_dee69d62f6dd2acac17218e148d3d8138e18cca99859936284942954b14b32" ; string offset=1799
	.asciz	"Stderr_handleErr_1c44a9ca60e694ea5bce656141adb8728c249dc46543e7c34883c1136ab140" ; string offset=1870
	.asciz	"Task_35_3899d549ca6f5b7757a69b861e0c9a44bfbbd717ac2039f8ca1abc46d7d32e" ; string offset=1950
	.asciz	"Task_67_fea4b522fb116c2bf818212d595291e57cec745699352eecbb7184315f386ce8" ; string offset=2021
	.asciz	"PlatformTasks_stdoutLine_4dcdd9fc1c563c9592918682f5bb9bfbff249c75cdcf934a994231c5c3a018" ; string offset=2094
	.asciz	"_8_8b8e749a7d5dc4035aed2d09b8b4ad59fac5ad694339521a2df23bf1ac35c3" ; string offset=2182
	.asciz	"Task_onErr_5fea3a382f6b6c4a2af77ea4365b5abbdda8b93d1f0b9b895dc2a48489fb2" ; string offset=2248
	.asciz	"PlatformTasks_task_closure_stdoutLine_e8e3cb4c459a1e25c7bed4d87759a21ad8b1f9ce7dd1dd4beba947ebadfffae4" ; string offset=2321
	.asciz	"Inspect_dbgInit_3bbacd33228bca14fe5573efe7278cde33c78fe9028ba98810cff368dece" ; string offset=2424
	.asciz	"Task_mapErr_78fff63b9d7571652dd558be04af7c0e5b15b7f19efda5bd78185837663f63" ; string offset=2501
	.asciz	"Str_isEmpty_cb411178cb7686889a4ee0e4b4c57e63975186dc9f1448b79e94c2721a21a2" ; string offset=2576
	.asciz	"List_getUnsafe_4a74cf314ac9371a5ea518de15e620d82137397f51a1fa6eff156547f363" ; string offset=2651
	.asciz	"Inspect_213_24ce363245042dce6c6647d3662b4b2c84c622d118936f8265c24f93e9d3a2c" ; string offset=2727
	.asciz	"Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6" ; string offset=2803
	.asciz	"Inspect_208_af2554e3880a1c7af81a4c13c1df135146f6cac58d2d046bda16fbd7c23db3" ; string offset=2883
	.asciz	"_10_8c3fdd6849785e1b32106ad9c6ae59845e2314f0a6799376d4e3e3b9be62d181" ; string offset=2958
	.asciz	"_73_c919149ababf2a569c5e2b164c2465c785dc3bc7f566b8dcef7ec4ae86e8d57" ; string offset=3027
	.asciz	"Num_addWrap_e84248fb50d0833361d0417df114b0b3b3448fff97c39cdde963b09a9aebb8" ; string offset=3095
	.asciz	"Task_attempt_1fbc6d79b671ab88e8a9425cd46a77344c0f7ee34ea43fdcaf5a014c6759d" ; string offset=3170
	.asciz	"Task_67_ca8af06be175497c1986028dec9ff9bde775267ac5c92d6992ca796b5e797c" ; string offset=3245
	.asciz	"Inspect_204_b7c59c3aec44645db91b229c81990d288c86aeb49f116d1eae85e2b9a39999f" ; string offset=3316
	.asciz	"Inspect_210_139c9542137b10e977a775e441e04012cc6d2c98579f3cdeb5fb42ef98df6d6" ; string offset=3392
	.asciz	"_mainForHost_9d949d48d48bd9629a662ead3e2fc9728ebe6544f0834563102ca492bac0" ; string offset=3468
	.asciz	"roc__mainForHost_1_exposed_generic" ; string offset=3542
	.asciz	"roc__mainForHost_1_exposed"    ; string offset=3577
	.asciz	"roc__mainForHost_1_exposed_size" ; string offset=3604
	.asciz	"Inspect_250_6bc1e748a2edd5eacd7f49eb7476d47387e76d8e94fcfcf34a1d5a6fa86e" ; string offset=3636
	.asciz	"PlatformTasks_stderrLine_aad9a2f5f9418b386cce489a0bac8cb5bba34171864909e4dfec1ea4e26bfb7" ; string offset=3709
	.asciz	"Task_err_72f11ea62bc2627ca7ca9959232e519a82934c5e521930f57f3646c32591" ; string offset=3798
	.asciz	"Inspect_custom_bfa1d47a221bdaf089999196bed323c433d1a6b8c78ec612e6fa7b3e3d811" ; string offset=3868
	.asciz	"Inspect_apply_95dbc324453309f26dee9436b39568cc8bcbe17ef409e9273c4edb58653fd" ; string offset=3945
	.asciz	"List_len_35bfe7dc6dba25ddadede12999f2a34775468912610779bf675f9c2d81ecac" ; string offset=4021
	.asciz	"Stdout_line_c852b6d75d2364d70d094699f8a9cda9129d5310ed82ea45564f47a9" ; string offset=4093
	.asciz	"Inspect_208_36ded37b63679dfb9096703c22eba74b3449a854bc97ac179ba6ffbbbaa21" ; string offset=4162
	.asciz	"Stderr_line_1484a21b4257566f7c1b3505e4f6c430eb1121cbfb946b32fb115b90b1ef50" ; string offset=4236
	.asciz	"Dict_defaultMaxLoadFactor_7a93171d29c34145ace0bed7f158bc6f747d259f21a8119f90767f874eb48b94" ; string offset=4311
	.asciz	"Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565" ; string offset=4402
	.asciz	"Inspect_toDbgStr_9d7544bbc8507265e131f9b42f567d6c54e799c62356103470ba3daf5673a8" ; string offset=4471
	.asciz	"List_len_4e123451c288c52798d3df0fc84811d2d957f324242982575c70dfd6d338df" ; string offset=4551
	.asciz	"List_isEmpty_99e2ebbd98e8a2a4c7ed9bd71d205d9f7b5d7e7a9ddb68dab65f2ad1c2198b" ; string offset=4623
	.asciz	"Num_subWrap_edaf1bd3d1c2ffcc44df55829c02f262426de2ffbea9be2cdf075ec12c528d" ; string offset=4699
	.asciz	"Bool_structuralEq_cabb163ea8b383114bab450f2ea4bdf6f97d5dc22e57b593db81e3bce47" ; string offset=4774
	.asciz	"Inspect_272_4fe2c0cee861629d2ef04c3f725dba5813b563598f88e6fe57cefd4dd1a133" ; string offset=4852
	.asciz	"Inspect_custom_1149386876d826e56f26fd066413b9c565aa3dea67161e512a9ba24db887d5" ; string offset=4927
	.asciz	"Inspect_custom_926c4e1deae44cb32fa91b0fc2f966fdf98af98ee562517f2d5df6cc1b8bf0" ; string offset=5005
	.asciz	"List_walkHelp_99aa979e4a9cadd6dbe48ea878ec84acb7696eb93470c375f6893f1da46c3772" ; string offset=5083
	.asciz	"Task_mapErr_b7a3f2a8f8a550a8b7d9f583e11fe2d9be1c46afd270ccbd14dc29ab1919b1" ; string offset=5162
	.asciz	"#Derived_toInspector_[BrokenPipe 0,Interrupted 0,Other 1,OutOfMemory 0,Unsupported 0,WouldBlock 0,WriteZero 0]_f03bf86f79d121cbfd774dec4a65912e99f5f17c33852bbc45e81916e62b53b" ; string offset=5237
	.asciz	"Inspect_custom_f0adb8f180253d489b50ac5199522556362f583929ee5e65c919bd9ed2bc82f" ; string offset=5412
	.asciz	"List_isEmpty_76e6e4fef22a778f22804a4a55d5f106b42fb9eadb9eb1f662982e2379174e" ; string offset=5491
	.asciz	"Num_toStr_7f7e162ee4345c12acb2c8dddfd129c8c9ef562ecb31841cfff13d4789ffc2" ; string offset=5567
	.asciz	"Test_calculateMiddleTotal_b5dcd15815911a96b9d7e883b1723ec1e9f2a35835ca79db2284140ebd0aa83" ; string offset=5640
	.asciz	"_11_2c7d993eadf275d994a1f98b824972fece3cfca6b6ac52dd7bb717e1f5753" ; string offset=5730
	.asciz	"Inspect_dbgStr_e3211b24ebda6e959f98c8dfabbb8bde232b75ae94930caa03d2bdb8e7b5674" ; string offset=5796
	.asciz	"Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d" ; string offset=5875
	.asciz	"List_getUnsafe_2cc6e6d3c5a48a76ea218c439d44b6318e7bd267419a22dcb25b258a2c06a" ; string offset=5954
	.asciz	"Inspect_250_92df2e9c67226884f739cd53c0493c2aabaabd406877a3b72a3e676dc54e081" ; string offset=6031
	.asciz	"Task_53_1dc6f9836252db90e110ad1b5e28c952e1292787deeab71a2a18c14f1d18ec0" ; string offset=6107
	.asciz	"Set_isEmpty_127cb22736133e34b265d61ea1d591a8834a13a1d4a2cb161a40b74f7c37b3" ; string offset=6179
	.asciz	"_3_12f97a97f61aca488b75d4cbbdb83020191eefe4f33d263875d76e4b447613" ; string offset=6254
	.asciz	"Set_empty_4c26d916fc42dd8d2a9bd5abfc2993ea3741d5b5db9aa72687bec6b6e3098" ; string offset=6320
	.asciz	"Dict_isEmpty_eabc27640eff330d625cb2f6435f5dccaec45dd590ad64015fdca105b70" ; string offset=6392
	.asciz	"Task_await_9ddbc9a5a6ab79818cf720ec32ba1aeb5838e37cd919c2ff6b897d7d866d5c7" ; string offset=6465
	.asciz	"Inspect_dbgTag_d1a1e4356bd9fe6c31754def4c60a14042ade1c6c101618179cfd5d1c73189" ; string offset=6540
	.asciz	"Inspect_apply_4afec3b1b615e34b46f852dc4576722a03d82d96cc27deb38d7b350ecaf31" ; string offset=6618
	.asciz	"Num_toStr_f273102d33b910ab8b1eda6e483bb587ec34372c3562cd9bfb68bcf889ba9cd" ; string offset=6694
	.asciz	"Num_isLt_669c1355a3e727bb53dd458f2e96e48571aa45dfabcfb4b7de1689484f11" ; string offset=6768
	.asciz	"Inspect_apply_8acb95ddb9a746c2bf4dc0f4f96ce3b3e1f1e4f2559e7641b193db1f161d1c41" ; string offset=6838
	.asciz	"Task_38_837964ef27185f97a31536069e8f60f59d43cf26aef4e69eeafaab204a51f2" ; string offset=6917
	.asciz	"List_len_dc3f621de1221c7c53a19e877c377561ede91cdd88b1a687d310a39785a" ; string offset=6988
	.asciz	"List_sortWith_91183c4be76c8c6e9a1aca423ca6b7bdfddc155d7aac337b8db73395e0e64d" ; string offset=7057
	.asciz	"List_len_68697e959be5e5da06cc73b6f998e193cbf2d9b22efd0355a3d37129951b" ; string offset=7134
	.asciz	"Task_46_56b1edb1daf8df7ae4fb1a2df75794dcef5a427f85ac1fa18ff4bea1e8e00" ; string offset=7204
	.asciz	"Dict_empty_392aebc0773ca1163ead8eb210e2c2aabca4fe4ded9f2b122a7dab30d082d98b" ; string offset=7274
	.asciz	"List_isEmpty_54b3c6d264e7c557f2fe74ef29431163e9a30a2e4aca38b681d4b9ee62de031" ; string offset=7350
	.asciz	"Inspect_213_bd5db9a62133a57f3c3971868413d37dfa646aa8a2764e7763fd4ba5b0b0d4" ; string offset=7427
	.asciz	"Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2" ; string offset=7502
	.asciz	"#Derived_toInspector_[Exit 2,StdoutErr 1]_ec2bd03bf86b935fa34d71ad7ebb49f1f10f87d343e521511d8f9e6625620cd" ; string offset=7579
	.asciz	"Dict_initialShifts_839d816e30d259b7a113479095a2bf4a37efc9c09ed13ea6ca0fa9b9a5ff9" ; string offset=7685
	.asciz	"#Attr_#dec_1"                  ; string offset=7766
	.asciz	"decrement_refcounted_ptr_8"    ; string offset=7779
	.asciz	"#Attr_#generic_rc_by_ref_1_dec" ; string offset=7806
	.asciz	"type_name"                     ; string offset=7837
	.asciz	"#Attr_#dec_2"                  ; string offset=7847
	.asciz	"#Attr_#inc_2"                  ; string offset=7860
	.asciz	"#Attr_#inc_1"                  ; string offset=7873
	.asciz	"#Attr_#dec_3"                  ; string offset=7886
	.asciz	"#Attr_#generic_rc_by_ref_2_dec" ; string offset=7899
	.asciz	"#Attr_#dec_4"                  ; string offset=7930
	.asciz	"#Attr_#dec_5"                  ; string offset=7943
	.asciz	"#Attr_#inc_4"                  ; string offset=7956
	.asciz	"#Attr_#inc_5"                  ; string offset=7969
	.asciz	"#Attr_#inc_3"                  ; string offset=7982
	.asciz	"#Attr_#dec_10"                 ; string offset=7995
	.asciz	"#Attr_#dec_11"                 ; string offset=8009
	.asciz	"#Attr_#dec_12"                 ; string offset=8023
	.asciz	"#Attr_#dec_13"                 ; string offset=8037
	.asciz	"#Attr_#dec_14"                 ; string offset=8051
	.asciz	"#Attr_#generic_rc_by_ref_5_dec" ; string offset=8065
	.asciz	"#Attr_#dec_15"                 ; string offset=8096
	.asciz	"#Attr_#dec_16"                 ; string offset=8110
	.asciz	"Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2_compare_wrapper" ; string offset=8124
	.asciz	"#Attr_#generic_rc_by_ref_6_inc_n" ; string offset=8217
	.asciz	"#Attr_#inc_17"                 ; string offset=8250
	.asciz	"#Attr_#inc_13"                 ; string offset=8264
	.asciz	"#Attr_#inc_15"                 ; string offset=8278
	.asciz	"#Attr_#generic_copy_by_ref_1"  ; string offset=8292
	.asciz	"#Attr_#dec_17"                 ; string offset=8321
	.section	__DWARF,__apple_names,regular,debug
Lnames_begin:
	.long	1212240712                      ; Header Magic
	.short	1                               ; Header Version
	.short	0                               ; Header Hash Function
	.long	65                              ; Header Bucket Count
	.long	130                             ; Header Hash Count
	.long	12                              ; Header Data Length
	.long	0                               ; HeaderData Die Offset Base
	.long	1                               ; HeaderData Atom Count
	.short	1                               ; DW_ATOM_die_offset
	.short	6                               ; DW_FORM_data4
	.long	0                               ; Bucket 0
	.long	-1                              ; Bucket 1
	.long	-1                              ; Bucket 2
	.long	5                               ; Bucket 3
	.long	7                               ; Bucket 4
	.long	8                               ; Bucket 5
	.long	9                               ; Bucket 6
	.long	12                              ; Bucket 7
	.long	16                              ; Bucket 8
	.long	18                              ; Bucket 9
	.long	20                              ; Bucket 10
	.long	-1                              ; Bucket 11
	.long	24                              ; Bucket 12
	.long	-1                              ; Bucket 13
	.long	25                              ; Bucket 14
	.long	28                              ; Bucket 15
	.long	30                              ; Bucket 16
	.long	-1                              ; Bucket 17
	.long	31                              ; Bucket 18
	.long	33                              ; Bucket 19
	.long	36                              ; Bucket 20
	.long	39                              ; Bucket 21
	.long	40                              ; Bucket 22
	.long	42                              ; Bucket 23
	.long	43                              ; Bucket 24
	.long	45                              ; Bucket 25
	.long	46                              ; Bucket 26
	.long	47                              ; Bucket 27
	.long	51                              ; Bucket 28
	.long	-1                              ; Bucket 29
	.long	53                              ; Bucket 30
	.long	54                              ; Bucket 31
	.long	55                              ; Bucket 32
	.long	57                              ; Bucket 33
	.long	58                              ; Bucket 34
	.long	64                              ; Bucket 35
	.long	67                              ; Bucket 36
	.long	69                              ; Bucket 37
	.long	-1                              ; Bucket 38
	.long	71                              ; Bucket 39
	.long	72                              ; Bucket 40
	.long	-1                              ; Bucket 41
	.long	-1                              ; Bucket 42
	.long	74                              ; Bucket 43
	.long	-1                              ; Bucket 44
	.long	76                              ; Bucket 45
	.long	79                              ; Bucket 46
	.long	80                              ; Bucket 47
	.long	82                              ; Bucket 48
	.long	87                              ; Bucket 49
	.long	-1                              ; Bucket 50
	.long	92                              ; Bucket 51
	.long	93                              ; Bucket 52
	.long	95                              ; Bucket 53
	.long	100                             ; Bucket 54
	.long	104                             ; Bucket 55
	.long	110                             ; Bucket 56
	.long	112                             ; Bucket 57
	.long	116                             ; Bucket 58
	.long	120                             ; Bucket 59
	.long	122                             ; Bucket 60
	.long	124                             ; Bucket 61
	.long	125                             ; Bucket 62
	.long	-1                              ; Bucket 63
	.long	128                             ; Bucket 64
	.long	1553523855                      ; Hash in Bucket 0
	.long	-1270458731                     ; Hash in Bucket 0
	.long	-1132342506                     ; Hash in Bucket 0
	.long	-874116616                      ; Hash in Bucket 0
	.long	-640219446                      ; Hash in Bucket 0
	.long	1698583708                      ; Hash in Bucket 3
	.long	1845167288                      ; Hash in Bucket 3
	.long	2007122719                      ; Hash in Bucket 4
	.long	-1818643311                     ; Hash in Bucket 5
	.long	2064330196                      ; Hash in Bucket 6
	.long	2110233846                      ; Hash in Bucket 6
	.long	-1325400755                     ; Hash in Bucket 6
	.long	1826365782                      ; Hash in Bucket 7
	.long	-1731490659                     ; Hash in Bucket 7
	.long	-1587503374                     ; Hash in Bucket 7
	.long	-885313509                      ; Hash in Bucket 7
	.long	760965928                       ; Hash in Bucket 8
	.long	-2091288148                     ; Hash in Bucket 8
	.long	196919329                       ; Hash in Bucket 9
	.long	519452189                       ; Hash in Bucket 9
	.long	371467730                       ; Hash in Bucket 10
	.long	-1190641321                     ; Hash in Bucket 10
	.long	-986560366                      ; Hash in Bucket 10
	.long	-982752146                      ; Hash in Bucket 10
	.long	649299767                       ; Hash in Bucket 12
	.long	109769154                       ; Hash in Bucket 14
	.long	373343569                       ; Hash in Bucket 14
	.long	-505500952                      ; Hash in Bucket 14
	.long	2085757390                      ; Hash in Bucket 15
	.long	-1992099701                     ; Hash in Bucket 15
	.long	109769156                       ; Hash in Bucket 16
	.long	109769158                       ; Hash in Bucket 18
	.long	-1558479953                     ; Hash in Bucket 18
	.long	1506271279                      ; Hash in Bucket 19
	.long	-1889058837                     ; Hash in Bucket 19
	.long	-1558479952                     ; Hash in Bucket 19
	.long	1840473265                      ; Hash in Bucket 20
	.long	-1558479951                     ; Hash in Bucket 20
	.long	-1379765116                     ; Hash in Bucket 20
	.long	-1558479950                     ; Hash in Bucket 21
	.long	77444402                        ; Hash in Bucket 22
	.long	-1558479949                     ; Hash in Bucket 22
	.long	500990968                       ; Hash in Bucket 23
	.long	830331539                       ; Hash in Bucket 24
	.long	1763786399                      ; Hash in Bucket 24
	.long	-2015913481                     ; Hash in Bucket 25
	.long	-83063795                       ; Hash in Bucket 26
	.long	1040523732                      ; Hash in Bucket 27
	.long	-1995657464                     ; Hash in Bucket 27
	.long	-1543898624                     ; Hash in Bucket 27
	.long	-1383698584                     ; Hash in Bucket 27
	.long	940104778                       ; Hash in Bucket 28
	.long	-1587888023                     ; Hash in Bucket 28
	.long	-1799129116                     ; Hash in Bucket 30
	.long	-1996843385                     ; Hash in Bucket 31
	.long	1510592687                      ; Hash in Bucket 32
	.long	1777055312                      ; Hash in Bucket 32
	.long	2076928133                      ; Hash in Bucket 33
	.long	847909369                       ; Hash in Bucket 34
	.long	1384563214                      ; Hash in Bucket 34
	.long	-2049458412                     ; Hash in Bucket 34
	.long	-1968338607                     ; Hash in Bucket 34
	.long	-1305604002                     ; Hash in Bucket 34
	.long	-820102557                      ; Hash in Bucket 34
	.long	1803442585                      ; Hash in Bucket 35
	.long	-1041884376                     ; Hash in Bucket 35
	.long	-22051731                       ; Hash in Bucket 35
	.long	1919626446                      ; Hash in Bucket 36
	.long	-349517310                      ; Hash in Bucket 36
	.long	-890332714                      ; Hash in Bucket 37
	.long	-82120374                       ; Hash in Bucket 37
	.long	1724953724                      ; Hash in Bucket 39
	.long	1978449630                      ; Hash in Bucket 40
	.long	-2146625151                     ; Hash in Bucket 40
	.long	360889013                       ; Hash in Bucket 43
	.long	470248848                       ; Hash in Bucket 43
	.long	-2025222501                     ; Hash in Bucket 45
	.long	-1564732991                     ; Hash in Bucket 45
	.long	-639261106                      ; Hash in Bucket 45
	.long	-1564732990                     ; Hash in Bucket 46
	.long	1045702822                      ; Hash in Bucket 47
	.long	-1564732989                     ; Hash in Bucket 47
	.long	859634343                       ; Hash in Bucket 48
	.long	1492275508                      ; Hash in Bucket 48
	.long	1502204843                      ; Hash in Bucket 48
	.long	1693077798                      ; Hash in Bucket 48
	.long	-1564732988                     ; Hash in Bucket 48
	.long	637573674                       ; Hash in Bucket 49
	.long	-2041324492                     ; Hash in Bucket 49
	.long	-1636064637                     ; Hash in Bucket 49
	.long	-1564732987                     ; Hash in Bucket 49
	.long	-509658317                      ; Hash in Bucket 49
	.long	-2039916655                     ; Hash in Bucket 51
	.long	1654273127                      ; Hash in Bucket 52
	.long	-1269293489                     ; Hash in Bucket 52
	.long	-2129289963                     ; Hash in Bucket 53
	.long	-762677053                      ; Hash in Bucket 53
	.long	-506105543                      ; Hash in Bucket 53
	.long	-448548628                      ; Hash in Bucket 53
	.long	-96581103                       ; Hash in Bucket 53
	.long	167926059                       ; Hash in Bucket 54
	.long	-1603413962                     ; Hash in Bucket 54
	.long	-1363128592                     ; Hash in Bucket 54
	.long	-96581102                       ; Hash in Bucket 54
	.long	1967968460                      ; Hash in Bucket 55
	.long	2128149325                      ; Hash in Bucket 55
	.long	-920264286                      ; Hash in Bucket 55
	.long	-840444546                      ; Hash in Bucket 55
	.long	-499129611                      ; Hash in Bucket 55
	.long	-96581101                       ; Hash in Bucket 55
	.long	-855849935                      ; Hash in Bucket 56
	.long	-96581100                       ; Hash in Bucket 56
	.long	309762757                       ; Hash in Bucket 57
	.long	1761199107                      ; Hash in Bucket 57
	.long	1996596802                      ; Hash in Bucket 57
	.long	-96581099                       ; Hash in Bucket 57
	.long	1883723393                      ; Hash in Bucket 58
	.long	-1345461653                     ; Hash in Bucket 58
	.long	-886257973                      ; Hash in Bucket 58
	.long	-96581098                       ; Hash in Bucket 58
	.long	1401768544                      ; Hash in Bucket 59
	.long	-96581097                       ; Hash in Bucket 59
	.long	-1085169606                     ; Hash in Bucket 60
	.long	-96581096                       ; Hash in Bucket 60
	.long	34810356                        ; Hash in Bucket 61
	.long	425388662                       ; Hash in Bucket 62
	.long	910503032                       ; Hash in Bucket 62
	.long	1537040112                      ; Hash in Bucket 62
	.long	390505894                       ; Hash in Bucket 64
	.long	-477740247                      ; Hash in Bucket 64
.set Lset134, LNames35-Lnames_begin     ; Offset in Bucket 0
	.long	Lset134
.set Lset135, LNames5-Lnames_begin      ; Offset in Bucket 0
	.long	Lset135
.set Lset136, LNames118-Lnames_begin    ; Offset in Bucket 0
	.long	Lset136
.set Lset137, LNames7-Lnames_begin      ; Offset in Bucket 0
	.long	Lset137
.set Lset138, LNames1-Lnames_begin      ; Offset in Bucket 0
	.long	Lset138
.set Lset139, LNames48-Lnames_begin     ; Offset in Bucket 3
	.long	Lset139
.set Lset140, LNames23-Lnames_begin     ; Offset in Bucket 3
	.long	Lset140
.set Lset141, LNames85-Lnames_begin     ; Offset in Bucket 4
	.long	Lset141
.set Lset142, LNames113-Lnames_begin    ; Offset in Bucket 5
	.long	Lset142
.set Lset143, LNames56-Lnames_begin     ; Offset in Bucket 6
	.long	Lset143
.set Lset144, LNames79-Lnames_begin     ; Offset in Bucket 6
	.long	Lset144
.set Lset145, LNames44-Lnames_begin     ; Offset in Bucket 6
	.long	Lset145
.set Lset146, LNames58-Lnames_begin     ; Offset in Bucket 7
	.long	Lset146
.set Lset147, LNames9-Lnames_begin      ; Offset in Bucket 7
	.long	Lset147
.set Lset148, LNames74-Lnames_begin     ; Offset in Bucket 7
	.long	Lset148
.set Lset149, LNames8-Lnames_begin      ; Offset in Bucket 7
	.long	Lset149
.set Lset150, LNames90-Lnames_begin     ; Offset in Bucket 8
	.long	Lset150
.set Lset151, LNames110-Lnames_begin    ; Offset in Bucket 8
	.long	Lset151
.set Lset152, LNames105-Lnames_begin    ; Offset in Bucket 9
	.long	Lset152
.set Lset153, LNames84-Lnames_begin     ; Offset in Bucket 9
	.long	Lset153
.set Lset154, LNames46-Lnames_begin     ; Offset in Bucket 10
	.long	Lset154
.set Lset155, LNames102-Lnames_begin    ; Offset in Bucket 10
	.long	Lset155
.set Lset156, LNames75-Lnames_begin     ; Offset in Bucket 10
	.long	Lset156
.set Lset157, LNames4-Lnames_begin      ; Offset in Bucket 10
	.long	Lset157
.set Lset158, LNames22-Lnames_begin     ; Offset in Bucket 12
	.long	Lset158
.set Lset159, LNames63-Lnames_begin     ; Offset in Bucket 14
	.long	Lset159
.set Lset160, LNames45-Lnames_begin     ; Offset in Bucket 14
	.long	Lset160
.set Lset161, LNames67-Lnames_begin     ; Offset in Bucket 14
	.long	Lset161
.set Lset162, LNames111-Lnames_begin    ; Offset in Bucket 15
	.long	Lset162
.set Lset163, LNames94-Lnames_begin     ; Offset in Bucket 15
	.long	Lset163
.set Lset164, LNames64-Lnames_begin     ; Offset in Bucket 16
	.long	Lset164
.set Lset165, LNames70-Lnames_begin     ; Offset in Bucket 18
	.long	Lset165
.set Lset166, LNames16-Lnames_begin     ; Offset in Bucket 18
	.long	Lset166
.set Lset167, LNames96-Lnames_begin     ; Offset in Bucket 19
	.long	Lset167
.set Lset168, LNames93-Lnames_begin     ; Offset in Bucket 19
	.long	Lset168
.set Lset169, LNames17-Lnames_begin     ; Offset in Bucket 19
	.long	Lset169
.set Lset170, LNames98-Lnames_begin     ; Offset in Bucket 20
	.long	Lset170
.set Lset171, LNames21-Lnames_begin     ; Offset in Bucket 20
	.long	Lset171
.set Lset172, LNames49-Lnames_begin     ; Offset in Bucket 20
	.long	Lset172
.set Lset173, LNames19-Lnames_begin     ; Offset in Bucket 21
	.long	Lset173
.set Lset174, LNames99-Lnames_begin     ; Offset in Bucket 22
	.long	Lset174
.set Lset175, LNames20-Lnames_begin     ; Offset in Bucket 22
	.long	Lset175
.set Lset176, LNames80-Lnames_begin     ; Offset in Bucket 23
	.long	Lset176
.set Lset177, LNames100-Lnames_begin    ; Offset in Bucket 24
	.long	Lset177
.set Lset178, LNames41-Lnames_begin     ; Offset in Bucket 24
	.long	Lset178
.set Lset179, LNames119-Lnames_begin    ; Offset in Bucket 25
	.long	Lset179
.set Lset180, LNames34-Lnames_begin     ; Offset in Bucket 26
	.long	Lset180
.set Lset181, LNames77-Lnames_begin     ; Offset in Bucket 27
	.long	Lset181
.set Lset182, LNames32-Lnames_begin     ; Offset in Bucket 27
	.long	Lset182
.set Lset183, LNames86-Lnames_begin     ; Offset in Bucket 27
	.long	Lset183
.set Lset184, LNames11-Lnames_begin     ; Offset in Bucket 27
	.long	Lset184
.set Lset185, LNames2-Lnames_begin      ; Offset in Bucket 28
	.long	Lset185
.set Lset186, LNames51-Lnames_begin     ; Offset in Bucket 28
	.long	Lset186
.set Lset187, LNames29-Lnames_begin     ; Offset in Bucket 30
	.long	Lset187
.set Lset188, LNames89-Lnames_begin     ; Offset in Bucket 31
	.long	Lset188
.set Lset189, LNames112-Lnames_begin    ; Offset in Bucket 32
	.long	Lset189
.set Lset190, LNames55-Lnames_begin     ; Offset in Bucket 32
	.long	Lset190
.set Lset191, LNames0-Lnames_begin      ; Offset in Bucket 33
	.long	Lset191
.set Lset192, LNames82-Lnames_begin     ; Offset in Bucket 34
	.long	Lset192
.set Lset193, LNames15-Lnames_begin     ; Offset in Bucket 34
	.long	Lset193
.set Lset194, LNames59-Lnames_begin     ; Offset in Bucket 34
	.long	Lset194
.set Lset195, LNames18-Lnames_begin     ; Offset in Bucket 34
	.long	Lset195
.set Lset196, LNames25-Lnames_begin     ; Offset in Bucket 34
	.long	Lset196
.set Lset197, LNames128-Lnames_begin    ; Offset in Bucket 34
	.long	Lset197
.set Lset198, LNames61-Lnames_begin     ; Offset in Bucket 35
	.long	Lset198
.set Lset199, LNames91-Lnames_begin     ; Offset in Bucket 35
	.long	Lset199
.set Lset200, LNames71-Lnames_begin     ; Offset in Bucket 35
	.long	Lset200
.set Lset201, LNames3-Lnames_begin      ; Offset in Bucket 36
	.long	Lset201
.set Lset202, LNames87-Lnames_begin     ; Offset in Bucket 36
	.long	Lset202
.set Lset203, LNames78-Lnames_begin     ; Offset in Bucket 37
	.long	Lset203
.set Lset204, LNames92-Lnames_begin     ; Offset in Bucket 37
	.long	Lset204
.set Lset205, LNames47-Lnames_begin     ; Offset in Bucket 39
	.long	Lset205
.set Lset206, LNames24-Lnames_begin     ; Offset in Bucket 40
	.long	Lset206
.set Lset207, LNames104-Lnames_begin    ; Offset in Bucket 40
	.long	Lset207
.set Lset208, LNames117-Lnames_begin    ; Offset in Bucket 43
	.long	Lset208
.set Lset209, LNames101-Lnames_begin    ; Offset in Bucket 43
	.long	Lset209
.set Lset210, LNames123-Lnames_begin    ; Offset in Bucket 45
	.long	Lset210
.set Lset211, LNames26-Lnames_begin     ; Offset in Bucket 45
	.long	Lset211
.set Lset212, LNames72-Lnames_begin     ; Offset in Bucket 45
	.long	Lset212
.set Lset213, LNames27-Lnames_begin     ; Offset in Bucket 46
	.long	Lset213
.set Lset214, LNames65-Lnames_begin     ; Offset in Bucket 47
	.long	Lset214
.set Lset215, LNames28-Lnames_begin     ; Offset in Bucket 47
	.long	Lset215
.set Lset216, LNames69-Lnames_begin     ; Offset in Bucket 48
	.long	Lset216
.set Lset217, LNames116-Lnames_begin    ; Offset in Bucket 48
	.long	Lset217
.set Lset218, LNames13-Lnames_begin     ; Offset in Bucket 48
	.long	Lset218
.set Lset219, LNames10-Lnames_begin     ; Offset in Bucket 48
	.long	Lset219
.set Lset220, LNames30-Lnames_begin     ; Offset in Bucket 48
	.long	Lset220
.set Lset221, LNames12-Lnames_begin     ; Offset in Bucket 49
	.long	Lset221
.set Lset222, LNames76-Lnames_begin     ; Offset in Bucket 49
	.long	Lset222
.set Lset223, LNames43-Lnames_begin     ; Offset in Bucket 49
	.long	Lset223
.set Lset224, LNames31-Lnames_begin     ; Offset in Bucket 49
	.long	Lset224
.set Lset225, LNames37-Lnames_begin     ; Offset in Bucket 49
	.long	Lset225
.set Lset226, LNames114-Lnames_begin    ; Offset in Bucket 51
	.long	Lset226
.set Lset227, LNames66-Lnames_begin     ; Offset in Bucket 52
	.long	Lset227
.set Lset228, LNames54-Lnames_begin     ; Offset in Bucket 52
	.long	Lset228
.set Lset229, LNames38-Lnames_begin     ; Offset in Bucket 53
	.long	Lset229
.set Lset230, LNames106-Lnames_begin    ; Offset in Bucket 53
	.long	Lset230
.set Lset231, LNames81-Lnames_begin     ; Offset in Bucket 53
	.long	Lset231
.set Lset232, LNames14-Lnames_begin     ; Offset in Bucket 53
	.long	Lset232
.set Lset233, LNames127-Lnames_begin    ; Offset in Bucket 53
	.long	Lset233
.set Lset234, LNames109-Lnames_begin    ; Offset in Bucket 54
	.long	Lset234
.set Lset235, LNames40-Lnames_begin     ; Offset in Bucket 54
	.long	Lset235
.set Lset236, LNames97-Lnames_begin     ; Offset in Bucket 54
	.long	Lset236
.set Lset237, LNames115-Lnames_begin    ; Offset in Bucket 54
	.long	Lset237
.set Lset238, LNames53-Lnames_begin     ; Offset in Bucket 55
	.long	Lset238
.set Lset239, LNames95-Lnames_begin     ; Offset in Bucket 55
	.long	Lset239
.set Lset240, LNames42-Lnames_begin     ; Offset in Bucket 55
	.long	Lset240
.set Lset241, LNames103-Lnames_begin    ; Offset in Bucket 55
	.long	Lset241
.set Lset242, LNames6-Lnames_begin      ; Offset in Bucket 55
	.long	Lset242
.set Lset243, LNames121-Lnames_begin    ; Offset in Bucket 55
	.long	Lset243
.set Lset244, LNames36-Lnames_begin     ; Offset in Bucket 56
	.long	Lset244
.set Lset245, LNames122-Lnames_begin    ; Offset in Bucket 56
	.long	Lset245
.set Lset246, LNames108-Lnames_begin    ; Offset in Bucket 57
	.long	Lset246
.set Lset247, LNames129-Lnames_begin    ; Offset in Bucket 57
	.long	Lset247
.set Lset248, LNames88-Lnames_begin     ; Offset in Bucket 57
	.long	Lset248
.set Lset249, LNames120-Lnames_begin    ; Offset in Bucket 57
	.long	Lset249
.set Lset250, LNames107-Lnames_begin    ; Offset in Bucket 58
	.long	Lset250
.set Lset251, LNames52-Lnames_begin     ; Offset in Bucket 58
	.long	Lset251
.set Lset252, LNames33-Lnames_begin     ; Offset in Bucket 58
	.long	Lset252
.set Lset253, LNames124-Lnames_begin    ; Offset in Bucket 58
	.long	Lset253
.set Lset254, LNames62-Lnames_begin     ; Offset in Bucket 59
	.long	Lset254
.set Lset255, LNames125-Lnames_begin    ; Offset in Bucket 59
	.long	Lset255
.set Lset256, LNames83-Lnames_begin     ; Offset in Bucket 60
	.long	Lset256
.set Lset257, LNames126-Lnames_begin    ; Offset in Bucket 60
	.long	Lset257
.set Lset258, LNames57-Lnames_begin     ; Offset in Bucket 61
	.long	Lset258
.set Lset259, LNames39-Lnames_begin     ; Offset in Bucket 62
	.long	Lset259
.set Lset260, LNames60-Lnames_begin     ; Offset in Bucket 62
	.long	Lset260
.set Lset261, LNames73-Lnames_begin     ; Offset in Bucket 62
	.long	Lset261
.set Lset262, LNames50-Lnames_begin     ; Offset in Bucket 64
	.long	Lset262
.set Lset263, LNames68-Lnames_begin     ; Offset in Bucket 64
	.long	Lset263
LNames35:
	.long	571                             ; Inspect_apply_676ec9e417566a851359c2c6d5d5332f7d40742f8274a8672f3cad244846
	.long	1                               ; Num DIEs
	.long	238
	.long	0
LNames5:
	.long	1646                            ; Inspect_toStr_7cfa03e91e0ec9327f388a68dbd26ae2735e7e95165f9e519543e02299bee9
	.long	1                               ; Num DIEs
	.long	630
	.long	0
LNames118:
	.long	895                             ; Inspect_dbgWrite_fc336bd1cd3ebaf6eb15720d63e6c19ad363d38ae324f70134d53791b44e
	.long	1                               ; Num DIEs
	.long	350
	.long	0
LNames7:
	.long	3027                            ; _73_c919149ababf2a569c5e2b164c2465c785dc3bc7f566b8dcef7ec4ae86e8d57
	.long	1                               ; Num DIEs
	.long	1134
	.long	0
LNames1:
	.long	1950                            ; Task_35_3899d549ca6f5b7757a69b861e0c9a44bfbbd717ac2039f8ca1abc46d7d32e
	.long	1                               ; Num DIEs
	.long	742
	.long	0
LNames48:
	.long	3798                            ; Task_err_72f11ea62bc2627ca7ca9959232e519a82934c5e521930f57f3646c32591
	.long	1                               ; Num DIEs
	.long	1470
	.long	0
LNames23:
	.long	7350                            ; List_isEmpty_54b3c6d264e7c557f2fe74ef29431163e9a30a2e4aca38b681d4b9ee62de031
	.long	1                               ; Num DIEs
	.long	2758
	.long	0
LNames85:
	.long	2094                            ; PlatformTasks_stdoutLine_4dcdd9fc1c563c9592918682f5bb9bfbff249c75cdcf934a994231c5c3a018
	.long	1                               ; Num DIEs
	.long	798
	.long	0
LNames113:
	.long	1209                            ; Str_concat_e6845638e158b704aa8395d259110713932beb5d7a34137f5739ba7e3dd198
	.long	1                               ; Num DIEs
	.long	462
	.long	0
LNames56:
	.long	3095                            ; Num_addWrap_e84248fb50d0833361d0417df114b0b3b3448fff97c39cdde963b09a9aebb8
	.long	1                               ; Num DIEs
	.long	1162
	.long	0
LNames79:
	.long	7779                            ; decrement_refcounted_ptr_8
	.long	1                               ; Num DIEs
	.long	2926
	.long	0
LNames44:
	.long	6618                            ; Inspect_apply_4afec3b1b615e34b46f852dc4576722a03d82d96cc27deb38d7b350ecaf31
	.long	1                               ; Num DIEs
	.long	2478
	.long	0
LNames58:
	.long	2321                            ; PlatformTasks_task_closure_stdoutLine_e8e3cb4c459a1e25c7bed4d87759a21ad8b1f9ce7dd1dd4beba947ebadfffae4
	.long	1                               ; Num DIEs
	.long	882
	.long	0
LNames9:
	.long	2424                            ; Inspect_dbgInit_3bbacd33228bca14fe5573efe7278cde33c78fe9028ba98810cff368dece
	.long	1                               ; Num DIEs
	.long	910
	.long	0
LNames74:
	.long	347                             ; Inspect_206_11922f5e717257e3c76632973ee406cbf106889cd4e80e37d14c1d9c194671
	.long	1                               ; Num DIEs
	.long	154
	.long	0
LNames8:
	.long	3636                            ; Inspect_250_6bc1e748a2edd5eacd7f49eb7476d47387e76d8e94fcfcf34a1d5a6fa86e
	.long	1                               ; Num DIEs
	.long	1414
	.long	0
LNames90:
	.long	1566                            ; Stdout_handleErr_539d94cac9151288c18279a5f1573e8d65d66aeb5922fa6ed8cbc577893894
	.long	1                               ; Num DIEs
	.long	602
	.long	0
LNames110:
	.long	973                             ; Inspect_dbgStr_d394208415ac8fe0ce8aa0ddf6a845c7cc74d818698e3d25c85705ce311f5ec
	.long	1                               ; Num DIEs
	.long	378
	.long	0
LNames105:
	.long	4852                            ; Inspect_272_4fe2c0cee861629d2ef04c3f725dba5813b563598f88e6fe57cefd4dd1a133
	.long	1                               ; Num DIEs
	.long	1862
	.long	0
LNames84:
	.long	6107                            ; Task_53_1dc6f9836252db90e110ad1b5e28c952e1292787deeab71a2a18c14f1d18ec0
	.long	1                               ; Num DIEs
	.long	2282
	.long	0
LNames46:
	.long	4551                            ; List_len_4e123451c288c52798d3df0fc84811d2d957f324242982575c70dfd6d338df
	.long	1                               ; Num DIEs
	.long	1750
	.long	0
LNames102:
	.long	6988                            ; List_len_dc3f621de1221c7c53a19e877c377561ede91cdd88b1a687d310a39785a
	.long	1                               ; Num DIEs
	.long	2618
	.long	0
LNames75:
	.long	2727                            ; Inspect_213_24ce363245042dce6c6647d3662b4b2c84c622d118936f8265c24f93e9d3a2c
	.long	1                               ; Num DIEs
	.long	1022
	.long	0
LNames4:
	.long	1870                            ; Stderr_handleErr_1c44a9ca60e694ea5bce656141adb8728c249dc46543e7c34883c1136ab140
	.long	1                               ; Num DIEs
	.long	714
	.long	0
LNames22:
	.long	2248                            ; Task_onErr_5fea3a382f6b6c4a2af77ea4365b5abbdda8b93d1f0b9b895dc2a48489fb2
	.long	1                               ; Num DIEs
	.long	854
	.long	0
LNames63:
	.long	8264                            ; #Attr_#inc_13
	.long	1                               ; Num DIEs
	.long	3598
	.long	0
LNames45:
	.long	495                             ; List_walkHelp_53eef38977ca9e3af29e8b6fc9f50f557be9bbd173abd2118eb5488f19fb2
	.long	1                               ; Num DIEs
	.long	210
	.long	0
LNames67:
	.long	4236                            ; Stderr_line_1484a21b4257566f7c1b3505e4f6c430eb1121cbfb946b32fb115b90b1ef50
	.long	1                               ; Num DIEs
	.long	1638
	.long	0
LNames111:
	.long	7274                            ; Dict_empty_392aebc0773ca1163ead8eb210e2c2aabca4fe4ded9f2b122a7dab30d082d98b
	.long	1                               ; Num DIEs
	.long	2730
	.long	0
LNames94:
	.long	8065                            ; #Attr_#generic_rc_by_ref_5_dec
	.long	1                               ; Num DIEs
	.long	3466
	.long	0
LNames64:
	.long	8278                            ; #Attr_#inc_15
	.long	1                               ; Num DIEs
	.long	3626
	.long	0
LNames70:
	.long	8250                            ; #Attr_#inc_17
	.long	1                               ; Num DIEs
	.long	3570
	.long	0
LNames16:
	.long	7873                            ; #Attr_#inc_1
	.long	1                               ; Num DIEs
	.long	3052
	.long	0
LNames96:
	.long	4471                            ; Inspect_toDbgStr_9d7544bbc8507265e131f9b42f567d6c54e799c62356103470ba3daf5673a8
	.long	1                               ; Num DIEs
	.long	1722
	.long	0
LNames93:
	.long	646                             ; #Derived_custom3_beb22fad19423347b2aa99b33212e862ded3f83df5d6238acb1a6a9ade3e
	.long	1                               ; Num DIEs
	.long	266
	.long	0
LNames17:
	.long	7860                            ; #Attr_#inc_2
	.long	1                               ; Num DIEs
	.long	3024
	.long	0
LNames98:
	.long	1723                            ; Inspect_210_3d7aff37b23cd9f9e6beb177d8bf818babb9d186ea278cc981a34be43b8cf34
	.long	1                               ; Num DIEs
	.long	658
	.long	0
LNames21:
	.long	7982                            ; #Attr_#inc_3
	.long	1                               ; Num DIEs
	.long	3255
	.long	0
LNames49:
	.long	1052                            ; #Derived_custom2_c610e85212d0697cb161d4ba431ba63f273feee7dcb7927c9ff5d74ae6cbfa3
	.long	1                               ; Num DIEs
	.long	406
	.long	0
LNames19:
	.long	7956                            ; #Attr_#inc_4
	.long	1                               ; Num DIEs
	.long	3199
	.long	0
LNames99:
	.long	3604                            ; roc__mainForHost_1_exposed_size
	.long	1                               ; Num DIEs
	.long	1386
	.long	0
LNames20:
	.long	7969                            ; #Attr_#inc_5
	.long	1                               ; Num DIEs
	.long	3227
	.long	0
LNames80:
	.long	3577                            ; roc__mainForHost_1_exposed
	.long	1                               ; Num DIEs
	.long	1358
	.long	0
LNames100:
	.long	1799                            ; Task_42_dee69d62f6dd2acac17218e148d3d8138e18cca99859936284942954b14b32
	.long	1                               ; Num DIEs
	.long	686
	.long	0
LNames41:
	.long	6465                            ; Task_await_9ddbc9a5a6ab79818cf720ec32ba1aeb5838e37cd919c2ff6b897d7d866d5c7
	.long	1                               ; Num DIEs
	.long	2422
	.long	0
LNames119:
	.long	2021                            ; Task_67_fea4b522fb116c2bf818212d595291e57cec745699352eecbb7184315f386ce8
	.long	1                               ; Num DIEs
	.long	770
	.long	0
LNames34:
	.long	5796                            ; Inspect_dbgStr_e3211b24ebda6e959f98c8dfabbb8bde232b75ae94930caa03d2bdb8e7b5674
	.long	1                               ; Num DIEs
	.long	2170
	.long	0
LNames77:
	.long	7134                            ; List_len_68697e959be5e5da06cc73b6f998e193cbf2d9b22efd0355a3d37129951b
	.long	1                               ; Num DIEs
	.long	2674
	.long	0
LNames32:
	.long	7899                            ; #Attr_#generic_rc_by_ref_2_dec
	.long	1                               ; Num DIEs
	.long	3151
	.long	0
LNames86:
	.long	5162                            ; Task_mapErr_b7a3f2a8f8a550a8b7d9f583e11fe2d9be1c46afd270ccbd14dc29ab1919b1
	.long	1                               ; Num DIEs
	.long	1974
	.long	0
LNames11:
	.long	4699                            ; Num_subWrap_edaf1bd3d1c2ffcc44df55829c02f262426de2ffbea9be2cdf075ec12c528d
	.long	1                               ; Num DIEs
	.long	1806
	.long	0
LNames2:
	.long	3170                            ; Task_attempt_1fbc6d79b671ab88e8a9425cd46a77344c0f7ee34ea43fdcaf5a014c6759d
	.long	1                               ; Num DIEs
	.long	1190
	.long	0
LNames51:
	.long	115                             ; Inspect_dbgI32_da6b85ec7e1e6f2f01e92f35cc48f7475ea87261d357876fef3f23dc338e
	.long	1                               ; Num DIEs
	.long	70
	.long	0
LNames29:
	.long	3468                            ; _mainForHost_9d949d48d48bd9629a662ead3e2fc9728ebe6544f0834563102ca492bac0
	.long	1                               ; Num DIEs
	.long	1302
	.long	0
LNames89:
	.long	7806                            ; #Attr_#generic_rc_by_ref_1_dec
	.long	1                               ; Num DIEs
	.long	3004
	.long	0
LNames112:
	.long	5237                            ; #Derived_toInspector_[BrokenPipe 0,Interrupted 0,Other 1,OutOfMemory 0,Unsupported 0,WouldBlock 0,WriteZero 0]_f03bf86f79d121cbfd774dec4a65912e99f5f17c33852bbc45e81916e62b53b
	.long	1                               ; Num DIEs
	.long	2002
	.long	0
LNames55:
	.long	5412                            ; Inspect_custom_f0adb8f180253d489b50ac5199522556362f583929ee5e65c919bd9ed2bc82f
	.long	1                               ; Num DIEs
	.long	2030
	.long	0
LNames0:
	.long	4402                            ; Task_err_e9513e158dcaac7638af486f43c35319478d2d67151e75c6ec6cccb6565
	.long	1                               ; Num DIEs
	.long	1694
	.long	0
LNames82:
	.long	7427                            ; Inspect_213_bd5db9a62133a57f3c3971868413d37dfa646aa8a2764e7763fd4ba5b0b0d4
	.long	1                               ; Num DIEs
	.long	2786
	.long	0
LNames15:
	.long	4623                            ; List_isEmpty_99e2ebbd98e8a2a4c7ed9bd71d205d9f7b5d7e7a9ddb68dab65f2ad1c2198b
	.long	1                               ; Num DIEs
	.long	1778
	.long	0
LNames59:
	.long	7502                            ; Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2
	.long	1                               ; Num DIEs
	.long	2814
	.long	0
LNames18:
	.long	4927                            ; Inspect_custom_1149386876d826e56f26fd066413b9c565aa3dea67161e512a9ba24db887d5
	.long	1                               ; Num DIEs
	.long	1890
	.long	0
LNames25:
	.long	6540                            ; Inspect_dbgTag_d1a1e4356bd9fe6c31754def4c60a14042ade1c6c101618179cfd5d1c73189
	.long	1                               ; Num DIEs
	.long	2450
	.long	0
LNames128:
	.long	6320                            ; Set_empty_4c26d916fc42dd8d2a9bd5abfc2993ea3741d5b5db9aa72687bec6b6e3098
	.long	1                               ; Num DIEs
	.long	2366
	.long	0
LNames61:
	.long	422                             ; List_walk_52459ae5e05017996bb4298dd9ac3944ffe997fa2e2ad98ba6fd7348395f63
	.long	1                               ; Num DIEs
	.long	182
	.long	0
LNames91:
	.long	2803                            ; Bool_structuralEq_f57b151e8a6dfbc520c29ccc134c8fb5357cdd96058ecd185f0787f48b7a6
	.long	1                               ; Num DIEs
	.long	1050
	.long	0
LNames71:
	.long	268                             ; Inspect_custom_653de62d66328bd02e166b818cc28fc7f76ad909358c5f3f340dd1c827546c9
	.long	1                               ; Num DIEs
	.long	126
	.long	0
LNames3:
	.long	724                             ; PlatformTasks_task_closure_stderrLine_df662f4854c7c5a297d6c339e28fd51ddc944983db9bc7f012ab2c1c69a52db6
	.long	1                               ; Num DIEs
	.long	294
	.long	0
LNames87:
	.long	2883                            ; Inspect_208_af2554e3880a1c7af81a4c13c1df135146f6cac58d2d046bda16fbd7c23db3
	.long	1                               ; Num DIEs
	.long	1078
	.long	0
LNames78:
	.long	7204                            ; Task_46_56b1edb1daf8df7ae4fb1a2df75794dcef5a427f85ac1fa18ff4bea1e8e00
	.long	1                               ; Num DIEs
	.long	2702
	.long	0
LNames92:
	.long	5954                            ; List_getUnsafe_2cc6e6d3c5a48a76ea218c439d44b6318e7bd267419a22dcb25b258a2c06a
	.long	1                               ; Num DIEs
	.long	2226
	.long	0
LNames47:
	.long	3709                            ; PlatformTasks_stderrLine_aad9a2f5f9418b386cce489a0bac8cb5bba34171864909e4dfec1ea4e26bfb7
	.long	1                               ; Num DIEs
	.long	1442
	.long	0
LNames24:
	.long	6254                            ; _3_12f97a97f61aca488b75d4cbbdb83020191eefe4f33d263875d76e4b447613
	.long	1                               ; Num DIEs
	.long	2338
	.long	0
LNames104:
	.long	2182                            ; _8_8b8e749a7d5dc4035aed2d09b8b4ad59fac5ad694339521a2df23bf1ac35c3
	.long	1                               ; Num DIEs
	.long	826
	.long	0
LNames117:
	.long	3245                            ; Task_67_ca8af06be175497c1986028dec9ff9bde775267ac5c92d6992ca796b5e797c
	.long	1                               ; Num DIEs
	.long	1218
	.long	0
LNames101:
	.long	5875                            ; Inspect_dbgTag_fb7917afe92ebaa35d275cfd557c2b25a5a46452e484a4eb8cac5175c61606d
	.long	1                               ; Num DIEs
	.long	2198
	.long	0
LNames123:
	.long	5730                            ; _11_2c7d993eadf275d994a1f98b824972fece3cfca6b6ac52dd7bb717e1f5753
	.long	1                               ; Num DIEs
	.long	2142
	.long	0
LNames26:
	.long	7766                            ; #Attr_#dec_1
	.long	1                               ; Num DIEs
	.long	2898
	.long	0
LNames72:
	.long	7579                            ; #Derived_toInspector_[Exit 2,StdoutErr 1]_ec2bd03bf86b935fa34d71ad7ebb49f1f10f87d343e521511d8f9e6625620cd
	.long	1                               ; Num DIEs
	.long	2842
	.long	0
LNames27:
	.long	7847                            ; #Attr_#dec_2
	.long	1                               ; Num DIEs
	.long	2976
	.long	0
LNames65:
	.long	7685                            ; Dict_initialShifts_839d816e30d259b7a113479095a2bf4a37efc9c09ed13ea6ca0fa9b9a5ff9
	.long	1                               ; Num DIEs
	.long	2870
	.long	0
LNames28:
	.long	7886                            ; #Attr_#dec_3
	.long	1                               ; Num DIEs
	.long	3080
	.long	0
LNames69:
	.long	8217                            ; #Attr_#generic_rc_by_ref_6_inc_n
	.long	1                               ; Num DIEs
	.long	3542
	.long	0
LNames116:
	.long	3542                            ; roc__mainForHost_1_exposed_generic
	.long	1                               ; Num DIEs
	.long	1330
	.long	0
LNames13:
	.long	7057                            ; List_sortWith_91183c4be76c8c6e9a1aca423ca6b7bdfddc155d7aac337b8db73395e0e64d
	.long	1                               ; Num DIEs
	.long	2646
	.long	0
LNames10:
	.long	6392                            ; Dict_isEmpty_eabc27640eff330d625cb2f6435f5dccaec45dd590ad64015fdca105b70
	.long	1                               ; Num DIEs
	.long	2394
	.long	0
LNames30:
	.long	7930                            ; #Attr_#dec_4
	.long	1                               ; Num DIEs
	.long	3123
	.long	0
LNames12:
	.long	5567                            ; Num_toStr_7f7e162ee4345c12acb2c8dddfd129c8c9ef562ecb31841cfff13d4789ffc2
	.long	1                               ; Num DIEs
	.long	2086
	.long	0
LNames76:
	.long	2958                            ; _10_8c3fdd6849785e1b32106ad9c6ae59845e2314f0a6799376d4e3e3b9be62d181
	.long	1                               ; Num DIEs
	.long	1106
	.long	0
LNames43:
	.long	5005                            ; Inspect_custom_926c4e1deae44cb32fa91b0fc2f966fdf98af98ee562517f2d5df6cc1b8bf0
	.long	1                               ; Num DIEs
	.long	1918
	.long	0
LNames31:
	.long	7943                            ; #Attr_#dec_5
	.long	1                               ; Num DIEs
	.long	3171
	.long	0
LNames37:
	.long	3392                            ; Inspect_210_139c9542137b10e977a775e441e04012cc6d2c98579f3cdeb5fb42ef98df6d6
	.long	1                               ; Num DIEs
	.long	1274
	.long	0
LNames114:
	.long	6694                            ; Num_toStr_f273102d33b910ab8b1eda6e483bb587ec34372c3562cd9bfb68bcf889ba9cd
	.long	1                               ; Num DIEs
	.long	2506
	.long	0
LNames66:
	.long	6917                            ; Task_38_837964ef27185f97a31536069e8f60f59d43cf26aef4e69eeafaab204a51f2
	.long	1                               ; Num DIEs
	.long	2590
	.long	0
LNames54:
	.long	5083                            ; List_walkHelp_99aa979e4a9cadd6dbe48ea878ec84acb7696eb93470c375f6893f1da46c3772
	.long	1                               ; Num DIEs
	.long	1946
	.long	0
LNames38:
	.long	36                              ; Inspect_inspect_e4f9cf3a6c4e3d6be9d05048391b2e3975855fa3e34f66d41fe2c9a84e5c7b
	.long	1                               ; Num DIEs
	.long	42
	.long	0
LNames106:
	.long	3316                            ; Inspect_204_b7c59c3aec44645db91b229c81990d288c86aeb49f116d1eae85e2b9a39999f
	.long	1                               ; Num DIEs
	.long	1246
	.long	0
LNames81:
	.long	191                             ; Inspect_204_50a9b514f5bf5c5ff0dff77dffab9b9f2c8b7084581b52c249d53019289d446b
	.long	1                               ; Num DIEs
	.long	98
	.long	0
LNames14:
	.long	1283                            ; List_walk_078eba49b7090dbd2c6fb82297218e6d2eb88883fa33ff213b919f6e68cc
	.long	1                               ; Num DIEs
	.long	490
	.long	0
LNames127:
	.long	7995                            ; #Attr_#dec_10
	.long	1                               ; Num DIEs
	.long	3283
	.long	0
LNames109:
	.long	2576                            ; Str_isEmpty_cb411178cb7686889a4ee0e4b4c57e63975186dc9f1448b79e94c2721a21a2
	.long	1                               ; Num DIEs
	.long	966
	.long	0
LNames40:
	.long	2651                            ; List_getUnsafe_4a74cf314ac9371a5ea518de15e620d82137397f51a1fa6eff156547f363
	.long	1                               ; Num DIEs
	.long	994
	.long	0
LNames97:
	.long	4774                            ; Bool_structuralEq_cabb163ea8b383114bab450f2ea4bdf6f97d5dc22e57b593db81e3bce47
	.long	1                               ; Num DIEs
	.long	1834
	.long	0
LNames115:
	.long	8009                            ; #Attr_#dec_11
	.long	1                               ; Num DIEs
	.long	3311
	.long	0
LNames53:
	.long	6179                            ; Set_isEmpty_127cb22736133e34b265d61ea1d591a8834a13a1d4a2cb161a40b74f7c37b3
	.long	1                               ; Num DIEs
	.long	2310
	.long	0
LNames95:
	.long	4093                            ; Stdout_line_c852b6d75d2364d70d094699f8a9cda9129d5310ed82ea45564f47a9
	.long	1                               ; Num DIEs
	.long	1582
	.long	0
LNames42:
	.long	4311                            ; Dict_defaultMaxLoadFactor_7a93171d29c34145ace0bed7f158bc6f747d259f21a8119f90767f874eb48b94
	.long	1                               ; Num DIEs
	.long	1666
	.long	0
LNames103:
	.long	4162                            ; Inspect_208_36ded37b63679dfb9096703c22eba74b3449a854bc97ac179ba6ffbbbaa21
	.long	1                               ; Num DIEs
	.long	1610
	.long	0
LNames6:
	.long	3945                            ; Inspect_apply_95dbc324453309f26dee9436b39568cc8bcbe17ef409e9273c4edb58653fd
	.long	1                               ; Num DIEs
	.long	1526
	.long	0
LNames121:
	.long	8023                            ; #Attr_#dec_12
	.long	1                               ; Num DIEs
	.long	3339
	.long	0
LNames36:
	.long	827                             ; Task_38_464ad9696114b8eea8bc3daaaa648b1d3685be4c8d824dbb0c93c169d61
	.long	1                               ; Num DIEs
	.long	322
	.long	0
LNames122:
	.long	8037                            ; #Attr_#dec_13
	.long	1                               ; Num DIEs
	.long	3367
	.long	0
LNames108:
	.long	1133                            ; Inspect_206_f784f33513051f4f09b2b103edd2f576ced88ace36b12d3f4e2a3dbe51fcfeb
	.long	1                               ; Num DIEs
	.long	434
	.long	0
LNames129:
	.long	1354                            ; _7_52aff1341cf42f5e6559a2cf028663f7bbbc7576ac1948fc58784a0613b79
	.long	1                               ; Num DIEs
	.long	518
	.long	0
LNames88:
	.long	8292                            ; #Attr_#generic_copy_by_ref_1
	.long	1                               ; Num DIEs
	.long	3654
	.long	0
LNames120:
	.long	8051                            ; #Attr_#dec_14
	.long	1                               ; Num DIEs
	.long	3395
	.long	0
LNames107:
	.long	5640                            ; Test_calculateMiddleTotal_b5dcd15815911a96b9d7e883b1723ec1e9f2a35835ca79db2284140ebd0aa83
	.long	1                               ; Num DIEs
	.long	2114
	.long	0
LNames52:
	.long	5491                            ; List_isEmpty_76e6e4fef22a778f22804a4a55d5f106b42fb9eadb9eb1f662982e2379174e
	.long	1                               ; Num DIEs
	.long	2058
	.long	0
LNames33:
	.long	1419                            ; #UserApp_main_bae7cba17581e9e24ed8c02e992f1bda9aeff2d299cc1289ddd0dbdf373061
	.long	1                               ; Num DIEs
	.long	546
	.long	0
LNames124:
	.long	8096                            ; #Attr_#dec_15
	.long	1                               ; Num DIEs
	.long	3438
	.long	0
LNames62:
	.long	6838                            ; Inspect_apply_8acb95ddb9a746c2bf4dc0f4f96ce3b3e1f1e4f2559e7641b193db1f161d1c41
	.long	1                               ; Num DIEs
	.long	2562
	.long	0
LNames125:
	.long	8110                            ; #Attr_#dec_16
	.long	1                               ; Num DIEs
	.long	3486
	.long	0
LNames83:
	.long	8124                            ; Test_sorter_ebcdc7d352ecfa1e7d1b4ba0644f3ace5e7298b5a4113365f27eee831460e3a2_compare_wrapper
	.long	1                               ; Num DIEs
	.long	3514
	.long	0
LNames126:
	.long	8321                            ; #Attr_#dec_17
	.long	1                               ; Num DIEs
	.long	3682
	.long	0
LNames57:
	.long	4021                            ; List_len_35bfe7dc6dba25ddadede12999f2a34775468912610779bf675f9c2d81ecac
	.long	1                               ; Num DIEs
	.long	1554
	.long	0
LNames39:
	.long	1496                            ; Task_ok_7f8c4a473141d41efa7657e3f378539f18179e0b2dff0f626f6dce25d295f
	.long	1                               ; Num DIEs
	.long	574
	.long	0
LNames60:
	.long	6031                            ; Inspect_250_92df2e9c67226884f739cd53c0493c2aabaabd406877a3b72a3e676dc54e081
	.long	1                               ; Num DIEs
	.long	2254
	.long	0
LNames73:
	.long	2501                            ; Task_mapErr_78fff63b9d7571652dd558be04af7c0e5b15b7f19efda5bd78185837663f63
	.long	1                               ; Num DIEs
	.long	938
	.long	0
LNames50:
	.long	6768                            ; Num_isLt_669c1355a3e727bb53dd458f2e96e48571aa45dfabcfb4b7de1689484f11
	.long	1                               ; Num DIEs
	.long	2534
	.long	0
LNames68:
	.long	3868                            ; Inspect_custom_bfa1d47a221bdaf089999196bed323c433d1a6b8c78ec612e6fa7b3e3d811
	.long	1                               ; Num DIEs
	.long	1498
	.long	0
	.section	__DWARF,__apple_objc,regular,debug
Lobjc_begin:
	.long	1212240712                      ; Header Magic
	.short	1                               ; Header Version
	.short	0                               ; Header Hash Function
	.long	1                               ; Header Bucket Count
	.long	0                               ; Header Hash Count
	.long	12                              ; Header Data Length
	.long	0                               ; HeaderData Die Offset Base
	.long	1                               ; HeaderData Atom Count
	.short	1                               ; DW_ATOM_die_offset
	.short	6                               ; DW_FORM_data4
	.long	-1                              ; Bucket 0
	.section	__DWARF,__apple_namespac,regular,debug
Lnamespac_begin:
	.long	1212240712                      ; Header Magic
	.short	1                               ; Header Version
	.short	0                               ; Header Hash Function
	.long	1                               ; Header Bucket Count
	.long	0                               ; Header Hash Count
	.long	12                              ; Header Data Length
	.long	0                               ; HeaderData Die Offset Base
	.long	1                               ; HeaderData Atom Count
	.short	1                               ; DW_ATOM_die_offset
	.short	6                               ; DW_FORM_data4
	.long	-1                              ; Bucket 0
	.section	__DWARF,__apple_types,regular,debug
Ltypes_begin:
	.long	1212240712                      ; Header Magic
	.short	1                               ; Header Version
	.short	0                               ; Header Hash Function
	.long	1                               ; Header Bucket Count
	.long	1                               ; Header Hash Count
	.long	20                              ; Header Data Length
	.long	0                               ; HeaderData Die Offset Base
	.long	3                               ; HeaderData Atom Count
	.short	1                               ; DW_ATOM_die_offset
	.short	6                               ; DW_FORM_data4
	.short	3                               ; DW_ATOM_die_tag
	.short	5                               ; DW_FORM_data2
	.short	4                               ; DW_ATOM_type_flags
	.short	11                              ; DW_FORM_data1
	.long	0                               ; Bucket 0
	.long	94768647                        ; Hash in Bucket 0
.set Lset264, Ltypes0-Ltypes_begin      ; Offset in Bucket 0
	.long	Lset264
Ltypes0:
	.long	7837                            ; type_name
	.long	1                               ; Num DIEs
	.long	2969
	.short	36
	.byte	0
	.long	0
.subsections_via_symbols
	.section	__DWARF,__debug_line,regular,debug
Lsection_line:
Lline_table_start0:
